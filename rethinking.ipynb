{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Test No data frame single likelihood](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import *\n",
    "formula = dict(main = 'y~Normal(m,s)',\n",
    "            likelihood = 'm ~  alpha + beta',\n",
    "            prior1 = 's~Exponential(1)',\n",
    "            prior2 = 'alpha ~ Normal(0,1)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')  \n",
    "self = model(formula= formula, float = 16) \n",
    "self.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Test No data frame multiple likelihood](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import *\n",
    "## Model m4.3\n",
    "d = pd.read_csv('./data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "formula = dict(main1 = 'height ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha + beta * weight',\n",
    "            prior1 = 'sigma ~ Uniform(0,50)',\n",
    "            prior2 = 'alpha ~ Normal(178,20)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')    \n",
    "\n",
    "self = model(formula, df = d, float = 32)\n",
    "print('tensor DICT:')\n",
    "print(self.tensor_dict)\n",
    "print('tensor likelihoods:')\n",
    "print(self.main_text)\n",
    "self.fit(observed_data = dict(height =d.height.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "self.summary()\n",
    "\n",
    "# expected \n",
    "#           Mean    StdDev  5.5%    94.5%   a   b   sigma\n",
    "#   a       154.60  0.27    154.17  155.03  1   0   0\n",
    "#   b       0.91    0.04    0.84    0.97    0   1   0\n",
    "#   sigma   5.07    0.19    4.77    5.38    0   0   1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Indices](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model m5.9 \n",
    "from  main import *\n",
    "self = model()\n",
    "self.import_csv('./data/milk.csv', sep = ';')\n",
    "self.df[\"K\"] = self.df[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "self.index(cols = \"clade\")\n",
    "\n",
    "formula = dict(main = 'K ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha[index_clade]',\n",
    "            prior1 = 'alpha~ Normal(0,0.5)',\n",
    "            prior2 = 'sigma ~ Exponential(1)') \n",
    "\n",
    "self.formula(f = formula)\n",
    "self.build_model()\n",
    "self.fit(observed_data = dict(K =self.df.K.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "self.summary()\n",
    "\n",
    "# Expected:\n",
    "#                mean\tsd\t    hdi_5.5%\thdi_94.5%\n",
    "# ape_alpha\t    -0.48\t0.27\t-0.93\t    -0.08\n",
    "# nwm_alpha\t    0.37\t0.22\t0.03\t    0.73\n",
    "# owm_alpha\t    0.65\t0.30\t0.26\t    1.18\n",
    "# strep_alpha\t-0.55\t0.29\t-1.07\t    -0.19\n",
    "# sigma\t        0.83\t0.13\t0.67\t    1.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Model comparaison](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import*\n",
    "# m8.1\n",
    "m = model()\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "# make log version of outcome\n",
    "d['log_gdp'] = np.log(d.rgdppc_2000)\n",
    "# extract countries with GDP data\n",
    "\n",
    "# rescale variables\n",
    "d['log_gdp_std'] = d[\"log_gdp\"].pipe(lambda x: (x / x.mean()) )\n",
    "d['rugged_std'] = d[\"rugged\"].pipe(lambda x: (x / x.max()) )\n",
    "d['rugged_std'] - 0.215\n",
    "d = d.loc[:,['rugged_std','log_gdp_std', 'cont_africa','log_gdp']]\n",
    "d = d.dropna()\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a + b* rugged_std ',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_1 = model(formula, d)\n",
    "\n",
    "m8_1.fit(observed_data = dict(log_gdp_std =d.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_1.summary()\n",
    "\n",
    "#Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a      1.00    0.01    0.98    1.0\n",
    "#b      0.00    0.05    -0.09   0.09\n",
    "#sigma  0.14    0.01    0.12    0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "d[\"log_gdp\"] = d[\"rgdppc_2000\"].pipe(np.log)\n",
    "\n",
    "# extract countries with GDP data\n",
    "dd = d[d[\"rgdppc_2000\"].notnull()].copy()\n",
    "\n",
    "# rescale variables\n",
    "dd[\"log_gdp_std\"] = dd.log_gdp / dd.log_gdp.mean()\n",
    "dd[\"rugged_std\"] = dd.rugged / dd.rugged.max()\n",
    "\n",
    "dd[\"cid\"] = np.where(dd.cont_africa.values == 1, 0, 1)\n",
    "dd[\"cid\"]\n",
    "\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a[cid] + b*rugged_std',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_2= model(formula, dd)\n",
    "m8_2.fit(observed_data = dict(log_gdp_std =dd.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_2.summary()\n",
    "\n",
    "#Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a[1]   0.88    0.02    0.85    0.91\n",
    "#a[2]   1.05    0.01    1.03    1.07\n",
    "#b      -0.05   0.05    -0.12   0.03\n",
    "#sigma  0.11    0.01    0.10    0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8_2.diag_compare({'m8.1': m8_1.trace, 'm8.2': m8_2.trace})\n",
    "#       rank\telpd_loo\tp_loo\t    elpd_diff\tweight\tse\t    dse\t    warning\t    scale\n",
    "#m8.2\t0\t    128.021790\t3.008224\t0.000000\t1.0\t    0.0\t    0.0\t    True\t    log\n",
    "#m8.1\t1\t    95.414886\t2.317650\t32.606903\t0.0\t    0.0\t    0.0\t    True\t    log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Multiple indices](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8.3\n",
    "from main import*\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "d[\"log_gdp\"] = d[\"rgdppc_2000\"].pipe(np.log)\n",
    "\n",
    "# extract countries with GDP data\n",
    "dd = d[d[\"rgdppc_2000\"].notnull()].copy()\n",
    "\n",
    "# rescale variables\n",
    "dd[\"log_gdp_std\"] = dd.log_gdp / dd.log_gdp.mean()\n",
    "dd[\"rugged_std\"] = dd.rugged / dd.rugged.max()\n",
    "\n",
    "dd[\"cid\"] = np.where(dd.cont_africa.values == 1, 0, 1)\n",
    "dd[\"cid\"]\n",
    "\n",
    "\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a[cid] + b[cid]*rugged_std',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_3= model(formula, dd)\n",
    "m8_3.fit(observed_data = dict(log_gdp_std =dd.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_3.summary()\n",
    "\n",
    "# Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a[1]   0.89    0.02    0.86    0.91\n",
    "#a[2]   1.05    0.01    1.03    1.07\n",
    "#b[1]   0.13    0.07    0.01    0.25\n",
    "#b[2]   -0.14   0.05    -0.23    -0.06\n",
    "#sigma  0.11    0.01    0.10    0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[ Categorical interactions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "m8_4 = model(formula, d)\n",
    "m8_4.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_4.summary()\n",
    "#Expected:\n",
    "#       mean   sd       5.5%    94.5%\n",
    "#a      0.36    0.03     0.31    0.41\n",
    "#bw     0.21    0.04     0.15    0.26\n",
    "#bs    -0.11    0.04    -0.17   -0.05\n",
    "#sigma  0.16    0.02     0.12    0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[ Continuous interactions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model m8.3\n",
    "d = pd.read_csv('./data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'bws ~ Normal( 0 , 0.25 ) ',\n",
    "            prior5 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "m8_5 = model(formula, d)\n",
    "m8_5.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_5.summary()\n",
    "\n",
    "# Expected\n",
    "#       mean   sd  5.5% 94.5%\n",
    "#a      0.36 0.02  0.32  0.40\n",
    "#bw     0.21 0.03  0.16  0.25\n",
    "#bs    -0.11 0.03 -0.16 -0.07\n",
    "#bws   -0.14 0.04 -0.20 -0.09\n",
    "#sigma  0.12 0.02  0.10  0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[Binomial model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import*\n",
    "d = pd.read_csv('./data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , logits = p )' ,\n",
    "    likelihood = 'p ~ a' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 10 )'\n",
    ")\n",
    "\n",
    "m11_1 = model(formula, d)\n",
    "m11_1.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m11_1.summary()\n",
    "\n",
    "\n",
    "# expected\n",
    "#  mean   sd 5.5% 94.5%\n",
    "#a 0.32 0.09 0.18  0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[Binomial with index](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Test No data frame single likelihood](#toc1_)    \n",
    "- [Test No data frame multiple likelihood](#toc2_)    \n",
    "- [Indices](#toc3_)    \n",
    "- [Model comparaison](#toc4_)    \n",
    "- [Multiple indices](#toc5_)    \n",
    "- [ Categorical interactions](#toc6_)    \n",
    "- [ Continuous interactions](#toc7_)    \n",
    "- [Binomial model](#toc8_)    \n",
    "- [Binomial with index](#toc9_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:02:56.072068: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 15:02:56.091609: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 15:02:56.091628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 15:02:56.092147: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 15:02:56.095734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 15:02:56.447323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-06 15:02:57.458143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.472779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.472812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.476501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.476532: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.476548: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.680545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.680581: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.680585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-06 15:02:57.680607: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 15:02:57.680625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[2]</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[3]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>3.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[5]</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[6]</th>\n",
       "      <td>1.94</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "b[0] -0.03  0.28     -0.50       0.41\n",
       "b[1]  0.49  0.28      0.04       0.94\n",
       "b[2] -0.37  0.28     -0.84       0.06\n",
       "b[3]  0.39  0.28     -0.03       0.87\n",
       "a[0] -0.46  0.33     -0.96       0.09\n",
       "a[1]  3.88  0.75      2.75       5.09\n",
       "a[2] -0.76  0.34     -1.31      -0.25\n",
       "a[3] -0.77  0.33     -1.31      -0.25\n",
       "a[4] -0.46  0.33     -0.96       0.08\n",
       "a[5]  0.46  0.33     -0.06       1.00\n",
       "a[6]  1.94  0.42      1.29       2.62"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import*\n",
    "d = pd.read_csv('./data/chimpanzees.csv', sep = ';')\n",
    "d.actor = d.actor - 1\n",
    "d[\"treatment\"] = d.prosoc_left + 2 * d.condition\n",
    "d[[\"actor\", \"prosoc_left\", \"condition\", \"treatment\"]]\n",
    "\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial(1 , p )' ,\n",
    "    likelihood = 'p ~ a[actor] + b[treatment]' ,\n",
    "    prior1 = 'a ~ Normal(0,1.5)',\n",
    "    prior2 = 'b ~ Normal(0,0.5)'\n",
    ")\n",
    "m11_4 = model(formula, d, float = 32)\n",
    "m11_4.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m11_4.summary()\n",
    "# Expected\n",
    "#          mean    sd   5.5%    94.5%   n_eff Rhat\n",
    "#a[1]   -0.45    0.32   -0.95    0.04   690 1\n",
    "#a[2]   3.86     0.73   2.78     5.09   1417 1\n",
    "#a[3]   -0.75    0.33   -1.28    -0.23   765 1\n",
    "#a[4]   -0.74    0.33   -1.26    -0.21   887 1\n",
    "#a[5]   -0.44    0.32   -0.94    0.10   743 1\n",
    "#a[6]   0.48     0.32   -0.02    1.00   894 1\n",
    "#a[7]   1.95     0.40   1.32    2.63    882 1\n",
    "#b[1]   -0.04    0.28   -0.51    0.40   669 1\n",
    "#b[2]   0.48     0.28   0.04    0.92    675 1\n",
    "#b[3]   -0.38    0.28   -0.83    0.06    768 1\n",
    "#b[4]   0.37     0.27   -0.07    0.79   666 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
