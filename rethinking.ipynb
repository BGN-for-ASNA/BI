{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test No data frame single likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import *\n",
    "formula = dict(main = 'y~Normal(m,s)',\n",
    "            likelihood = 'm ~  alpha + beta',\n",
    "            prior1 = 's~Exponential(1)',\n",
    "            prior2 = 'alpha ~ Normal(0,1)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')  \n",
    "self = model(formula= formula, float = 16) \n",
    "self.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test No data frame multiple likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import *\n",
    "## Model m4.3\n",
    "d = pd.read_csv('./data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "formula = dict(main1 = 'height ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha + beta * weight',\n",
    "            prior1 = 'sigma ~ Uniform(0,50)',\n",
    "            prior2 = 'alpha ~ Normal(178,20)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')    \n",
    "\n",
    "self = model(formula, df = d, float = 32)\n",
    "print('tensor DICT:')\n",
    "print(self.tensor_dict)\n",
    "print('tensor likelihoods:')\n",
    "print(self.main_text)\n",
    "self.fit(observed_data = dict(height =d.height.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "self.summary()\n",
    "\n",
    "# expected \n",
    "#           Mean    StdDev  5.5%    94.5%   a   b   sigma\n",
    "#   a       154.60  0.27    154.17  155.03  1   0   0\n",
    "#   b       0.91    0.04    0.84    0.97    0   1   0\n",
    "#   sigma   5.07    0.19    4.77    5.38    0   0   1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model m5.9 \n",
    "from  main import *\n",
    "self = model()\n",
    "self.import_csv('./data/milk.csv', sep = ';')\n",
    "self.df[\"K\"] = self.df[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "self.index(cols = \"clade\")\n",
    "\n",
    "formula = dict(main = 'K ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha[index_clade]',\n",
    "            prior1 = 'alpha~ Normal(0,0.5)',\n",
    "            prior2 = 'sigma ~ Exponential(1)') \n",
    "\n",
    "self.formula(f = formula)\n",
    "self.build_model()\n",
    "self.fit(observed_data = dict(K =self.df.K.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "self.summary()\n",
    "\n",
    "# Expected:\n",
    "#                mean\tsd\t    hdi_5.5%\thdi_94.5%\n",
    "# ape_alpha\t    -0.48\t0.27\t-0.93\t    -0.08\n",
    "# nwm_alpha\t    0.37\t0.22\t0.03\t    0.73\n",
    "# owm_alpha\t    0.65\t0.30\t0.26\t    1.18\n",
    "# strep_alpha\t-0.55\t0.29\t-1.07\t    -0.19\n",
    "# sigma\t        0.83\t0.13\t0.67\t    1.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  main import*\n",
    "# m8.1\n",
    "m = model()\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "# make log version of outcome\n",
    "d['log_gdp'] = np.log(d.rgdppc_2000)\n",
    "# extract countries with GDP data\n",
    "\n",
    "# rescale variables\n",
    "d['log_gdp_std'] = d[\"log_gdp\"].pipe(lambda x: (x / x.mean()) )\n",
    "d['rugged_std'] = d[\"rugged\"].pipe(lambda x: (x / x.max()) )\n",
    "d['rugged_std'] - 0.215\n",
    "d = d.loc[:,['rugged_std','log_gdp_std', 'cont_africa','log_gdp']]\n",
    "d = d.dropna()\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a + b* rugged_std ',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_1 = model(formula, d)\n",
    "\n",
    "m8_1.fit(observed_data = dict(log_gdp_std =d.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_1.summary()\n",
    "\n",
    "#Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a      1.00    0.01    0.98    1.0\n",
    "#b      0.00    0.05    -0.09   0.09\n",
    "#sigma  0.14    0.01    0.12    0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "d[\"log_gdp\"] = d[\"rgdppc_2000\"].pipe(np.log)\n",
    "\n",
    "# extract countries with GDP data\n",
    "dd = d[d[\"rgdppc_2000\"].notnull()].copy()\n",
    "\n",
    "# rescale variables\n",
    "dd[\"log_gdp_std\"] = dd.log_gdp / dd.log_gdp.mean()\n",
    "dd[\"rugged_std\"] = dd.rugged / dd.rugged.max()\n",
    "\n",
    "dd[\"cid\"] = np.where(dd.cont_africa.values == 1, 0, 1)\n",
    "dd[\"cid\"]\n",
    "\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a[cid] + b*rugged_std',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_2= model(formula, dd)\n",
    "m8_2.fit(observed_data = dict(log_gdp_std =dd.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_2.summary()\n",
    "\n",
    "#Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a[1]   0.88    0.02    0.85    0.91\n",
    "#a[2]   1.05    0.01    1.03    1.07\n",
    "#b      -0.05   0.05    -0.12   0.03\n",
    "#sigma  0.11    0.01    0.10    0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8_2.diag_compare({'m8.1': m8_1.trace, 'm8.2': m8_2.trace})\n",
    "#       rank\telpd_loo\tp_loo\t    elpd_diff\tweight\tse\t    dse\t    warning\t    scale\n",
    "#m8.2\t0\t    128.021790\t3.008224\t0.000000\t1.0\t    0.0\t    0.0\t    True\t    log\n",
    "#m8.1\t1\t    95.414886\t2.317650\t32.606903\t0.0\t    0.0\t    0.0\t    True\t    log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8.3\n",
    "from main import*\n",
    "d = pd.read_csv('./data/rugged.csv', sep = ';')\n",
    "d[\"log_gdp\"] = d[\"rgdppc_2000\"].pipe(np.log)\n",
    "\n",
    "# extract countries with GDP data\n",
    "dd = d[d[\"rgdppc_2000\"].notnull()].copy()\n",
    "\n",
    "# rescale variables\n",
    "dd[\"log_gdp_std\"] = dd.log_gdp / dd.log_gdp.mean()\n",
    "dd[\"rugged_std\"] = dd.rugged / dd.rugged.max()\n",
    "\n",
    "dd[\"cid\"] = np.where(dd.cont_africa.values == 1, 0, 1)\n",
    "dd[\"cid\"]\n",
    "\n",
    "\n",
    "formula = dict(\n",
    "    main = 'log_gdp_std ~ Normal( mu , sigma ) ',\n",
    "    likelihood = 'mu ~ a[cid] + b[cid]*rugged_std',\n",
    "    prior1 = 'a ~ Normal( 1 , 0.1  )' ,\n",
    "    prior2 = 'b ~ Normal( 0 , 0.3 )' ,\n",
    "    prior3 = 'sigma ~ Exponential( 1 )'\n",
    ")\n",
    "\n",
    "m8_3= model(formula, dd)\n",
    "m8_3.fit(observed_data = dict(log_gdp_std =dd.log_gdp_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_3.summary()\n",
    "\n",
    "# Expected:\n",
    "#       mean    sd      5.5%    94.5%\n",
    "#a[1]   0.89    0.02    0.86    0.91\n",
    "#a[2]   1.05    0.01    1.03    1.07\n",
    "#b[1]   0.13    0.07    0.01    0.25\n",
    "#b[2]   -0.14   0.05    -0.23    -0.06\n",
    "#sigma  0.11    0.01    0.10    0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Categorical interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "m8_4 = model(formula, d)\n",
    "m8_4.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_4.summary()\n",
    "#Expected:\n",
    "#       mean   sd       5.5%    94.5%\n",
    "#a      0.36    0.03     0.31    0.41\n",
    "#bw     0.21    0.04     0.15    0.26\n",
    "#bs    -0.11    0.04    -0.17   -0.05\n",
    "#sigma  0.16    0.02     0.12    0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Continuous interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model m8.3\n",
    "d = pd.read_csv('./data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'bws ~ Normal( 0 , 0.25 ) ',\n",
    "            prior5 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "m8_5 = model(formula, d)\n",
    "m8_5.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m8_5.summary()\n",
    "\n",
    "# Expected\n",
    "#       mean   sd  5.5% 94.5%\n",
    "#a      0.36 0.02  0.32  0.40\n",
    "#bw     0.21 0.03  0.16  0.25\n",
    "#bs    -0.11 0.03 -0.16 -0.07\n",
    "#bws   -0.14 0.04 -0.20 -0.09\n",
    "#sigma  0.12 0.02  0.10  0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import*\n",
    "d = pd.read_csv('./data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , logits = p )' ,\n",
    "    likelihood = 'p ~ a' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 10 )'\n",
    ")\n",
    "\n",
    "m11_1 = model(formula, d)\n",
    "m11_1.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m11_1.summary()\n",
    "\n",
    "\n",
    "# expected\n",
    "#  mean   sd 5.5% 94.5%\n",
    "#a 0.32 0.09 0.18  0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial with index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import*\n",
    "d = pd.read_csv('./data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , p )' ,\n",
    "    likelihood = 'p ~ a[actor] + b[treatment]' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 1.5 )',\n",
    "    prior2 = 'b ~ Normal(0,0.5)'\n",
    ")\n",
    "\n",
    "m11_4 = model(formula, d, float = 32)\n",
    "m11_4.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "m11_4.summary()\n",
    "\n",
    "# Expected\n",
    "#          mean    sd   5.5%    94.5%   n_eff Rhat\n",
    "#a[1]   -0.45    0.32   -0.95    0.04   690 1\n",
    "#a[2]   3.86     0.73   2.78     5.09   1417 1\n",
    "#a[3]   -0.75    0.33   -1.28    -0.23   765 1\n",
    "#a[4]   -0.74    0.33   -1.26    -0.21   887 1\n",
    "#a[5]   -0.44    0.32   -0.94    0.10   743 1\n",
    "#a[6]   0.48     0.32   -0.02    1.00   894 1\n",
    "#a[7]   1.95     0.40   1.32    2.63    882 1\n",
    "#b[1]   -0.04    0.28   -0.51    0.40   669 1\n",
    "#b[2]   0.48     0.28   0.04    0.92    675 1\n",
    "#b[3]   -0.38    0.28   -0.83    0.06    768 1\n",
    "#b[4]   0.37     0.27   -0.07    0.79   666 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pulled_left': 'lambda a, b: tfd.Independent(tfd.Binomial(tf.cast(1.0, dtype = tf.float64),logits =  tf.squeeze(tf.gather(a,tf.cast(df.actor, dtype=tf.int64), axis = -1))+ tf.squeeze(tf.gather(b,tf.cast(df.treatment, dtype=tf.int64), axis = -1)),), reinterpreted_batch_ndims=1)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_4.main_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
