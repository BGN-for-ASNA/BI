{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI output results and speed comparaison\n",
    "## 1. Continuous variable\n",
    "### 1.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import*\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 10:16:46.701691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:16:46.701763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:16:46.701779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:16:46.701897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:16:46.701903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-13 10:16:46.701918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:16:46.701931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5664 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_3:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 2.6304 seconds\n"
     ]
    }
   ],
   "source": [
    "## Model m4.3\n",
    "d = pd.read_csv('/home/sosa/BI//data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "formula = dict(main1 = 'height ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha + beta * weight',\n",
    "            prior1 = 'sigma ~ Uniform(0,50)',\n",
    "            prior2 = 'alpha ~ Normal(178,20)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')    \n",
    "\n",
    "start = tm.time()\n",
    "m4_3 = model(formula, df = d, float = 32)\n",
    "m4_3.fit(observed_data = dict(height =d.height.astype('float32').values),\n",
    "                                           num_results = 500, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)   \n",
    "end = tm.time()    \n",
    "m4_3.summary(round_to = 'none')     \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.3s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_x4ijudci/model_qkflh4ud.stan', line 15, column 20: Argument\n",
      "    20 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_x4ijudci/model_qkflh4ud.stan', line 15, column 14: Argument\n",
      "    178 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_x4ijudci/model_qkflh4ud.stan', line 13, column 23: Argument\n",
      "    50 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning: Your Stan program has a parameter sigma with a lower and upper bound\n",
      "    in its declaration. These hard constraints are not recommended, for two\n",
      "    reasons: (a) Except when there are logical or physical constraints, it is\n",
      "    very unusual for you to be sure that a parameter will fall inside a\n",
      "    specified range, and (b) The infinite gradient induced by a hard\n",
      "    constraint can cause difficulties for Stan's sampling algorithm. As a\n",
      "    consequence, we recommend soft constraints rather than hard constraints;\n",
      "    for example, instead of constraining an elasticity parameter to fall\n",
      "    between 0, and 1, leave it unconstrained and give it a normal(0.5,0.5)\n",
      "    prior distribution.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.8e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.7191 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "nest_asyncio.apply()\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "  vector[346] height;\n",
    "  vector[346] weight;\n",
    "}\n",
    "parameters{\n",
    "  real a;\n",
    "  real<lower=0> b;\n",
    "  real<lower=0,upper=50> sigma;\n",
    "}\n",
    "model{\n",
    "  vector[346] mu;\n",
    "  sigma ~ uniform( 0 , 50 );\n",
    "  b ~ lognormal( 0 , 1 );\n",
    "  a ~ normal( 178 , 20 );\n",
    "  for ( i in 1:346 ) {\n",
    "    mu[i] = a + b* weight[i] ;\n",
    "  }\n",
    "  height ~ normal( mu , sigma );  \n",
    "  \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'height': d.height.values,\n",
    "  'weight': d.weight.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>5.144818</td>\n",
       "      <td>5.142683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.905484</td>\n",
       "      <td>0.904648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>154.653671</td>\n",
       "      <td>154.651727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfp      pystan\n",
       "sigma[0]    5.144818    5.142683\n",
       "beta[0]     0.905484    0.904648\n",
       "alpha[0]  154.653671  154.651727"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m4_3.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df.b.mean(), df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable\n",
    "### 2.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 4.5559 seconds\n"
     ]
    }
   ],
   "source": [
    "m5_9 = model()\n",
    "m5_9.import_csv('../data/milk.csv', sep = ';')\n",
    "m5_9.df[\"K\"] = m5_9.df[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "m5_9.index(cols = \"clade\")\n",
    "formula = dict(main = 'K ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha[index_clade]',\n",
    "            prior1 = 'alpha~ Normal(0,0.5)',\n",
    "            prior2 = 'sigma ~ Exponential(1)') \n",
    "\n",
    "m5_9.f = formula\n",
    "\n",
    "start = tm.time()\n",
    "m5_9.build_model()\n",
    "m5_9.fit(observed_data = dict(K = m5_9.df.K.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.8s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 13.0942 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[29] K;\n",
    "    array[29] int clade_id;\n",
    "}\n",
    "parameters{\n",
    "    vector[4] a;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[29] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 0.5 );\n",
    "    for ( i in 1:29 ) {\n",
    "        mu[i] = a[clade_id[i]];\n",
    "    }\n",
    "    K ~ normal( mu , sigma );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'clade_id': m5_9.df.index_clade.values+1,\n",
    "  'K': m5_9.df.K.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.803290</td>\n",
       "      <td>0.797921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-0.464192</td>\n",
       "      <td>-0.459282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.342569</td>\n",
       "      <td>0.351477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.636661</td>\n",
       "      <td>0.644489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>-0.548822</td>\n",
       "      <td>-0.559232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.803290  0.797921\n",
       "alpha[0] -0.464192 -0.459282\n",
       "alpha[1]  0.342569  0.351477\n",
       "alpha[2]  0.636661  0.644489\n",
       "alpha[3] -0.548822 -0.559232"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m5_9.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)\n",
    "### 3.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_5:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__3` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__4` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 7.8796 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('../data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'bws ~ Normal( 0 , 0.25 ) ',\n",
    "            prior5 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "start = tm.time()\n",
    "m8_5 = model(formula, d)\n",
    "m8_5.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_z9a2w5bq/model_epcjb2i5.stan', line 26, column 4 to column 38)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 2.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_z9a2w5bq/model_epcjb2i5.stan', line 26, column 4 to column 38)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 2.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 0.4508 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[27] blooms_std;\n",
    "    array[27] int shade_cent;\n",
    "    array[27] int water_cent;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real bw;\n",
    "    real bs;\n",
    "    real bws;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[27] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    bws ~ normal( 0 , 0.25 );\n",
    "    bs ~ normal( 0 , 0.25 );\n",
    "    bw ~ normal( 0 , 0.25 );\n",
    "    a ~ normal( 0.5 , 0.25 );\n",
    "    for ( i in 1:27 ) {\n",
    "        mu[i] = a + bw * water_cent[i] + bs * shade_cent[i] + bws * water_cent[i] * shade_cent[i];\n",
    "    }\n",
    "\n",
    "    \n",
    "    blooms_std ~ normal( mu , sigma );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'blooms_std' : d[\"blooms_std\"].values,\n",
    "    \"water_cent\": d[\"water_cent\"].values.astype(int),\n",
    "    \"shade_cent\": d[\"shade_cent\"].values.astype(int),\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.143580</td>\n",
       "      <td>0.142830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bws[0]</th>\n",
       "      <td>-0.142295</td>\n",
       "      <td>-0.142159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bw[0]</th>\n",
       "      <td>0.205505</td>\n",
       "      <td>0.206085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs[0]</th>\n",
       "      <td>-0.112597</td>\n",
       "      <td>-0.113380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.357749</td>\n",
       "      <td>0.358612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.143580  0.142830\n",
       "bws[0]   -0.142295 -0.142159\n",
       "bw[0]     0.205505  0.206085\n",
       "bs[0]    -0.112597 -0.113380\n",
       "a[0]      0.357749  0.358612"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m8_5.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['bws'].mean(), df['bw'].mean(), df['bs'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial model\n",
    "### 4.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 10:13:29.004995: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:13:29.005080: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:13:29.005096: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:13:29.005287: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:13:29.005300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-13 10:13:29.005325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:13:29.005343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5664 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_1:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function run_modelH at 0x7f1b6d744280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "BI took: 1.8334 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , logits = p )' ,\n",
    "    likelihood = 'p ~ a' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 10 )'\n",
    ")\n",
    "start = tm.time()\n",
    "m11_1 = model(formula, d)\n",
    "m11_1.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 500, num_burnin_steps=500, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 10.6s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 4e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 10.8129 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    a ~ normal( 0 , 10 );\n",
    "    p = a;\n",
    "    p = inv_logit(p);\n",
    "    pulled_left ~ binomial( 1 , p );    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.323562</td>\n",
       "      <td>0.321279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "a[0]  0.323562  0.321279"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices\n",
    "### 5.1.Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 10:15:27.668572: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:15:27.668633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:15:27.668648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:15:27.668941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:15:27.668955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-13 10:15:27.668988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:15:27.669009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5664 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 2.5820 seconds\n"
     ]
    }
   ],
   "source": [
    "from main import*\n",
    "import time as tm\n",
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d.actor = d.actor - 1\n",
    "d[\"treatment\"] = d.prosoc_left + 2 * d.condition\n",
    "d[[\"actor\", \"prosoc_left\", \"condition\", \"treatment\"]]\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial(1 , p )' ,\n",
    "    likelihood = 'p ~ a[actor] + b[treatment]' ,\n",
    "    prior1 = 'a ~ Normal(0, 1.5)',\n",
    "    prior2 = 'b ~ Normal(0, 0.5)'\n",
    ")\n",
    "\n",
    "start = tm.time()\n",
    "m11_4 = model(formula, d, float = 32)\n",
    "m11_4.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 500, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.8s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.9997 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "    array[504] int treatment;\n",
    "    array[504] int actor;\n",
    "}\n",
    "parameters{\n",
    "    vector[7] a;\n",
    "    vector[4] b;\n",
    "}\n",
    "model{\n",
    "    vector[504] p;\n",
    "    b ~ normal( 0 , 0.5 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    pulled_left ~ binomial( 1 , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[504] log_lik;\n",
    "    vector[504] p;\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:504 ) log_lik[i] = binomial_lpmf( pulled_left[i] | 1 , p[i] );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int),\n",
    "    'treatment' : d[\"treatment\"].values.astype(int) +1,\n",
    "    'actor' : d[\"actor\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.018401</td>\n",
       "      <td>-0.029877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.480739</td>\n",
       "      <td>0.487075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[2]</th>\n",
       "      <td>-0.393431</td>\n",
       "      <td>-0.376524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[3]</th>\n",
       "      <td>0.346507</td>\n",
       "      <td>0.375007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.442843</td>\n",
       "      <td>-0.457223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>3.867759</td>\n",
       "      <td>3.881077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>-0.750635</td>\n",
       "      <td>-0.760654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.746566</td>\n",
       "      <td>-0.757124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>-0.453323</td>\n",
       "      <td>-0.457064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[5]</th>\n",
       "      <td>0.475934</td>\n",
       "      <td>0.469725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[6]</th>\n",
       "      <td>1.951961</td>\n",
       "      <td>1.954872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "b[0] -0.018401 -0.029877\n",
       "b[1]  0.480739  0.487075\n",
       "b[2] -0.393431 -0.376524\n",
       "b[3]  0.346507  0.375007\n",
       "a[0] -0.442843 -0.457223\n",
       "a[1]  3.867759  3.881077\n",
       "a[2] -0.750635 -0.760654\n",
       "a[3] -0.746566 -0.757124\n",
       "a[4] -0.453323 -0.457064\n",
       "a[5]  0.475934  0.469725\n",
       "a[6]  1.951961  1.954872"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_4.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), df['b.3'].mean(), df['b.4'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean(), df['a.5'].mean(), df['a.6'].mean(), df['a.7'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson\n",
    "### 6.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function run_modelH at 0x7fbfe0508a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "BI took: 11.7549 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/Kline.csv', sep = ';')\n",
    "d[\"P\"] = d.population.pipe(np.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d[\"cid\"] = (d.contact == \"high\").astype(int)\n",
    "d['pLog'] = tf.math.log(d.P).numpy()\n",
    "formula = dict(main = 'total_tools ~ Poisson(log_rate = lambda)',\n",
    "               likelihood = 'lambda ~ alpha[cid] + beta[cid]*P',\n",
    "               prior1 = 'alpha ~ Normal(3,0.5)',\n",
    "               prior2 = 'beta ~ Normal(0,0.2)')\n",
    "start = tm.time()\n",
    "m11_10 = model(formula, d)\n",
    "m11_10.fit(observed_data = dict(total_tools =d.total_tools.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 13.7s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 14.2478 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[10] int T;\n",
    "    vector[10] P;\n",
    "    array[10] int cid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    vector[2] b;\n",
    "}\n",
    "model{\n",
    "    vector[10] lambda;\n",
    "    b ~ normal( 0 , 0.2 );\n",
    "    a ~ normal( 3 , 0.5 );\n",
    "    for ( i in 1:10 ) {\n",
    "       lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "       lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    T ~ poisson( lambda );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[10] log_lik;\n",
    "    vector[10] lambda;\n",
    "    for ( i in 1:10 ) {\n",
    "        lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    for ( i in 1:10 ) log_lik[i] = poisson_lpmf( T[i] | lambda[i]);\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'T' : d[\"total_tools\"].values.astype(int),\n",
    "    'P' : d[\"P\"].values.astype(float),\n",
    "    'cid' : d[\"cid\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.375577</td>\n",
       "      <td>0.377992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>0.192251</td>\n",
       "      <td>0.192584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.321725</td>\n",
       "      <td>3.320130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>3.603758</td>\n",
       "      <td>3.611133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "beta[0]   0.375577  0.377992\n",
       "beta[1]   0.192251  0.192584\n",
       "alpha[0]  3.321725  3.320130\n",
       "alpha[1]  3.603758  3.611133"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_10.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), \n",
    "                   df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial\n",
    "### 7.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 10:10:13.710123: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:10:13.710204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:10:13.710219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:10:13.710446: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:10:13.710459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-13 10:10:13.710479: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 10:10:13.710490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5664 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "BI took: 4.4430 seconds\n"
     ]
    }
   ],
   "source": [
    "from main import*\n",
    "import time as tm\n",
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample((num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample((num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)\n",
    "\n",
    "formula = dict(main = 'y ~ Poisson(rate = lambda)',\n",
    "               likelihood = 'lambda ~ tf.exp(log_days + alpha +  beta * monastery)',\n",
    "               prior1 = 'alpha ~ Normal(0,1)',\n",
    "               prior2 = 'beta ~ Normal(0,1)')\n",
    "start = tm.time()\n",
    "m11_12 = model(formula, d, float=32)\n",
    "m11_12.fit(observed_data = dict(y =d.y.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=1)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "b[0] -0.93  0.30     -1.40      -0.48\n",
       "a[0]  0.29  0.15      0.07       0.54"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.8s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.0326 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[34] int days;\n",
    "    array[34] int y;\n",
    "    array[34] int monastery;\n",
    "    vector[34] log_days;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real b;\n",
    "}\n",
    "model{\n",
    "    vector[34] lambda;\n",
    "    b ~ normal( 0 , 1 );\n",
    "    a ~ normal( 0 , 1 );\n",
    "    for ( i in 1:34 ) {\n",
    "        lambda[i] = log_days[i] + a + b * monastery[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    \n",
    "    y ~ poisson( lambda );    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'days' : d[\"days\"].values.astype(int),\n",
    "    'y' : d[\"y\"].values.astype(int),\n",
    "    'monastery' : d[\"monastery\"].values.astype(int) +1,\n",
    "    'log_days' : d[\"log_days\"].values.astype(float),\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.931697</td>\n",
       "      <td>-0.849008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.294794</td>\n",
       "      <td>1.102113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "b[0] -0.931697 -0.849008\n",
       "a[0]  0.294794  1.102113"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_12.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial\n",
    "TODO : This model can't account for indices in the formula nor varying intercepts of varying effects.\n",
    "### 8.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import pandas as pd\n",
    "from src.main import*\n",
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = tf.nn.softmax(score)\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = np.repeat(np.nan, N)  # empty vector of choices for each individual\n",
    "\n",
    "# sample chosen career for each individual\n",
    "for i in range(N):\n",
    "    career[i] = tfd.Categorical(probs=p).sample()\n",
    "\n",
    "career = career.astype(int)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 13:22:52.357350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:22:52.357402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:22:52.357417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:22:52.357775: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:22:52.357786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-04 13:22:52.357804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:22:52.357820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': \"tfd.Sample(tfd.Normal(0,1, name = 'prior1'), sample_shape = 3)\",\n",
       " 'beta': \"tfd.Sample(tfd.Normal(0,0.5, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = dict(main = 'y ~ Poisson(log_rate = p)',\n",
    "               likelihood = 'p ~ alpha[income] + beta * income',\n",
    "               prior1 = 'alpha ~ Normal(0,1)',\n",
    "               prior2 = 'beta ~ Normal(0, 0.5)')\n",
    "m11_13 = model(formula, d)\n",
    "m11_13.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': \"lambda alpha, beta : tfd.Independent(tfd.Poisson(log_rate= tf.squeeze(tf.gather(alpha,tf.cast(df.income.astype('float32').values, dtype=tf.int32), axis = -1))+beta*df.income.astype('float32').values, name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_13.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.nn.softmax(tf.stack([alpha[0]+beta*1.0,alpha[1]+beta*2.0,0 +beta*2.0], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 13:23:03.781042: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:23:03.781090: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:23:03.781104: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:23:03.781219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:23:03.781225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-04 13:23:03.781238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-04 13:23:03.781251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 4.7173 seconds\n"
     ]
    }
   ],
   "source": [
    "formula = dict(main = 'y ~ Categorical(probs = p, cat = income)',\n",
    "               likelihood = 'p ~ alpha[income] + beta * income',\n",
    "               prior1 = 'alpha ~ Normal(0, 1)',\n",
    "               prior2 = 'beta ~ HalfNormal(0.5)'\n",
    "               )\n",
    "start = tm.time()   \n",
    "m11_13 = model(formula, d)\n",
    "m11_13.fit(observed_data = dict(y =d.career.astype('float32').values), num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': \"tfd.Sample(tfd.Normal(0,1, name = 'prior1'), sample_shape = 2)\",\n",
       " 'beta': \"tfd.Sample(tfd.HalfNormal(0.5, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_13.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': \"lambda alpha, beta : tfd.Independent(tfd.Categorical(probs=tf.nn.softmax(tf.stack([alpha[0]+beta*1.0,alpha[1]+beta*2.0,0 +beta*2.0], axis=1)), name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_13.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5985735], dtype=float32)>,\n",
       " 'alpha': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.17174956, 0.14360788], dtype=float32)>,\n",
       " 'y': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {}\n",
    "m['alpha'] = tfd.Sample(tfd.Normal(0,1, name = 'prior1'), sample_shape = 2)\n",
    "m['beta'] = tfd.Sample(tfd.HalfNormal(0.5, name = 'prior2'), sample_shape = 1)\n",
    "m['y'] = lambda alpha, beta : tfd.Independent(tfd.Categorical(probs=tf.nn.softmax(tf.stack([alpha[0]+beta*1.0, alpha[1]+beta*2.0,0 +beta*2.0], axis=1)), name ='main'), reinterpreted_batch_ndims=1)\n",
    "M = tfd.JointDistributionNamedAutoBatched(m)\n",
    "M.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 00:07&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 8 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "with pm.Model() as m11_13_pm:\n",
    "    a = pm.Normal(\"a\", 0.0, 1.0, shape=2)  # intercepts\n",
    "    b = pm.HalfNormal(\"b\", 0.5)  # association of income with choice\n",
    "\n",
    "    s0 = a[0] + b * income[0]\n",
    "    s1 = a[1] + b * income[1]\n",
    "    s2 = 0.0 + b * income[2]  # pivoting the intercept for the third category\n",
    "    s = pm.math.stack([s0, s1, s2])\n",
    "\n",
    "    p_ = pm.math.softmax(s)\n",
    "    career_obs = pm.Categorical(\"career\", p=p_, observed=career)\n",
    "\n",
    "    trace_11_13 = pm.sample(tune=2000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 0.5682 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    int N; // number of individuals\n",
    "    int K; // number of possible careers\n",
    "    array[N] int career; // outcome\n",
    "    vector[K] career_income;\n",
    "}\n",
    "parameters{\n",
    "    vector[K-1] a; // intercepts\n",
    "    real<lower=0> b; // association of income with choice\n",
    "}\n",
    "model{\n",
    "    vector[K] p;\n",
    "    vector[K] s;\n",
    "    a ~ normal( 0 , 1 );\n",
    "    b ~ normal( 0 , 0.5 );\n",
    "    s[1] = a[1] + b*career_income[1];\n",
    "    s[2] = a[2] + b*career_income[2];\n",
    "    s[3] = 0; // pivot\n",
    "    p = softmax( s );\n",
    "    career ~ categorical( p );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'N' : 500,\n",
    "    'K' : 3,\n",
    "    'career' : d[\"career\"].values.astype(int) + 1,\n",
    "    'career_income' : d[\"income\"].unique().astype(int).tolist(),\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_210862/3955049630.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"pymc\": [tmp[2], tmp[0], tmp[1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "      <th>pymc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.563190</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-1.493981</td>\n",
       "      <td>-2.332273</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>-1.493982</td>\n",
       "      <td>-1.601035</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan  pymc\n",
       "beta[0]   0.563190  0.059036  0.45\n",
       "alpha[0] -1.493981 -2.332273 -0.29\n",
       "alpha[1] -1.493982 -1.601035 -0.16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = az.summary(trace_11_13, round_to=2)['mean']\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_13.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b'].mean(), df['a.1'].mean(), df['a.2'].mean()],\n",
    "        \"pymc\": [tmp[2], tmp[0], tmp[1]]\n",
    "    })\n",
    "# It seems that beta should be 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial\n",
    "### 9.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:31:42.302331: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-08 14:31:42.322643: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-08 14:31:42.322667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-08 14:31:42.323262: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-08 14:31:42.327869: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 14:31:42.725397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-08 14:31:44.053254: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.4995 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:31:44.071293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.071326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.212103: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.212212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.212218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-08 14:31:44.212243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.212258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5271 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-04-08 14:31:44.218678: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.218714: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.218732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.218842: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.218855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.218866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.219005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.219011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-08 14:31:44.219025: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 14:31:44.219033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5271 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/UCBadmit.csv', sep = ';')\n",
    "d[\"gid\"] = (d[\"applicant.gender\"] != \"male\").astype(int)\n",
    "len(d.applications)\n",
    "formula = dict(main = 'y ~ BetaBinomial(applications, concentration1 = pbar*theta, concentration0 = (1 - pbar) * theta)',\n",
    "               likelihood = 'pbar ~ sigmoid(alpha[gid])',\n",
    "               likelihood2 = 'theta ~ phi + 2.0',\n",
    "               prior1 = 'alpha ~ Normal(0.,1.5)',\n",
    "               prior2 = 'phi ~ Exponential(1)'\n",
    "               )\n",
    "start = tm.time()\n",
    "m12_1 = model(formula, d)\n",
    "#m12_1.fit(observed_data = dict(y =d.admit.astype('float32').values),\n",
    "#                                           num_results = 1000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': \"tfd.Sample(tfd.Normal(0.,1.5, name = 'prior1'), sample_shape = 2)\",\n",
       " 'phi': \"tfd.Sample(tfd.Exponential(1, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m12_1.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': \"lambda alpha, phi : tfd.Independent(tfd.BetaBinomial(df.applications.astype('float32').values,concentration1=tf.sigmoid( tf.squeeze(tf.gather(alpha,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1)))*phi+2.0,concentration0=(1-tf.sigmoid( tf.squeeze(tf.gather(alpha,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1))))*phi+2.0, name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m12_1.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[2] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[2] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 1.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[2] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 1.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: First prior sample size parameter[2] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[1] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 0.5019 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[12] int N;\n",
    "    array[12] int A;\n",
    "    array[12] int gid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    real<lower=0> phi;\n",
    "}\n",
    "transformed parameters{\n",
    "    real theta;\n",
    "    theta = phi + 2;\n",
    "}\n",
    "model{\n",
    "    vector[12] pbar;\n",
    "    phi ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:12 ) {\n",
    "        pbar[i] = a[gid[i]];\n",
    "        pbar[i] = inv_logit(pbar[i]);\n",
    "    }\n",
    "    A ~ beta_binomial( N , pbar*theta , (1-pbar)*theta );    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'A' : d[\"admit\"].values.astype(int),\n",
    "    'N' : d[\"applications\"].values.astype(int),\n",
    "    'gid' : d[\"gid\"].values.astype(int) +1,\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phi[0]</th>\n",
       "      <td>-0.844513</td>\n",
       "      <td>1.014828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.549613</td>\n",
       "      <td>-0.440553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.446013</td>\n",
       "      <td>-0.320719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "phi[0]   -0.844513  1.014828\n",
       "alpha[0]  0.549613 -0.440553\n",
       "alpha[1]  0.446013 -0.320719"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['phi'].mean(), df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial\n",
    "### 10.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.read_csv('../data/Kline.csv', sep = ';')\n",
    "#formula = dict(main = 'y ~ BetaBinomial(12,  concentration1 = pbar/phi, concentration0 = g_rate)',\n",
    "#               likelihood1 = 'pbar ~ tf.exp(alpha[gid])*tf.math.pow(beta[gid])/gamma',\n",
    "#               likelihood2 = 'g_rate ~ 1/phi',\n",
    "#               prior1 = 'alpha ~ Normal(1,1)',\n",
    "#               prior2 = 'beta ~ Exponential(1)',\n",
    "#               prior3 = 'gamma ~ Exponential(1)',\n",
    "#               prior4 = 'phi ~ Exponential(1)',\n",
    "#               )\n",
    "#start = tm.time()\n",
    "#m12_1 = model(formula, d)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the model\n",
    "def model():\n",
    "    m = {}\n",
    "    m['alpha'] = tfp.distributions.Sample(tfp.distributions.Normal(1, 1), sample_shape=2)\n",
    "    m['beta'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=2)\n",
    "    m['gamma'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=1)\n",
    "    m['phi'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=1)\n",
    "    \n",
    "    # Define the distribution 'y' which depends on alpha, beta, gamma, and phi\n",
    "    def y_dist(phi, alpha, beta, gamma):\n",
    "        concentration1 = ((tf.exp(alpha) * beta) / gamma) / phi\n",
    "        concentration0 = 1. / phi\n",
    "        return tfp.distributions.Independent(\n",
    "            tfp.distributions.BetaBinomial(12, concentration1=concentration1, concentration0=concentration0),\n",
    "            reinterpreted_batch_ndims=1)\n",
    "\n",
    "    m['y'] = y_dist\n",
    "    return tfp.distributions.JointDistributionNamedAutoBatched(m)\n",
    "\n",
    "# Sample from the model\n",
    "sampled_values = model().sample(alpha=tf.random.normal((2,)), beta=tfp.distributions.Exponential(rate=1.).sample((2,)), gamma=tfp.distributions.Exponential(rate=1.).sample((1,)), phi=tfp.distributions.Exponential(rate=1.).sample((1,)))\n",
    "\n",
    "print(sampled_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d\n",
    "m = {}\n",
    "m['alpha']= tfd.Sample(tfd.Normal(1,1, name = 'prior1'), sample_shape = 2)\n",
    "m['beta']= tfd.Sample(tfd.Exponential(1, name = 'prior2'), sample_shape = 2)\n",
    "m['gamma']= tfd.Sample(tfd.Exponential(1, name = 'prior3'), sample_shape = 1)\n",
    "m['phi']= tfd.Sample(tfd.Exponential(1, name = 'prior4'), sample_shape = 1)\n",
    "m['y'] = lambda phi, alpha, beta, gamma : tfd.Independent(\n",
    "    tfd.BetaBinomial(12,\n",
    "                     concentration1=(\n",
    "                         tf.exp(tf.squeeze(tf.gather(alpha,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1)))\n",
    "                         *( tf.math.powtf.squeeze(tf.gather(beta,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1)))\n",
    "                         /gamma)/phi,\n",
    "                     concentration0=(1/phi), name ='main'), reinterpreted_batch_ndims=1)\n",
    "m = tfd.JointDistributionNamedAutoBatched(m)\n",
    "m.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes\n",
    "### 11.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "BI took: 5.2086 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "import random\n",
    "random.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "d = pd.DataFrame(y)\n",
    "formula = dict(main = 'y ~ ZeroInflatedNegativeBinomial(total_count = 365, inflated_loc_logits = p, logits = AL)',\n",
    "               likelihood = \"p ~ ap\",\n",
    "               likelihood2 = \"AL ~ tf.math.log(al)\",\n",
    "               prior1 = 'ap ~ Normal(-1.5 , 1)',\n",
    "               prior2 = 'al ~ Normal(1,0.5)'\n",
    "               )\n",
    "\n",
    "start = tm.time()\n",
    "m12_3 = model()\n",
    "m12_3 = model(formula)       \n",
    "m12_3.fit(observed_data = dict(y = d.iloc[:,0].astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 6.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.63 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.73 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 1.4643 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[365] int y;\n",
    "}\n",
    "parameters{\n",
    "    real ap;\n",
    "    real al;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    real lambda;\n",
    "    al ~ normal( 1 , 0.5 );\n",
    "    ap ~ normal( -1.5 , 1 );\n",
    "    lambda = al;\n",
    "    lambda = exp(lambda);\n",
    "    p = ap;\n",
    "    p = inv_logit(p);\n",
    "    for ( i in 1:365 ) {\n",
    "        if ( y[i]==0 )\n",
    "            target += log_mix( p , 0 , poisson_lpmf(0|lambda) );\n",
    "        if ( y[i] > 0 )\n",
    "            target += log1m( p ) + poisson_lpmf(y[i] | lambda );\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'y' :d.iloc[:,0].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ap[0]</th>\n",
       "      <td>-0.536237</td>\n",
       "      <td>-1.370638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al[0]</th>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.104704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfp    pystan\n",
       "ap[0] -0.536237 -1.370638\n",
       "al[0]  0.012864  0.104704"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_3.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['ap'].mean(), df['al'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Varying interceps\n",
    "### 12.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 0.0298 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 15:54:43.655730: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 15:54:43.655986: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 15:54:43.656006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 15:54:43.657012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 15:54:43.657041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-08 15:54:43.657103: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-08 15:54:43.657194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5271 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "import time as tm\n",
    "d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "start = tm.time()   \n",
    "m13_2 = model(formula, d, float=32)\n",
    "#m13_2.fit(observed_data = dict(y =d.#.astype('float32').values), num_chains= 4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 'lambda a_bar, sigma: tfd.Sample(tfd.Normal(a_bar,sigma), sample_shape = 48)',\n",
       " 'a_bar': \"tfd.Sample(tfd.Normal(0.,1.5, name = 'prior1'), sample_shape = 1)\",\n",
       " 'sigma': \"tfd.Sample(tfd.Exponential(1, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m13_2.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': \"lambda alpha : tfd.Independent(tfd.Binomial(total_count= df.density.astype('float32').values,logits= tf.squeeze(tf.gather(alpha,tf.cast(df.tank.astype('float32').values, dtype=tf.int32), axis = -1)), name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m13_2.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.8s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 14.1939 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[48] int N;\n",
    "    array[48] int S;\n",
    "    array[48] int tank;\n",
    "}\n",
    "parameters{\n",
    "    vector[48] a;\n",
    "    real a_bar;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[48] p;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a_bar ~ normal( 0 , 1.5 );\n",
    "    a ~ normal( a_bar , sigma );\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    S ~ binomial( N , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[48] log_lik;\n",
    "    vector[48] p;\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:48 ) log_lik[i] = binomial_lpmf( S[i] | N[i] , p[i] );    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'S' : d['surv'].values.astype(int),\n",
    "    'N' : d['density'].values.astype(int),\n",
    "    'tank' : d['tank'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>1.582260</td>\n",
       "      <td>1.621539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_bar[0]</th>\n",
       "      <td>1.328517</td>\n",
       "      <td>1.345123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 0]</th>\n",
       "      <td>2.148721</td>\n",
       "      <td>2.140623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 1]</th>\n",
       "      <td>3.079518</td>\n",
       "      <td>3.075581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 2]</th>\n",
       "      <td>1.016805</td>\n",
       "      <td>0.997040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 3]</th>\n",
       "      <td>3.192842</td>\n",
       "      <td>3.067604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 4]</th>\n",
       "      <td>2.127380</td>\n",
       "      <td>2.138858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 5]</th>\n",
       "      <td>2.157298</td>\n",
       "      <td>2.146644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 6]</th>\n",
       "      <td>3.008012</td>\n",
       "      <td>3.069126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 7]</th>\n",
       "      <td>2.075862</td>\n",
       "      <td>2.131292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 8]</th>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.177990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 9]</th>\n",
       "      <td>2.110499</td>\n",
       "      <td>2.145196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 10]</th>\n",
       "      <td>1.007005</td>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 11]</th>\n",
       "      <td>0.564224</td>\n",
       "      <td>0.578882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 12]</th>\n",
       "      <td>0.966946</td>\n",
       "      <td>1.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 13]</th>\n",
       "      <td>0.192338</td>\n",
       "      <td>0.184045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 14]</th>\n",
       "      <td>2.127514</td>\n",
       "      <td>2.152843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 15]</th>\n",
       "      <td>2.087098</td>\n",
       "      <td>2.130130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 16]</th>\n",
       "      <td>2.834438</td>\n",
       "      <td>2.909044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 17]</th>\n",
       "      <td>2.379401</td>\n",
       "      <td>2.404756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 18]</th>\n",
       "      <td>1.979197</td>\n",
       "      <td>2.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 19]</th>\n",
       "      <td>3.536548</td>\n",
       "      <td>3.670685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 20]</th>\n",
       "      <td>2.407232</td>\n",
       "      <td>2.392812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 21]</th>\n",
       "      <td>2.393023</td>\n",
       "      <td>2.403261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 22]</th>\n",
       "      <td>2.421967</td>\n",
       "      <td>2.403139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 23]</th>\n",
       "      <td>1.719151</td>\n",
       "      <td>1.702271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 24]</th>\n",
       "      <td>-0.995488</td>\n",
       "      <td>-1.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 25]</th>\n",
       "      <td>0.158083</td>\n",
       "      <td>0.162632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 26]</th>\n",
       "      <td>-1.456072</td>\n",
       "      <td>-1.439793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 27]</th>\n",
       "      <td>-0.461049</td>\n",
       "      <td>-0.472672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 28]</th>\n",
       "      <td>0.152583</td>\n",
       "      <td>0.158220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 29]</th>\n",
       "      <td>1.447651</td>\n",
       "      <td>1.444945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 30]</th>\n",
       "      <td>-0.647255</td>\n",
       "      <td>-0.630888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 31]</th>\n",
       "      <td>-0.308502</td>\n",
       "      <td>-0.307811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 32]</th>\n",
       "      <td>3.205485</td>\n",
       "      <td>3.185393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 33]</th>\n",
       "      <td>2.684178</td>\n",
       "      <td>2.712255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 34]</th>\n",
       "      <td>2.688454</td>\n",
       "      <td>2.706410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 35]</th>\n",
       "      <td>2.057781</td>\n",
       "      <td>2.059125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 36]</th>\n",
       "      <td>2.068824</td>\n",
       "      <td>2.054994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 37]</th>\n",
       "      <td>3.834669</td>\n",
       "      <td>3.904811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 38]</th>\n",
       "      <td>2.742415</td>\n",
       "      <td>2.701189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 39]</th>\n",
       "      <td>2.359826</td>\n",
       "      <td>2.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 40]</th>\n",
       "      <td>-1.807387</td>\n",
       "      <td>-1.814108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 41]</th>\n",
       "      <td>-0.566495</td>\n",
       "      <td>-0.572653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 42]</th>\n",
       "      <td>-0.447269</td>\n",
       "      <td>-0.450904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 43]</th>\n",
       "      <td>-0.334382</td>\n",
       "      <td>-0.341859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 44]</th>\n",
       "      <td>0.583905</td>\n",
       "      <td>0.578379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 45]</th>\n",
       "      <td>-0.567013</td>\n",
       "      <td>-0.580085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 46]</th>\n",
       "      <td>2.040790</td>\n",
       "      <td>2.066660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 47]</th>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tfp    pystan\n",
       "sigma[0]      1.582260  1.621539\n",
       "a_bar[0]      1.328517  1.345123\n",
       "alpha[0, 0]   2.148721  2.140623\n",
       "alpha[0, 1]   3.079518  3.075581\n",
       "alpha[0, 2]   1.016805  0.997040\n",
       "alpha[0, 3]   3.192842  3.067604\n",
       "alpha[0, 4]   2.127380  2.138858\n",
       "alpha[0, 5]   2.157298  2.146644\n",
       "alpha[0, 6]   3.008012  3.069126\n",
       "alpha[0, 7]   2.075862  2.131292\n",
       "alpha[0, 8]  -0.127496 -0.177990\n",
       "alpha[0, 9]   2.110499  2.145196\n",
       "alpha[0, 10]  1.007005  0.999936\n",
       "alpha[0, 11]  0.564224  0.578882\n",
       "alpha[0, 12]  0.966946  1.009545\n",
       "alpha[0, 13]  0.192338  0.184045\n",
       "alpha[0, 14]  2.127514  2.152843\n",
       "alpha[0, 15]  2.087098  2.130130\n",
       "alpha[0, 16]  2.834438  2.909044\n",
       "alpha[0, 17]  2.379401  2.404756\n",
       "alpha[0, 18]  1.979197  2.015801\n",
       "alpha[0, 19]  3.536548  3.670685\n",
       "alpha[0, 20]  2.407232  2.392812\n",
       "alpha[0, 21]  2.393023  2.403261\n",
       "alpha[0, 22]  2.421967  2.403139\n",
       "alpha[0, 23]  1.719151  1.702271\n",
       "alpha[0, 24] -0.995488 -1.001493\n",
       "alpha[0, 25]  0.158083  0.162632\n",
       "alpha[0, 26] -1.456072 -1.439793\n",
       "alpha[0, 27] -0.461049 -0.472672\n",
       "alpha[0, 28]  0.152583  0.158220\n",
       "alpha[0, 29]  1.447651  1.444945\n",
       "alpha[0, 30] -0.647255 -0.630888\n",
       "alpha[0, 31] -0.308502 -0.307811\n",
       "alpha[0, 32]  3.205485  3.185393\n",
       "alpha[0, 33]  2.684178  2.712255\n",
       "alpha[0, 34]  2.688454  2.706410\n",
       "alpha[0, 35]  2.057781  2.059125\n",
       "alpha[0, 36]  2.068824  2.054994\n",
       "alpha[0, 37]  3.834669  3.904811\n",
       "alpha[0, 38]  2.742415  2.701189\n",
       "alpha[0, 39]  2.359826  2.354839\n",
       "alpha[0, 40] -1.807387 -1.814108\n",
       "alpha[0, 41] -0.566495 -0.572653\n",
       "alpha[0, 42] -0.447269 -0.450904\n",
       "alpha[0, 43] -0.334382 -0.341859\n",
       "alpha[0, 44]  0.583905  0.578379\n",
       "alpha[0, 45] -0.567013 -0.580085\n",
       "alpha[0, 46]  2.040790  2.066660\n",
       "alpha[0, 47]  0.012115  0.001912"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m13_2.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma'].mean(), df['a_bar'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(),\n",
    "                   df['a.3'].mean(), df['a.4'].mean(),\n",
    "                   df['a.5'].mean(), df['a.6'].mean(),\n",
    "                   df['a.7'].mean(), df['a.8'].mean(),\n",
    "                   df['a.9'].mean(), df['a.10'].mean(),\n",
    "                   df['a.11'].mean(), df['a.12'].mean(),\n",
    "                   df['a.13'].mean(), df['a.14'].mean(),\n",
    "                   df['a.15'].mean(), df['a.16'].mean(),\n",
    "                   df['a.17'].mean(), df['a.18'].mean(),\n",
    "                   df['a.19'].mean(), df['a.20'].mean(),\n",
    "                   df['a.21'].mean(), df['a.22'].mean(),\n",
    "                   df['a.23'].mean(), df['a.24'].mean(),\n",
    "                   df['a.25'].mean(), df['a.26'].mean(),\n",
    "                   df['a.27'].mean(), df['a.28'].mean(),\n",
    "                   df['a.29'].mean(), df['a.30'].mean(),\n",
    "                   df['a.31'].mean(), df['a.32'].mean(),\n",
    "                   df['a.33'].mean(), df['a.34'].mean(),\n",
    "                   df['a.35'].mean(), df['a.36'].mean(),\n",
    "                   df['a.37'].mean(), df['a.38'].mean(),\n",
    "                   df['a.39'].mean(), df['a.40'].mean(),\n",
    "                   df['a.41'].mean(), df['a.42'].mean(),\n",
    "                   df['a.43'].mean(), df['a.44'].mean(),\n",
    "                   df['a.45'].mean(), df['a.46'].mean(),\n",
    "                   df['a.47'].mean(), df['a.48'].mean()\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying effects\n",
    "### 13.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import*\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = tf.constant([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = tf.constant([[sigma_a ** 2, cov_ab], [cov_ab, sigma_b ** 2]])\n",
    "tf.transpose(tf.reshape(tf.constant([1, 2, 3, 4]), (2, 2)))\n",
    "sigmas = tf.constant([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = tf.constant([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = tf.linalg.tensor_diag(sigmas) @ Rho @ tf.linalg.tensor_diag(sigmas)\n",
    "Sigma\n",
    "N_cafes = 20\n",
    "\n",
    "def build_vary_effects():\n",
    "    _seed = 5\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"vary_effects\")\n",
    "\n",
    "    Mu = tf.constant([a, b])\n",
    "\n",
    "    vary_effects = tfd.MultivariateNormalTriL(\n",
    "        loc=Mu, scale_tril=tf.linalg.cholesky(Sigma)\n",
    "    ).sample((N_cafes,), seed=seed())\n",
    "\n",
    "    return vary_effects\n",
    "\n",
    "vary_effects = build_vary_effects()\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "N_visits = 10\n",
    "afternoon = np.tile(np.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = np.repeat(np.arange(N_cafes), N_visits)\n",
    "\n",
    "def generate_data_frame():\n",
    "    sigma = 0.5  # std dev within cafes\n",
    "\n",
    "    _seed = 22\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"generate_data_frame\")\n",
    "\n",
    "    mu = tf.gather(a_cafe, cafe_id) + tf.gather(b_cafe, cafe_id) * afternoon\n",
    "\n",
    "    wait = tfd.Normal(loc=mu, scale=sigma).sample(seed=seed())\n",
    "    d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))\n",
    "\n",
    "    return d\n",
    "d = generate_data_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 16:15:41.300950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 16:15:41.301034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 16:15:41.301051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 16:15:41.301302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 16:15:41.301309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-20 16:15:41.301325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 16:15:41.301340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1433 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_6:0\", shape=(1,), dtype=float32)\n",
      "BI took: 13.6313 seconds\n"
     ]
    }
   ],
   "source": [
    "formula = dict(main = 'y ~ Normal(mu, sigma)',\n",
    "likelihood1 = 'mu ~ a_cafe_b_cafe[cafe] + a_cafe_b_cafe[cafe]*afternoon',\n",
    "prior0 = 'a_cafe_b_cafe ~ MultivariateNormalTriL(concat([alpha, beta],axis=-1), LinearOperatorDiag(sigma_alpha_beta).matmul(Rho))',\n",
    "prior1 = 'sigma ~ Exponential(1)',\n",
    "prior2 = 'sigma_alpha_beta ~ Exponential(1)',\n",
    "prior3 = 'alpha ~ Normal(5,2)',\n",
    "prior4 = 'beta ~ Normal(-1,0.5)',\n",
    "prior5 = 'Rho ~ LKJ(2,2)',\n",
    ")\n",
    "\n",
    "start = tm.time()\n",
    "m14_1 = model(formula, d)\n",
    "m14_1.fit(observed_data = dict(y = d.wait.astype('float32').values),num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([alpha,beta],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.427885], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Normal(5,2, name = 'prior3').sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Sample 'SampleMultivariateNormalTriL' batch_shape=[] event_shape=[20, 2] dtype=float32>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rho = tfd.LKJ(2,2, name = 'prior5').sample()\n",
    "sigma_alpha_beta = tfd.Exponential(1).sample(2)\n",
    "alpha = tfd.Normal(5,2, name = 'prior3').sample(1)\n",
    "beta = tfd.Normal(-1,0.5, name = 'prior4').sample(1)\n",
    "tfd.Sample(tfd.MultivariateNormalTriL(tf.concat([alpha,beta],axis=-1),tf.linalg.LinearOperatorDiag(sigma_alpha_beta).matmul(Rho)), sample_shape = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0.36      , -0.04961141, -0.11254194],\n",
       "        [-0.01653714,  0.12      ,  0.02241089],\n",
       "        [-0.01875699,  0.01120544,  0.06      ]],\n",
       "\n",
       "       [[ 0.12      , -0.01653714, -0.03751398],\n",
       "        [-0.03996475,  0.29      ,  0.05415964],\n",
       "        [ 0.04064014, -0.02427846, -0.13      ]],\n",
       "\n",
       "       [[ 0.06      , -0.00826857, -0.01875699],\n",
       "        [ 0.01791523, -0.13      , -0.02427846],\n",
       "        [-0.08128028,  0.04855692,  0.26      ]]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.experimental import jax2tf\n",
    "from jax import numpy as jnp\n",
    "import tensorflow as tf\n",
    "s = tfd.LKJ(3,3).sample()\n",
    "cov = [[ 0.36,  0.12,  0.06],\n",
    "       [ 0.12,  0.29, -0.13],\n",
    "       [ 0.06, -0.13,  0.26]]\n",
    "def f_tf(cov, s):\n",
    "  return tf.linalg.LinearOperatorDiag(cov).matmul(s)\n",
    "\n",
    "f_jax = jax2tf.call_tf(f_tf)\n",
    "f_jax(jnp.array(cov), jnp.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 28.1s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_ybzqyjsi/model_y5f2lzzr.stan', line 18, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.57 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 3.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -8.07097e+09, but Covariance matrix[2,1] = -8.07097e+09 (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 28, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 3.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.8e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6wb7ab_/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 30.2324 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    vector[200] wait;\n",
    "    array[200] int afternoon;\n",
    "    array[200] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[20] b_cafe;\n",
    "    vector[20] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[200] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[20] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:20 ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:200 ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[0]</th>\n",
       "      <td>0.929867</td>\n",
       "      <td>1.008988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[1]</th>\n",
       "      <td>0.277413</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.041695</td>\n",
       "      <td>-1.048060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.648558</td>\n",
       "      <td>3.682503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 0]</th>\n",
       "      <td>2.235871</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 1]</th>\n",
       "      <td>1.804596</td>\n",
       "      <td>-0.636917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 0]</th>\n",
       "      <td>-2.661619</td>\n",
       "      <td>-0.636917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 1]</th>\n",
       "      <td>1.833624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.042303</td>\n",
       "      <td>3.028316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-0.984078</td>\n",
       "      <td>-0.975079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>2.998218</td>\n",
       "      <td>3.105807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.453708</td>\n",
       "      <td>-0.578648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>5.444488</td>\n",
       "      <td>5.393527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-1.824124</td>\n",
       "      <td>-1.720940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>3.765313</td>\n",
       "      <td>3.716519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.154434</td>\n",
       "      <td>-1.108608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.588086</td>\n",
       "      <td>3.616919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-0.950921</td>\n",
       "      <td>-0.987344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>4.014534</td>\n",
       "      <td>4.002456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-1.433165</td>\n",
       "      <td>-1.414968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>2.977923</td>\n",
       "      <td>2.958082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.081331</td>\n",
       "      <td>-1.069877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.285587</td>\n",
       "      <td>3.274751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.563103</td>\n",
       "      <td>-1.579361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>4.087215</td>\n",
       "      <td>4.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-0.576998</td>\n",
       "      <td>-0.493882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>5.399755</td>\n",
       "      <td>5.357402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.623693</td>\n",
       "      <td>-1.526799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>5.465671</td>\n",
       "      <td>5.415930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-2.280972</td>\n",
       "      <td>-2.191029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>2.805156</td>\n",
       "      <td>2.826774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.729691</td>\n",
       "      <td>-0.749428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.207561</td>\n",
       "      <td>3.208065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-1.318694</td>\n",
       "      <td>-1.348136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>4.460339</td>\n",
       "      <td>4.472420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.620131</td>\n",
       "      <td>-1.632526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>3.650996</td>\n",
       "      <td>3.665808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-0.715286</td>\n",
       "      <td>-0.755379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>3.639079</td>\n",
       "      <td>3.616951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-0.874918</td>\n",
       "      <td>-0.810692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>2.551058</td>\n",
       "      <td>2.583677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>0.147807</td>\n",
       "      <td>0.122992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>1.577713</td>\n",
       "      <td>1.608907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>0.101126</td>\n",
       "      <td>0.015986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>4.276358</td>\n",
       "      <td>4.262534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.090469</td>\n",
       "      <td>-1.069588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>3.144829</td>\n",
       "      <td>3.146787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-0.946249</td>\n",
       "      <td>-0.988162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.494182</td>\n",
       "      <td>0.498470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tfp    pystan\n",
       "sigma_alpha_beta[0]   0.929867  1.008988\n",
       "sigma_alpha_beta[1]   0.277413  0.636535\n",
       "beta[0]              -1.041695 -1.048060\n",
       "alpha[0]              3.648558  3.682503\n",
       "Rho[0, 0]             2.235871  1.000000\n",
       "Rho[0, 1]             1.804596 -0.636917\n",
       "Rho[1, 0]            -2.661619 -0.636917\n",
       "Rho[1, 1]             1.833624  1.000000\n",
       "a_cafe_b_cafe[0, 0]   3.042303  3.028316\n",
       "a_cafe_b_cafe[0, 1]  -0.984078 -0.975079\n",
       "a_cafe_b_cafe[1, 0]   2.998218  3.105807\n",
       "a_cafe_b_cafe[1, 1]  -0.453708 -0.578648\n",
       "a_cafe_b_cafe[2, 0]   5.444488  5.393527\n",
       "a_cafe_b_cafe[2, 1]  -1.824124 -1.720940\n",
       "a_cafe_b_cafe[3, 0]   3.765313  3.716519\n",
       "a_cafe_b_cafe[3, 1]  -1.154434 -1.108608\n",
       "a_cafe_b_cafe[4, 0]   3.588086  3.616919\n",
       "a_cafe_b_cafe[4, 1]  -0.950921 -0.987344\n",
       "a_cafe_b_cafe[5, 0]   4.014534  4.002456\n",
       "a_cafe_b_cafe[5, 1]  -1.433165 -1.414968\n",
       "a_cafe_b_cafe[6, 0]   2.977923  2.958082\n",
       "a_cafe_b_cafe[6, 1]  -1.081331 -1.069877\n",
       "a_cafe_b_cafe[7, 0]   3.285587  3.274751\n",
       "a_cafe_b_cafe[7, 1]  -1.563103 -1.579361\n",
       "a_cafe_b_cafe[8, 0]   4.087215  4.072200\n",
       "a_cafe_b_cafe[8, 1]  -0.576998 -0.493882\n",
       "a_cafe_b_cafe[9, 0]   5.399755  5.357402\n",
       "a_cafe_b_cafe[9, 1]  -1.623693 -1.526799\n",
       "a_cafe_b_cafe[10, 0]  5.465671  5.415930\n",
       "a_cafe_b_cafe[10, 1] -2.280972 -2.191029\n",
       "a_cafe_b_cafe[11, 0]  2.805156  2.826774\n",
       "a_cafe_b_cafe[11, 1] -0.729691 -0.749428\n",
       "a_cafe_b_cafe[12, 0]  3.207561  3.208065\n",
       "a_cafe_b_cafe[12, 1] -1.318694 -1.348136\n",
       "a_cafe_b_cafe[13, 0]  4.460339  4.472420\n",
       "a_cafe_b_cafe[13, 1] -1.620131 -1.632526\n",
       "a_cafe_b_cafe[14, 0]  3.650996  3.665808\n",
       "a_cafe_b_cafe[14, 1] -0.715286 -0.755379\n",
       "a_cafe_b_cafe[15, 0]  3.639079  3.616951\n",
       "a_cafe_b_cafe[15, 1] -0.874918 -0.810692\n",
       "a_cafe_b_cafe[16, 0]  2.551058  2.583677\n",
       "a_cafe_b_cafe[16, 1]  0.147807  0.122992\n",
       "a_cafe_b_cafe[17, 0]  1.577713  1.608907\n",
       "a_cafe_b_cafe[17, 1]  0.101126  0.015986\n",
       "a_cafe_b_cafe[18, 0]  4.276358  4.262534\n",
       "a_cafe_b_cafe[18, 1] -1.090469 -1.069588\n",
       "a_cafe_b_cafe[19, 0]  3.144829  3.146787\n",
       "a_cafe_b_cafe[19, 1] -0.946249 -0.988162\n",
       "sigma[0]              0.494182  0.498470"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m14_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),\n",
    "                   df['b'].mean(),df['a'].mean(),\n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),\n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   df['sigma'].mean()]\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
