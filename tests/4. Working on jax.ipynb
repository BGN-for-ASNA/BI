{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 10:00:50.469742: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-20 10:00:50.496721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 10:00:50.496743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 10:00:50.497353: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 10:00:50.502849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 10:00:50.996738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-20 10:00:52.484862: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.503148: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.503188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.684094: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.684133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.684139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-20 10:00:52.684162: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.684176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-03-20 10:00:52.690169: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690385: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690640: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-20 10:00:52.690684: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-20 10:00:52.690699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from src.main import*\n",
    "import time as tm\n",
    "d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "start = tm.time()   \n",
    "m13_2 = model(formula, d, float=32)\n",
    "#m13_2.fit(observed_data = dict(y =d.surv.astype('float32').values), num_chains= 4, num_results=2000)\n",
    "#end = tm.time()    \n",
    "#print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 08:23:40.304893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 08:23:40.304943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 08:23:40.305543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 08:23:40.786388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionSequentialAutoBatched 'JointDistributionSequentialAutoBatched' batch_shape=[] event_shape=[[1], [1], [1, 48], [48]] dtype=[float32, float32, float32, float32]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from src.main_jax import*\n",
    "d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "m13_2 = model(formula, d, float=32)\n",
    "m13_2.tensor_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "@jit\n",
    "def replace_elements(list_of_arrays, index,  replace_array):\n",
    "    # Ensure replace_array is a JAX array\n",
    "    #replace_array = jnp.array(replace_array)\n",
    "\n",
    "    # Create a new list with replaced elements\n",
    "    #new_list = [jnp.where(jnp.isclose(i, index), replace_array, arr)\n",
    "    #            for i, arr in enumerate(list_of_arrays)]\n",
    "    new_list = jnp.empty(len(list_of_arrays))\n",
    "    for i, arr in enumerate(list_of_arrays):\n",
    "        print(i)\n",
    "        print(jnp.all(jnp.isclose(i, index)))\n",
    "        jnp.where(jnp.isclose(i, index), )\n",
    "        if jnp.all(jnp.isclose(i, index)):\n",
    "            print('replace')\n",
    "            new_list[i] =  replace_array\n",
    "        else:\n",
    "            new_list[i] =  list_of_arrays[i]\n",
    "\n",
    "    return new_list\n",
    "replace_elements(init_params, int(2), init_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "Compiling.. :   0%|          | 0/2500 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Running chain 0: 100%|██████████| 2500/2500 [00:01<00:00, 1350.61it/s]\n",
      "Running chain 1: 100%|██████████| 2500/2500 [00:01<00:00, 1351.60it/s]\n",
      "Running chain 2: 100%|██████████| 2500/2500 [00:01<00:00, 1353.77it/s]\n",
      "Running chain 3: 100%|██████████| 2500/2500 [00:01<00:00, 1355.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumpyPro took: 2.0605 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from src.main import*\n",
    "import time as tm\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import lax, random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(4)\n",
    "\n",
    "reedfrogs = pd.read_csv(\"../data/reedfrogs.csv\", sep=\";\")\n",
    "d = reedfrogs\n",
    "d[\"tank\"] = jnp.arange(d.shape[0])\n",
    "\n",
    "dat = dict(S=d.surv.values, N=d.density.values, tank=d.tank.values)\n",
    "\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "def model(tank, N, S):\n",
    "    a_bar = numpyro.sample(\"a_bar\", dist.Normal(0, 1.5))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    a = numpyro.sample(\"a\", dist.Normal(a_bar, sigma), sample_shape=tank.shape)\n",
    "    logit_p = a[tank]\n",
    "    numpyro.sample(\"S\", dist.Binomial(N, logits=logit_p), obs=S)\n",
    "\n",
    "start = tm.time()  \n",
    "m13_2 = MCMC(NUTS(model), num_warmup=500, num_samples=2000, num_chains=4)\n",
    "m13_2.run(random.PRNGKey(0), **dat)\n",
    "end = tm.time()    \n",
    "print(f\"NumpyPro took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF took: 3.3722 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from tensorflow_probability.substrates.jax.distributions import JointDistributionNamedAutoBatched as JDNAB\n",
    "tfd = tfp.distributions\n",
    "d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "# Define the model using JointDistributionNamed\n",
    "m = {}\n",
    "m['alpha'] = lambda a_bar, sigma: tfd.Sample(tfd.Normal(a_bar, sigma), sample_shape=48)\n",
    "m['a_bar'] = tfd.Normal(0., 1.5, name='a_bar')\n",
    "m['sigma'] = tfd.Exponential(1., name='sigma')\n",
    "m['y'] = lambda alpha: tfd.Independent(\n",
    "    tfd.Binomial(\n",
    "        total_count=jnp.array(d.density.values, dtype=jnp.float32),\n",
    "        logits=jnp.squeeze(jnp.take(alpha, jnp.array(jnp.array(d.tank.values, dtype=jnp.float32), dtype=jnp.int32), axis=-1)),\n",
    "        name='main'), reinterpreted_batch_ndims=1)\n",
    "\n",
    "dist = JDNAB(m)\n",
    "\n",
    "observed_data = d.surv.astype('float32').values\n",
    "observed_data_jax = jnp.array(observed_data)  # Convert observed_data to JAX array\n",
    "\n",
    "n_chain = jax.local_device_count()\n",
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init_params = dist.sample(seed=jnp.array(init_key, dtype=jnp.uint32))\n",
    "init_params.pop('y')\n",
    "init_params = list(init_params.values())\n",
    "init_params\n",
    "\n",
    "def target_log_prob(*params):\n",
    "    param_dict = {}\n",
    "    keys = dist._flat_resolve_names()\n",
    "    for i, key in enumerate(keys):\n",
    "        if key != 'y':\n",
    "            param_dict[key] = params[i]\n",
    "    param_dict['y'] = observed_data_jax\n",
    "    return dist.log_prob(param_dict)\n",
    "\n",
    "@jit\n",
    "def run_chain(key, obs_name = 'y'):\n",
    "    init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "    init_params = dist.sample(seed=jnp.array(init_key, dtype=jnp.uint32))\n",
    "    init_params.pop(obs_name)\n",
    "    init_params = list(init_params.values())   \n",
    "\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(target_log_prob, 1e-3)\n",
    "    return tfp.mcmc.sample_chain(2000,\n",
    "                                  current_state=init_params,\n",
    "                                  parallel_iterations = 4,\n",
    "                                  kernel=kernel,\n",
    "                                  trace_fn=lambda _, results: results.target_log_prob,\n",
    "                                  num_burnin_steps=500,\n",
    "                                  seed=key)\n",
    "\n",
    "start = tm.time() \n",
    "states, log_probs = run_chain(sample_key)\n",
    "end = tm.time()    \n",
    "print(f\"TF took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret value of type <class '__main__.test'> as an abstract array; it does not have a dtype attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api_util.py:584\u001b[0m, in \u001b[0;36mshaped_abstractify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_shaped_abstractify_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <class '__main__.test'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m init_key, sample_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     70\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime() \n\u001b[0;32m---> 71\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_chain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api_util.py:575\u001b[0m, in \u001b[0;36m_shaped_abstractify_slow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    573\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x\u001b[38;5;241m.\u001b[39mdtype, allow_extended_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    576\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot interpret value of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as an abstract array; it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not have a dtype attribute\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mShapedArray(np\u001b[38;5;241m.\u001b[39mshape(x), dtype, weak_type\u001b[38;5;241m=\u001b[39mweak_type,\n\u001b[1;32m    579\u001b[0m                         named_shape\u001b[38;5;241m=\u001b[39mnamed_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret value of type <class '__main__.test'> as an abstract array; it does not have a dtype attribute"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from tensorflow_probability.substrates.jax.distributions import JointDistributionNamedAutoBatched as JDNAB\n",
    "tfd = tfp.distributions\n",
    "import random as r\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class test():\n",
    "    def __init__(self, obs_names, observed_data_jax) :\n",
    "        d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "        d[\"tank\"] = np.arange(d.shape[0])\n",
    "        # Define the model using JointDistributionNamed\n",
    "        m = {}\n",
    "        m['alpha'] = lambda a_bar, sigma: tfd.Sample(tfd.Normal(a_bar, sigma), sample_shape=48)\n",
    "        m['a_bar'] = tfd.Normal(0., 1.5, name='a_bar')\n",
    "        m['sigma'] = tfd.Exponential(1., name='sigma')\n",
    "        m['y'] = lambda alpha: tfd.Independent(\n",
    "            tfd.Binomial(\n",
    "                total_count=jnp.array(d.density.values, dtype=jnp.float32),\n",
    "                logits=jnp.squeeze(jnp.take(alpha, jnp.array(jnp.array(d.tank.values, dtype=jnp.float32), dtype=jnp.int32), axis=-1)),\n",
    "                name='main'), reinterpreted_batch_ndims=1)\n",
    "\n",
    "        self.tensor = JDNAB(m)\n",
    "        self.obs_names = obs_names\n",
    "        self.observed_data_jax = observed_data_jax\n",
    "        self.keys = self.tensor._flat_resolve_names()\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def target_log_prob(self, *params):\n",
    "        param_dict = {}\n",
    "        for i, key in enumerate(self.keys):\n",
    "            if key != self.obs_names:\n",
    "                param_dict[key] = params[i]\n",
    "        param_dict[self.obs_names] = self.observed_data_jax\n",
    "        return self.tensor.log_prob(param_dict)\n",
    "\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def run_chain(self, key):        \n",
    "        init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "        init_params = self.tensor.sample(seed=jnp.array(init_key, dtype=jnp.uint32))\n",
    "        init_params.pop(self.obs_names)\n",
    "        init_params = list(init_params.values())   \n",
    "        kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn = self.target_log_prob, step_size = 1e-3)\n",
    "        return tfp.mcmc.sample_chain(2000,\n",
    "                                      current_state=init_params,\n",
    "                                      parallel_iterations = 4,\n",
    "                                      kernel=kernel,\n",
    "                                      trace_fn=lambda _, results: results.target_log_prob,\n",
    "                                      num_burnin_steps=500,\n",
    "                                      seed=key)\n",
    "    \n",
    "    @jit\n",
    "    def parallel_keys(self, n_chains):\n",
    "        return jax.random.split(random.PRNGKey(0), n_chain)\n",
    "    \n",
    "    @jit\n",
    "    def fit(self, n_chain = 4):\n",
    "        #rng_keys = jax.random.split(random.PRNGKey(0), n_chain)\n",
    "        return jax.pmap(self.run_chain)(self.parallel_keys(int(n_chain)))\n",
    "\n",
    "observed_data = d.surv.astype('float32').values\n",
    "observed_data_jax = jnp.array(observed_data)  # Convert observed_data to JAX array\n",
    "m = test(obs_names = 'y', observed_data_jax = observed_data_jax)\n",
    "\n",
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "start = tm.time() \n",
    "res = m.fit(n_chain = 4)\n",
    "end = tm.time()    \n",
    "print(f\"TF took: {end - start:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
