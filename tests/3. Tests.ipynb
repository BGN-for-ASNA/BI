{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI output results and speed comparaison\n",
    "## 1. Continuous variable (model 4.3)\n",
    "### 1.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "__file__\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 13:16:13.553739: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.572328: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.572536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.706443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.706477: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.706481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 13:16:13.706501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.706511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-03-12 13:16:13.710551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710685: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 13:16:13.710886: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 13:16:13.710894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 4.6471 seconds\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from src.main import*\n",
    "## Model m4.3\n",
    "d = pd.read_csv('../data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "formula = dict(main1 = 'height ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha + beta * weight',\n",
    "            prior1 = 'sigma ~ Uniform(0,50)',\n",
    "            prior2 = 'alpha ~ Normal(178,20)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')    \n",
    "\n",
    "self = model(formula, df = d, float = 32)\n",
    "start = tm.time()\n",
    "self.fit(observed_data = dict(height =d.height.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)   \n",
    "end = tm.time()    \n",
    "self.summary(round_to = 'none')     \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.1s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_bzl01w9e/model_qxjp4bwu.stan', line 15, column 20: Argument\n",
      "    20 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_bzl01w9e/model_qxjp4bwu.stan', line 15, column 14: Argument\n",
      "    178 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning in '/tmp/httpstan_bzl01w9e/model_qxjp4bwu.stan', line 13, column 23: Argument\n",
      "    50 suggests there may be parameters that are not unit scale; consider\n",
      "    rescaling with a multiplier (see manual section 22.12).\n",
      "Warning: Your Stan program has a parameter sigma with a lower and upper bound\n",
      "    in its declaration. These hard constraints are not recommended, for two\n",
      "    reasons: (a) Except when there are logical or physical constraints, it is\n",
      "    very unusual for you to be sure that a parameter will fall inside a\n",
      "    specified range, and (b) The infinite gradient induced by a hard\n",
      "    constraint can cause difficulties for Stan's sampling algorithm. As a\n",
      "    consequence, we recommend soft constraints rather than hard constraints;\n",
      "    for example, instead of constraining an elasticity parameter to fall\n",
      "    between 0, and 1, leave it unconstrained and give it a normal(0.5,0.5)\n",
      "    prior distribution.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.7146 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "  vector[346] height;\n",
    "  vector[346] weight;\n",
    "}\n",
    "parameters{\n",
    "  real a;\n",
    "  real<lower=0> b;\n",
    "  real<lower=0,upper=50> sigma;\n",
    "}\n",
    "model{\n",
    "  vector[346] mu;\n",
    "  sigma ~ uniform( 0 , 50 );\n",
    "  b ~ lognormal( 0 , 1 );\n",
    "  a ~ normal( 178 , 20 );\n",
    "  for ( i in 1:346 ) {\n",
    "    mu[i] = a + b* weight[i] ;\n",
    "  }\n",
    "  height ~ normal( mu , sigma );\n",
    "  \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'height': d.height.values,\n",
    "  'weight': d.weight.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>5.138569</td>\n",
       "      <td>5.142233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.905371</td>\n",
       "      <td>0.904922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>154.649124</td>\n",
       "      <td>154.653531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfp      pystan\n",
       "sigma[0]    5.138569    5.142233\n",
       "beta[0]     0.905371    0.904922\n",
       "alpha[0]  154.649124  154.653531"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": self.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df.b.mean(), df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable (model 5.9)\n",
    "### 2.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:41:05.610587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:05.610635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:05.610650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:05.610885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:05.610897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:41:05.610914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:05.610927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 4.2587 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "self = model()\n",
    "self.import_csv('../data/milk.csv', sep = ';')\n",
    "self.df[\"K\"] = self.df[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "self.index(cols = \"clade\")\n",
    "formula = dict(main = 'K ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha[index_clade]',\n",
    "            prior1 = 'alpha~ Normal(0,0.5)',\n",
    "            prior2 = 'sigma ~ Exponential(1)') \n",
    "\n",
    "self.f = formula\n",
    "\n",
    "start = tm.time()\n",
    "self.build_model()\n",
    "self.fit(observed_data = dict(K =self.df.K.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.5s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_wva56780/model_utzoleag.stan', line 17, column 4 to column 29)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 2.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.8828 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[29] K;\n",
    "    array[29] int clade_id;\n",
    "}\n",
    "parameters{\n",
    "    vector[4] a;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[29] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 0.5 );\n",
    "    for ( i in 1:29 ) {\n",
    "        mu[i] = a[clade_id[i]];\n",
    "    }\n",
    "    K ~ normal( mu , sigma );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'clade_id': self.df.index_clade.values+1,\n",
    "  'K': self.df.K.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.797389</td>\n",
       "      <td>0.800678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-0.463416</td>\n",
       "      <td>-0.463840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.348681</td>\n",
       "      <td>0.345072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.633578</td>\n",
       "      <td>0.637753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>-0.550391</td>\n",
       "      <td>-0.546003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.797389  0.800678\n",
       "alpha[0] -0.463416 -0.463840\n",
       "alpha[1]  0.348681  0.345072\n",
       "alpha[2]  0.633578  0.637753\n",
       "alpha[3] -0.550391 -0.546003"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": self.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)\n",
    "### 3.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:41:28.892398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:28.892472: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:28.892486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:28.892659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:28.892672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:41:28.892694: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:28.892709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__2` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__3` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__4` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 7.1625 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'bws ~ Normal( 0 , 0.25 ) ',\n",
    "            prior5 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "start = tm.time()\n",
    "m8_5 = model(formula, d)\n",
    "m8_5.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.3s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_5kkvti7s/model_7gq22chx.stan', line 25, column 4 to column 38)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.7797 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[27] blooms_std;\n",
    "    array[27] int shade_cent;\n",
    "    array[27] int water_cent;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real bw;\n",
    "    real bs;\n",
    "    real bws;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[27] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    bws ~ normal( 0 , 0.25 );\n",
    "    bs ~ normal( 0 , 0.25 );\n",
    "    bw ~ normal( 0 , 0.25 );\n",
    "    a ~ normal( 0.5 , 0.25 );\n",
    "    for ( i in 1:27 ) {\n",
    "        mu[i] = a + bw * water_cent[i] + bs * shade_cent[i] + bws * water_cent[i] * shade_cent[i];\n",
    "    }\n",
    "    \n",
    "    blooms_std ~ normal( mu , sigma );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'blooms_std' : d[\"blooms_std\"].values,\n",
    "    \"water_cent\": d[\"water_cent\"].values.astype(int),\n",
    "    \"shade_cent\": d[\"shade_cent\"].values.astype(int),\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.095120</td>\n",
       "      <td>0.142249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bws[0]</th>\n",
       "      <td>-0.223282</td>\n",
       "      <td>-0.142495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bw[0]</th>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.206738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs[0]</th>\n",
       "      <td>0.078516</td>\n",
       "      <td>-0.112914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.393192</td>\n",
       "      <td>0.358084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.095120  0.142249\n",
       "bws[0]   -0.223282 -0.142495\n",
       "bw[0]     0.010972  0.206738\n",
       "bs[0]     0.078516 -0.112914\n",
       "a[0]      0.393192  0.358084"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m8_5.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['bws'].mean(), df['bw'].mean(), df['bs'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial model\n",
    "### 4.1. Output comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:41:56.291437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:56.291516: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:56.291531: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:56.291699: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:56.291712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:41:56.291734: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:41:56.291746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 3.9502 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , logits = p )' ,\n",
    "    likelihood = 'p ~ a' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 10 )'\n",
    ")\n",
    "start = tm.time()\n",
    "m11_1 = model(formula, d)\n",
    "m11_1.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 9.5s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 9.7943 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    a ~ normal( 0 , 10 );\n",
    "    p = a;\n",
    "    p = inv_logit(p);\n",
    "    pulled_left ~ binomial( 1 , p );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.323123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "a[0]  0.321594  0.323123"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices\n",
    "### 5.1.Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:42:21.132350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:42:21.132419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:42:21.132433: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:42:21.132622: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:42:21.132634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:42:21.132652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:42:21.132663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 6.8511 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/chimpanzees.csv', sep = ';')\n",
    "d.actor = d.actor - 1\n",
    "d[\"treatment\"] = d.prosoc_left + 2 * d.condition\n",
    "d[[\"actor\", \"prosoc_left\", \"condition\", \"treatment\"]]\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial(1 , p )' ,\n",
    "    likelihood = 'p ~ a[actor] + b[treatment]' ,\n",
    "    prior1 = 'a ~ Normal(0, 1.5)',\n",
    "    prior2 = 'b ~ Normal(0, 0.5)'\n",
    ")\n",
    "\n",
    "start = tm.time()\n",
    "m11_4 = model(formula, d, float = 32)\n",
    "m11_4.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.6s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 15.2016 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "    array[504] int treatment;\n",
    "    array[504] int actor;\n",
    "}\n",
    "parameters{\n",
    "    vector[7] a;\n",
    "    vector[4] b;\n",
    "}\n",
    "model{\n",
    "    vector[504] p;\n",
    "    b ~ normal( 0 , 0.5 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    pulled_left ~ binomial( 1 , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[504] log_lik;\n",
    "    vector[504] p;\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:504 ) log_lik[i] = binomial_lpmf( pulled_left[i] | 1 , p[i] );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int),\n",
    "    'treatment' : d[\"treatment\"].values.astype(int) +1,\n",
    "    'actor' : d[\"actor\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.034848</td>\n",
       "      <td>-0.045185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.475208</td>\n",
       "      <td>0.475823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[2]</th>\n",
       "      <td>-0.386461</td>\n",
       "      <td>-0.387507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[3]</th>\n",
       "      <td>0.366866</td>\n",
       "      <td>0.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.444979</td>\n",
       "      <td>-0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>3.917305</td>\n",
       "      <td>3.890319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>-0.739946</td>\n",
       "      <td>-0.744365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.741094</td>\n",
       "      <td>-0.743383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>-0.447257</td>\n",
       "      <td>-0.443050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[5]</th>\n",
       "      <td>0.482430</td>\n",
       "      <td>0.483948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[6]</th>\n",
       "      <td>1.959534</td>\n",
       "      <td>1.965689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "b[0] -0.034848 -0.045185\n",
       "b[1]  0.475208  0.475823\n",
       "b[2] -0.386461 -0.387507\n",
       "b[3]  0.366866  0.364700\n",
       "a[0] -0.444979 -0.443071\n",
       "a[1]  3.917305  3.890319\n",
       "a[2] -0.739946 -0.744365\n",
       "a[3] -0.741094 -0.743383\n",
       "a[4] -0.447257 -0.443050\n",
       "a[5]  0.482430  0.483948\n",
       "a[6]  1.959534  1.965689"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_4.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), df['b.3'].mean(), df['b.4'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean(), df['a.5'].mean(), df['a.6'].mean(), df['a.7'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson\n",
    "### 6.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:43:18.468534: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:43:18.468588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:43:18.468601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:43:18.468813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:43:18.468826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:43:18.468847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:43:18.468859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.6212 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/Kline.csv', sep = ';')\n",
    "d[\"P\"] = d.population.pipe(np.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d[\"cid\"] = (d.contact == \"high\").astype(int)\n",
    "d['pLog'] = tf.math.log(d.P).numpy()\n",
    "formula = dict(main = 'total_tools ~ Poisson(log_rate = lambda)',\n",
    "               likelihood = 'lambda ~ alpha[cid] + beta[cid]*P',\n",
    "               prior1 = 'alpha ~ Normal(3,0.5)',\n",
    "               prior2 = 'beta ~ Normal(0,0.2)')\n",
    "start = tm.time()\n",
    "m11_10 = model(formula, d)\n",
    "m11_10.fit(observed_data = dict(total_tools =d.total_tools.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.8s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 6e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.1948 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[10] int T;\n",
    "    vector[10] P;\n",
    "    array[10] int cid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    vector[2] b;\n",
    "}\n",
    "model{\n",
    "    vector[10] lambda;\n",
    "    b ~ normal( 0 , 0.2 );\n",
    "    a ~ normal( 3 , 0.5 );\n",
    "    for ( i in 1:10 ) {\n",
    "       lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "       lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    T ~ poisson( lambda );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[10] log_lik;\n",
    "    vector[10] lambda;\n",
    "    for ( i in 1:10 ) {\n",
    "        lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    for ( i in 1:10 ) log_lik[i] = poisson_lpmf( T[i] | lambda[i]);\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'T' : d[\"total_tools\"].values.astype(int),\n",
    "    'P' : d[\"P\"].values.astype(float),\n",
    "    'cid' : d[\"cid\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.377117</td>\n",
       "      <td>0.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>0.191245</td>\n",
       "      <td>0.193386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.319345</td>\n",
       "      <td>3.319936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>3.605054</td>\n",
       "      <td>3.609570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "beta[0]   0.377117  0.377000\n",
       "beta[1]   0.191245  0.193386\n",
       "alpha[0]  3.319345  3.319936\n",
       "alpha[1]  3.605054  3.609570"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_10.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), \n",
    "                   df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial\n",
    "### 7.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 09:06:24.196772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 09:06:24.196850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 09:06:24.196869: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 09:06:24.197046: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 09:06:24.197058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 09:06:24.197077: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 09:06:24.197090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.3948 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample((num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample((num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)\n",
    "\n",
    "\n",
    "formula = dict(main = 'y ~ Poisson(log_rate = lambda)',\n",
    "               likelihood = 'lambda ~ log_days + alpha +  beta * monastery',\n",
    "               prior1 = 'alpha ~ Normal(0,1)',\n",
    "               prior2 = 'beta ~ Normal(0,1)')\n",
    "start = tm.time()\n",
    "m11_12 = model(formula, d, float=32)\n",
    "m11_12.fit(observed_data = dict(y =d.y.astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.0s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 7e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.3787 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[34] int days;\n",
    "    array[34] int y;\n",
    "    array[34] int monastery;\n",
    "    vector[34] log_days;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real b;\n",
    "}\n",
    "model{\n",
    "    vector[34] lambda;\n",
    "    b ~ normal( 0 , 1 );\n",
    "    a ~ normal( 0 , 1 );\n",
    "    for ( i in 1:34 ) {\n",
    "        lambda[i] = log_days[i] + a + b * monastery[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    \n",
    "    y ~ poisson( lambda );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'days' : d[\"days\"].values.astype(int),\n",
    "    'y' : d[\"y\"].values.astype(int),\n",
    "    'monastery' : d[\"monastery\"].values.astype(int) +1,\n",
    "    'log_days' : d[\"log_days\"].values.astype(float),\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.015814</td>\n",
       "      <td>-0.904373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.294309</td>\n",
       "      <td>1.150375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "beta[0]  -1.015814 -0.904373\n",
       "alpha[0]  0.294309  1.150375"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_12.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial\n",
    "### 9.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:59:11.428620: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:59:11.428674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:59:11.428687: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:59:11.428890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:59:11.428902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:59:11.428924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:59:11.428939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 3.5001 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "d = pd.read_csv('../data/UCBadmit.csv', sep = ';')\n",
    "d[\"gid\"] = (d[\"applicant.gender\"] != \"male\").astype(int)\n",
    "len(d.applications)\n",
    "formula = dict(main = 'y ~ BetaBinomial(12, concentration1 = pbar, concentration0 = theta)',\n",
    "               likelihood = 'pbar ~ sigmoid(a[gid])',\n",
    "               likelihood2 = 'theta ~ phi + -2.0',\n",
    "               prior1 = 'a ~ Normal(0.,1.5)',\n",
    "               prior2 = 'phi ~ Exponential(1)'\n",
    "               )\n",
    "start = tm.time()\n",
    "m12_1 = model(formula, d)\n",
    "m12_1.fit(observed_data = dict(y =d.admit.astype('float32').values),\n",
    "                                           num_results = 1000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.3s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[1] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 9e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[1] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[2] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[1] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: beta_binomial_lpmf: Second prior sample size parameter[1] is 0, but must be positive finite! (in '/tmp/httpstan_r_32hiex/model_aokd6ccs.stan', line 23, column 4 to column 57)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.7666 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[12] int N;\n",
    "    array[12] int A;\n",
    "    array[12] int gid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    real<lower=0> phi;\n",
    "}\n",
    "transformed parameters{\n",
    "    real theta;\n",
    "    theta = phi + 2;\n",
    "}\n",
    "model{\n",
    "    vector[12] pbar;\n",
    "    phi ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:12 ) {\n",
    "        pbar[i] = a[gid[i]];\n",
    "        pbar[i] = inv_logit(pbar[i]);\n",
    "    }\n",
    "    A ~ beta_binomial( N , pbar*theta , (1-pbar)*theta );    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'A' : d[\"admit\"].values.astype(int),\n",
    "    'N' : d[\"applications\"].values.astype(int),\n",
    "    'gid' : d[\"gid\"].values.astype(int) +1,\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phi[0]</th>\n",
       "      <td>0.515661</td>\n",
       "      <td>1.016125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.249002</td>\n",
       "      <td>-0.437358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>-0.622455</td>\n",
       "      <td>-0.326787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tfp    pystan\n",
       "phi[0]  0.515661  1.016125\n",
       "a[0]    0.249002 -0.437358\n",
       "a[1]   -0.622455 -0.326787"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['phi'].mean(), df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Zero inflated outcomes\n",
    "### 10.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 08:56:24.978128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978175: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978344: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:56:24.978372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-03-12 08:56:24.978641: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978750: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 08:56:24.978767: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 08:56:24.978775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.8690 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "import random\n",
    "random.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "d = pd.DataFrame(y)\n",
    "formula = dict(main = 'y ~ ZeroInflatedNegativeBinomial(total_count = 365, inflated_loc_logits = p, logits = AL)',\n",
    "               likelihood = \"p ~ ap\",\n",
    "               likelihood2 = \"AL ~ tf.math.log(al)\",\n",
    "               prior1 = 'ap ~ Normal(-1.5 , 1)',\n",
    "               prior2 = 'al ~ Normal(1,0.5)'\n",
    "               )\n",
    "\n",
    "start = tm.time()\n",
    "m12_3 = model()\n",
    "m12_3 = model(formula)       \n",
    "m12_3.fit(observed_data = dict(y = d.iloc[:,0].astype('float32').values),\n",
    "                                           num_results = 2000, num_burnin_steps=500, num_adaptation_steps=400, num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 9.8s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.71 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.55 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.2434 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[365] int y;\n",
    "}\n",
    "parameters{\n",
    "    real ap;\n",
    "    real al;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    real lambda;\n",
    "    al ~ normal( 1 , 0.5 );\n",
    "    ap ~ normal( -1.5 , 1 );\n",
    "    lambda = al;\n",
    "    lambda = exp(lambda);\n",
    "    p = ap;\n",
    "    p = inv_logit(p);\n",
    "    for ( i in 1:365 ) {\n",
    "        if ( y[i]==0 )\n",
    "            target += log_mix( p , 0 , poisson_lpmf(0|lambda) );\n",
    "        if ( y[i] > 0 )\n",
    "            target += log1m( p ) + poisson_lpmf(y[i] | lambda );\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'y' :d.iloc[:,0].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ap[0]</th>\n",
       "      <td>-0.687577</td>\n",
       "      <td>-1.352273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al[0]</th>\n",
       "      <td>0.381126</td>\n",
       "      <td>0.111060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfp    pystan\n",
       "ap[0] -0.687577 -1.352273\n",
       "al[0]  0.381126  0.111060"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_3.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['ap'].mean(), df['al'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Varying interceps\n",
    "### 11.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 14:21:58.003696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:21:58.003744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:21:58.003757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:21:58.004107: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:21:58.004120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 14:21:58.004143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:21:58.004156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 4.4995 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "import time as tm\n",
    "d = pd.read_csv('../data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "start = tm.time()   \n",
    "m13_2 = model(formula, d, float=32)\n",
    "num_chains = 4\n",
    "samples = m13_2.sample(num_chains)\n",
    "\n",
    "# Reshape samples to desired shapes\n",
    "samples['a_bar'] = tf.ones(shape=(4,))\n",
    "samples['sigma'] = tf.ones(shape=(4,))\n",
    "samples['alpha'] = tf.ones(shape=(4, 48))\n",
    "\n",
    "observed_data = dict(y =d.surv.astype('float32').values)\n",
    "for k in observed_data.keys():\n",
    "    samples.pop(k)\n",
    "init_state = list(samples.values())\n",
    "init_state\n",
    "\n",
    "m13_2.fit(observed_data = observed_data, num_chains= num_chains, init = init_state, parallel_iterations = 4, \n",
    "          num_leapfrog_steps = 3, num_results = 500, \n",
    "          step_size=0.1)\n",
    "end = tm.time()    \n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")\n",
    "#m13_2 = model(formula, d, float=32)\n",
    "#m = {}\n",
    "#m['a_bar']= tfd.Normal(0.,1.5, name = 'prior1')\n",
    "#m['sigma']= tfd.Exponential(1, name = 'prior2')\n",
    "#m['alpha']= lambda a_bar, sigma: tfd.Sample(tfd.Normal(a_bar,sigma), sample_shape = 48)\n",
    "#m['y']= lambda alpha : tfd.Independent(tfd.Binomial(total_count= d.density.astype('float32').values,logits= tf.squeeze(tf.gather(alpha,tf.cast(d.tank.astype('float32').values, dtype=tf.int32), axis = -1)), name ='main'), reinterpreted_batch_ndims=1)\n",
    "#\n",
    "#m13_2.tensor = tfd.JointDistributionNamed(m)\n",
    "#m13_2.fit(observed_data = observed_data, num_chains= 4, parallel_iterations = 4, \n",
    "#          num_leapfrog_steps = 3, num_results = 500, \n",
    "#          step_size=0.1)\n",
    "#\n",
    "#m13_2 = model(formula, d, float=32)\n",
    "#m = {}\n",
    "#m['a_bar']= tfd.Normal(0.,1.5, name = 'prior1')\n",
    "#m['sigma']= tfd.Exponential(1, name = 'prior2')\n",
    "#m['alpha']= lambda a_bar, sigma: tfd.Sample(tfd.Normal(a_bar,sigma), sample_shape = 48)\n",
    "#m['y']= lambda alpha : tfd.Independent(tfd.Binomial(total_count= d.density.astype('float32').values,logits= alpha, name ='main'), reinterpreted_batch_ndims=1)\n",
    "#\n",
    "#m13_2.tensor = tfd.JointDistributionNamed(m)\n",
    "#m13_2.fit(observed_data = observed_data, num_chains= 4, parallel_iterations = 4, \n",
    "#          num_leapfrog_steps = 3, num_results = 500, \n",
    "#          step_size=0.1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.7s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_o89kziwc/model_4vp4dja7.stan', line 16, column 4 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 1.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 14.1654 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[48] int N;\n",
    "    array[48] int S;\n",
    "    array[48] int tank;\n",
    "}\n",
    "parameters{\n",
    "    vector[48] a;\n",
    "    real a_bar;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[48] p;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a_bar ~ normal( 0 , 1.5 );\n",
    "    a ~ normal( a_bar , sigma );\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    S ~ binomial( N , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[48] log_lik;\n",
    "    vector[48] p;\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:48 ) log_lik[i] = binomial_lpmf( S[i] | N[i] , p[i] );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'S' : d['surv'].values.astype(int),\n",
    "    'N' : d['density'].values.astype(int),\n",
    "    'tank' : d['tank'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Output comparaison (instable output from BI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>1.610350</td>\n",
       "      <td>1.618321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_bar</th>\n",
       "      <td>1.344235</td>\n",
       "      <td>1.349615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>1.962730</td>\n",
       "      <td>2.136232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>3.078145</td>\n",
       "      <td>3.060428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.968580</td>\n",
       "      <td>1.011729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>2.958655</td>\n",
       "      <td>3.072418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>1.982622</td>\n",
       "      <td>2.134639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>2.308683</td>\n",
       "      <td>2.157695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>3.035657</td>\n",
       "      <td>3.075069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>2.666209</td>\n",
       "      <td>2.145086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>-0.140904</td>\n",
       "      <td>-0.181821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>1.801188</td>\n",
       "      <td>2.131870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.950859</td>\n",
       "      <td>0.999425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.640482</td>\n",
       "      <td>0.582544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.861960</td>\n",
       "      <td>1.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.352497</td>\n",
       "      <td>0.211755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>2.174142</td>\n",
       "      <td>2.144577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>2.002482</td>\n",
       "      <td>2.143309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>2.945265</td>\n",
       "      <td>2.925744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>2.266901</td>\n",
       "      <td>2.395111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>1.990767</td>\n",
       "      <td>2.020389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>3.682651</td>\n",
       "      <td>3.681524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[20]</th>\n",
       "      <td>2.331074</td>\n",
       "      <td>2.394519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[21]</th>\n",
       "      <td>2.525169</td>\n",
       "      <td>2.407162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[22]</th>\n",
       "      <td>2.446259</td>\n",
       "      <td>2.396210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[23]</th>\n",
       "      <td>1.694183</td>\n",
       "      <td>1.710853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[24]</th>\n",
       "      <td>-1.020484</td>\n",
       "      <td>-0.999594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[25]</th>\n",
       "      <td>0.102454</td>\n",
       "      <td>0.161103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[26]</th>\n",
       "      <td>-1.347818</td>\n",
       "      <td>-1.432346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[27]</th>\n",
       "      <td>-0.392767</td>\n",
       "      <td>-0.464656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[28]</th>\n",
       "      <td>0.139946</td>\n",
       "      <td>0.157770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[29]</th>\n",
       "      <td>1.533064</td>\n",
       "      <td>1.444068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[30]</th>\n",
       "      <td>-0.680466</td>\n",
       "      <td>-0.631892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[31]</th>\n",
       "      <td>-0.320711</td>\n",
       "      <td>-0.312323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[32]</th>\n",
       "      <td>3.285807</td>\n",
       "      <td>3.184801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[33]</th>\n",
       "      <td>2.790789</td>\n",
       "      <td>2.714677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[34]</th>\n",
       "      <td>2.615421</td>\n",
       "      <td>2.715663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[35]</th>\n",
       "      <td>2.101973</td>\n",
       "      <td>2.057772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[36]</th>\n",
       "      <td>1.925531</td>\n",
       "      <td>2.066867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[37]</th>\n",
       "      <td>4.058318</td>\n",
       "      <td>3.894103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[38]</th>\n",
       "      <td>2.724877</td>\n",
       "      <td>2.703608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[39]</th>\n",
       "      <td>2.504100</td>\n",
       "      <td>2.341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[40]</th>\n",
       "      <td>-1.784866</td>\n",
       "      <td>-1.812313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[41]</th>\n",
       "      <td>-0.590724</td>\n",
       "      <td>-0.570327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[42]</th>\n",
       "      <td>-0.468486</td>\n",
       "      <td>-0.453043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[43]</th>\n",
       "      <td>-0.391482</td>\n",
       "      <td>-0.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[44]</th>\n",
       "      <td>0.576858</td>\n",
       "      <td>0.579489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[45]</th>\n",
       "      <td>-0.599638</td>\n",
       "      <td>-0.570127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[46]</th>\n",
       "      <td>2.100393</td>\n",
       "      <td>2.058981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[47]</th>\n",
       "      <td>0.051222</td>\n",
       "      <td>0.008029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tfp    pystan\n",
       "sigma      1.610350  1.618321\n",
       "a_bar      1.344235  1.349615\n",
       "alpha[0]   1.962730  2.136232\n",
       "alpha[1]   3.078145  3.060428\n",
       "alpha[2]   0.968580  1.011729\n",
       "alpha[3]   2.958655  3.072418\n",
       "alpha[4]   1.982622  2.134639\n",
       "alpha[5]   2.308683  2.157695\n",
       "alpha[6]   3.035657  3.075069\n",
       "alpha[7]   2.666209  2.145086\n",
       "alpha[8]  -0.140904 -0.181821\n",
       "alpha[9]   1.801188  2.131870\n",
       "alpha[10]  0.950859  0.999425\n",
       "alpha[11]  0.640482  0.582544\n",
       "alpha[12]  0.861960  1.000907\n",
       "alpha[13]  0.352497  0.211755\n",
       "alpha[14]  2.174142  2.144577\n",
       "alpha[15]  2.002482  2.143309\n",
       "alpha[16]  2.945265  2.925744\n",
       "alpha[17]  2.266901  2.395111\n",
       "alpha[18]  1.990767  2.020389\n",
       "alpha[19]  3.682651  3.681524\n",
       "alpha[20]  2.331074  2.394519\n",
       "alpha[21]  2.525169  2.407162\n",
       "alpha[22]  2.446259  2.396210\n",
       "alpha[23]  1.694183  1.710853\n",
       "alpha[24] -1.020484 -0.999594\n",
       "alpha[25]  0.102454  0.161103\n",
       "alpha[26] -1.347818 -1.432346\n",
       "alpha[27] -0.392767 -0.464656\n",
       "alpha[28]  0.139946  0.157770\n",
       "alpha[29]  1.533064  1.444068\n",
       "alpha[30] -0.680466 -0.631892\n",
       "alpha[31] -0.320711 -0.312323\n",
       "alpha[32]  3.285807  3.184801\n",
       "alpha[33]  2.790789  2.714677\n",
       "alpha[34]  2.615421  2.715663\n",
       "alpha[35]  2.101973  2.057772\n",
       "alpha[36]  1.925531  2.066867\n",
       "alpha[37]  4.058318  3.894103\n",
       "alpha[38]  2.724877  2.703608\n",
       "alpha[39]  2.504100  2.341588\n",
       "alpha[40] -1.784866 -1.812313\n",
       "alpha[41] -0.590724 -0.570327\n",
       "alpha[42] -0.468486 -0.453043\n",
       "alpha[43] -0.391482 -0.332031\n",
       "alpha[44]  0.576858  0.579489\n",
       "alpha[45] -0.599638 -0.570127\n",
       "alpha[46]  2.100393  2.058981\n",
       "alpha[47]  0.051222  0.008029"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m13_2.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma'].mean(), df['a_bar'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(),\n",
    "                   df['a.3'].mean(), df['a.4'].mean(),\n",
    "                   df['a.5'].mean(), df['a.6'].mean(),\n",
    "                   df['a.7'].mean(), df['a.8'].mean(),\n",
    "                   df['a.9'].mean(), df['a.10'].mean(),\n",
    "                   df['a.11'].mean(), df['a.12'].mean(),\n",
    "                   df['a.13'].mean(), df['a.14'].mean(),\n",
    "                   df['a.15'].mean(), df['a.16'].mean(),\n",
    "                   df['a.17'].mean(), df['a.18'].mean(),\n",
    "                   df['a.19'].mean(), df['a.20'].mean(),\n",
    "                   df['a.21'].mean(), df['a.22'].mean(),\n",
    "                   df['a.23'].mean(), df['a.24'].mean(),\n",
    "                   df['a.25'].mean(), df['a.26'].mean(),\n",
    "                   df['a.27'].mean(), df['a.28'].mean(),\n",
    "                   df['a.29'].mean(), df['a.30'].mean(),\n",
    "                   df['a.31'].mean(), df['a.32'].mean(),\n",
    "                   df['a.33'].mean(), df['a.34'].mean(),\n",
    "                   df['a.35'].mean(), df['a.36'].mean(),\n",
    "                   df['a.37'].mean(), df['a.38'].mean(),\n",
    "                   df['a.39'].mean(), df['a.40'].mean(),\n",
    "                   df['a.41'].mean(), df['a.42'].mean(),\n",
    "                   df['a.43'].mean(), df['a.44'].mean(),\n",
    "                   df['a.45'].mean(), df['a.46'].mean(),\n",
    "                   df['a.47'].mean(), df['a.48'].mean()\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Varying effects\n",
    "### 12.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 14:56:37.517599: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:56:37.517668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:56:37.517681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:56:37.517835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:56:37.517847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 14:56:37.517868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 14:56:37.517879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 21.6142 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.main import*\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = tf.constant([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = tf.constant([[sigma_a ** 2, cov_ab], [cov_ab, sigma_b ** 2]])\n",
    "tf.transpose(tf.reshape(tf.constant([1, 2, 3, 4]), (2, 2)))\n",
    "sigmas = tf.constant([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = tf.constant([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = tf.linalg.tensor_diag(sigmas) @ Rho @ tf.linalg.tensor_diag(sigmas)\n",
    "Sigma\n",
    "N_cafes = 20\n",
    "\n",
    "def build_vary_effects():\n",
    "    _seed = 5\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"vary_effects\")\n",
    "\n",
    "    Mu = tf.constant([a, b])\n",
    "\n",
    "    vary_effects = tfd.MultivariateNormalTriL(\n",
    "        loc=Mu, scale_tril=tf.linalg.cholesky(Sigma)\n",
    "    ).sample((N_cafes,), seed=seed())\n",
    "\n",
    "    return vary_effects\n",
    "\n",
    "vary_effects = build_vary_effects()\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "N_visits = 10\n",
    "afternoon = np.tile(np.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = np.repeat(np.arange(N_cafes), N_visits)\n",
    "\n",
    "def generate_data_frame():\n",
    "    sigma = 0.5  # std dev within cafes\n",
    "\n",
    "    _seed = 22\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"generate_data_frame\")\n",
    "\n",
    "    mu = tf.gather(a_cafe, cafe_id) + tf.gather(b_cafe, cafe_id) * afternoon\n",
    "\n",
    "    wait = tfd.Normal(loc=mu, scale=sigma).sample(seed=seed())\n",
    "    d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))\n",
    "\n",
    "    return d\n",
    "d = generate_data_frame()\n",
    "\n",
    "d.head()\n",
    "\n",
    "formula = dict(main = 'y ~ Normal(mu, sigma)',\n",
    "likelihood1 = 'mu ~ a_cafe_b_cafe[cafe] + a_cafe_b_cafe[cafe]*afternoon',\n",
    "prior0 = 'a_cafe_b_cafe ~ MultivariateNormalTriL(concat([alpha, beta],axis=-1), LinearOperatorDiag(sigma_alpha_beta).matmul(Rho))',\n",
    "prior1 = 'sigma ~ Exponential(1)',\n",
    "prior2 = 'sigma_alpha_beta ~ Exponential(1)',\n",
    "prior3 = 'alpha ~ Normal(5,2)',\n",
    "prior4 = 'beta ~ Normal(-1,0.5)',\n",
    "prior5 = 'Rho ~ LKJ(2,2)',\n",
    ")\n",
    "\n",
    "start = tm.time()\n",
    "m14_1 = model(formula, d)\n",
    "init_rho = tf.stack([tf.eye(2) for _ in range(4)])\n",
    "init_sigma = tf.ones_like(samples['sigma'])\n",
    "init_sigma_café = tf.ones_like(samples['sigma_alpha_beta'])\n",
    "init_b = tf.ones_like(samples['beta'])\n",
    "init_a = tf.ones_like(samples['alpha'])\n",
    "init_mvn = tf.ones_like(samples['a_cafe_b_cafe'])\n",
    "bijectors_list = [\n",
    "    tfb.Exp(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Exp(),\n",
    "    tfb.CorrelationCholesky(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "]\n",
    "m14_1.fit(observed_data = dict(y = d.wait.astype('float32').values),num_chains=4, \n",
    "          init= [init_sigma_café, init_b, init_a, init_rho, init_mvn, init_sigma], bijectors = bijectors_list)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 23.1s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_uv1wdhmn/model_adioy7mi.stan', line 18, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.000205 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 2.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.000193 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.93 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -1.04062e+12, but Covariance matrix[2,1] = -1.04062e+12 (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 28, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -4.87949e+10, but Covariance matrix[2,1] = -4.87949e+10 (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 28, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.00021 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 2.1 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.000185 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.85 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_sc3ckzyo/model_adioy7mi.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 25.7621 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    vector[200] wait;\n",
    "    array[200] int afternoon;\n",
    "    array[200] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[20] b_cafe;\n",
    "    vector[20] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[200] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[20] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:20 ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:200 ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];\n",
    "        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[0]</th>\n",
       "      <td>1.018232</td>\n",
       "      <td>1.008108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[1]</th>\n",
       "      <td>0.638057</td>\n",
       "      <td>0.636689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.041135</td>\n",
       "      <td>-1.045726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.677720</td>\n",
       "      <td>3.677060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 0]</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 1]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.637854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 0]</th>\n",
       "      <td>-0.668078</td>\n",
       "      <td>-0.637854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 1]</th>\n",
       "      <td>0.721207</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.037596</td>\n",
       "      <td>3.031840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-0.973616</td>\n",
       "      <td>-0.976320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>3.090242</td>\n",
       "      <td>3.104790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.560916</td>\n",
       "      <td>-0.578745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>5.392863</td>\n",
       "      <td>5.392082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-1.724727</td>\n",
       "      <td>-1.715804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>3.727342</td>\n",
       "      <td>3.716231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.116740</td>\n",
       "      <td>-1.108272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.609382</td>\n",
       "      <td>3.616085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-0.966598</td>\n",
       "      <td>-0.983754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>4.003802</td>\n",
       "      <td>4.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-1.416219</td>\n",
       "      <td>-1.419661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>2.945245</td>\n",
       "      <td>2.965385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.047529</td>\n",
       "      <td>-1.082336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.284343</td>\n",
       "      <td>3.273397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.578365</td>\n",
       "      <td>-1.576372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>4.075502</td>\n",
       "      <td>4.070465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-0.506308</td>\n",
       "      <td>-0.493805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>5.356876</td>\n",
       "      <td>5.353307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.540889</td>\n",
       "      <td>-1.526589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>5.413885</td>\n",
       "      <td>5.413727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-2.185248</td>\n",
       "      <td>-2.190666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>2.823516</td>\n",
       "      <td>2.830267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.737809</td>\n",
       "      <td>-0.752494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.198101</td>\n",
       "      <td>3.208405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-1.321572</td>\n",
       "      <td>-1.346734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>4.464320</td>\n",
       "      <td>4.468217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.621957</td>\n",
       "      <td>-1.632916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>3.661059</td>\n",
       "      <td>3.662828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-0.751007</td>\n",
       "      <td>-0.753498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>3.629206</td>\n",
       "      <td>3.613739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-0.825719</td>\n",
       "      <td>-0.803888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>2.597153</td>\n",
       "      <td>2.587446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>0.105202</td>\n",
       "      <td>0.122514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>1.614443</td>\n",
       "      <td>1.612757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.013450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>4.268631</td>\n",
       "      <td>4.263616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.077163</td>\n",
       "      <td>-1.066608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>3.145357</td>\n",
       "      <td>3.146751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-0.985485</td>\n",
       "      <td>-0.981634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.497881</td>\n",
       "      <td>0.498309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tfp    pystan\n",
       "sigma_alpha_beta[0]   1.018232  1.008108\n",
       "sigma_alpha_beta[1]   0.638057  0.636689\n",
       "beta[0]              -1.041135 -1.045726\n",
       "alpha[0]              3.677720  3.677060\n",
       "Rho[0, 0]             1.000000  1.000000\n",
       "Rho[0, 1]             0.000000 -0.637854\n",
       "Rho[1, 0]            -0.668078 -0.637854\n",
       "Rho[1, 1]             0.721207  1.000000\n",
       "a_cafe_b_cafe[0, 0]   3.037596  3.031840\n",
       "a_cafe_b_cafe[0, 1]  -0.973616 -0.976320\n",
       "a_cafe_b_cafe[1, 0]   3.090242  3.104790\n",
       "a_cafe_b_cafe[1, 1]  -0.560916 -0.578745\n",
       "a_cafe_b_cafe[2, 0]   5.392863  5.392082\n",
       "a_cafe_b_cafe[2, 1]  -1.724727 -1.715804\n",
       "a_cafe_b_cafe[3, 0]   3.727342  3.716231\n",
       "a_cafe_b_cafe[3, 1]  -1.116740 -1.108272\n",
       "a_cafe_b_cafe[4, 0]   3.609382  3.616085\n",
       "a_cafe_b_cafe[4, 1]  -0.966598 -0.983754\n",
       "a_cafe_b_cafe[5, 0]   4.003802  4.003458\n",
       "a_cafe_b_cafe[5, 1]  -1.416219 -1.419661\n",
       "a_cafe_b_cafe[6, 0]   2.945245  2.965385\n",
       "a_cafe_b_cafe[6, 1]  -1.047529 -1.082336\n",
       "a_cafe_b_cafe[7, 0]   3.284343  3.273397\n",
       "a_cafe_b_cafe[7, 1]  -1.578365 -1.576372\n",
       "a_cafe_b_cafe[8, 0]   4.075502  4.070465\n",
       "a_cafe_b_cafe[8, 1]  -0.506308 -0.493805\n",
       "a_cafe_b_cafe[9, 0]   5.356876  5.353307\n",
       "a_cafe_b_cafe[9, 1]  -1.540889 -1.526589\n",
       "a_cafe_b_cafe[10, 0]  5.413885  5.413727\n",
       "a_cafe_b_cafe[10, 1] -2.185248 -2.190666\n",
       "a_cafe_b_cafe[11, 0]  2.823516  2.830267\n",
       "a_cafe_b_cafe[11, 1] -0.737809 -0.752494\n",
       "a_cafe_b_cafe[12, 0]  3.198101  3.208405\n",
       "a_cafe_b_cafe[12, 1] -1.321572 -1.346734\n",
       "a_cafe_b_cafe[13, 0]  4.464320  4.468217\n",
       "a_cafe_b_cafe[13, 1] -1.621957 -1.632916\n",
       "a_cafe_b_cafe[14, 0]  3.661059  3.662828\n",
       "a_cafe_b_cafe[14, 1] -0.751007 -0.753498\n",
       "a_cafe_b_cafe[15, 0]  3.629206  3.613739\n",
       "a_cafe_b_cafe[15, 1] -0.825719 -0.803888\n",
       "a_cafe_b_cafe[16, 0]  2.597153  2.587446\n",
       "a_cafe_b_cafe[16, 1]  0.105202  0.122514\n",
       "a_cafe_b_cafe[17, 0]  1.614443  1.612757\n",
       "a_cafe_b_cafe[17, 1]  0.012251  0.013450\n",
       "a_cafe_b_cafe[18, 0]  4.268631  4.263616\n",
       "a_cafe_b_cafe[18, 1] -1.077163 -1.066608\n",
       "a_cafe_b_cafe[19, 0]  3.145357  3.146751\n",
       "a_cafe_b_cafe[19, 1] -0.985485 -0.981634\n",
       "sigma[0]              0.497881  0.498309"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m14_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),\n",
    "                   df['b'].mean(),df['a'].mean(),\n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),\n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   df['sigma'].mean()]\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
