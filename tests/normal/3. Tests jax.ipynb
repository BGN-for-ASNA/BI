{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI output results and speed comparaison\n",
    "## 1. Continuous variable\n",
    "### 1.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "import re\n",
    "Ncores = os.cpu_count()    \n",
    "platform = os.getenv(\"JAX_PLATFORM_NAME\", \"cpu\")\n",
    "jax.config.update(\"jax_platform_name\", platform)  \n",
    "xla_flags = os.getenv(\"XLA_FLAGS\", \"\")\n",
    "xla_flags = re.sub(r\"--xla_force_host_platform_device_count=\\S+\", \"\", xla_flags).split()\n",
    "os.environ[\"XLA_FLAGS\"] = \" \".join([\"--xla_force_host_platform_device_count={}\".format(Ncores)] + xla_flags)\n",
    "jax.config.update(\"jax_platform_name\", platform)\n",
    "print('jax.local_device_count ',jax.local_device_count(backend=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 10:41:08.803890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 10:41:08.803932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 10:41:08.804443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-13 10:41:09.188102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main_jax import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "BI took: 2.2220 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Model m4.3\n",
    "d = pd.read_csv('/home/sosa/BI/data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "formula = dict(main1 = 'height ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha + beta * weight',\n",
    "            prior1 = 'sigma ~ Uniform(0,50)',\n",
    "            prior2 = 'alpha ~ Normal(178,20)',\n",
    "            prior3 = 'beta ~ Normal(0,1)')    \n",
    "\n",
    "start = tm.time()\n",
    "m4_3 = model(formula, df = d, float = 32)\n",
    "m4_3.fit(observed_data = dict(height = d.height.astype('float32').values), num_chains=1)   \n",
    "end = tm.time()        \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "nest_asyncio.apply()\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "  vector[346] height;\n",
    "  vector[346] weight;\n",
    "}\n",
    "parameters{\n",
    "  real a;\n",
    "  real<lower=0> b;\n",
    "  real<lower=0,upper=50> sigma;\n",
    "}\n",
    "model{\n",
    "  vector[346] mu;\n",
    "  sigma ~ uniform( 0 , 50 );\n",
    "  b ~ lognormal( 0 , 1 );\n",
    "  a ~ normal( 178 , 20 );\n",
    "  for ( i in 1:346 ) {\n",
    "    mu[i] = a + b* weight[i] ;\n",
    "  }\n",
    "  height ~ normal( mu , sigma );  \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'height': d.height.values,\n",
    "  'weight': d.weight.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=2000, num_warmup = 500)  \n",
    "df = fit.to_frame()\n",
    "end = tm.time()  \n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>5.141531</td>\n",
       "      <td>5.144897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.905336</td>\n",
       "      <td>0.904733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>154.653732</td>\n",
       "      <td>154.649662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfp      pystan\n",
       "sigma[0]    5.141531    5.144897\n",
       "beta[0]     0.905336    0.904733\n",
       "alpha[0]  154.653732  154.649662"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m4_3.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df.b.mean(), df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable\n",
    "### 2.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "BI took: 1.4856 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "m5_9 = model()\n",
    "m5_9.import_csv('/home/sosa/BI/data/milk.csv', sep = ';')\n",
    "m5_9.df[\"K\"] = m5_9.df[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "m5_9.index(cols = \"clade\")\n",
    "formula = dict(main = 'K ~ Normal(mu,sigma)',\n",
    "            likelihood = 'mu ~ alpha[index_clade]',\n",
    "            prior1 = 'alpha~ Normal(0,0.5)',\n",
    "            prior2 = 'sigma ~ Exponential(1)') \n",
    "\n",
    "m5_9.f = formula\n",
    "\n",
    "start = tm.time()\n",
    "m5_9.build_model()\n",
    "m5_9.fit(observed_data = dict(K = m5_9.df.K.astype('float32').values))\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.6s, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 13.0510 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[29] K;\n",
    "    array[29] int clade_id;\n",
    "}\n",
    "parameters{\n",
    "    vector[4] a;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[29] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 0.5 );\n",
    "    for ( i in 1:29 ) {\n",
    "        mu[i] = a[clade_id[i]];\n",
    "    }\n",
    "    K ~ normal( mu , sigma );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "  'clade_id': m5_9.df.index_clade.values+1,\n",
    "  'K': m5_9.df.K.values,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.799599</td>\n",
       "      <td>0.801640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-0.461480</td>\n",
       "      <td>-0.459873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.351941</td>\n",
       "      <td>0.353296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.636618</td>\n",
       "      <td>0.636981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>-0.549415</td>\n",
       "      <td>-0.547616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.799599  0.801640\n",
       "alpha[0] -0.461480 -0.459873\n",
       "alpha[1]  0.351941  0.353296\n",
       "alpha[2]  0.636618  0.636981\n",
       "alpha[3] -0.549415 -0.547616"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m5_9.summary(round_to = 'none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)\n",
    "### 3.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "BI took: 1.7607 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "formula = dict(\n",
    "            main = 'blooms_std ~ Normal( mu , sigma ) ',\n",
    "            likelihood ='mu ~ a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent' ,\n",
    "            prior1 = 'a ~ Normal( 0.5 , 0.25 ) ',\n",
    "            prior2 = 'bw ~ Normal( 0 , 0.25 ) ',\n",
    "            prior3 = 'bs ~ Normal( 0 , 0.25 ) ',\n",
    "            prior4 = 'bws ~ Normal( 0 , 0.25 ) ',\n",
    "            prior5 = 'sigma ~ Exponential( 1 )',\n",
    "            )\n",
    "start = tm.time()\n",
    "m8_5 = model(formula, d)\n",
    "m8_5.fit(observed_data = dict(blooms_std =d.blooms_std.astype('float32').values))\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.0s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_42xyozqc/model_epcjb2i5.stan', line 26, column 4 to column 38)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 2.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 2.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.3110 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    vector[27] blooms_std;\n",
    "    array[27] int shade_cent;\n",
    "    array[27] int water_cent;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real bw;\n",
    "    real bs;\n",
    "    real bws;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[27] mu;\n",
    "    sigma ~ exponential( 1 );\n",
    "    bws ~ normal( 0 , 0.25 );\n",
    "    bs ~ normal( 0 , 0.25 );\n",
    "    bw ~ normal( 0 , 0.25 );\n",
    "    a ~ normal( 0.5 , 0.25 );\n",
    "    for ( i in 1:27 ) {\n",
    "        mu[i] = a + bw * water_cent[i] + bs * shade_cent[i] + bws * water_cent[i] * shade_cent[i];\n",
    "    }\n",
    "\n",
    "    \n",
    "    blooms_std ~ normal( mu , sigma );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'blooms_std' : d[\"blooms_std\"].values,\n",
    "    \"water_cent\": d[\"water_cent\"].values.astype(int),\n",
    "    \"shade_cent\": d[\"shade_cent\"].values.astype(int),\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.142805</td>\n",
       "      <td>0.142327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bws[0]</th>\n",
       "      <td>-0.142726</td>\n",
       "      <td>-0.143176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bw[0]</th>\n",
       "      <td>0.205038</td>\n",
       "      <td>0.206099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs[0]</th>\n",
       "      <td>-0.112257</td>\n",
       "      <td>-0.112393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.358838</td>\n",
       "      <td>0.358277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "sigma[0]  0.142805  0.142327\n",
       "bws[0]   -0.142726 -0.143176\n",
       "bw[0]     0.205038  0.206099\n",
       "bs[0]    -0.112257 -0.112393\n",
       "a[0]      0.358838  0.358277"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m8_5.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.sigma.mean(),  df['bws'].mean(), df['bw'].mean(), df['bs'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial model\n",
    "### 4.1. Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "BI took: 1.1723 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial( 1 , logits = p )' ,\n",
    "    likelihood = 'p ~ a' ,\n",
    "    prior1 = 'a ~ Normal( 0 , 10 )'\n",
    ")\n",
    "start = tm.time()\n",
    "m11_1 = model(formula, d)\n",
    "m11_1.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values))\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': \"tfd.Sample(tfd.Normal(0,10, name = 'prior1'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_1.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pulled_left': \"lambda a : tfd.Independent(tfd.Binomial(1,logits=a, name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_1.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 10.2s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 10.5593 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    a ~ normal( 0 , 10 );\n",
    "    p = a;\n",
    "    p = inv_logit(p);\n",
    "    pulled_left ~ binomial( 1 , p );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.323161</td>\n",
       "      <td>0.321119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "a[0]  0.323161  0.321119"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df.a.mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices\n",
    "### 5.1.Speed comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "BI took: 10.6183 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d.actor = d.actor - 1\n",
    "d[\"treatment\"] = d.prosoc_left + 2 * d.condition\n",
    "d[[\"actor\", \"prosoc_left\", \"condition\", \"treatment\"]]\n",
    "\n",
    "formula = dict(\n",
    "    main = 'pulled_left ~ Binomial(1 , p )' ,\n",
    "    likelihood = 'p ~ a[actor] + b[treatment]' ,\n",
    "    prior1 = 'a ~ Normal(0, 1.5)',\n",
    "    prior2 = 'b ~ Normal(0, 0.5)'\n",
    ")\n",
    "\n",
    "start = tm.time()\n",
    "m11_4 = model(formula, d, float = 32)\n",
    "m11_4.fit(observed_data = dict(pulled_left =d.pulled_left.astype('float32').values))\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pulled_left': \"lambda a, b : tfd.Independent(tfd.Binomial(1, tf.squeeze(tf.gather(a,tf.cast(df.actor.astype('float32').values, dtype=tf.int32), axis = -1))+ tf.squeeze(tf.gather(b,tf.cast(df.treatment.astype('float32').values, dtype=tf.int32), axis = -1)), name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_4.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': \"tfd.Sample(tfd.Normal(0,1.5, name = 'prior1'), sample_shape = 7)\",\n",
       " 'b': \"tfd.Sample(tfd.Normal(0,0.5, name = 'prior2'), sample_shape = 4)\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_4.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.8s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling:  79% (7900/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.8e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.61 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 15.5431 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    array[504] int pulled_left;\n",
    "    array[504] int treatment;\n",
    "    array[504] int actor;\n",
    "}\n",
    "parameters{\n",
    "    vector[7] a;\n",
    "    vector[4] b;\n",
    "}\n",
    "model{\n",
    "    vector[504] p;\n",
    "    b ~ normal( 0 , 0.5 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    pulled_left ~ binomial( 1 , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[504] log_lik;\n",
    "    vector[504] p;\n",
    "    for ( i in 1:504 ) {\n",
    "        p[i] = a[actor[i]] + b[treatment[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:504 ) log_lik[i] = binomial_lpmf( pulled_left[i] | 1 , p[i] );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'pulled_left' : d[\"pulled_left\"].values.astype(int),\n",
    "    'treatment' : d[\"treatment\"].values.astype(int) +1,\n",
    "    'actor' : d[\"actor\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.041349</td>\n",
       "      <td>-0.031648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.480509</td>\n",
       "      <td>0.490967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[2]</th>\n",
       "      <td>-0.356620</td>\n",
       "      <td>-0.375165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[3]</th>\n",
       "      <td>0.375912</td>\n",
       "      <td>0.376894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.468963</td>\n",
       "      <td>-0.455304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>3.874392</td>\n",
       "      <td>3.887521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>-0.752882</td>\n",
       "      <td>-0.757069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.749913</td>\n",
       "      <td>-0.758169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>-0.468166</td>\n",
       "      <td>-0.459580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[5]</th>\n",
       "      <td>0.461863</td>\n",
       "      <td>0.471230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[6]</th>\n",
       "      <td>1.954741</td>\n",
       "      <td>1.946828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfp    pystan\n",
       "b[0] -0.041349 -0.031648\n",
       "b[1]  0.480509  0.490967\n",
       "b[2] -0.356620 -0.375165\n",
       "b[3]  0.375912  0.376894\n",
       "a[0] -0.468963 -0.455304\n",
       "a[1]  3.874392  3.887521\n",
       "a[2] -0.752882 -0.757069\n",
       "a[3] -0.749913 -0.758169\n",
       "a[4] -0.468166 -0.459580\n",
       "a[5]  0.461863  0.471230\n",
       "a[6]  1.954741  1.946828"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_4.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), df['b.3'].mean(), df['b.4'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(), df['a.3'].mean(), df['a.4'].mean(), df['a.5'].mean(), df['a.6'].mean(), df['a.7'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson\n",
    "### 6.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2499 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from main_jax import*\n",
    "import time as tm\n",
    "d = pd.read_csv('/home/sosa/BI/data/Kline.csv', sep = ';')\n",
    "d[\"P\"] = d.population.pipe(np.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d[\"cid\"] = (d.contact == \"high\").astype(int)\n",
    "d['pLog'] = tf.math.log(d.P).numpy()\n",
    "formula = dict(main = 'total_tools ~ Poisson(log_rate = lambda)',\n",
    "               likelihood = 'lambda ~ alpha[cid] + beta[cid]*P',\n",
    "               prior1 = 'alpha ~ Normal(3,0.5)',\n",
    "               prior2 = 'beta ~ Normal(0,0.2)')\n",
    "start = tm.time()\n",
    "m11_10 = model(formula, d)\n",
    "m11_10.fit(observed_data = dict(total_tools =d.total_tools.astype('float32').values))\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 13.1s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 9e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 13.4400 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[10] int T;\n",
    "    vector[10] P;\n",
    "    array[10] int cid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    vector[2] b;\n",
    "}\n",
    "model{\n",
    "    vector[10] lambda;\n",
    "    b ~ normal( 0 , 0.2 );\n",
    "    a ~ normal( 3 , 0.5 );\n",
    "    for ( i in 1:10 ) {\n",
    "       lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "       lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    T ~ poisson( lambda );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[10] log_lik;\n",
    "    vector[10] lambda;\n",
    "    for ( i in 1:10 ) {\n",
    "        lambda[i] = a[cid[i]] + b[cid[i]] * P[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    for ( i in 1:10 ) log_lik[i] = poisson_lpmf( T[i] | lambda[i]);\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'T' : d[\"total_tools\"].values.astype(int),\n",
    "    'P' : d[\"P\"].values.astype(float),\n",
    "    'cid' : d[\"cid\"].values.astype(int) +1\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Output comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.377608</td>\n",
       "      <td>0.377975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>0.186534</td>\n",
       "      <td>0.190583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.318159</td>\n",
       "      <td>3.319431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>3.615976</td>\n",
       "      <td>3.610163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "beta[0]   0.377608  0.377975\n",
       "beta[1]   0.186534  0.190583\n",
       "alpha[0]  3.318159  3.319431\n",
       "alpha[1]  3.615976  3.610163"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_10.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b.1'].mean(), df['b.2'].mean(), \n",
    "                   df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (PB estimation)\n",
    "### 7.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"JointDistributionNamedAutoBatched/log_prob/add_2:0\", shape=(1,), dtype=float32)\n",
      "WARNING:tensorflow:`_` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "WARNING:tensorflow:`__1` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
      "BI took: 4.6588 seconds\n"
     ]
    }
   ],
   "source": [
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample((num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample((num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)\n",
    "\n",
    "formula = dict(main = 'y ~ Poisson(rate = lambda)',\n",
    "               likelihood = 'lambda ~ tf.exp(log_days + alpha +  beta * monastery)',\n",
    "               prior1 = 'alpha ~ Normal(0,1)',\n",
    "               prior2 = 'beta ~ Normal(0,1)')\n",
    "start = tm.time()\n",
    "m11_12 = model(formula, d, float=32)\n",
    "m11_12.fit(observed_data = dict(y =d.y.astype('float32').values))\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.0s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 7e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 8e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.4282 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[34] int days;\n",
    "    array[34] int y;\n",
    "    array[34] int monastery;\n",
    "    vector[34] log_days;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    real b;\n",
    "}\n",
    "model{\n",
    "    vector[34] lambda;\n",
    "    b ~ normal( 0 , 1 );\n",
    "    a ~ normal( 0 , 1 );\n",
    "    for ( i in 1:34 ) {\n",
    "        lambda[i] = log_days[i] + a + b * monastery[i];\n",
    "        lambda[i] = exp(lambda[i]);\n",
    "    }\n",
    "    \n",
    "    y ~ poisson( lambda );\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'days' : d[\"days\"].values.astype(int),\n",
    "    'y' : d[\"y\"].values.astype(int),\n",
    "    'monastery' : d[\"monastery\"].values.astype(int) +1,\n",
    "    'log_days' : d[\"log_days\"].values.astype(float),\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-0.979285</td>\n",
       "      <td>-0.866921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.389058</td>\n",
       "      <td>1.210285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "beta[0]  -0.979285 -0.866921\n",
       "alpha[0]  0.389058  1.210285"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_12.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b'].mean(), df['a'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial\n",
    "TODO : This model can't account for indices in the formula nor varying intercepts of varying effects.\n",
    "### 8.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = tf.nn.softmax(score)\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = np.repeat(np.nan, N)  # empty vector of choices for each individual\n",
    "\n",
    "# sample chosen career for each individual\n",
    "for i in range(N):\n",
    "    career[i] = tfd.Categorical(probs=p).sample()\n",
    "\n",
    "career = career.astype(int)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:32:43.869962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 14:32:43.870024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 14:32:43.870038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 14:32:43.870218: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 14:32:43.870231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 14:32:43.870248: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 14:32:43.870262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 OEM, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': \"tfd.Sample(tfd.Normal(0,1, name = 'prior1'), sample_shape = 3)\",\n",
       " 'beta': \"tfd.Sample(tfd.Normal(0,0.5, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = dict(main = 'y ~ Poisson(log_rate = p)',\n",
    "               likelihood = 'p ~ alpha[income] + beta * income',\n",
    "               prior1 = 'alpha ~ Normal(0,1)',\n",
    "               prior2 = 'beta ~ Normal(0, 0.5)')\n",
    "m11_13 = model(formula, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.nn.softmax(tf.stack([alpha[0]+beta*1.0,alpha[1]+beta*2.0,0 +beta*2.0], axis=1))\n",
      "BI took: 0.0071 seconds\n"
     ]
    }
   ],
   "source": [
    "formula = dict(main = 'y ~ Categorical(probs = p, cat = income)',\n",
    "               likelihood = 'p ~ alpha[income] + beta * income',\n",
    "               prior1 = 'alpha ~ Normal(0, 1)',\n",
    "               prior2 = 'beta ~ HalfNormal(0.5)'\n",
    "               )\n",
    "start = tm.time()   \n",
    "m11_13 = model(formula, d)\n",
    "m11_13.fit(observed_data = dict(y =d.career.astype('float32').values), num_chains=4)\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': \"tfd.Sample(tfd.Normal(0,1, name = 'prior1'), sample_shape = 2)\",\n",
       " 'beta': \"tfd.Sample(tfd.HalfNormal(0.5, name = 'prior2'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_13.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': \"lambda alpha, beta : tfd.Independent(tfd.Categorical(probs=tf.nn.softmax(tf.stack([alpha[0]+beta*1.0,alpha[1]+beta*2.0,0 +beta*2.0], axis=1)), name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m11_13.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-617' coro=<HttpstanClient.post() done, defined at /home/sosa/.local/lib/python3.10/site-packages/stan/common.py:50> exception=ServerDisconnectedError('Server disconnected')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/stan/model.py\", line 519, in build\n",
      "    return asyncio.run(go())\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/nest_asyncio.py\", line 31, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/nest_asyncio.py\", line 93, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/nest_asyncio.py\", line 116, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/usr/lib/python3.10/selectors.py\", line 469, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/stan/common.py\", line 51, in post\n",
      "    async with self.session.post(f\"{self.base_url}{path}\", json=json) as resp:\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/aiohttp/client.py\", line 1194, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/aiohttp/client.py\", line 605, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 966, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"/home/sosa/.local/lib/python3.10/site-packages/aiohttp/streams.py\", line 622, in read\n",
      "    await self._waiter\n",
      "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 00:06&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 7 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "with pm.Model() as m11_13_pm:\n",
    "    a = pm.Normal(\"a\", 0.0, 1.0, shape=2)  # intercepts\n",
    "    b = pm.HalfNormal(\"b\", 0.5)  # association of income with choice\n",
    "\n",
    "    s0 = a[0] + b * income[0]\n",
    "    s1 = a[1] + b * income[1]\n",
    "    s2 = 0.0 + b * income[2]  # pivoting the intercept for the third category\n",
    "    s = pm.math.stack([s0, s1, s2])\n",
    "\n",
    "    p_ = pm.math.softmax(s)\n",
    "    career_obs = pm.Categorical(\"career\", p=p_, observed=career)\n",
    "\n",
    "    trace_11_13 = pm.sample(tune=2000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 12.2s, done.Sampling:   0%\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 1.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 9e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 9e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.7902 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    int N; // number of individuals\n",
    "    int K; // number of possible careers\n",
    "    array[N] int career; // outcome\n",
    "    vector[K] career_income;\n",
    "}\n",
    "parameters{\n",
    "    vector[K-1] a; // intercepts\n",
    "    real<lower=0> b; // association of income with choice\n",
    "}\n",
    "model{\n",
    "    vector[K] p;\n",
    "    vector[K] s;\n",
    "    a ~ normal( 0 , 1 );\n",
    "    b ~ normal( 0 , 0.5 );\n",
    "    s[1] = a[1] + b*career_income[1];\n",
    "    s[2] = a[2] + b*career_income[2];\n",
    "    s[3] = 0; // pivot\n",
    "    p = softmax( s );\n",
    "    career ~ categorical( p );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'N' : 500,\n",
    "    'K' : 3,\n",
    "    'career' : d[\"career\"].values.astype(int) + 1,\n",
    "    'career_income' : d[\"income\"].unique().astype(int).tolist(),\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212934/3955049630.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"pymc\": [tmp[2], tmp[0], tmp[1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "      <th>pymc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.572273</td>\n",
       "      <td>0.052870</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-1.634189</td>\n",
       "      <td>-2.454034</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>-1.395898</td>\n",
       "      <td>-1.498306</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan  pymc\n",
       "beta[0]   0.572273  0.052870  0.46\n",
       "alpha[0] -1.634189 -2.454034 -0.42\n",
       "alpha[1] -1.395898 -1.498306 -0.05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = az.summary(trace_11_13, round_to=2)['mean']\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m11_13.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['b'].mean(), df['a.1'].mean(), df['a.2'].mean()],\n",
    "        \"pymc\": [tmp[2], tmp[0], tmp[1]]\n",
    "    })\n",
    "# It seems that beta should be 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (PB estimation)\n",
    "### 9.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    },
    {
     "ename": "TracerArrayConversionError",
     "evalue": "The numpy.ndarray conversion method __array__() was called on traced array with shape float32[12].\nThe error occurred while tracing the function <lambda> at /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:u32[]\u001b[39m = convert_element_type[new_dtype=uint32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/samplers.py:179 (fold_in)\n\n  operation a\u001b[35m:key<fry>[]\u001b[39m = random_wrap[impl=fry] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/samplers.py:178 (fold_in)\n\n  operation a\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:149 (_normal_jax)\n\n  operation a\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:149 (_normal_jax)\n\n  operation a\u001b[35m:f32[2]\u001b[39m = mul b c\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/normal.py:181 (_sample_n)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     14\u001b[0m m12_1 \u001b[38;5;241m=\u001b[39m model(formula, d)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mm12_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madmit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BI/bi/normal/main_jax.py:141\u001b[0m, in \u001b[0;36mmodel.fit\u001b[0;34m(self, observed_data, num_chains)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(observed_data\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved_data_jax \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(observed_data\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallele_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \n\u001b[1;32m    143\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39m_flat_resolve_names(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior))\n",
      "File \u001b[0;32m~/BI/bi/normal/fit_jax.py:50\u001b[0m, in \u001b[0;36mfit.parallele_chains\u001b[0;34m(self, n_chain)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallele_chains\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m4\u001b[39m)):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Jax parallel\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     rng_keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), n_chain)\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_chain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "File \u001b[0;32m~/BI/bi/normal/fit_jax.py:34\u001b[0m, in \u001b[0;36mfit.run_chain\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jit, static_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_chain\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):        \n\u001b[1;32m     33\u001b[0m     init_key, sample_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 34\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     init_params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_names)\n\u001b[1;32m     36\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(init_params\u001b[38;5;241m.\u001b[39mvalues())   \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:956\u001b[0m, in \u001b[0;36mJointDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, value, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 956\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/distribution_util.py:1350\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:693\u001b[0m, in \u001b[0;36mJointDistribution._sample_n\u001b[0;34m(self, sample_shape, seed, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;129m@distribution_util\u001b[39m\u001b[38;5;241m.\u001b[39mAppendDocstring(kwargs_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    685\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother dependent (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownstream\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) distribution-making functions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m   might_have_batch_dims \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    696\u001b[0m       distribution_util\u001b[38;5;241m.\u001b[39mshape_may_be_nontrivial(sample_shape)\n\u001b[1;32m    697\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:361\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcallable_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/callable_util.py:55\u001b[0m, in \u001b[0;36mget_output_spec\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_tensor_spec\u001b[39m(t):\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensorSpec):\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m callable_util\u001b[38;5;241m.\u001b[39mget_output_spec(\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:1047\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[0;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m==\u001b[39m stop_index:\n\u001b[1;32m   1046\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution_sequential.py:399\u001b[0m, in \u001b[0;36m_JointDistributionSequential._model_coroutine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m xs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dist_fn, args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist_fn_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist_fn_args):\n\u001b[0;32m--> 399\u001b[0m   dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    401\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRoot(dist)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution_named.py:419\u001b[0m, in \u001b[0;36m_prob_chain_rule_model_flatten.<locals>._make.<locals>._fn\u001b[0;34m(*xs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39mxs):\n\u001b[1;32m    418\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dist_fn_name, xs) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[0;32m--> 419\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(alpha, phi)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:684\u001b[0m, in \u001b[0;36mTracer.__array__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 684\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerArrayConversionError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m: The numpy.ndarray conversion method __array__() was called on traced array with shape float32[12].\nThe error occurred while tracing the function <lambda> at /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:u32[]\u001b[39m = convert_element_type[new_dtype=uint32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/samplers.py:179 (fold_in)\n\n  operation a\u001b[35m:key<fry>[]\u001b[39m = random_wrap[impl=fry] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/samplers.py:178 (fold_in)\n\n  operation a\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:149 (_normal_jax)\n\n  operation a\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] b\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:149 (_normal_jax)\n\n  operation a\u001b[35m:f32[2]\u001b[39m = mul b c\n    from line /home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/normal.py:181 (_sample_n)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError"
     ]
    }
   ],
   "source": [
    "from main_jax import*\n",
    "import jax\n",
    "import time as tm\n",
    "d = pd.read_csv('/home/sosa/BI/data/UCBadmit.csv', sep = ';')\n",
    "d[\"gid\"] = (d[\"applicant.gender\"] != \"male\").astype(int)\n",
    "len(d.applications)\n",
    "formula = dict(main = 'y ~ BetaBinomial(applications, concentration1 = pbar*theta, concentration0 = (1 - pbar) * theta)',\n",
    "               likelihood = 'pbar ~ tf.sigmoid(alpha[gid])',\n",
    "               likelihood2 = 'theta ~ phi + 2.0',\n",
    "               prior1 = 'alpha ~ Normal(0.,1.5)',\n",
    "               prior2 = 'phi ~ Exponential(1)'\n",
    "               )\n",
    "start = tm.time()\n",
    "m12_1 = model(formula, d)\n",
    "m12_1.fit(observed_data = dict(y =d.admit.astype('float32').values))\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code =\"\"\" \n",
    "data{\n",
    "    array[12] int N;\n",
    "    array[12] int A;\n",
    "    array[12] int gid;\n",
    "}\n",
    "parameters{\n",
    "    vector[2] a;\n",
    "    real<lower=0> phi;\n",
    "}\n",
    "transformed parameters{\n",
    "    real theta;\n",
    "    theta = phi + 2;\n",
    "}\n",
    "model{\n",
    "    vector[12] pbar;\n",
    "    phi ~ exponential( 1 );\n",
    "    a ~ normal( 0 , 1.5 );\n",
    "    for ( i in 1:12 ) {\n",
    "        pbar[i] = a[gid[i]];\n",
    "        pbar[i] = inv_logit(pbar[i]);\n",
    "    }\n",
    "    A ~ beta_binomial( N , pbar*theta , (1-pbar)*theta );    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'A' : d[\"admit\"].values.astype(int),\n",
    "    'N' : d[\"applications\"].values.astype(int),\n",
    "    'gid' : d[\"gid\"].values.astype(int) +1,\n",
    "}\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phi[0]</th>\n",
       "      <td>-0.820031</td>\n",
       "      <td>1.025307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.535661</td>\n",
       "      <td>-0.446708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.320808</td>\n",
       "      <td>-0.321521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfp    pystan\n",
       "phi[0]   -0.820031  1.025307\n",
       "alpha[0]  0.535661 -0.446708\n",
       "alpha[1]  0.320808 -0.321521"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['phi'].mean(), df['a.1'].mean(), df['a.2'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial (WIP)\n",
    "### 10.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.main import*\n",
    "#d = pd.read_csv('/home/sosa/BI/data/Kline.csv', sep = ';')\n",
    "#formula = dict(main = 'y ~ BetaBinomial(12,  concentration1 = pbar/phi, concentration0 = g_rate)',\n",
    "#               likelihood1 = 'pbar ~ tf.exp(alpha[gid])*tf.math.pow(beta[gid])/gamma',\n",
    "#               likelihood2 = 'g_rate ~ 1/phi',\n",
    "#               prior1 = 'alpha ~ Normal(1,1)',\n",
    "#               prior2 = 'beta ~ Exponential(1)',\n",
    "#               prior3 = 'gamma ~ Exponential(1)',\n",
    "#               prior4 = 'phi ~ Exponential(1)',\n",
    "#               )\n",
    "#start = tm.time()\n",
    "#m12_1 = model(formula, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "#\n",
    "#tf.random.set_seed(42)\n",
    "#\n",
    "## Define the model\n",
    "#def model():\n",
    "#    m = {}\n",
    "#    m['alpha'] = tfp.distributions.Sample(tfp.distributions.Normal(1, 1), sample_shape=2)\n",
    "#    m['beta'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=2)\n",
    "#    m['gamma'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=1)\n",
    "#    m['phi'] = tfp.distributions.Sample(tfp.distributions.Exponential(1), sample_shape=1)\n",
    "#    \n",
    "#    # Define the distribution 'y' which depends on alpha, beta, gamma, and phi\n",
    "#    def y_dist(phi, alpha, beta, gamma):\n",
    "#        concentration1 = ((tf.exp(alpha) * beta) / gamma) / phi\n",
    "#        concentration0 = 1. / phi\n",
    "#        return tfp.distributions.Independent(\n",
    "#            tfp.distributions.BetaBinomial(12, concentration1=concentration1, concentration0=concentration0),\n",
    "#            reinterpreted_batch_ndims=1)\n",
    "#\n",
    "#    m['y'] = y_dist\n",
    "#    return tfp.distributions.JointDistributionNamedAutoBatched(m)\n",
    "#\n",
    "## Sample from the model\n",
    "#sampled_values = model().sample(alpha=tf.random.normal((2,)), beta=tfp.distributions.Exponential(rate=1.).sample((2,)), gamma=tfp.distributions.Exponential(rate=1.).sample((1,)), phi=tfp.distributions.Exponential(rate=1.).sample((1,)))\n",
    "#\n",
    "#print(sampled_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = d\n",
    "#m = {}\n",
    "#m['alpha']= tfd.Sample(tfd.Normal(1,1, name = 'prior1'), sample_shape = 2)\n",
    "#m['beta']= tfd.Sample(tfd.Exponential(1, name = 'prior2'), sample_shape = 2)\n",
    "#m['gamma']= tfd.Sample(tfd.Exponential(1, name = 'prior3'), sample_shape = 1)\n",
    "#m['phi']= tfd.Sample(tfd.Exponential(1, name = 'prior4'), sample_shape = 1)\n",
    "#m['y'] = lambda phi, alpha, beta, gamma : tfd.Independent(\n",
    "#    tfd.BetaBinomial(12,\n",
    "#                     concentration1=(\n",
    "#                         tf.exp(tf.squeeze(tf.gather(alpha,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1)))\n",
    "#                         *( tf.math.powtf.squeeze(tf.gather(beta,tf.cast(df.gid.astype('float32').values, dtype=tf.int32), axis = -1)))\n",
    "#                         /gamma)/phi,\n",
    "#                     concentration0=(1/phi), name ='main'), reinterpreted_batch_ndims=1)\n",
    "#m = tfd.JointDistributionNamedAutoBatched(m)\n",
    "#m.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes (PB estimation)\n",
    "### 11.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model() missing 3 required positional arguments: 'cafe', 'afternoon', and 'wait'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m formula \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(main \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my ~ ZeroInflatedNegativeBinomial(total_count = 365, inflated_loc_logits = p, logits = AL)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp ~ ap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m                likelihood2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAL ~ tf.math.log(al)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m                prior1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124map ~ Normal(-1.5 , 1)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                prior2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mal ~ Normal(1,0.5)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m                )\n\u001b[1;32m     21\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 22\u001b[0m m12_3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m m12_3 \u001b[38;5;241m=\u001b[39m model(formula)       \n\u001b[1;32m     24\u001b[0m m12_3\u001b[38;5;241m.\u001b[39mfit(observed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(y \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues))\n",
      "\u001b[0;31mTypeError\u001b[0m: model() missing 3 required positional arguments: 'cafe', 'afternoon', and 'wait'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "d = pd.DataFrame(y)\n",
    "formula = dict(main = 'y ~ ZeroInflatedNegativeBinomial(total_count = 365, inflated_loc_logits = p, logits = AL)',\n",
    "               likelihood = \"p ~ ap\",\n",
    "               likelihood2 = \"AL ~ tf.math.log(al)\",\n",
    "               prior1 = 'ap ~ Normal(-1.5 , 1)',\n",
    "               prior2 = 'al ~ Normal(1,0.5)'\n",
    "               )\n",
    "\n",
    "start = tm.time()\n",
    "m12_3 = model()\n",
    "m12_3 = model(formula)       \n",
    "m12_3.fit(observed_data = dict(y = d.iloc[:,0].astype('float32').values))\n",
    "end = tm.time()\n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 10.5s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 7.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.7 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.7 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 11.0766 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[365] int y;\n",
    "}\n",
    "parameters{\n",
    "    real ap;\n",
    "    real al;\n",
    "}\n",
    "model{\n",
    "    real p;\n",
    "    real lambda;\n",
    "    al ~ normal( 1 , 0.5 );\n",
    "    ap ~ normal( -1.5 , 1 );\n",
    "    lambda = al;\n",
    "    lambda = exp(lambda);\n",
    "    p = ap;\n",
    "    p = inv_logit(p);\n",
    "    for ( i in 1:365 ) {\n",
    "        if ( y[i]==0 )\n",
    "            target += log_mix( p , 0 , poisson_lpmf(0|lambda) );\n",
    "        if ( y[i] > 0 )\n",
    "            target += log1m( p ) + poisson_lpmf(y[i] | lambda );\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'y' :d.iloc[:,0].values.astype(int)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2. Output comparaison (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ap[0]</th>\n",
       "      <td>-1.965017</td>\n",
       "      <td>-1.356490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al[0]</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.109806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfp    pystan\n",
       "ap[0] -1.965017 -1.356490\n",
       "al[0]  0.001720  0.109806"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m12_3.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['ap'].mean(), df['al'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Varying interceps\n",
    "### 12.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n",
      "total_count=density\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Found incompatible dtypes, <class 'numpy.int32'> and <class 'numpy.float32'>. Seen so far: [<class 'numpy.int32'>, <class 'numpy.float32'>, ...]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()   \n\u001b[1;32m     11\u001b[0m m13_2 \u001b[38;5;241m=\u001b[39m model(formula, d, \u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mm13_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BI/bi/normal/main_jax.py:141\u001b[0m, in \u001b[0;36mmodel.fit\u001b[0;34m(self, observed_data, num_chains)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(observed_data\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved_data_jax \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(observed_data\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallele_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \n\u001b[1;32m    143\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39m_flat_resolve_names(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior))\n",
      "File \u001b[0;32m~/BI/bi/normal/fit_jax.py:50\u001b[0m, in \u001b[0;36mfit.parallele_chains\u001b[0;34m(self, n_chain)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallele_chains\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m4\u001b[39m)):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Jax parallel\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     rng_keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), n_chain)\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_chain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "File \u001b[0;32m~/BI/bi/normal/fit_jax.py:34\u001b[0m, in \u001b[0;36mfit.run_chain\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jit, static_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_chain\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):        \n\u001b[1;32m     33\u001b[0m     init_key, sample_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 34\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     init_params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_names)\n\u001b[1;32m     36\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(init_params\u001b[38;5;241m.\u001b[39mvalues())   \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:956\u001b[0m, in \u001b[0;36mJointDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, value, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 956\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/distribution_util.py:1350\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:693\u001b[0m, in \u001b[0;36mJointDistribution._sample_n\u001b[0;34m(self, sample_shape, seed, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;129m@distribution_util\u001b[39m\u001b[38;5;241m.\u001b[39mAppendDocstring(kwargs_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    685\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother dependent (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownstream\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) distribution-making functions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m   might_have_batch_dims \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    696\u001b[0m       distribution_util\u001b[38;5;241m.\u001b[39mshape_may_be_nontrivial(sample_shape)\n\u001b[1;32m    697\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:361\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcallable_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/callable_util.py:55\u001b[0m, in \u001b[0;36mget_output_spec\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_tensor_spec\u001b[39m(t):\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensorSpec):\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m callable_util\u001b[38;5;241m.\u001b[39mget_output_spec(\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:1047\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[0;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m==\u001b[39m stop_index:\n\u001b[1;32m   1046\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution_sequential.py:399\u001b[0m, in \u001b[0;36m_JointDistributionSequential._model_coroutine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m xs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dist_fn, args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist_fn_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist_fn_args):\n\u001b[0;32m--> 399\u001b[0m   dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    401\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRoot(dist)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution_named.py:419\u001b[0m, in \u001b[0;36m_prob_chain_rule_model_flatten.<locals>._make.<locals>._fn\u001b[0;34m(*xs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39mxs):\n\u001b[1;32m    418\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dist_fn_name, xs) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[0;32m--> 419\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(alpha)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342\u001b[0m, in \u001b[0;36m_DistributionMeta.__new__.<locals>.wrapped_init\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to have things set in `self` before `__init__` is\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# called, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m \u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to override things set in `self` by subclass\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# `__init__`, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;66;03m# We prefer subclasses will set `parameters = dict(locals())` because\u001b[39;00m\n\u001b[1;32m    347\u001b[0m   \u001b[38;5;66;03m# this has nearly zero overhead. However, failing to do this, we will\u001b[39;00m\n\u001b[1;32m    348\u001b[0m   \u001b[38;5;66;03m# resolve the input arguments dynamically and only when needed.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/binomial.py:371\u001b[0m, in \u001b[0;36mBinomial.__init__\u001b[0;34m(self, total_count, logits, probs, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    369\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConstruct `Binomial` with `probs` or `logits`, but not both.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinomial\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m--> 371\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m \u001b[43mdtype_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtotal_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_count \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(\n\u001b[1;32m    373\u001b[0m       total_count, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logits \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(\n\u001b[1;32m    375\u001b[0m       logits, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/dtype_util.py:220\u001b[0m, in \u001b[0;36mcommon_dtype\u001b[0;34m(args, dtype_hint)\u001b[0m\n\u001b[1;32m    218\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(_unify_dtype, dtype, dt)\n\u001b[1;32m    219\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound incompatible dtypes, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Seen so far: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    222\u001b[0m             dtype, dt, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(shallow_structure, seen))\n\u001b[1;32m    223\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_hint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(base_dtype, dtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: Found incompatible dtypes, <class 'numpy.int32'> and <class 'numpy.float32'>. Seen so far: [<class 'numpy.int32'>, <class 'numpy.float32'>, ...]"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "formula = dict(main = 'y ~ Binomial(total_count = density, logits = p)',\n",
    "               likelihood = 'p ~ alpha[tank]', \n",
    "               prior = 'alpha ~ Normal(a_bar, sigma)',\n",
    "               prior1 = 'a_bar ~ Normal(0.,1.5)',\n",
    "               prior2 = 'sigma ~ Exponential(1)'\n",
    "               )\n",
    "\n",
    "start = tm.time()   \n",
    "m13_2 = model(formula, d, float=32)\n",
    "m13_2.fit(observed_data = dict(y =d.surv.astype('int32').values), num_chains= 4)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 11.6s, done.Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.9e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_c8nksisu/model_h35q2y55.stan', line 16, column 4 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 12.1450 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    array[48] int N;\n",
    "    array[48] int S;\n",
    "    array[48] int tank;\n",
    "}\n",
    "parameters{\n",
    "    vector[48] a;\n",
    "    real a_bar;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "model{\n",
    "    vector[48] p;\n",
    "    sigma ~ exponential( 1 );\n",
    "    a_bar ~ normal( 0 , 1.5 );\n",
    "    a ~ normal( a_bar , sigma );\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    S ~ binomial( N , p );\n",
    "}\n",
    "generated quantities{\n",
    "    vector[48] log_lik;\n",
    "    vector[48] p;\n",
    "    for ( i in 1:48 ) {\n",
    "        p[i] = a[tank[i]];\n",
    "        p[i] = inv_logit(p[i]);\n",
    "    }\n",
    "    for ( i in 1:48 ) log_lik[i] = binomial_lpmf( S[i] | N[i] , p[i] );    \n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'S' : d['surv'].values.astype(int),\n",
    "    'N' : d['density'].values.astype(int),\n",
    "    'tank' : d['tank'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>1.626218</td>\n",
       "      <td>1.620453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_bar[0]</th>\n",
       "      <td>1.351135</td>\n",
       "      <td>1.348769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 0]</th>\n",
       "      <td>2.148302</td>\n",
       "      <td>2.140860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 1]</th>\n",
       "      <td>3.182271</td>\n",
       "      <td>3.077484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 2]</th>\n",
       "      <td>1.007853</td>\n",
       "      <td>0.997670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 3]</th>\n",
       "      <td>3.174410</td>\n",
       "      <td>3.075111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 4]</th>\n",
       "      <td>2.165270</td>\n",
       "      <td>2.146803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 5]</th>\n",
       "      <td>2.177249</td>\n",
       "      <td>2.135257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 6]</th>\n",
       "      <td>3.050784</td>\n",
       "      <td>3.081528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 7]</th>\n",
       "      <td>2.126648</td>\n",
       "      <td>2.135861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 8]</th>\n",
       "      <td>-0.182801</td>\n",
       "      <td>-0.178863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 9]</th>\n",
       "      <td>2.149825</td>\n",
       "      <td>2.165780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 10]</th>\n",
       "      <td>1.017289</td>\n",
       "      <td>0.998232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 11]</th>\n",
       "      <td>0.587782</td>\n",
       "      <td>0.582025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 12]</th>\n",
       "      <td>1.023714</td>\n",
       "      <td>1.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 13]</th>\n",
       "      <td>0.212295</td>\n",
       "      <td>0.192227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 14]</th>\n",
       "      <td>2.093900</td>\n",
       "      <td>2.131494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 15]</th>\n",
       "      <td>2.170717</td>\n",
       "      <td>2.141905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 16]</th>\n",
       "      <td>2.919388</td>\n",
       "      <td>2.911370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 17]</th>\n",
       "      <td>2.387000</td>\n",
       "      <td>2.399580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 18]</th>\n",
       "      <td>2.006687</td>\n",
       "      <td>2.006390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 19]</th>\n",
       "      <td>3.695935</td>\n",
       "      <td>3.693251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 20]</th>\n",
       "      <td>2.401524</td>\n",
       "      <td>2.400074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 21]</th>\n",
       "      <td>2.427003</td>\n",
       "      <td>2.390040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 22]</th>\n",
       "      <td>2.392018</td>\n",
       "      <td>2.402681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 23]</th>\n",
       "      <td>1.684565</td>\n",
       "      <td>1.700469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 24]</th>\n",
       "      <td>-1.002580</td>\n",
       "      <td>-0.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 25]</th>\n",
       "      <td>0.157274</td>\n",
       "      <td>0.166003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 26]</th>\n",
       "      <td>-1.444577</td>\n",
       "      <td>-1.424604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 27]</th>\n",
       "      <td>-0.474610</td>\n",
       "      <td>-0.466732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 28]</th>\n",
       "      <td>0.158350</td>\n",
       "      <td>0.157696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 29]</th>\n",
       "      <td>1.426129</td>\n",
       "      <td>1.444401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 30]</th>\n",
       "      <td>-0.628595</td>\n",
       "      <td>-0.633593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 31]</th>\n",
       "      <td>-0.303776</td>\n",
       "      <td>-0.315833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 32]</th>\n",
       "      <td>3.200550</td>\n",
       "      <td>3.181673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 33]</th>\n",
       "      <td>2.691208</td>\n",
       "      <td>2.713592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 34]</th>\n",
       "      <td>2.711707</td>\n",
       "      <td>2.710875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 35]</th>\n",
       "      <td>2.052027</td>\n",
       "      <td>2.067803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 36]</th>\n",
       "      <td>2.068563</td>\n",
       "      <td>2.060266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 37]</th>\n",
       "      <td>3.860800</td>\n",
       "      <td>3.910408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 38]</th>\n",
       "      <td>2.693505</td>\n",
       "      <td>2.710431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 39]</th>\n",
       "      <td>2.364832</td>\n",
       "      <td>2.344790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 40]</th>\n",
       "      <td>-1.812784</td>\n",
       "      <td>-1.802345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 41]</th>\n",
       "      <td>-0.583196</td>\n",
       "      <td>-0.571043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 42]</th>\n",
       "      <td>-0.446164</td>\n",
       "      <td>-0.447995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 43]</th>\n",
       "      <td>-0.331809</td>\n",
       "      <td>-0.337741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 44]</th>\n",
       "      <td>0.581561</td>\n",
       "      <td>0.579856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 45]</th>\n",
       "      <td>-0.573670</td>\n",
       "      <td>-0.572225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 46]</th>\n",
       "      <td>2.059275</td>\n",
       "      <td>2.062478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0, 47]</th>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.007779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tfp    pystan\n",
       "sigma[0]      1.626218  1.620453\n",
       "a_bar[0]      1.351135  1.348769\n",
       "alpha[0, 0]   2.148302  2.140860\n",
       "alpha[0, 1]   3.182271  3.077484\n",
       "alpha[0, 2]   1.007853  0.997670\n",
       "alpha[0, 3]   3.174410  3.075111\n",
       "alpha[0, 4]   2.165270  2.146803\n",
       "alpha[0, 5]   2.177249  2.135257\n",
       "alpha[0, 6]   3.050784  3.081528\n",
       "alpha[0, 7]   2.126648  2.135861\n",
       "alpha[0, 8]  -0.182801 -0.178863\n",
       "alpha[0, 9]   2.149825  2.165780\n",
       "alpha[0, 10]  1.017289  0.998232\n",
       "alpha[0, 11]  0.587782  0.582025\n",
       "alpha[0, 12]  1.023714  1.002805\n",
       "alpha[0, 13]  0.212295  0.192227\n",
       "alpha[0, 14]  2.093900  2.131494\n",
       "alpha[0, 15]  2.170717  2.141905\n",
       "alpha[0, 16]  2.919388  2.911370\n",
       "alpha[0, 17]  2.387000  2.399580\n",
       "alpha[0, 18]  2.006687  2.006390\n",
       "alpha[0, 19]  3.695935  3.693251\n",
       "alpha[0, 20]  2.401524  2.400074\n",
       "alpha[0, 21]  2.427003  2.390040\n",
       "alpha[0, 22]  2.392018  2.402681\n",
       "alpha[0, 23]  1.684565  1.700469\n",
       "alpha[0, 24] -1.002580 -0.998900\n",
       "alpha[0, 25]  0.157274  0.166003\n",
       "alpha[0, 26] -1.444577 -1.424604\n",
       "alpha[0, 27] -0.474610 -0.466732\n",
       "alpha[0, 28]  0.158350  0.157696\n",
       "alpha[0, 29]  1.426129  1.444401\n",
       "alpha[0, 30] -0.628595 -0.633593\n",
       "alpha[0, 31] -0.303776 -0.315833\n",
       "alpha[0, 32]  3.200550  3.181673\n",
       "alpha[0, 33]  2.691208  2.713592\n",
       "alpha[0, 34]  2.711707  2.710875\n",
       "alpha[0, 35]  2.052027  2.067803\n",
       "alpha[0, 36]  2.068563  2.060266\n",
       "alpha[0, 37]  3.860800  3.910408\n",
       "alpha[0, 38]  2.693505  2.710431\n",
       "alpha[0, 39]  2.364832  2.344790\n",
       "alpha[0, 40] -1.812784 -1.802345\n",
       "alpha[0, 41] -0.583196 -0.571043\n",
       "alpha[0, 42] -0.446164 -0.447995\n",
       "alpha[0, 43] -0.331809 -0.337741\n",
       "alpha[0, 44]  0.581561  0.579856\n",
       "alpha[0, 45] -0.573670 -0.572225\n",
       "alpha[0, 46]  2.059275  2.062478\n",
       "alpha[0, 47]  0.004438  0.007779"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m13_2.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma'].mean(), df['a_bar'].mean(),\n",
    "                   df['a.1'].mean(), df['a.2'].mean(),\n",
    "                   df['a.3'].mean(), df['a.4'].mean(),\n",
    "                   df['a.5'].mean(), df['a.6'].mean(),\n",
    "                   df['a.7'].mean(), df['a.8'].mean(),\n",
    "                   df['a.9'].mean(), df['a.10'].mean(),\n",
    "                   df['a.11'].mean(), df['a.12'].mean(),\n",
    "                   df['a.13'].mean(), df['a.14'].mean(),\n",
    "                   df['a.15'].mean(), df['a.16'].mean(),\n",
    "                   df['a.17'].mean(), df['a.18'].mean(),\n",
    "                   df['a.19'].mean(), df['a.20'].mean(),\n",
    "                   df['a.21'].mean(), df['a.22'].mean(),\n",
    "                   df['a.23'].mean(), df['a.24'].mean(),\n",
    "                   df['a.25'].mean(), df['a.26'].mean(),\n",
    "                   df['a.27'].mean(), df['a.28'].mean(),\n",
    "                   df['a.29'].mean(), df['a.30'].mean(),\n",
    "                   df['a.31'].mean(), df['a.32'].mean(),\n",
    "                   df['a.33'].mean(), df['a.34'].mean(),\n",
    "                   df['a.35'].mean(), df['a.36'].mean(),\n",
    "                   df['a.37'].mean(), df['a.38'].mean(),\n",
    "                   df['a.39'].mean(), df['a.40'].mean(),\n",
    "                   df['a.41'].mean(), df['a.42'].mean(),\n",
    "                   df['a.43'].mean(), df['a.44'].mean(),\n",
    "                   df['a.45'].mean(), df['a.46'].mean(),\n",
    "                   df['a.47'].mean(), df['a.48'].mean()\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying effects (Building issue)\n",
    "### 13.1. Speed comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "jnp.array([1, 2, 3, 4]).reshape(2, 2).T\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = dist.MultivariateNormal(Mu, Sigma).sample(seed, (N_cafes,))\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = dist.Normal(mu, sigma).sample(seed)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 9.3961 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from main_jax import*\n",
    "formula = dict(main = 'y ~ Normal(mu, sigma)',\n",
    "likelihood1 = 'mu ~ a_cafe_b_cafe[cafe] + a_cafe_b_cafe[cafe]*afternoon',\n",
    "prior0 = 'a_cafe_b_cafe ~ MultivariateNormalTriL(concat([alpha, beta],axis=-1), LinearOperatorDiag(sigma_alpha_beta, Rho))',\n",
    "prior1 = 'sigma ~ Exponential(1)',\n",
    "prior2 = 'sigma_alpha_beta ~ Exponential(1)',\n",
    "prior3 = 'alpha ~ Normal(5,2)',\n",
    "prior4 = 'beta ~ Normal(-1,0.5)',\n",
    "prior5 = 'Rho ~ LKJ(2,2)',\n",
    ")\n",
    "start = tm.time()\n",
    "m14_1 = model(formula, d)\n",
    "m14_1.fit(observed_data = dict(y = d.wait.astype('float32').values),num_chains=1)\n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 23.6s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_j1a9awij/model_5p5ra3gb.stan', line 18, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  50% (2000/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 5.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_fyhc3zwg/model_5p5ra3gb.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 24.6055 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    vector[200] wait;\n",
    "    array[200] int afternoon;\n",
    "    array[200] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[20] b_cafe;\n",
    "    vector[20] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[200] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[20] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:20 ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:200 ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }    \n",
    "    wait ~ normal( mu , sigma );\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2. Output comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[0]</th>\n",
       "      <td>0.298643</td>\n",
       "      <td>1.009866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_alpha_beta[1]</th>\n",
       "      <td>0.030658</td>\n",
       "      <td>0.635834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.046877</td>\n",
       "      <td>-1.044446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.684431</td>\n",
       "      <td>3.678972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 0]</th>\n",
       "      <td>9.344820</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 1]</th>\n",
       "      <td>-25.079983</td>\n",
       "      <td>-0.636287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 0]</th>\n",
       "      <td>22.498947</td>\n",
       "      <td>-0.636287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 1]</th>\n",
       "      <td>22.166206</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.022719</td>\n",
       "      <td>3.031275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-0.955079</td>\n",
       "      <td>-0.973707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>3.098739</td>\n",
       "      <td>3.105115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.572903</td>\n",
       "      <td>-0.576020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>5.413657</td>\n",
       "      <td>5.390617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-1.755731</td>\n",
       "      <td>-1.716827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>3.719385</td>\n",
       "      <td>3.716398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.109769</td>\n",
       "      <td>-1.108079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.615417</td>\n",
       "      <td>3.617178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-0.979649</td>\n",
       "      <td>-0.985705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>4.008886</td>\n",
       "      <td>4.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-1.424934</td>\n",
       "      <td>-1.419050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>2.956323</td>\n",
       "      <td>2.963777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.049075</td>\n",
       "      <td>-1.077343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.269439</td>\n",
       "      <td>3.271207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.548781</td>\n",
       "      <td>-1.573139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>4.077104</td>\n",
       "      <td>4.071916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-0.523068</td>\n",
       "      <td>-0.493761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>5.378857</td>\n",
       "      <td>5.355886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.572555</td>\n",
       "      <td>-1.524741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>5.434064</td>\n",
       "      <td>5.414005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-2.220307</td>\n",
       "      <td>-2.188522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>2.823230</td>\n",
       "      <td>2.826476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.733951</td>\n",
       "      <td>-0.748935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.203431</td>\n",
       "      <td>3.209135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-1.323942</td>\n",
       "      <td>-1.345004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>4.483381</td>\n",
       "      <td>4.467639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.644863</td>\n",
       "      <td>-1.626915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>3.663274</td>\n",
       "      <td>3.660902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-0.761361</td>\n",
       "      <td>-0.752973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>3.619195</td>\n",
       "      <td>3.616268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-0.814667</td>\n",
       "      <td>-0.807304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>2.571178</td>\n",
       "      <td>2.584698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>0.129222</td>\n",
       "      <td>0.118413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>1.586502</td>\n",
       "      <td>1.610652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>0.056976</td>\n",
       "      <td>0.016913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>4.272022</td>\n",
       "      <td>4.267494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.088246</td>\n",
       "      <td>-1.074241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>3.139413</td>\n",
       "      <td>3.147512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-0.970396</td>\n",
       "      <td>-0.985619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.499177</td>\n",
       "      <td>0.498710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tfp    pystan\n",
       "sigma_alpha_beta[0]    0.298643  1.009866\n",
       "sigma_alpha_beta[1]    0.030658  0.635834\n",
       "beta[0]               -1.046877 -1.044446\n",
       "alpha[0]               3.684431  3.678972\n",
       "Rho[0, 0]              9.344820  1.000000\n",
       "Rho[0, 1]            -25.079983 -0.636287\n",
       "Rho[1, 0]             22.498947 -0.636287\n",
       "Rho[1, 1]             22.166206  1.000000\n",
       "a_cafe_b_cafe[0, 0]    3.022719  3.031275\n",
       "a_cafe_b_cafe[0, 1]   -0.955079 -0.973707\n",
       "a_cafe_b_cafe[1, 0]    3.098739  3.105115\n",
       "a_cafe_b_cafe[1, 1]   -0.572903 -0.576020\n",
       "a_cafe_b_cafe[2, 0]    5.413657  5.390617\n",
       "a_cafe_b_cafe[2, 1]   -1.755731 -1.716827\n",
       "a_cafe_b_cafe[3, 0]    3.719385  3.716398\n",
       "a_cafe_b_cafe[3, 1]   -1.109769 -1.108079\n",
       "a_cafe_b_cafe[4, 0]    3.615417  3.617178\n",
       "a_cafe_b_cafe[4, 1]   -0.979649 -0.985705\n",
       "a_cafe_b_cafe[5, 0]    4.008886  4.003979\n",
       "a_cafe_b_cafe[5, 1]   -1.424934 -1.419050\n",
       "a_cafe_b_cafe[6, 0]    2.956323  2.963777\n",
       "a_cafe_b_cafe[6, 1]   -1.049075 -1.077343\n",
       "a_cafe_b_cafe[7, 0]    3.269439  3.271207\n",
       "a_cafe_b_cafe[7, 1]   -1.548781 -1.573139\n",
       "a_cafe_b_cafe[8, 0]    4.077104  4.071916\n",
       "a_cafe_b_cafe[8, 1]   -0.523068 -0.493761\n",
       "a_cafe_b_cafe[9, 0]    5.378857  5.355886\n",
       "a_cafe_b_cafe[9, 1]   -1.572555 -1.524741\n",
       "a_cafe_b_cafe[10, 0]   5.434064  5.414005\n",
       "a_cafe_b_cafe[10, 1]  -2.220307 -2.188522\n",
       "a_cafe_b_cafe[11, 0]   2.823230  2.826476\n",
       "a_cafe_b_cafe[11, 1]  -0.733951 -0.748935\n",
       "a_cafe_b_cafe[12, 0]   3.203431  3.209135\n",
       "a_cafe_b_cafe[12, 1]  -1.323942 -1.345004\n",
       "a_cafe_b_cafe[13, 0]   4.483381  4.467639\n",
       "a_cafe_b_cafe[13, 1]  -1.644863 -1.626915\n",
       "a_cafe_b_cafe[14, 0]   3.663274  3.660902\n",
       "a_cafe_b_cafe[14, 1]  -0.761361 -0.752973\n",
       "a_cafe_b_cafe[15, 0]   3.619195  3.616268\n",
       "a_cafe_b_cafe[15, 1]  -0.814667 -0.807304\n",
       "a_cafe_b_cafe[16, 0]   2.571178  2.584698\n",
       "a_cafe_b_cafe[16, 1]   0.129222  0.118413\n",
       "a_cafe_b_cafe[17, 0]   1.586502  1.610652\n",
       "a_cafe_b_cafe[17, 1]   0.056976  0.016913\n",
       "a_cafe_b_cafe[18, 0]   4.272022  4.267494\n",
       "a_cafe_b_cafe[18, 1]  -1.088246 -1.074241\n",
       "a_cafe_b_cafe[19, 0]   3.139413  3.147512\n",
       "a_cafe_b_cafe[19, 1]  -0.970396 -0.985619\n",
       "sigma[0]               0.499177  0.498710"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": m14_1.summary(round_to='none')['mean'],\n",
    "        \"pystan\": [df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),\n",
    "                   df['b'].mean(),df['a'].mean(),\n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),\n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   df['sigma'].mean()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Gaussian process (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main_jax import*\n",
    "tfb = tfp.bijectors\n",
    "# from: https://www.tensorflow.org/probability/examples/Gaussian_Process_Regression_In_TFP?hl=fr\n",
    "def sinusoid(x):\n",
    "  return np.sin(3 * np.pi * x[..., 0])\n",
    "\n",
    "def generate_1d_data(num_training_points, observation_noise_variance):\n",
    "  \"\"\"Generate noisy sinusoidal observations at a random set of points.\n",
    "\n",
    "  Returns:\n",
    "     observation_index_points, observations\n",
    "  \"\"\"\n",
    "  index_points_ = np.random.uniform(-1., 1., (num_training_points, 1))\n",
    "  index_points_ = index_points_.astype(np.float64)\n",
    "  # y = f(x) + noise\n",
    "  observations_ = (sinusoid(index_points_) +\n",
    "                   np.random.normal(loc=0,\n",
    "                                    scale=np.sqrt(observation_noise_variance),\n",
    "                                    size=(num_training_points)))\n",
    "  return index_points_, observations_\n",
    "\n",
    "# Generate training data with a known noise level (we'll later try to recover\n",
    "# this value from the data).\n",
    "NUM_TRAINING_POINTS = 100\n",
    "observation_index_points_, observations_ = generate_1d_data(\n",
    "    num_training_points=NUM_TRAINING_POINTS,\n",
    "    observation_noise_variance=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m formula \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(main \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations ~ GaussianProcess(kernel=tfp.math.psd_kernels.ExponentiatedQuadratic(amplitude, length_scale),index_points=observation_index_points_,observation_noise_variance=observation_noise_variance)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                prior1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation_noise_variance ~ LogNormal(0,1)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                prior2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_scale~LogNormal(0,1)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                prior3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitude~LogNormal(0,1)\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m                )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m model(formula, d)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BI/src/main_jax.py:127\u001b[0m, in \u001b[0;36mmodel.sample\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     init_key, sample_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;28mint\u001b[39m(r\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10000000\u001b[39m))))\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:956\u001b[0m, in \u001b[0;36mJointDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, value, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 956\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/distribution_util.py:1350\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:693\u001b[0m, in \u001b[0;36mJointDistribution._sample_n\u001b[0;34m(self, sample_shape, seed, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;129m@distribution_util\u001b[39m\u001b[38;5;241m.\u001b[39mAppendDocstring(kwargs_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    685\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother dependent (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownstream\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) distribution-making functions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m   might_have_batch_dims \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    696\u001b[0m       distribution_util\u001b[38;5;241m.\u001b[39mshape_may_be_nontrivial(sample_shape)\n\u001b[1;32m    697\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:361\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcallable_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/internal/callable_util.py:55\u001b[0m, in \u001b[0;36mget_output_spec\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_tensor_spec\u001b[39m(t):\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensorSpec):\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m callable_util\u001b[38;5;241m.\u001b[39mget_output_spec(\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:1005\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[0;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m   1003\u001b[0m   value_at_index \u001b[38;5;241m=\u001b[39m value[index]\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m   next_value, traced_values \u001b[38;5;241m=\u001b[39m \u001b[43msample_and_trace_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m      \u001b[49m\u001b[43mactual_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRoot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstateful_sample_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstateless_sample_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstateless_sample_seed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue_at_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1012\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected int for argument\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m       TENSOR_SEED_MSG_PREFIX \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1014\u001b[0m           stateful_sample_seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:156\u001b[0m, in \u001b[0;36mtrace_static_attributes\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m sample_shape\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ValueWithTrace(\n\u001b[1;32m    158\u001b[0m     value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m    159\u001b[0m     traced\u001b[38;5;241m=\u001b[39mStaticDistributionAttributes(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         name\u001b[38;5;241m=\u001b[39mget_explicit_name_for_component(dist),\n\u001b[1;32m    165\u001b[0m         reparameterization_type\u001b[38;5;241m=\u001b[39mdist\u001b[38;5;241m.\u001b[39mreparameterization_type))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/independent.py:276\u001b[0m, in \u001b[0;36m_Independent._sample_n\u001b[0;34m(self, n, seed, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, seed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/gaussian_process.py:616\u001b[0m, in \u001b[0;36mGaussianProcess._sample_n\u001b[0;34m(self, n, seed, index_points)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 616\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_marginal_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_points\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample(n, seed\u001b[38;5;241m=\u001b[39mseed)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/gaussian_process.py:419\u001b[0m, in \u001b[0;36mGaussianProcess.get_marginal_distribution\u001b[0;34m(self, index_points)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the marginal of this GP over function values at `index_points`.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m  marginal: a Normal distribution with vector event shape.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_marginal_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 419\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_marginal_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_points\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/gaussian_process.py:422\u001b[0m, in \u001b[0;36mGaussianProcess._get_marginal_distribution\u001b[0;34m(self, index_points, is_missing)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_marginal_distribution\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, is_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 422\u001b[0m   index_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_index_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m   observation_noise_variance \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    424\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_noise_variance)\n\u001b[1;32m    425\u001b[0m   loc, covariance \u001b[38;5;241m=\u001b[39m stochastic_process_util\u001b[38;5;241m.\u001b[39mget_loc_and_kernel_matrix(\n\u001b[1;32m    426\u001b[0m       kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[1;32m    427\u001b[0m       mean_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mean_fn,\n\u001b[1;32m    428\u001b[0m       observation_noise_variance\u001b[38;5;241m=\u001b[39mobservation_noise_variance,\n\u001b[1;32m    429\u001b[0m       index_points\u001b[38;5;241m=\u001b[39mindex_points,\n\u001b[1;32m    430\u001b[0m       is_missing\u001b[38;5;241m=\u001b[39mis_missing)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/gaussian_process.py:513\u001b[0m, in \u001b[0;36mGaussianProcess._get_index_points\u001b[0;34m(self, index_points)\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    502\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis GaussianProcess instance was not instantiated with a value for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    503\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_points. One must therefore be provided when calling sample, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man argument and returns a Normal distribution instance, whose KL \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    509\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan be computed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    510\u001b[0m index_points \u001b[38;5;241m=\u001b[39m nest_util\u001b[38;5;241m.\u001b[39mconvert_to_nested_tensor(\n\u001b[1;32m    511\u001b[0m     index_points \u001b[38;5;28;01mif\u001b[39;00m index_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_points,\n\u001b[1;32m    512\u001b[0m     dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mdtype, allow_packing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 513\u001b[0m \u001b[43mstochastic_process_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_nested_index_points\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_points\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/internal/stochastic_process_util.py:107\u001b[0m, in \u001b[0;36mcheck_nested_index_points\u001b[0;34m(kernel, index_points)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_nested_index_points\u001b[39m(kernel, index_points):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that the example dimensions are the same or broadcastable.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   num_index_points \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnd\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m      \u001b[49m\u001b[43mindex_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_ndims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m   flat_num_index_points \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(num_index_points)\n\u001b[1;32m    111\u001b[0m   static_non_singleton_num_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    112\u001b[0m       n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m flat_num_index_points \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:320\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree_util  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m    319\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tree_util\u001b[38;5;241m.\u001b[39mtree_map(func, \u001b[38;5;241m*\u001b[39mstructure)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdm_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/distributions/internal/stochastic_process_util.py:108\u001b[0m, in \u001b[0;36mcheck_nested_index_points.<locals>.<lambda>\u001b[0;34m(x, nd)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_nested_index_points\u001b[39m(kernel, index_points):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that the example dimensions are the same or broadcastable.\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   num_index_points \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m--> 108\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m x, nd: tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mdimension_value(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m),\n\u001b[1;32m    109\u001b[0m       index_points, kernel\u001b[38;5;241m.\u001b[39mfeature_ndims)\n\u001b[1;32m    110\u001b[0m   flat_num_index_points \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(num_index_points)\n\u001b[1;32m    111\u001b[0m   static_non_singleton_num_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    112\u001b[0m       n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m flat_num_index_points \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame({'observation_index_points_' : tf.reshape(observation_index_points_, -1)})\n",
    "tfk = tfp.math.psd_kernels\n",
    "formula = dict(main = 'observations ~ GaussianProcess(kernel=tfp.math.psd_kernels.ExponentiatedQuadratic(amplitude, length_scale),index_points=observation_index_points_,observation_noise_variance=observation_noise_variance)',\n",
    "               prior1 = 'observation_noise_variance ~ LogNormal(0,1)',\n",
    "               prior2 = 'length_scale~LogNormal(0,1)',\n",
    "               prior3 = 'amplitude~LogNormal(0,1)', \n",
    "               )\n",
    "self = model(formula, d)\n",
    "self.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation_noise_variance': \"tfd.Sample(tfd.LogNormal(0,1, name = 'prior1'), sample_shape = 1)\",\n",
       " 'length_scale': \"tfd.Sample(tfd.LogNormal(0,1, name = 'prior2'), sample_shape = 1)\",\n",
       " 'amplitude': \"tfd.Sample(tfd.LogNormal(0,1, name = 'prior3'), sample_shape = 1)\"}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observations': \"lambda observation_noise_variance, length_scale, amplitude : tfd.Independent(tfd.GaussianProcess(kernel=tfp.substrates.jax.math.psd_kernels.ExponentiatedQuadratic(amplitude,length_scale),index_points= df.observation_index_points_.astype('float32').values,observation_noise_variance=observation_noise_variance, name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import *\n",
    "tfk = tfp.math.psd_kernels\n",
    "m = {}\n",
    "# GP prios \n",
    "m['amplitude'] = tfd.Sample(tfd.LogNormal(loc=0., scale=np.float64(1.)), sample_shape = ())\n",
    "m['length_scale'] =  tfd.Sample(tfd.LogNormal(loc=0., scale=np.float64(1.)), sample_shape = ())\n",
    "m['observation_noise_variance'] =  tfd.Sample(tfd.LogNormal(loc=0., scale=np.float64(1.)), sample_shape =())\n",
    "m['observations'] = lambda amplitude, length_scale, observation_noise_variance: tfd.Independent(\n",
    "      tfd.GaussianProcess(\n",
    "            kernel=tfk.ExponentiatedQuadratic(amplitude, length_scale),\n",
    "            index_points=observation_index_points_,\n",
    "            observation_noise_variance=observation_noise_variance), reinterpreted_batch_ndims = 0)\n",
    "M = tfd.JointDistributionNamed(m)\n",
    "M.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionNamedAutoBatched 'JointDistributionNamedAutoBatched' batch_shape=[] event_shape={amplitude: [1], length_scale: [1], observation_noise_variance: [1], observations: [1, 100]} dtype={amplitude: float32, length_scale: float32, observation_noise_variance: float32, observations: float32}>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.main import*\n",
    "m = {}\n",
    "m['amplitude'] = tfd.Sample(tfd.LogNormal(0,1, name = 'prior3'), sample_shape = 1)\n",
    "m['length_scale'] = tfd.Sample(tfd.LogNormal(0,1, name = 'prior2'), sample_shape = 1)\n",
    "m['observation_noise_variance'] = tfd.Sample(tfd.LogNormal(0,1, name = 'prior1'), sample_shape = 1)\n",
    "m['observations'] = lambda  observation_noise_variance, length_scale, amplitude: tfd.Independent(\n",
    "    tfd.GaussianProcess(\n",
    "        kernel=tfp.math.psd_kernels.ExponentiatedQuadratic(amplitude,length_scale),\n",
    "        index_points= d.observation_index_points_.astype('float32').values,\n",
    "        observation_noise_variance=observation_noise_variance, name ='main'), reinterpreted_batch_ndims=1)\n",
    "m = tfd.JointDistributionNamedAutoBatched(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': \"lambda sigma, alpha : tfd.Independent(tfd.Normal( jnp.squeeze(jnp.take(alpha,jnp.array(df.index_clade.astype('float32').values, dtype=jnp.int32), axis = -1)),sigma, name ='main'), reinterpreted_batch_ndims=1)\"}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5_9.main_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO**</font>: need to arrays 1:N to n:1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
