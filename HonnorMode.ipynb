{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "# Get all names defined in the jnp\n",
    "all_names = dir(tfd)\n",
    "# Create a dictionary with all names\n",
    "class_dict = {name: getattr(tfd, name) for name in all_names}\n",
    "\n",
    "# Function to create new functions\n",
    "def create_new_function(class_obj):\n",
    "    def new_function(sample_shape=(), *args, **kwargs):\n",
    "        return tfd.Sample(class_obj(*args, **kwargs), sample_shape)\n",
    "    return new_function\n",
    "\n",
    "# Create a Python file and write the functions to it\n",
    "with open(\"generated_functions.py\", \"w\") as file:\n",
    "    for key, value in class_dict.items():\n",
    "        if callable(value):\n",
    "            try:\n",
    "                # Create the new function using the class object from class_dict\n",
    "                func_name = key.lower()\n",
    "                function_str = f\"def {func_name}(sample_shape=(), *args, **kwargs):\\n\"\n",
    "                function_str += f\"    return root(tfd.Sample({value.__name__}(*args, **kwargs), sample_shape))\\n\"\n",
    "                file.write(function_str)\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating function for {key}: {e}\")\n",
    "        else:\n",
    "            print(f\"Ignoring non-callable object for key {key}: {value}\")\n",
    "\n",
    "# Now all functions have been written to \"generated_functions.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 12:56:20.909325: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 12:56:20.909367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 12:56:20.909868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 12:56:21.347732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from generated_functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  var0=Array([1316015.4], dtype=float32),\n",
       "  var1=Array([1263855.1], dtype=float32),\n",
       "  var2=Array([565713.06], dtype=float32),\n",
       "  y=Array([2105595.], dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "def model():\n",
    "    a = yield normal(1, 0, 1e6)\n",
    "    b = yield normal(1, 0, 1e6)\n",
    "    s = yield normal(1, 0, 1e6)\n",
    "    y = yield tfd.Independent(\n",
    "        tfd.Normal(a+b, s), name = 'y'\n",
    "    )\n",
    "    \n",
    "tmp = tfd.JointDistributionCoroutineAutoBatched(model)\n",
    "tmp.sample(seed=init_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  a=Array([2016480.5], dtype=float32),\n",
       "  b=Array([-152975.55], dtype=float32),\n",
       "  s=Array([196093.52], dtype=float32),\n",
       "  y=Array([-129115.49,  656726.9 ,  842405.4 ,  108049.67,  427953.66,\n",
       "            272430.62,  168389.4 ,  335846.5 ,  722380.56,  477951.  ,\n",
       "            428336.38,  373258.12,  143430.2 ,  849390.6 ,  485359.12,\n",
       "            555898.6 ,   73203.5 ,  427286.9 ,  533781.5 ,  602774.4 ],      dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = tfd.Normal(10, 3).sample(20, seed=jnp.array(init_key))\n",
    "root = tfd.JointDistributionCoroutine.Root\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "import random as r\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "def model():\n",
    "    a = yield normal('a', 1,0,1e6)\n",
    "    b = yield normal('b', 1,0,1e6)\n",
    "    s = yield normal('s', 1,0,1e6)\n",
    "    y = yield tfd.Independent(\n",
    "        tfd.Normal(a+b*obs, s), name = 'y'\n",
    "    )    \n",
    "tmp = tfd.JointDistributionCoroutine(model)\n",
    "tmp.sample(seed=jnp.array(init_key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  var0=Array([45.295776], dtype=float32),\n",
       "  var1=Array([1.2638551], dtype=float32),\n",
       "  var2=Array([189.31425], dtype=float32),\n",
       "  var3=Array([151.765 , 139.7   , 136.525 , 156.845 , 145.415 , 163.83  ,\n",
       "           149.225 , 168.91  , 147.955 , 165.1   , 154.305 , 151.13  ,\n",
       "           144.78  , 149.9   , 150.495 , 163.195 , 157.48  , 143.9418,\n",
       "           161.29  , 156.21  , 146.4   , 148.59  , 147.32  , 147.955 ,\n",
       "           161.925 , 146.05  , 146.05  , 152.7048, 142.875 , 142.875 ,\n",
       "           147.955 , 160.655 , 151.765 , 162.8648, 171.45  , 147.32  ,\n",
       "           147.955 , 154.305 , 143.51  , 146.7   , 165.735 , 152.4   ,\n",
       "           141.605 , 158.8   , 155.575 , 164.465 , 151.765 , 161.29  ,\n",
       "           154.305 , 145.415 , 145.415 , 152.4   , 163.83  , 144.145 ,\n",
       "           153.67  , 142.875 , 167.005 , 158.4198, 165.735 , 149.86  ,\n",
       "           154.94  , 160.9598, 161.925 , 147.955 , 159.385 , 148.59  ,\n",
       "           136.525 , 158.115 , 144.78  , 156.845 , 179.07  , 170.18  ,\n",
       "           146.05  , 147.32  , 162.56  , 152.4   , 160.02  , 149.86  ,\n",
       "           142.875 , 167.005 , 159.385 , 154.94  , 162.56  , 152.4   ,\n",
       "           170.18  , 146.05  , 159.385 , 151.13  , 160.655 , 169.545 ,\n",
       "           158.75  , 149.86  , 153.035 , 161.925 , 162.56  , 149.225 ,\n",
       "           163.195 , 161.925 , 145.415 , 163.195 , 151.13  , 150.495 ,\n",
       "           170.815 , 157.48  , 152.4   , 147.32  , 145.415 , 157.48  ,\n",
       "           154.305 , 167.005 , 142.875 , 152.4   , 160.    , 159.385 ,\n",
       "           149.86  , 160.655 , 160.655 , 149.225 , 140.97  , 154.94  ,\n",
       "           141.605 , 160.02  , 150.1648, 155.575 , 156.21  , 153.035 ,\n",
       "           167.005 , 149.86  , 147.955 , 159.385 , 161.925 , 155.575 ,\n",
       "           159.385 , 146.685 , 172.72  , 166.37  , 141.605 , 151.765 ,\n",
       "           156.845 , 148.59  , 157.48  , 147.955 , 153.035 , 160.655 ,\n",
       "           149.225 , 138.43  , 162.56  , 149.225 , 158.75  , 149.86  ,\n",
       "           158.115 , 156.21  , 148.59  , 154.305 , 157.48  , 157.48  ,\n",
       "           154.305 , 168.275 , 145.415 , 149.225 , 154.94  , 162.56  ,\n",
       "           156.845 , 161.0106, 144.78  , 143.51  , 149.86  , 165.735 ,\n",
       "           144.145 , 157.48  , 154.305 , 163.83  , 156.21  , 144.145 ,\n",
       "           162.56  , 146.05  , 154.94  , 144.78  , 146.685 , 152.4   ,\n",
       "           163.83  , 165.735 , 156.21  , 152.4   , 140.335 , 163.195 ,\n",
       "           151.13  , 171.1198, 149.86  , 163.83  , 141.605 , 149.225 ,\n",
       "           146.05  , 161.29  , 162.56  , 145.415 , 170.815 , 159.385 ,\n",
       "           159.4   , 153.67  , 160.02  , 150.495 , 149.225 , 142.875 ,\n",
       "           142.113 , 147.32  , 162.56  , 164.465 , 160.02  , 153.67  ,\n",
       "           167.005 , 151.13  , 153.035 , 139.065 , 152.4   , 154.94  ,\n",
       "           147.955 , 144.145 , 155.575 , 150.495 , 155.575 , 154.305 ,\n",
       "           168.91  , 150.495 , 160.02  , 167.64  , 144.145 , 145.415 ,\n",
       "           160.02  , 164.465 , 153.035 , 149.225 , 160.02  , 149.225 ,\n",
       "           153.67  , 150.495 , 151.765 , 158.115 , 149.225 , 151.765 ,\n",
       "           154.94  , 161.29  , 148.59  , 160.655 , 157.48  , 167.005 ,\n",
       "           157.48  , 152.4   , 152.4   , 161.925 , 152.4   , 159.385 ,\n",
       "           142.24  , 168.91  , 160.02  , 158.115 , 152.4   , 155.575 ,\n",
       "           154.305 , 156.845 , 156.21  , 168.275 , 147.955 , 157.48  ,\n",
       "           160.7   , 161.29  , 150.495 , 163.195 , 148.59  , 148.59  ,\n",
       "           161.925 , 151.13  , 163.83  , 153.035 , 151.765 , 156.21  ,\n",
       "           140.335 , 158.75  , 142.875 , 151.9428, 161.29  , 160.9852,\n",
       "           144.78  , 160.02  , 160.9852, 165.989 , 157.988 , 154.94  ,\n",
       "           160.655 , 147.32  , 146.7   , 147.32  , 172.9994, 158.115 ,\n",
       "           147.32  , 165.989 , 149.86  , 161.925 , 163.83  , 160.02  ,\n",
       "           154.94  , 152.4   , 146.05  , 151.9936, 151.765 , 144.78  ,\n",
       "           160.655 , 151.13  , 153.67  , 147.32  , 139.7   , 157.48  ,\n",
       "           154.94  , 143.51  , 158.115 , 147.32  , 160.02  , 165.1   ,\n",
       "           154.94  , 153.67  , 141.605 , 163.83  , 161.29  , 154.9   ,\n",
       "           161.3   , 170.18  , 149.86  , 160.655 , 154.94  , 166.37  ,\n",
       "           148.2852, 151.765 , 148.59  , 153.67  , 146.685 , 154.94  ,\n",
       "           156.21  , 160.655 , 146.05  , 156.21  , 152.4   , 162.56  ,\n",
       "           142.875 , 162.56  , 156.21  , 158.75  ], dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "\n",
    "def model():\n",
    "    sigma = yield uniform(1, 0, 50)\n",
    "    alpha = yield normal(1, 0, 1)\n",
    "    beta = yield normal(1, 178, 20)\n",
    "    height = yield Independent(Normal(alpha + beta * jnp.array(d.weight.values, dtype=jnp.float32), sigma))\n",
    "    \n",
    "tmp = tfd.JointDistributionCoroutine(model)\n",
    "r = tmp.sample(seed=jnp.array(init_key))\n",
    "r._replace(var3=jnp.array(d.height.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  var0=Array([45.295776], dtype=float32),\n",
       "  var1=Array([1.2638551], dtype=float32),\n",
       "  var2=Array([189.31425], dtype=float32),\n",
       "  var3=Array([ 5.24895569e+02, -1.65329822e+03, -2.48176660e+03,  1.58646301e+03,\n",
       "           -6.70531738e+02,  3.39413477e+03, -1.24367114e+03,  1.99619739e+03,\n",
       "           -1.94112744e+03,  1.83926025e+03,  9.57691467e+02, -7.51466248e+02,\n",
       "           -1.66698779e+03,  4.66132904e+02, -2.17104761e+03,  6.02172668e+02,\n",
       "           -5.09897339e+02, -1.23505798e+03,  7.71507629e+02, -4.50738953e+02,\n",
       "           -1.73380139e+03, -1.31726465e+03, -1.74052283e+03, -8.75049622e+02,\n",
       "            1.93978125e+03, -1.41244812e+03, -1.18915674e+03,  2.20680954e+02,\n",
       "           -1.14977979e+03, -1.74735596e+03,  4.88830933e+02,  5.99290100e+02,\n",
       "            9.12052673e+02,  7.99225159e+02,  2.15954541e+03, -1.09067920e+03,\n",
       "            8.91225098e+02, -6.90867676e+02, -1.16549402e+03, -4.88088745e+02,\n",
       "            2.55402930e+03,  3.29889557e+02, -2.25736649e+02,  1.02510730e+03,\n",
       "            1.85674902e+03,  1.98162262e+02,  5.30041443e+02,  1.40061462e+03,\n",
       "            5.59167847e+02,  8.70378723e+01, -5.56856812e+02, -1.58718665e+03,\n",
       "            2.10836450e+03, -1.44217029e+03,  5.98693176e+02, -1.41638550e+03,\n",
       "            4.26379242e+02,  4.69008514e+02,  2.40094922e+03, -1.34271069e+03,\n",
       "            4.67465057e+02, -4.17724518e+02,  9.89874390e+02, -1.01519086e+03,\n",
       "            1.01341083e+03, -1.00852716e+03, -1.73688745e+03,  2.53593872e+02,\n",
       "           -5.66059692e+02,  5.03979797e+02,  1.95765588e+03,  6.38873596e+02,\n",
       "           -3.73516632e+02, -1.93956213e+03,  2.19065015e+03,  1.18272327e+03,\n",
       "            3.79367462e+02, -7.63529663e+02, -2.31337402e+03,  2.29615967e+03,\n",
       "           -3.43129272e+02, -9.98003052e+02,  1.52472565e+02, -7.65688416e+02,\n",
       "            5.86704651e+02, -1.39190625e+03,  2.13503895e+01, -5.22526489e+02,\n",
       "            1.89238391e+03,  1.60288586e+03,  1.32552124e+03, -4.51926880e+02,\n",
       "            8.58067017e+02, -6.32126404e+02,  2.01354504e+03, -5.14013977e+02,\n",
       "            1.62877148e+03,  9.42280640e+02, -4.82981171e+02,  7.72395264e+02,\n",
       "           -1.28751904e+03,  8.85092407e+02,  2.77533911e+03,  5.83340210e+02,\n",
       "           -1.13676624e+03, -1.51081421e+03, -5.97821594e+02, -9.45392456e+01,\n",
       "            5.30332458e+02,  1.91357092e+03, -2.29271777e+03, -7.95089783e+02,\n",
       "            1.14614758e+03,  6.96520325e+02,  1.49296130e+03,  1.70267981e+03,\n",
       "            1.95169470e+03, -5.30437073e+02, -7.63647766e+02,  8.38189636e+02,\n",
       "           -8.67006226e+01,  8.70588989e+01, -6.06955688e+02,  1.21901538e+03,\n",
       "           -1.86335922e+02, -2.44404883e+03,  2.23892163e+03,  1.45768152e+03,\n",
       "           -1.62550964e+03,  7.55062927e+02,  2.22864868e+03, -5.61687256e+02,\n",
       "            9.15183105e+02,  3.08168091e+02,  3.22907520e+03,  8.30426392e+02,\n",
       "           -2.56350513e+03, -1.75883350e+03,  6.79038696e+01, -2.22950104e+02,\n",
       "            1.30901382e+02, -6.41494202e+02, -9.05279160e+00,  1.69706763e+03,\n",
       "            1.36145618e+03, -1.15334314e+03,  1.26462387e+02, -9.05179565e+02,\n",
       "            1.20187256e+03, -1.11715381e+03, -1.04612793e+03, -1.40415100e+02,\n",
       "           -9.67144958e+02,  3.29621338e+02, -8.43496826e+02,  9.34649475e+02,\n",
       "           -7.10232849e+02,  1.84945435e+03, -1.34502983e+00, -1.77631628e+03,\n",
       "            5.62770195e+01,  6.51190369e+02,  1.46412704e+02,  6.51355042e+02,\n",
       "           -7.16522400e+02, -1.19932434e+03, -1.28213232e+03,  6.17795837e+02,\n",
       "           -1.17634155e+03, -9.19152588e+02,  9.20428528e+02,  1.77471716e+03,\n",
       "            1.34163742e+02, -1.00890149e+03, -3.85590881e+02, -2.52228491e+03,\n",
       "            1.05604797e+02, -1.35693298e+03, -1.69019495e+03, -7.58759644e+02,\n",
       "            5.86664795e+02,  5.05616425e+02,  2.28617386e+02, -6.89512268e+02,\n",
       "           -1.70064099e+03,  5.64513367e+02, -1.57205225e+03,  2.17147290e+03,\n",
       "           -1.14875854e+03,  4.75707489e+02, -1.71594312e+03, -7.18503723e+02,\n",
       "           -1.01308380e+02,  9.71719849e+02,  1.91423608e+03, -1.34224194e+03,\n",
       "            2.45272754e+03, -1.20003845e+02, -1.28680511e+02, -1.10012711e+02,\n",
       "           -7.43850784e+01, -8.89958801e+02, -9.27534103e+01, -2.03961829e+03,\n",
       "           -2.28495679e+03, -1.73263013e+03,  8.57452698e+02,  1.56961035e+03,\n",
       "           -1.54436792e+03, -8.22022400e+02,  1.07953113e+03, -1.37452377e+02,\n",
       "            9.63683594e+02, -2.23690210e+03, -2.25209961e+02,  6.14053101e+02,\n",
       "           -4.00065155e+02, -2.02671936e+03, -1.03517578e+03, -1.71827637e+03,\n",
       "            1.10314160e+03,  1.99763443e+02,  2.69128198e+03, -3.34183807e+02,\n",
       "            1.29267236e+03,  1.02754395e+03, -2.06973584e+03, -1.10923010e+03,\n",
       "            2.71919678e+03,  1.34003381e+03, -9.71914856e+02, -1.83702606e+02,\n",
       "            1.81903857e+03, -2.28387165e+00, -7.02642578e+02, -5.67795959e+02,\n",
       "           -4.84452606e+02, -3.38874603e+02, -7.72624146e+02, -4.22294403e+02,\n",
       "            2.43645264e+02,  5.41070557e+02, -5.04140198e+02,  6.47159302e+02,\n",
       "            1.22051224e+02,  1.55603345e+03,  4.16483978e+02, -2.99940186e+02,\n",
       "           -3.03284271e+02,  1.56470154e+03, -8.00259933e+01,  4.32563965e+02,\n",
       "           -2.45147534e+03,  2.21560303e+03,  2.08255029e+03,  5.59625061e+02,\n",
       "           -4.21728592e+01,  6.56850281e+01,  7.64835754e+02,  2.87447906e+02,\n",
       "           -1.62918762e+02,  2.02783215e+03, -8.14585388e+02,  1.12909802e+03,\n",
       "            2.55449066e+02,  8.94241211e+02, -1.63147354e+02,  1.12131360e+03,\n",
       "           -7.56664490e+02, -1.47649866e+03,  1.22922961e+03, -3.08164337e+02,\n",
       "            2.49572357e+02, -1.00556683e+03, -1.94288452e+03, -1.00048615e+03,\n",
       "           -1.41957263e+03,  6.81314941e+02, -1.81100781e+03, -2.96021667e+02,\n",
       "            6.35925598e+02,  1.16609497e+03, -1.64641632e+02,  6.05683044e+02,\n",
       "            2.86426178e+02,  2.10640723e+03,  6.01912231e+02,  5.86698425e+02,\n",
       "            5.62450317e+02, -1.76109082e+03, -1.51205725e+03,  7.66883545e+02,\n",
       "            1.11703479e+03,  3.24841064e+02, -1.53647229e+03,  6.86588684e+02,\n",
       "           -1.34040759e+03,  4.25459930e+02,  1.97637878e+03,  1.84992102e+03,\n",
       "            6.41387878e+02, -3.59031525e+02, -2.08781543e+03,  9.59201355e+02,\n",
       "           -1.24182152e+02, -2.15572363e+03,  4.18971771e+02,  1.86398834e+02,\n",
       "            4.65214600e+02, -7.84136108e+02,  1.03363257e+03, -1.27011814e+01,\n",
       "           -4.67409332e+02, -5.54562317e+02,  1.01948578e+02,  1.15039990e+03,\n",
       "            7.00362244e+02,  1.11954114e+03, -1.30598663e+02, -1.81809851e+03,\n",
       "           -4.33856293e+02,  4.23291504e+02, -6.13725769e+02, -1.27923975e+03,\n",
       "           -2.74484833e+02,  1.63719714e+03, -3.27397217e+02, -9.48663696e+02,\n",
       "           -2.79292358e+02,  1.44615662e+03, -1.19115503e+03, -4.20970612e+02,\n",
       "           -1.71937048e+03, -1.56790344e+02, -1.28514465e+03, -1.79566895e+02,\n",
       "           -1.81565063e+02,  5.54386169e+02, -1.03597107e+03, -8.51225830e+02,\n",
       "           -7.53504333e+02,  3.27913330e+02, -2.04183459e+03,  1.31014868e+03,\n",
       "            1.80199097e+03,  1.40660010e+03], dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "\n",
    "def model():\n",
    "    sigma = yield uniform(1, 0, 50, name = 'sigma')\n",
    "    alpha_sample = yield normal(1, 0, 1)  # Renamed var1 to alpha_sample\n",
    "    beta = yield normal(1, 178, 20)\n",
    "    height = yield Independent(Normal(alpha_sample + beta * jnp.array(d.weight.values, dtype=jnp.float32), sigma))\n",
    "    \n",
    "tmp = tfd.JointDistributionCoroutine(model)\n",
    "r = tmp.sample(seed=jnp.array(init_key))\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, set_matplotlib_formats\n",
    "from matplotlib.patches import Ellipse, transforms\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(4)\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = dist.MultivariateNormal(Mu, Sigma).sample(seed, (N_cafes,))\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = dist.Normal(mu, sigma).sample(seed)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "cafe_id = jnp.array(d.cafe.values)\n",
    "def model(cafe, afternoon, wait):\n",
    "    a = numpyro.sample(\"a\", dist.Normal(5, 2))\n",
    "    b = numpyro.sample(\"b\", dist.Normal(-1, 0.5))\n",
    "    sigma_cafe = numpyro.sample(\"sigma_cafe\", dist.Exponential(1).expand([2]))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    Rho = numpyro.sample(\"Rho\", dist.LKJ(2, 2))\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = numpyro.sample(\n",
    "        \"a_cafe,b_cafe\", dist.MultivariateNormal(jnp.stack([a, b]), cov).expand([20])\n",
    "    )\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    print(b_cafe[cafe])\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    numpyro.sample(\"wait\", dist.Normal(mu, sigma), obs=wait)\n",
    "model(cafe_id, afternoon, jnp.array(d.wait.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "N_cafes = 20\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = tf.constant([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = tf.constant([[sigma_a ** 2, cov_ab], [cov_ab, sigma_b ** 2]])\n",
    "sigmas = tf.constant([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = tf.constant([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = tf.linalg.tensor_diag(sigmas) @ Rho @ tf.linalg.tensor_diag(sigmas)\n",
    "\n",
    "Sigma\n",
    "def build_vary_effects():\n",
    "    _seed = 5\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"vary_effects\")\n",
    "\n",
    "    Mu = tf.constant([a, b])\n",
    "\n",
    "    vary_effects = tfd.MultivariateNormalTriL(\n",
    "        loc=Mu, scale_tril=tf.linalg.cholesky(Sigma)\n",
    "    ).sample((N_cafes,), seed=seed())\n",
    "\n",
    "    return vary_effects\n",
    "\n",
    "\n",
    "vary_effects = build_vary_effects()\n",
    "\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "N_visits = 10\n",
    "afternoon = np.tile(np.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = np.repeat(np.arange(N_cafes), N_visits)\n",
    "\n",
    "\n",
    "def generate_data_frame():\n",
    "    sigma = 0.5  # std dev within cafes\n",
    "\n",
    "    _seed = 22\n",
    "    tf.random.set_seed(_seed)\n",
    "\n",
    "    seed = tfp.util.SeedStream(_seed, salt=\"generate_data_frame\")\n",
    "\n",
    "    mu = tf.gather(a_cafe, cafe_id) + tf.gather(b_cafe, cafe_id) * afternoon\n",
    "\n",
    "    wait = tfd.Normal(loc=mu, scale=sigma).sample(seed=seed())\n",
    "    d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "d = generate_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import jax\n",
    "Ncores = os.cpu_count()    \n",
    "xla_flags = os.getenv(\"XLA_FLAGS\", \"\")\n",
    "xla_flags = re.sub(r\"--xla_force_host_platform_device_count=\\S+\", \"\", xla_flags).split()\n",
    "os.environ[\"XLA_FLAGS\"] = \" \".join([\"--xla_force_host_platform_device_count={}\".format(Ncores)] + xla_flags)\n",
    "print('jax.local_device_count ',jax.local_device_count(backend=None))\n",
    "from generated_functions import*\n",
    "cafe = jnp.array(d.cafe.values)\n",
    "afternoon = jnp.array(d.afternoon.values)\n",
    "wait = jnp.array(d.wait.values)\n",
    "\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "@jit\n",
    "def jax_LinearOperatorDiag(s, cov):    \n",
    "    def multiply_with_s(a):\n",
    "        return jnp.multiply(a, s)\n",
    "    vectorized_multiply = vmap(multiply_with_s)\n",
    "    return jnp.transpose(vectorized_multiply(cov))\n",
    "\n",
    "\n",
    "def model():\n",
    "    a = yield normal(1, 5, 2)\n",
    "    b = yield normal(1, -1, 0.5)\n",
    "    sigma_cafe = yield exponential(2, 1)\n",
    "    sigma = yield exponential(1, 1)\n",
    "    rho = yield lkj((), 2, 2)\n",
    "    a_cafe_b_cafe = yield multivariatenormaltril(N_cafes, jnp.concatenate([a,b]), jax_LinearOperatorDiag(sigma_cafe, rho))\n",
    "    mu = a_cafe_b_cafe[:, 0][cafe] +  a_cafe_b_cafe[:, 1][cafe] * afternoon\n",
    "    y = yield Independent(Normal(mu, sigma))\n",
    "    \n",
    "tensor = JointDistributionCoroutineAutoBatched(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([3.4546597], dtype=float32),\n",
       " Array([-0.24745472], dtype=float32),\n",
       " Array([0.73393834, 3.7439718 ], dtype=float32),\n",
       " Array([0.10379245], dtype=float32),\n",
       " Array([[ 1.        , -0.48375353],\n",
       "        [-0.48375353,  1.        ]], dtype=float32),\n",
       " Array([[ 4.5433025 , -1.4463906 ],\n",
       "        [ 2.409135  , -3.1256952 ],\n",
       "        [ 2.4117396 ,  0.17069174],\n",
       "        [ 3.8825395 ,  1.5221831 ],\n",
       "        [ 2.8445044 , 12.678833  ],\n",
       "        [ 3.9465768 , -7.089362  ],\n",
       "        [ 3.7777708 ,  2.7931075 ],\n",
       "        [ 1.9723744 ,  4.6654067 ],\n",
       "        [ 2.942348  , -1.2520821 ],\n",
       "        [ 2.9606543 ,  1.4972082 ],\n",
       "        [ 3.7153726 , -0.9360685 ],\n",
       "        [ 2.5986958 , 10.558637  ],\n",
       "        [ 3.3644547 , -3.0091937 ],\n",
       "        [ 3.1064672 ,  5.7687573 ],\n",
       "        [ 4.417675  , -4.533324  ],\n",
       "        [ 4.871417  , -0.8105924 ],\n",
       "        [ 3.495174  , -5.119223  ],\n",
       "        [ 2.931318  ,  0.9195129 ],\n",
       "        [ 4.8179026 , -6.0424337 ],\n",
       "        [ 2.6771631 ,  6.3740478 ]], dtype=float32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_params2 = []\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[0])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[1])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[2])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[3])))\n",
    "init_params2.append(jnp.array(tf.eye(2)))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[5])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.9787 seconds\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import time as tm\n",
    "@partial(jit, static_argnums=1)\n",
    "def init_params(tensor, remove):\n",
    "    init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "    init = list(tensor.sample(seed=jnp.array(init_key, dtype=jnp.uint32)))\n",
    "    init.pop(remove)\n",
    "    return init\n",
    "\n",
    "init_params = init_params(tensor, 6)\n",
    "init_params2 = []\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[0])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[1])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[2])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[3])))\n",
    "init_params2.append(jnp.array(tf.eye(2)))\n",
    "init_params2.append(jnp.array(tf.ones_like(init_params[5])))\n",
    "\n",
    "def trace_fn(_, pkr): \n",
    "    return (\n",
    "        pkr.target_log_prob,\n",
    "        pkr.log_accept_ratio,\n",
    "        pkr.has_divergence,\n",
    "        pkr.energy\n",
    "    )\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (wait,))\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(target_log_prob, 1e-3)\n",
    "    return tfp.mcmc.sample_chain(2000,\n",
    "        current_state= init_params2,\n",
    "        kernel=kernel,\n",
    "        trace_fn=trace_fn,\n",
    "        num_burnin_steps=500,\n",
    "        parallel_iterations = 10,\n",
    "        seed=key)\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 4)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "p = dict(zip(tensor._flat_resolve_names(), posterior))\n",
    "def tfp_trace_to_arviz(posterior, \n",
    "                       sample_stats,\n",
    "                       var_names=None, \n",
    "                       sample_stats_name=['target_log_prob','log_accept_ratio','has_divergence','energy']):\n",
    "    sample_stats = {k:jnp.transpose(v) for k, v in zip(sample_stats_name, sample_stats)}\n",
    "    trace = {}\n",
    "    for name, samp in zip(var_names, posterior):\n",
    "        if len(samp.shape) == 2:\n",
    "            transposed_shape = [1, 0]\n",
    "        elif len(samp.shape) == 3:\n",
    "            transposed_shape = [1, 0, 2]\n",
    "        else:\n",
    "            transposed_shape = [1, 0, 2, 3]\n",
    "        trace[name] = tf.transpose(samp, transposed_shape)\n",
    "    trace = az.from_dict(posterior=trace, sample_stats=sample_stats)\n",
    "    return trace\n",
    "\n",
    "\n",
    "\n",
    "trace = tfp_trace_to_arviz(posterior = posterior, sample_stats = sample_stats, var_names = ['alpha', 'beta', 'sigma_cafe', 'sigma', 'rho', 'a_cafe_b_cafe'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 24.3s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_kziqn6tn/model_y5f2lzzr.stan', line 18, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 8.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 8.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 8.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 9.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.93 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6mt83bpx/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 27.5516 seconds\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    vector[200] wait;\n",
    "    array[200] int afternoon;\n",
    "    array[200] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[20] b_cafe;\n",
    "    vector[20] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[200] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[20] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:20 ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:200 ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.679906</td>\n",
       "      <td>3.676953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.047126</td>\n",
       "      <td>-1.045073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[0]</th>\n",
       "      <td>0.180061</td>\n",
       "      <td>1.008454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[1]</th>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.633495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.499404</td>\n",
       "      <td>0.498925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[0, 0]</th>\n",
       "      <td>16.831242</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[0, 1]</th>\n",
       "      <td>-21.672058</td>\n",
       "      <td>-0.636803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[1, 0]</th>\n",
       "      <td>31.480253</td>\n",
       "      <td>-0.636803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[1, 1]</th>\n",
       "      <td>17.490580</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.023294</td>\n",
       "      <td>3.030511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-0.950339</td>\n",
       "      <td>-0.970327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>3.100387</td>\n",
       "      <td>3.106751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.576176</td>\n",
       "      <td>-0.581565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>5.417605</td>\n",
       "      <td>5.391189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-1.766814</td>\n",
       "      <td>-1.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>3.716179</td>\n",
       "      <td>3.715676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.104432</td>\n",
       "      <td>-1.106009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.619090</td>\n",
       "      <td>3.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-0.987458</td>\n",
       "      <td>-0.984966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>4.007306</td>\n",
       "      <td>3.998718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-1.417969</td>\n",
       "      <td>-1.414143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>2.946201</td>\n",
       "      <td>2.961904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.036769</td>\n",
       "      <td>-1.071148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.273089</td>\n",
       "      <td>3.268399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.548673</td>\n",
       "      <td>-1.571130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>4.079142</td>\n",
       "      <td>4.070478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-0.535414</td>\n",
       "      <td>-0.494864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>5.379828</td>\n",
       "      <td>5.357812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.583972</td>\n",
       "      <td>-1.527031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>5.441957</td>\n",
       "      <td>5.411571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-2.230138</td>\n",
       "      <td>-2.185735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>2.818310</td>\n",
       "      <td>2.825429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.724233</td>\n",
       "      <td>-0.743570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.200917</td>\n",
       "      <td>3.202582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-1.313965</td>\n",
       "      <td>-1.336699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>4.484490</td>\n",
       "      <td>4.466324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.644005</td>\n",
       "      <td>-1.622906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>3.662827</td>\n",
       "      <td>3.661274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-0.763882</td>\n",
       "      <td>-0.753785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>3.614687</td>\n",
       "      <td>3.616477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-0.811974</td>\n",
       "      <td>-0.808960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>2.565789</td>\n",
       "      <td>2.588126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>0.132947</td>\n",
       "      <td>0.115627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>1.573789</td>\n",
       "      <td>1.613336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>0.074685</td>\n",
       "      <td>0.011671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>4.276095</td>\n",
       "      <td>4.262892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.100084</td>\n",
       "      <td>-1.069385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>3.137397</td>\n",
       "      <td>3.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-0.961415</td>\n",
       "      <td>-0.992030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tfp    pystan\n",
       "alpha[0]               3.679906  3.676953\n",
       "beta[0]               -1.047126 -1.045073\n",
       "sigma_cafe[0]          0.180061  1.008454\n",
       "sigma_cafe[1]          0.032513  0.633495\n",
       "sigma[0]               0.499404  0.498925\n",
       "rho[0, 0]             16.831242  1.000000\n",
       "rho[0, 1]            -21.672058 -0.636803\n",
       "rho[1, 0]             31.480253 -0.636803\n",
       "rho[1, 1]             17.490580  1.000000\n",
       "a_cafe_b_cafe[0, 0]    3.023294  3.030511\n",
       "a_cafe_b_cafe[0, 1]   -0.950339 -0.970327\n",
       "a_cafe_b_cafe[1, 0]    3.100387  3.106751\n",
       "a_cafe_b_cafe[1, 1]   -0.576176 -0.581565\n",
       "a_cafe_b_cafe[2, 0]    5.417605  5.391189\n",
       "a_cafe_b_cafe[2, 1]   -1.766814 -1.714900\n",
       "a_cafe_b_cafe[3, 0]    3.716179  3.715676\n",
       "a_cafe_b_cafe[3, 1]   -1.104432 -1.106009\n",
       "a_cafe_b_cafe[4, 0]    3.619090  3.619345\n",
       "a_cafe_b_cafe[4, 1]   -0.987458 -0.984966\n",
       "a_cafe_b_cafe[5, 0]    4.007306  3.998718\n",
       "a_cafe_b_cafe[5, 1]   -1.417969 -1.414143\n",
       "a_cafe_b_cafe[6, 0]    2.946201  2.961904\n",
       "a_cafe_b_cafe[6, 1]   -1.036769 -1.071148\n",
       "a_cafe_b_cafe[7, 0]    3.273089  3.268399\n",
       "a_cafe_b_cafe[7, 1]   -1.548673 -1.571130\n",
       "a_cafe_b_cafe[8, 0]    4.079142  4.070478\n",
       "a_cafe_b_cafe[8, 1]   -0.535414 -0.494864\n",
       "a_cafe_b_cafe[9, 0]    5.379828  5.357812\n",
       "a_cafe_b_cafe[9, 1]   -1.583972 -1.527031\n",
       "a_cafe_b_cafe[10, 0]   5.441957  5.411571\n",
       "a_cafe_b_cafe[10, 1]  -2.230138 -2.185735\n",
       "a_cafe_b_cafe[11, 0]   2.818310  2.825429\n",
       "a_cafe_b_cafe[11, 1]  -0.724233 -0.743570\n",
       "a_cafe_b_cafe[12, 0]   3.200917  3.202582\n",
       "a_cafe_b_cafe[12, 1]  -1.313965 -1.336699\n",
       "a_cafe_b_cafe[13, 0]   4.484490  4.466324\n",
       "a_cafe_b_cafe[13, 1]  -1.644005 -1.622906\n",
       "a_cafe_b_cafe[14, 0]   3.662827  3.661274\n",
       "a_cafe_b_cafe[14, 1]  -0.763882 -0.753785\n",
       "a_cafe_b_cafe[15, 0]   3.614687  3.616477\n",
       "a_cafe_b_cafe[15, 1]  -0.811974 -0.808960\n",
       "a_cafe_b_cafe[16, 0]   2.565789  2.588126\n",
       "a_cafe_b_cafe[16, 1]   0.132947  0.115627\n",
       "a_cafe_b_cafe[17, 0]   1.573789  1.613336\n",
       "a_cafe_b_cafe[17, 1]   0.074685  0.011671\n",
       "a_cafe_b_cafe[18, 0]   4.276095  4.262892\n",
       "a_cafe_b_cafe[18, 1]  -1.100084 -1.069385\n",
       "a_cafe_b_cafe[19, 0]   3.137397  3.148290\n",
       "a_cafe_b_cafe[19, 1]  -0.961415 -0.992030"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": az.summary(trace,round_to='none')['mean'],\n",
    "        \"pystan\": [df['a'].mean(),df['b'].mean(),\n",
    "                   df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),   \n",
    "                   df['sigma'].mean(),                \n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),                   \n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   ]\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
