{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    }
   ],
   "source": [
    "from main import*\n",
    "from functools import partial\n",
    "import time as tm\n",
    "m = bi(platform='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distributions creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import inspect\n",
    "#import numpyro as numpyro\n",
    "#\n",
    "## Get all names defined in numpyro.distributions\n",
    "#all_names = dir(numpyro.distributions)\n",
    "#\n",
    "## Create a dictionary with all names\n",
    "#class_dict = {name: getattr(numpyro.distributions, name) for name in all_names}\n",
    "#\n",
    "## Create a Python file and write the import statement and class with methods to it\n",
    "#with open(\"dists.py\", \"w\") as file:\n",
    "#    # Write the import statement\n",
    "#    file.write(\"import numpyro as numpyro\\n\\n\")\n",
    "#    \n",
    "#    # Write the class definition with __init__ method\n",
    "#    file.write(\"class Dist:\\n\\n\")\n",
    "#    file.write(\"    def __init__(self):\\n\")\n",
    "#    file.write(\"        pass\\n\\n\")\n",
    "#    \n",
    "#    # Write the generated methods with enhanced docstrings and dynamic signatures\n",
    "#    for key, value in class_dict.items():\n",
    "#        if callable(value):\n",
    "#            try:\n",
    "#                # Use inspect to get the signature of the function\n",
    "#                signature = inspect.signature(value)\n",
    "#                parameters = signature.parameters\n",
    "#                \n",
    "#                # Build the method signature string\n",
    "#                param_str = \", \".join([str(param) for param in parameters.values()])\n",
    "#                full_signature = f\"{param_str}, sample_shape=()\"\n",
    "#                \n",
    "#                # Create the method definition string with dynamic arguments\n",
    "#                method_name = key.lower()\n",
    "#                method_str = f\"    def {method_name}(self, name, {full_signature}):\\n\"\n",
    "#                \n",
    "#                # Create a docstring with the method name and parameters\n",
    "#                docstring = f\"{value.__name__} distribution.\\n\\n\"\n",
    "#                docstring += \"    Arguments:\\n\"\n",
    "#                for param in parameters.values():\n",
    "#                    docstring += f\"        {param}\\n\"\n",
    "#                docstring += \"        sample_shape: Shape of samples to be drawn.\\n\"\n",
    "#                \n",
    "#                # Format and indent the docstring\n",
    "#                indented_docstring = '\\n    '.join(docstring.splitlines())\n",
    "#                method_str += f'        \"\"\"\\n        {indented_docstring}\\n        \"\"\"\\n'\n",
    "#                \n",
    "#                # Create the argument string for the return statement\n",
    "#                arg_names = [param.name for param in parameters.values()]\n",
    "#                arg_str = \", \".join([f\"{arg}={arg}\" for arg in arg_names])\n",
    "#                \n",
    "#                # Add the method body with explicit argument passing\n",
    "#                method_str += f\"        return numpyro.sample(name, numpyro.distributions.{value.__name__}({arg_str}).expand(sample_shape))\\n\"\n",
    "#                \n",
    "#                # Write the method string to the file\n",
    "#                file.write(method_str + \"\\n\")\n",
    "#            except Exception as e:\n",
    "#                print(f\"Error creating method for {key}: {e}\")\n",
    "#        else:\n",
    "#            print(f\"Ignoring non-callable object for key {key}: {value}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dist.exponential of <dists.Dist object at 0x7f2a9c13d8d0>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dists import Dist\n",
    "dist = Dist()\n",
    "dist.exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler for pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring non-callable object for key __all__: ['biject_to', 'constraints', 'kl_divergence', 'transforms', 'AsymmetricLaplace', 'AsymmetricLaplaceQuantile', 'Bernoulli', 'BernoulliLogits', 'BernoulliProbs', 'Beta', 'BetaBinomial', 'BetaProportion', 'Binomial', 'BinomialLogits', 'BinomialProbs', 'Categorical', 'CategoricalLogits', 'CategoricalProbs', 'Cauchy', 'Chi2', 'Delta', 'Dirichlet', 'DirichletMultinomial', 'DiscreteUniform', 'Distribution', 'EulerMaruyama', 'Exponential', 'ExpandedDistribution', 'FoldedDistribution', 'Gamma', 'GammaPoisson', 'GaussianCopula', 'GaussianCopulaBeta', 'GaussianRandomWalk', 'Geometric', 'GeometricLogits', 'GeometricProbs', 'Gompertz', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'ImproperUniform', 'Independent', 'InverseGamma', 'Kumaraswamy', 'LKJ', 'LKJCholesky', 'Laplace', 'LeftTruncatedDistribution', 'Logistic', 'LogNormal', 'LogUniform', 'MatrixNormal', 'MaskedDistribution', 'Mixture', 'MixtureSameFamily', 'MixtureGeneral', 'Multinomial', 'MultinomialLogits', 'MultinomialProbs', 'MultivariateNormal', 'CAR', 'MultivariateStudentT', 'LowRankMultivariateNormal', 'Normal', 'NegativeBinomialProbs', 'NegativeBinomialLogits', 'NegativeBinomial2', 'OrderedLogistic', 'Pareto', 'Poisson', 'ProjectedNormal', 'RelaxedBernoulli', 'RelaxedBernoulliLogits', 'RightTruncatedDistribution', 'SineBivariateVonMises', 'SineSkewed', 'SoftLaplace', 'StudentT', 'TransformedDistribution', 'TruncatedCauchy', 'TruncatedDistribution', 'TruncatedNormal', 'TruncatedPolyaGamma', 'TwoSidedTruncatedDistribution', 'Uniform', 'Unit', 'VonMises', 'Weibull', 'ZeroInflatedDistribution', 'ZeroInflatedPoisson', 'ZeroInflatedNegativeBinomial2']\n",
      "Ignoring non-callable object for key __builtins__: {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f2b70382470>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x7f2b70850c10>, 'runfile': <function runfile at 0x7f2b706bfd00>, '__IPYTHON__': True, 'display': <function display at 0x7f2b716fae60>, '__pybind11_internals_v4_clang_libstdcpp_cxxabi1002__': <capsule object NULL at 0x7f2af9e81ef0>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1014__': <capsule object NULL at 0x7f2860d03a20>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f2b70382980>>}\n",
      "Ignoring non-callable object for key __cached__: /home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/__pycache__/__init__.cpython-310.pyc\n",
      "Ignoring non-callable object for key __doc__: None\n",
      "Ignoring non-callable object for key __file__: /home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/__init__.py\n",
      "Ignoring non-callable object for key __loader__: <_frozen_importlib_external.SourceFileLoader object at 0x7f2aecefb910>\n",
      "Ignoring non-callable object for key __name__: numpyro.distributions\n",
      "Ignoring non-callable object for key __package__: numpyro.distributions\n",
      "Ignoring non-callable object for key __path__: ['/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions']\n",
      "Ignoring non-callable object for key __spec__: ModuleSpec(name='numpyro.distributions', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f2aecefb910>, origin='/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/__init__.py', submodule_search_locations=['/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions'])\n",
      "Error creating method for biject_to: 'ConstraintRegistry' object has no attribute '__name__'\n",
      "Ignoring non-callable object for key conjugate: <module 'numpyro.distributions.conjugate' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/conjugate.py'>\n",
      "Ignoring non-callable object for key constraints: <module 'numpyro.distributions.constraints' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/constraints.py'>\n",
      "Ignoring non-callable object for key continuous: <module 'numpyro.distributions.continuous' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/continuous.py'>\n",
      "Ignoring non-callable object for key copula: <module 'numpyro.distributions.copula' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/copula.py'>\n",
      "Ignoring non-callable object for key directional: <module 'numpyro.distributions.directional' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/directional.py'>\n",
      "Ignoring non-callable object for key discrete: <module 'numpyro.distributions.discrete' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/discrete.py'>\n",
      "Ignoring non-callable object for key distribution: <module 'numpyro.distributions.distribution' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/distribution.py'>\n",
      "Ignoring non-callable object for key flows: <module 'numpyro.distributions.flows' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/flows.py'>\n",
      "Ignoring non-callable object for key kl: <module 'numpyro.distributions.kl' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/kl.py'>\n",
      "Ignoring non-callable object for key mixtures: <module 'numpyro.distributions.mixtures' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/mixtures.py'>\n",
      "Ignoring non-callable object for key transforms: <module 'numpyro.distributions.transforms' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/transforms.py'>\n",
      "Ignoring non-callable object for key truncated: <module 'numpyro.distributions.truncated' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/truncated.py'>\n",
      "Ignoring non-callable object for key util: <module 'numpyro.distributions.util' from '/home/sosa/.local/lib/python3.10/site-packages/numpyro/distributions/util.py'>\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import numpyro as numpyro\n",
    "#\n",
    "#t all names defined in numpyro.distributions\n",
    "all_names = dir(numpyro.distributions)\n",
    "#\n",
    "#eate a dictionary with all names\n",
    "class_dict = {name: getattr(numpyro.distributions, name) for name in all_names}\n",
    "\n",
    "#eate a Python file and write the import statement and class with methods to it\n",
    "with open(\"samplers.py\", \"w\") as file:\n",
    "    # Write the import statement\n",
    "    file.write(\"import numpyro as numpyro\\n\")\n",
    "    file.write(\"from jax import random\\n\")\n",
    "    #file.write(\"from numpyro import truncated\\n\")\n",
    "    #file.write(\"from numpyro import util\\n\")\n",
    "    #file.write(\"from numpyro import mixtures\\n\\n\")\n",
    "\n",
    "    # Write the class definition with __init__ method\n",
    "    file.write(\"class sampler:\\n\\n\")\n",
    "    file.write(\"    def __init__(self):\\n\")\n",
    "    file.write(\"        pass\\n\\n\")\n",
    "\n",
    "    ## Write the generated methods with enhanced docstrings and dynamic signatures\n",
    "    for key, value in class_dict.items():\n",
    "        if callable(value):\n",
    "            try:\n",
    "                # Use inspect to get the signature of the function\n",
    "                signature = inspect.signature(value)\n",
    "                parameters = signature.parameters\n",
    "\n",
    "                # Build the method signature string\n",
    "                param_str = \", \".join([str(param) for param in parameters.values()])\n",
    "                full_signature = f\"{param_str}, sample_shape=()\"\n",
    "\n",
    "                # Create the method definition string with dynamic arguments\n",
    "                method_name = key.lower()\n",
    "                method_str = f\"    def {method_name}(self, {full_signature}, seed=0):\\n\"\n",
    "\n",
    "                # Create a docstring with the method name and parameters\n",
    "                docstring = f\"{value.__name__} distribution.\\n\\n\"\n",
    "                docstring += \"        Arguments:\\n\"\n",
    "                for param in parameters.values():\n",
    "                    docstring += f\"        {param}\\n\"\n",
    "                docstring += \"        sample_shape (tuple): Shape of samples to be drawn.\\n\"\n",
    "\n",
    "                # Format and indent the docstring\n",
    "                indented_docstring = '\\n    '.join(docstring.splitlines())\n",
    "                method_str += f'        \"\"\"\\n        {indented_docstring}\\n        \"\"\"\\n'\n",
    "\n",
    "                # Create the argument string for the return statement\n",
    "                arg_names = [param.name for param in parameters.values()]\n",
    "                arg_str = \", \".join([f\"{arg}={arg}\" for arg in arg_names])\n",
    "\n",
    "                # Build the distribution call with sample_shape\n",
    "                method_str += f\"        seed = random.PRNGKey(seed)\\n\"\n",
    "                method_str += f\"        return  numpyro.distributions.{value.__name__}({arg_str}).sample(seed, sample_shape)\\n\"\n",
    "\n",
    "                # Write the method string to the file\n",
    "                file.write(method_str + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating method for {key}: {e}\")\n",
    "        else:\n",
    "            print(f\"Ignoring non-callable object for key {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.5420704], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpyro import sample as lk\n",
    "from samplers import sampler\n",
    "\n",
    "sample = sampler()\n",
    "sample.exponential(sample_shape = (1,), seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "@partial(jit, static_argnums=(1, 2,))\n",
    "def vec_to_mat(arr, N, K):\n",
    "    return jnp.reshape(arr, (N, K))\n",
    "\n",
    "@jit\n",
    "def jax_LinearOperatorDiag(s, cov):    \n",
    "    def multiply_with_s(a):\n",
    "        return jnp.multiply(a, s)\n",
    "    vectorized_multiply = vmap(multiply_with_s)\n",
    "    return jnp.transpose(vectorized_multiply(cov))\n",
    "import jax.numpy as jnp\n",
    "\n",
    "@jit\n",
    "def diag_pre_multiply(v, m):\n",
    "    return jnp.matmul(jnp.diag(v), m)\n",
    "\n",
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_to_mat: \n",
      "[[ 0  1  1  1  1  1  1  1  1  1]\n",
      " [ 2  0  2  2  2  2  2  2  2  2]\n",
      " [ 3  3  0  3  3  3  3  3  3  3]\n",
      " [ 4  4  4  0  4  4  4  4  4  4]\n",
      " [ 5  5  5  5  0  5  5  5  5  5]\n",
      " [ 6  6  6  6  6  0  6  6  6  6]\n",
      " [ 7  7  7  7  7  7  0  7  7  7]\n",
      " [ 8  8  8  8  8  8  8  0  8  8]\n",
      " [ 9  9  9  9  9  9  9  9  0  9]\n",
      " [10 10 10 10 10 10 10 10 10  0]]\n",
      "get_upper_tri: \n",
      "[2 3 6]\n",
      "get_lower_tri: \n",
      "[4 7 8]\n",
      "On function for upper,  lower and both triangles: \n",
      "Upper triangle elements (excluding diagonal): [2 3 6]\n",
      "Lower triangle elements (excluding diagonal): [4 7 8]\n",
      "Both triangle elements (excluding diagonal): [[4 2]\n",
      " [7 3]\n",
      " [8 6]]\n",
      "Dot product betwee matrix and 2x2 cov mat\n",
      "[[-1.7161117   3.8507886   2.6675742  -1.2665143  -2.5273848   1.5500902\n",
      "  -0.56202716 -0.19732404 -1.3603567   0.8664815 ]\n",
      " [-4.0113864  -1.0849247   0.08289719  4.2800307  -0.29872686  1.4720304\n",
      "  -3.766257   -2.42005    -4.7452354   2.517879  ]\n",
      " [-2.399936    2.1465735   0.24681944  1.4653203  -0.04389387 -1.331646\n",
      "  -0.42534143 -3.0043678   1.5274246  -2.8574095 ]\n",
      " [ 2.1985683  -5.28951    -0.97243196  0.52319175 -2.375515    0.44109926\n",
      "  -0.9721045  -3.6193433   2.5031362  -1.6038274 ]\n",
      " [ 2.032421   -0.45143068  0.21383949  3.082756    1.5077829   2.882153\n",
      "  -0.765796   -2.905682   -1.852034    1.2984151 ]\n",
      " [-0.62112886 -0.20698333  3.147057    0.0148387  -2.5300467  -0.33965975\n",
      "  -1.9962643   5.4495344   0.4039624  -0.548226  ]\n",
      " [ 1.0118315   4.703859    0.18517044  2.2761464   1.2174578   3.4529765\n",
      "   0.39946204 -0.435966   -0.44351754  4.5684686 ]\n",
      " [-0.5720065   2.2101119   3.3897924   2.550859    2.1159594  -4.2990017\n",
      "   0.38712543  1.5366087  -3.8165128  -2.9029124 ]\n",
      " [ 2.3046231   3.365604   -1.0326629  -2.1595197   0.8815889  -0.29888955\n",
      "  -0.03953516  3.1525688  -0.88793373 -0.55513495]\n",
      " [-2.4216936  -3.8494189   0.5966314   0.83933854  0.09861016 -0.68377066\n",
      "  -3.7963939   5.007627    1.9496675  -0.19646278]]\n",
      "sr_to_dr_shape:\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [5 4]\n",
      " [7 2]\n",
      " [7 4]\n",
      " [7 6]]\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jaxr\n",
    "\n",
    "@jit\n",
    "def logit(x):\n",
    "    return jnp.log(x / (1 - x))\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def batch_matrix_vector_multiplication(A, v):\n",
    "    \"\"\"\n",
    "    Perform matrix-vector multiplication for each row of the array v.\n",
    "\n",
    "    Parameters:\n",
    "    A (jax.numpy.ndarray): A 2x2 matrix.\n",
    "    v (jax.numpy.ndarray): An array of shape (n, 2) where each row is a 2-vector.\n",
    "\n",
    "    Returns:\n",
    "    jax.numpy.ndarray: An array of shape (n, 2) where each row is the result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "    # Define a function that performs the matrix-vector multiplication\n",
    "    def matvec(A, v):\n",
    "        return jnp.dot(A, v)\n",
    "    \n",
    "    # Vectorize the function using jax.vmap\n",
    "    vmap_matvec = jax.vmap(lambda v: matvec(A, v))\n",
    "    \n",
    "    # Apply the vectorized function to the array of vectors\n",
    "    result = vmap_matvec(v)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def transform_matrix(X):\n",
    "    Y = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if i != j:\n",
    "                Y.append(jnp.array([X[i, j], X[j, i]]))\n",
    "    return jnp.concatenate(Y).reshape(-1, 2)\n",
    "\n",
    "# vec_to_mat ------------------------------------------------------------------\n",
    "@jit\n",
    "def vec_to_mat(vec):\n",
    "    # Repeat the array to fill a 10x10 matrix\n",
    "    m = jnp.transpose(jnp.tile(vec, (vec.shape[0] , 1)))\n",
    "    m = jnp.where(jnp.eye(m.shape[0], dtype=bool), 0, m)\n",
    "    return m\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "print(\"vec_to_mat: \")\n",
    "v = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(vec_to_mat(v))\n",
    "\n",
    "\n",
    "# Triangles ------------------------------------------------------------------\n",
    "def upper_tri(array, diag=1):\n",
    "    \"\"\"Extracts the upper triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "    \"\"\"\n",
    "    upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "    upper_triangle_elements = array[upper_triangle_indices]\n",
    "    return upper_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_upper_tri = jit(upper_tri, static_argnums=(1,))\n",
    "\n",
    "\n",
    "def lower_tri(array, diag=-1):\n",
    "    \"\"\"Extracts the lower triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=0 includes the diagonal, diag=-1 excludes it.\n",
    "    \"\"\"\n",
    "    lower_triangle_indices = jnp.tril_indices(array.shape[0], k=diag)\n",
    "    lower_triangle_elements = array[lower_triangle_indices]\n",
    "    return lower_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_lower_tri = jit(lower_tri, static_argnums=(1,))\n",
    "\n",
    "\n",
    "def get_tri(array, type='upper', diag=0):\n",
    "    \"\"\"Extracts the upper, lower, or both triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        type (str): A string indicating which part of the triangle to extract.\n",
    "                    It can be 'upper', 'lower', or 'both'.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "\n",
    "    Returns:\n",
    "        If argument type is 'upper', 'lower', it return a 1D JAX array containing the requested triangle elements.\n",
    "        If argument type is 'both', it return a 2D JAX array containing the the first column the lower triangle and in the second ecolumn the upper triangle\n",
    "    \"\"\"\n",
    "    if type == 'upper':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        triangle_elements = array[upper_triangle_indices]\n",
    "    elif type == 'lower':\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        triangle_elements = array[lower_triangle_indices]\n",
    "    elif type == 'both':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        upper_triangle_elements = array[upper_triangle_indices]\n",
    "        lower_triangle_elements = array[lower_triangle_indices]\n",
    "        triangle_elements = jnp.stack((lower_triangle_elements, upper_triangle_elements), axis = 1)\n",
    "    else:\n",
    "        raise ValueError(\"type must be 'upper', 'lower', or 'both'\")\n",
    "\n",
    "    return triangle_elements\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "array = jnp.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "print(\"get_upper_tri: \")\n",
    "result1 = get_upper_tri(array, 1)\n",
    "print(result1)\n",
    "\n",
    "print(\"get_lower_tri: \")\n",
    "result2 = get_lower_tri(array, -1)  # Change diag to -1 to exclude the diagonal\n",
    "print(result2)\n",
    "\n",
    "# JIT compile the function with static_argnums\n",
    "get_triangle = jit(get_tri, static_argnames=('type', 'diag'))\n",
    "\n",
    "print(\"On function for upper,  lower and both triangles: \")\n",
    "# Test the function\n",
    "result_upper = get_triangle(array, 'upper', 1)\n",
    "print(\"Upper triangle elements (excluding diagonal):\", result_upper)\n",
    "\n",
    "result_lower = get_triangle(array, 'lower', 1)\n",
    "print(\"Lower triangle elements (excluding diagonal):\", result_lower)\n",
    "\n",
    "result_both = get_triangle(array, 'both', 1)\n",
    "print(\"Both triangle elements (excluding diagonal):\", result_both)\n",
    "\n",
    "\n",
    "# Dot product betwee matrix and 2x2 cov mat-----------------------------\n",
    "# Seed for reproducibility\n",
    "seed = 0\n",
    "key = jaxr.PRNGKey(seed)\n",
    "\n",
    "# Define shapes\n",
    "shape_M = (10, 10)\n",
    "shape_diag = (2, 2)\n",
    "\n",
    "# Generate random matrices\n",
    "sr_raw_M = jaxr.normal(key, shape_M)  # Random matrix with shape (10, 10)\n",
    "diag = jaxr.normal(key, shape_diag)   # Random matrix with shape (2, 2)\n",
    "\n",
    "# Initialize the result matrix with zeros\n",
    "result = jnp.zeros(shape_M)\n",
    "\n",
    "# Compute the result matrix\n",
    "@jit\n",
    "def dot_mat_cov(mat, cov):\n",
    "    \"\"\"dot productbetween [sr_raw_M[i,j],sr_raw_M[j,i]] and diag for each combinations of i and j. where M is a 2x2 matrix of shape 10x10 and diag a 2x2x matrix of 2x2. The return object should be a matrix of shape equal to M.\n",
    "\n",
    "    Args:\n",
    "        mat (2d jax array): _description_\n",
    "        cov (2d jax array): _description_\n",
    "    \"\"\"\n",
    "    def compute_ij(i, j):\n",
    "        # Create the 2x2 tensor from sr_raw_M for indices (i, j)\n",
    "        tensor_2 = jnp.array([[mat[i, j], mat[j, i]]])\n",
    "        \n",
    "        # Perform the dot product with cov\n",
    "        return jnp.einsum('ij,ij->',tensor_2 , cov)\n",
    "    \n",
    "    # Create a result matrix with the same shape as sr_raw_M\n",
    "    result_matrix = jnp.zeros_like(mat)\n",
    "    \n",
    "    # Vectorized computation using broadcasting\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            result_matrix = result_matrix.at[i, j].set(compute_ij(i, j))\n",
    "    \n",
    "    return result_matrix\n",
    "\n",
    "# Compute the result matrix\n",
    "result_matrix = dot_mat_cov(sr_raw_M, diag)\n",
    "\n",
    "# Display the resulting matrix\n",
    "print(\"Dot product betwee matrix and 2x2 cov mat\")\n",
    "print(result_matrix)\n",
    "\n",
    "\n",
    "# sr_to_dr_shape-----------------------------\n",
    "@jit\n",
    "def sr_to_dr_shape(sr):      \n",
    "    # Extract columns\n",
    "    sr1 = array[:, 0] # i to j value\n",
    "    sr2 = array[:, 1] # j to i value\n",
    "\n",
    "    # Create a grid of indices\n",
    "    N = sr.shape[0]\n",
    "    i_indices, j_indices = jnp.tril_indices(N, -1)  # Indices for upper triangle, excluding diagonal\n",
    "\n",
    "    # Generate combinations\n",
    "    return jnp.stack([sr1[i_indices], sr2[j_indices]], axis=-1)\n",
    "\n",
    "\n",
    "array = jnp.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "print(\"sr_to_dr_shape:\")\n",
    "print(sr_to_dr_shape(array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def index(df, cols = 'all'):\n",
    "    index_map = {}\n",
    "    if cols == 'all':\n",
    "        colCat = list(df.select_dtypes(['object']).columns)    \n",
    "        for a in range(len(colCat)):                \n",
    "            df[\"index_\"+ colCat[a]] =  df.loc[:,colCat[a]].astype(\"category\").cat.codes\n",
    "            df[\"index_\"+ colCat[a]] = df[\"index_\"+ colCat[a]].astype(np.int64)\n",
    "            index_map[colCat[a]] = dict(enumerate(df[colCat[a]].astype(\"category\").cat.categories ) )\n",
    "    else:\n",
    "        if isinstance(cols, list) == False:\n",
    "            cols = [cols]\n",
    "        for a in range(len(cols)):\n",
    "            df[\"index_\"+ cols[a]] =  df.loc[:,cols[a]].astype(\"category\").cat.codes\n",
    "            df[\"index_\"+ cols[a]] = df[\"index_\"+ cols[a]].astype(np.int64)\n",
    "            index_map[cols[a]] = dict(enumerate(df[cols[a]].astype(\"category\").cat.categories ) )\n",
    "    df.columns = df.columns.str.replace('.', '_')\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Continuous variable: Model (model 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1367.03it/s, 7 steps of size 7.33e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.8920 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]    154.65      0.28    154.66    154.21    155.07    542.38      1.00\n",
      "      b[0]      0.90      0.04      0.90      0.84      0.97    532.56      1.00\n",
      "      s[0]      5.15      0.20      5.14      4.81      5.44    484.57      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "#from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Howell1.csv', sep=';') \n",
    "m.data = m.data[m.data .age > 18]\n",
    "m.data.weight = m.data.weight - m.data.weight.mean()\n",
    "m.data.age = m.data.age - m.data.age.mean()\n",
    "weight = jnp.array(m.data.weight.values)\n",
    "height = jnp.array(m.data.height.values)\n",
    "# TODO: use jax arrays with hugging face package\n",
    "\n",
    "m.data = dict(height = height, weight = weight)\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s = dist.uniform('s', 0, 50, sample_shape= [1])\n",
    "    a = dist.normal('a', 178, 20, sample_shape= [1])\n",
    "    b = dist.normal('b',  0, 1, sample_shape= [1])  \n",
    "    lk(\"y\", Normal(a + b * weight, s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable: Model (model 5.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1112.14it/s, 1023 steps of size 1.09e-03. acc. prob=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2912 seconds\n",
      "BI took: 1.3888 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.03      0.16      0.03     -0.22      0.28     43.13      1.02\n",
      "      s[0]      1.00      0.12      0.99      0.84      1.22     28.57      1.01\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/milk.csv', sep=';') \n",
    "m.data = index(m.data, cols = \"clade\")\n",
    "m.data[\"K\"] = m.data [\"kcal_per_g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "index_clade = jnp.array(m.data.index_clade.values, dtype=jnp.int32)\n",
    "K = jnp.array(m.data.K.values, dtype=jnp.float32)\n",
    "\n",
    "m.data = dict(K = K, index_clade = index_clade)\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(K, index_clade):\n",
    "    s = dist.exponential('s', 1, sample_shape=[1])\n",
    "    a = dist.normal('a', 0, 0.5, sample_shape=[1])\n",
    "    m = a[index_clade]\n",
    "    lk(\"y\", Normal(m, s), obs=K)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1203.75it/s, 3 steps of size 6.69e-01. acc. prob=0.90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.4784 seconds\n",
      "BI took: 1.6254 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         a      0.36      0.03      0.36      0.33      0.40    677.65      1.00\n",
      "        bs     -0.11      0.03     -0.11     -0.17     -0.06    555.15      1.00\n",
      "        bw      0.20      0.04      0.20      0.16      0.26    355.66      1.00\n",
      "       bws     -0.14      0.04     -0.14     -0.20     -0.08    515.77      1.00\n",
      "     sigma      0.14      0.02      0.14      0.11      0.18    444.69      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/tulips.csv', sep=';') \n",
    "m.data[\"blooms_std\"] = m.data.blooms /m.data.blooms.max()\n",
    "m.data[\"water_cent\"] = m.data.water - m.data.water.mean()\n",
    "m.data[\"shade_cent\"] = m.data.shade - m.data.shade.mean()\n",
    "\n",
    "water_cent = jnp.array(m.data.water_cent.values)\n",
    "blooms_std = jnp.array(m.data.blooms_std.values)\n",
    "shade_cent = jnp.array(m.data.shade_cent.values)\n",
    "\n",
    "\n",
    "m.data = dict(water_cent = water_cent, blooms_std = blooms_std, shade_cent = shade_cent)\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(blooms_std,water_cent, shade_cent):\n",
    "    sigma = dist.exponential('sigma',  1)\n",
    "    bws = dist.normal('bws',  0, 0.25)\n",
    "    bs = dist.normal('bs', 0, 0.25)\n",
    "    bw = dist.normal('bw',  0, 0.25)\n",
    "    a = dist.normal('a',  0.5, 0.25)\n",
    "    mu = a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent\n",
    "    lk(\"y\", Normal(mu, sigma), obs=blooms_std)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial (model 11.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1590.37it/s, 1 steps of size 9.55e-01. acc. prob=0.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 0.6655 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         a      0.33      0.08      0.33      0.19      0.47    206.41      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = bi()\n",
    "m.data = dict(pulled_left = jnp.array(d.pulled_left.values, dtype=jnp.int32))\n",
    "def model(pulled_left):\n",
    "    a = dist.normal('a', 0, 10)\n",
    "    lk(\"y\", Binomial(logits=a), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model, init_strategy = numpyro.infer.initialization.init_to_mean()) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices (model 11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/chimpanzees.csv', sep=';') \n",
    "m.data[\"treatment\"] = 1 + m.data.prosoc_left + 2 * m.data.condition\n",
    "treatment = jnp.array(m.data[\"treatment\"], dtype=jnp.int32)\n",
    "actor = jnp.array(m.data[\"actor\"] )\n",
    "n_actor = len(jnp.unique(actor))\n",
    "n_treatment= len(jnp.unique(treatment))\n",
    "n_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:03<00:00, 301.78it/s, 1023 steps of size 6.48e-04. acc. prob=0.80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.3374 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.46      1.30      0.36     -1.82      2.12      5.02      1.39\n",
      "      a[1]      0.07      0.26      0.08     -0.31      0.52      6.16      1.36\n",
      "      a[2]      3.73      0.45      3.71      3.02      4.40     22.51      1.03\n",
      "      a[3]     -0.11      0.20     -0.12     -0.41      0.22     17.17      1.00\n",
      "      a[4]     -0.01      0.21     -0.03     -0.32      0.31      6.31      1.00\n",
      "      a[5]      0.10      0.15      0.12     -0.15      0.33     26.70      1.01\n",
      "      a[6]      1.69      0.18      1.67      1.41      1.99     11.01      1.00\n",
      "      b[0]      0.22      0.46      0.17     -0.44      0.97      8.12      1.18\n",
      "      b[1]     -0.62      0.24     -0.63     -0.97     -0.22      6.81      1.11\n",
      "      b[2]     -0.08      0.24     -0.11     -0.48      0.23     11.00      1.00\n",
      "      b[3]     -0.51      0.19     -0.52     -0.80     -0.21      8.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/chimpanzees.csv', sep=';') \n",
    "m.data[\"treatment\"] = 1 + m.data.prosoc_left + 2 * m.data.condition\n",
    "treatment = jnp.array(m.data[\"treatment\"], dtype=jnp.int32)\n",
    "actor = jnp.array(m.data[\"actor\"] )\n",
    "pulled_left = jnp.array(m.data[\"pulled_left\"] )\n",
    "n_actor = len(jnp.unique(actor))\n",
    "n_treatment= len(jnp.unique(treatment))\n",
    "\n",
    "m.data = dict(\n",
    "    actor = actor,\n",
    "    treatment = treatment,\n",
    "    pulled_left = pulled_left,\n",
    "    n_actor = n_actor,\n",
    "    n_treatment = n_treatment\n",
    ")\n",
    "\n",
    "def model(n_actor, n_treatment, actor, treatment, pulled_left):\n",
    "    a = dist.normal('a', 0, 1.5, sample_shape = [n_actor])\n",
    "    b = dist.normal('b', 0, 0.5, sample_shape = [n_treatment])\n",
    "    p = a[actor] + b[treatment]\n",
    "    lk(\"y\", Binomial(1, logits=p), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson (model 11.10) PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 08:29:59.359188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1148.76it/s, 511 steps of size 1.04e-03. acc. prob=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2166 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      3.49      0.06      3.49      3.40      3.57     15.07      1.07\n",
      "      b[0]      0.34      0.05      0.34      0.26      0.41     14.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Kline.csv', sep=';') \n",
    "m.data[\"P\"] = m.data.population.apply(math.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "m.data[\"contact_id\"] = (m.data.contact == \"high\").astype(int)\n",
    "m.data = dict(total_tools=m.data.total_tools.values, P=m.data.P.values, cid=m.data.contact_id.values)\n",
    "def model(cid, P, total_tools):\n",
    "    a = dist.normal('a', 3, 0.5, sample_shape= [1])\n",
    "    b = dist.normal('b', 0, 0.2, sample_shape=[1])\n",
    "    l = jnp.exp(a[cid] + b[cid]*P)\n",
    "    lk(\"y\", Poisson(l), obs=total_tools)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (model 11.12) (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>days</th>\n",
       "      <th>monastery</th>\n",
       "      <th>log_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y  days  monastery  log_days\n",
       "0   0.0     1          0   0.00000\n",
       "1   2.0     1          0   0.00000\n",
       "2   0.0     1          0   0.00000\n",
       "3   0.0     1          0   0.00000\n",
       "4   1.0     1          0   0.00000\n",
       "5   3.0     1          0   0.00000\n",
       "6   1.0     1          0   0.00000\n",
       "7   1.0     1          0   0.00000\n",
       "8   1.0     1          0   0.00000\n",
       "9   2.0     1          0   0.00000\n",
       "10  1.0     1          0   0.00000\n",
       "11  1.0     1          0   0.00000\n",
       "12  0.0     1          0   0.00000\n",
       "13  2.0     1          0   0.00000\n",
       "14  1.0     1          0   0.00000\n",
       "15  4.0     1          0   0.00000\n",
       "16  0.0     1          0   0.00000\n",
       "17  2.0     1          0   0.00000\n",
       "18  1.0     1          0   0.00000\n",
       "19  2.0     1          0   0.00000\n",
       "20  0.0     1          0   0.00000\n",
       "21  1.0     1          0   0.00000\n",
       "22  1.0     1          0   0.00000\n",
       "23  1.0     1          0   0.00000\n",
       "24  1.0     1          0   0.00000\n",
       "25  1.0     1          0   0.00000\n",
       "26  1.0     1          0   0.00000\n",
       "27  2.0     1          0   0.00000\n",
       "28  4.0     1          0   0.00000\n",
       "29  6.0     1          0   0.00000\n",
       "30  5.0     7          1   1.94591\n",
       "31  3.0     7          1   1.94591\n",
       "32  3.0     7          1   1.94591\n",
       "33  4.0     7          1   1.94591"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1393.84it/s, 1 steps of size 7.95e-01. acc. prob=0.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 0.7640 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.41      0.22      1.40      1.09      1.79    319.78      1.00\n",
      "      b[0]      0.28      0.66      0.26     -0.63      1.47    326.37      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data = dict(\n",
    "    log_days = jnp.array(d.log_days.values),\n",
    "    monastery = jnp.array(d.monastery.values),\n",
    "    output = jnp.array(d.y.values)\n",
    ")\n",
    "\n",
    "def model(log_days, monastery, output):\n",
    "    a = dist.normal('a', 0, 1, sample_shape=[1])\n",
    "    b = dist.normal('b', 0, 1, sample_shape=[1])\n",
    "    l = log_days + a +  b * monastery\n",
    "    lk(\"y\", Poisson(rate = l), obs=output)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial (model 11.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = jnp.array(tf.nn.softmax(score))\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = tfd.Categorical(probs=p).sample(seed = init_key, sample_shape = N)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)\n",
    "career = jnp.array(d.career.values)\n",
    "career_income = jnp.array(d.income.values)\n",
    "income = jnp.array(income)\n",
    "m.data = dict(\n",
    "    income = income,\n",
    "    career = career\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1001.23it/s, 7 steps of size 2.85e-01. acc. prob=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.8195 seconds\n",
      "BI took: 1.0786 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      2.37      0.77      2.38      1.31      3.76    145.16      1.00\n",
      "      a[1]     -2.62      0.77     -2.62     -3.80     -1.45    139.20      1.00\n",
      "      b[0]      0.23      0.20      0.17      0.00      0.49    342.90      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "def model(income, career):\n",
    "    a = dist.normal('a', 0, 1, sample_shape= [2])\n",
    "    b = dist.halfnormal('b', 0.5, sample_shape=[1])\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = a[0] + b * income[0]\n",
    "    p = jax.nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    lk(\"y\", Categorical(probs =  p[career]), obs=career)\n",
    "\n",
    "# Run sampler ------------------------------------------------ \n",
    "m.run(model)  \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (model m12.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 847.01it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.0819 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/UCBadmit.csv', sep=';') \n",
    "m.data[\"gid\"] = (m.data[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.data[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.data[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.data[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential('phi', 1, sample_shape=[1])\n",
    "    alpha = dist.normal('alpha', 0., 1.5, sample_shape=[2])\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 870.88it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2368 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/UCBadmit.csv', sep=';') \n",
    "m.data[\"gid\"] = (m.data[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.data[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.data[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.data[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential('phi', 1, sample_shape=[1])\n",
    "    alpha = dist.normal('alpha', 0., 1.5, sample_shape=[2])\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1360.33it/s, 15 steps of size 5.52e-01. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.1393 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "        al      0.12      0.08      0.12     -0.02      0.24    196.44      1.00\n",
      "        ap     -1.35      0.32     -1.33     -1.82     -0.86    266.48      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "from jax.scipy.special import expit\n",
    "r.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "\n",
    "m.data = dict(\n",
    "    y = jnp.array(y)\n",
    ")\n",
    "\n",
    "def model(y):\n",
    "    al = dist.normal('al', 1, 0.5, [1])\n",
    "    ap = dist.normal('ap', -1.5, 1, [1])\n",
    "    p = expit(ap)\n",
    "    lambda_ = jnp.exp(al)\n",
    "    lk(\"y\", ZeroInflatedPoisson(p, lambda_), obs=y)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. OrderedLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    }
   ],
   "source": [
    "import numpyro.distributions as dist\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Trolley.csv', sep=';') \n",
    "d = m.data\n",
    "# discrete proportion of each response value\n",
    "pr_k = d.response.value_counts().sort_index().values / d.shape[0]\n",
    "# cumsum converts to cumulative proportions\n",
    "cum_pr_k = jnp.cumsum(pr_k, -1)\n",
    "logit = lambda x: jnp.log(x / (1 - x))  # convenience function\n",
    "lco = logit(cum_pr_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "transforms must be a Transform or a list of Transforms",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run sampler ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     14\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[0;32m---> 15\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     16\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BI/bi/honnor/main.py:129\u001b[0m, in \u001b[0;36mbi.run\u001b[0;34m(self, model, potential_fn, kinetic_fn, step_size, inverse_mass_matrix, adapt_step_size, adapt_mass_matrix, dense_mass, target_accept_prob, trajectory_length, max_tree_depth, init_strategy, find_heuristic_step_size, forward_mode_differentiation, regularize_mass_matrix, num_warmup, num_samples, num_chains, thinning, postprocess_fn, chain_method, progress_bar, jit_model_args)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m MCMC(NUTS(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    106\u001b[0m                         potential_fn\u001b[38;5;241m=\u001b[39mpotential_fn,\n\u001b[1;32m    107\u001b[0m                         kinetic_fn\u001b[38;5;241m=\u001b[39mkinetic_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    127\u001b[0m                         jit_model_args\u001b[38;5;241m=\u001b[39mjit_model_args)\n\u001b[1;32m    128\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()  \n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:644\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m map_args \u001b[38;5;241m=\u001b[39m (rng_key, init_state, init_params)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 644\u001b[0m     states_flat, last_state \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     states \u001b[38;5;241m=\u001b[39m tree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[jnp\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], states_flat)\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:426\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Check if _sample_fn is None, then we need to initialize the sampler.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sample_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 426\u001b[0m     new_init_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     init_state \u001b[38;5;241m=\u001b[39m new_init_state \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m init_state\n\u001b[1;32m    434\u001b[0m sample_fn, postprocess_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cached_fns()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:743\u001b[0m, in \u001b[0;36mHMC.init\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# vectorized\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     rng_key, rng_key_init_model \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mswapaxes(\n\u001b[1;32m    741\u001b[0m         vmap(random\u001b[38;5;241m.\u001b[39msplit)(rng_key), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    742\u001b[0m     )\n\u001b[0;32m--> 743\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_key_init_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn \u001b[38;5;129;01mand\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid value of `init_params` must be provided with\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `potential_fn`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:687\u001b[0m, in \u001b[0;36mHMC._init_state\u001b[0;34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         (\n\u001b[1;32m    683\u001b[0m             new_init_params,\n\u001b[1;32m    684\u001b[0m             potential_fn,\n\u001b[1;32m    685\u001b[0m             postprocess_fn,\n\u001b[1;32m    686\u001b[0m             model_trace,\n\u001b[0;32m--> 687\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforward_mode_differentiation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_mode_differentiation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m             init_params \u001b[38;5;241m=\u001b[39m new_init_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/util.py:656\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[1;32m    646\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[1;32m    647\u001b[0m substituted_model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[1;32m    648\u001b[0m     seed(model, rng_key \u001b[38;5;28;01mif\u001b[39;00m is_prng_key(rng_key) \u001b[38;5;28;01melse\u001b[39;00m rng_key[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    649\u001b[0m     substitute_fn\u001b[38;5;241m=\u001b[39minit_strategy,\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    651\u001b[0m (\n\u001b[1;32m    652\u001b[0m     inv_transforms,\n\u001b[1;32m    653\u001b[0m     replay_model,\n\u001b[1;32m    654\u001b[0m     has_enumerate_support,\n\u001b[1;32m    655\u001b[0m     model_trace,\n\u001b[0;32m--> 656\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstituted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# substitute param sites from model_trace to model so\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# we don't need to generate again parameters of `numpyro.module`\u001b[39;00m\n\u001b[1;32m    659\u001b[0m model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[1;32m    660\u001b[0m     model,\n\u001b[1;32m    661\u001b[0m     data\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     },\n\u001b[1;32m    666\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/util.py:450\u001b[0m, in \u001b[0;36m_get_model_transforms\u001b[0;34m(model, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_transforms\u001b[39m(model, model_args\u001b[38;5;241m=\u001b[39m(), model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    449\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[0;32m--> 450\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     inv_transforms \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# model code may need to be replayed in the presence of deterministic sites\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/handlers.py:171\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(response):\n\u001b[0;32m----> 6\u001b[0m     cutpoints \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformeddistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcutpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                         \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mOrderedTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     lk(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist\u001b[38;5;241m.\u001b[39mOrderedLogistic(\u001b[38;5;241m0\u001b[39m, cutpoints), obs\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m~/BI/bi/honnor/dists.py:934\u001b[0m, in \u001b[0;36mDist.transformeddistribution\u001b[0;34m(self, name, base_distribution, transforms, validate_args, sample_shape)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformeddistribution\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, base_distribution, transforms, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_shape\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m    TransformedDistribution distribution.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m        sample_shape: Shape of samples to be drawn.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpyro\u001b[38;5;241m.\u001b[39msample(name, \u001b[43mnumpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformedDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_distribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand(sample_shape))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/distributions/distribution.py:99\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/distributions/distribution.py:971\u001b[0m, in \u001b[0;36mTransformedDistribution.__init__\u001b[0;34m(self, base_distribution, transforms, validate_args)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transforms, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(t, Transform) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transforms):\n\u001b[0;32m--> 971\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms must be a Transform or a list of Transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms must be a Transform or list, but was \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(transforms)\n\u001b[1;32m    977\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: transforms must be a Transform or a list of Transforms"
     ]
    }
   ],
   "source": [
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions.transforms import OrderedTransform\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(response = jnp.array(d.response.values - 1))\n",
    "def model(response):\n",
    "    cutpoints = numpyro.sample(\n",
    "        \n",
    "        dist.transformeddistribution(\"cutpoints\",\n",
    "            dist.Normal(0, 1.5, sample_shape = [6]), OrderedTransform()\n",
    "        ),\n",
    "    )\n",
    "    numpyro.sample(\"R\", dist.OrderedLogistic(0, cutpoints), obs=response)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying interceps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 939.01it/s, 15 steps of size 1.06e-01. acc. prob=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9784 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  a_bar[0]      0.83      0.90      0.92     -0.12      2.42     28.91      1.08\n",
      "  alpha[0]      0.83      0.07      0.84      0.72      0.92    152.28      1.01\n",
      "  alpha[1]      0.80      1.55      0.89     -1.53      3.38     82.40      1.03\n",
      "  alpha[2]      0.82      1.86      0.90     -1.22      3.84     89.87      1.03\n",
      "  alpha[3]      0.83      1.53      0.90     -1.36      3.15    109.65      1.01\n",
      "  alpha[4]      0.84      1.78      0.89     -2.14      3.17    108.21      1.02\n",
      "  alpha[5]      0.87      1.54      0.98     -1.71      3.08     67.36      1.03\n",
      "  alpha[6]      0.77      1.78      0.85     -1.66      3.43     85.76      1.02\n",
      "  alpha[7]      0.90      1.52      1.05     -1.68      2.92     73.27      1.05\n",
      "  alpha[8]      0.79      1.57      0.89     -1.19      3.30     76.00      1.04\n",
      "  alpha[9]      0.83      1.51      0.87     -1.21      2.83     75.38      1.02\n",
      " alpha[10]      0.79      1.71      0.96     -1.14      3.65     82.64      1.03\n",
      " alpha[11]      0.82      1.57      0.91     -1.17      3.07     84.09      1.02\n",
      " alpha[12]      0.85      1.73      0.90     -1.58      3.60     74.53      1.04\n",
      " alpha[13]      0.79      1.68      0.86     -1.60      3.24    163.52      1.02\n",
      " alpha[14]      0.85      1.58      0.94     -0.94      3.83     89.79      1.02\n",
      " alpha[15]      0.87      1.63      0.89     -1.28      3.15    102.49      1.01\n",
      " alpha[16]      0.84      1.59      0.96     -1.42      3.11     76.68      1.03\n",
      " alpha[17]      0.91      1.70      0.91     -1.63      3.38     89.86      1.02\n",
      " alpha[18]      0.88      1.62      0.99     -1.49      3.20     79.28      1.03\n",
      " alpha[19]      0.85      1.60      0.91     -1.43      3.48     79.63      1.03\n",
      " alpha[20]      0.87      1.70      0.96     -1.08      3.32     98.30      1.02\n",
      " alpha[21]      0.80      1.60      0.89     -1.63      3.33     91.41      1.02\n",
      " alpha[22]      0.88      1.52      0.94     -1.27      3.35     88.01      1.03\n",
      " alpha[23]      0.87      1.60      0.95     -1.06      3.59    133.47      1.01\n",
      " alpha[24]      0.76      1.80      0.93     -0.87      3.87     95.39      1.03\n",
      " alpha[25]      0.81      1.74      0.91     -1.85      3.51     82.99      1.02\n",
      " alpha[26]      0.86      1.76      0.90     -1.31      3.65     66.97      1.02\n",
      " alpha[27]      0.77      1.67      0.93     -2.01      3.29     82.09      1.03\n",
      " alpha[28]      0.83      1.62      0.92     -0.63      3.88     83.88      1.02\n",
      " alpha[29]      0.70      1.89      0.91     -1.41      3.62     85.67      1.05\n",
      " alpha[30]      0.82      1.49      0.90     -1.02      3.21     82.11      1.02\n",
      " alpha[31]      0.85      1.41      0.94     -0.88      2.74     74.49      1.03\n",
      " alpha[32]      0.80      1.60      0.88     -1.55      3.14     93.61      1.02\n",
      " alpha[33]      0.92      1.67      0.94     -1.64      3.46     95.65      1.00\n",
      " alpha[34]      0.86      1.67      0.92     -1.48      3.25     62.73      1.02\n",
      " alpha[35]      0.79      1.73      0.93     -1.72      3.39    106.68      1.03\n",
      " alpha[36]      0.88      1.47      1.00     -0.94      3.26     68.86      1.04\n",
      " alpha[37]      0.85      1.72      0.92     -2.14      3.07    106.00      1.02\n",
      " alpha[38]      0.87      1.47      0.89     -1.24      3.12     77.45      1.03\n",
      " alpha[39]      0.75      1.86      0.96     -1.97      3.44     85.08      1.03\n",
      " alpha[40]      0.78      1.87      1.03     -1.32      3.91     84.61      1.02\n",
      " alpha[41]      0.72      1.93      0.84     -1.27      4.30    109.55      1.02\n",
      " alpha[42]      0.84      1.79      0.94     -1.24      3.23     90.72      1.02\n",
      " alpha[43]      0.86      1.54      0.97     -1.45      3.30     89.63      1.02\n",
      " alpha[44]      0.92      1.66      1.09     -1.12      3.76    111.30      1.01\n",
      " alpha[45]      0.89      1.70      0.93     -1.15      3.43    229.84      1.01\n",
      " alpha[46]      0.90      1.52      0.91     -1.55      2.76     85.47      1.01\n",
      " alpha[47]      0.77      1.82      0.87     -1.34      3.97     87.19      1.03\n",
      "  sigma[0]      1.11      0.87      0.85      0.29      2.14     11.96      1.11\n",
      "\n",
      "Number of divergences: 3\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/reedfrogs.csv', sep=';') \n",
    "m.data[\"tank\"] = np.arange(m.data.shape[0])\n",
    "tank = jnp.array(m.data[\"tank\"].astype('int32').values)\n",
    "density = jnp.array(m.data[\"density\"].astype('float32').values)\n",
    "surv = jnp.array(m.data[\"surv\"].astype('int32').values)\n",
    "m.data = dict(\n",
    "    tank = tank,\n",
    "    surv = surv\n",
    ")\n",
    "\n",
    "def model(tank, surv):\n",
    "    sigma = dist.exponential('sigma', 1, sample_shape= [1])\n",
    "    a_bar = dist.normal('a_bar', 0., 1.5, sample_shape= [1])\n",
    "    alpha = dist.normal('alpha', a_bar, sigma, sample_shape= [48])\n",
    "    p = jnp.squeeze(alpha[tank])[0]\n",
    "    lk(\"y\", Binomial(total_count = density, logits = p), obs=surv)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dd\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "jnp.array([1, 2, 3, 4]).reshape(2, 2).T\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = sample.multivariatenormal(Mu, Sigma, sample_shape=(N_cafes,))\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = sample.normal(mu, sigma)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:37<00:00, 26.80it/s, 31 steps of size 1.35e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 37.5668 seconds\n",
      "BI took: 37.6322 seconds\n",
      "\n",
      "                         mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "           Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "           Rho[0,1]     -0.46      0.33     -0.50     -0.95     -0.00    245.91      1.00\n",
      "           Rho[1,0]     -0.46      0.33     -0.50     -0.95     -0.00    245.91      1.00\n",
      "           Rho[1,1]      1.00      0.00      1.00      1.00      1.00     18.97      1.00\n",
      "                  a      3.50      0.17      3.50      3.20      3.74    273.45      1.00\n",
      " a_cafe,b_cafe[0,0]      3.22      0.18      3.21      2.94      3.48    416.72      1.00\n",
      " a_cafe,b_cafe[0,1]     -0.83      0.14     -0.84     -1.06     -0.62    187.79      1.00\n",
      " a_cafe,b_cafe[1,0]      4.34      0.19      4.34      4.01      4.60    479.57      1.00\n",
      " a_cafe,b_cafe[1,1]     -0.97      0.17     -0.96     -1.25     -0.72    355.66      1.00\n",
      " a_cafe,b_cafe[2,0]      3.71      0.19      3.72      3.42      4.00    439.08      1.00\n",
      " a_cafe,b_cafe[2,1]     -0.85      0.16     -0.87     -1.09     -0.62    255.08      1.00\n",
      " a_cafe,b_cafe[3,0]      2.65      0.19      2.65      2.38      2.95    345.45      1.00\n",
      " a_cafe,b_cafe[3,1]     -0.73      0.17     -0.74     -0.99     -0.48    108.57      1.01\n",
      " a_cafe,b_cafe[4,0]      3.48      0.19      3.50      3.17      3.74    534.37      1.00\n",
      " a_cafe,b_cafe[4,1]     -0.84      0.15     -0.85     -1.06     -0.60    258.23      1.00\n",
      " a_cafe,b_cafe[5,0]      2.65      0.18      2.65      2.39      2.93    346.10      1.00\n",
      " a_cafe,b_cafe[5,1]     -0.80      0.16     -0.81     -1.06     -0.57    202.30      1.00\n",
      " a_cafe,b_cafe[6,0]      3.76      0.19      3.75      3.43      4.04    540.90      1.00\n",
      " a_cafe,b_cafe[6,1]     -0.82      0.15     -0.83     -1.06     -0.57    172.70      1.00\n",
      " a_cafe,b_cafe[7,0]      3.41      0.18      3.40      3.11      3.69    624.66      1.00\n",
      " a_cafe,b_cafe[7,1]     -0.82      0.16     -0.83     -1.05     -0.60    242.48      1.02\n",
      " a_cafe,b_cafe[8,0]      3.16      0.17      3.15      2.86      3.39    306.17      1.00\n",
      " a_cafe,b_cafe[8,1]     -0.87      0.13     -0.85     -1.09     -0.69    173.76      1.00\n",
      " a_cafe,b_cafe[9,0]      2.94      0.18      2.94      2.68      3.22    502.99      1.00\n",
      " a_cafe,b_cafe[9,1]     -0.85      0.14     -0.84     -1.08     -0.63    287.16      1.00\n",
      "a_cafe,b_cafe[10,0]      3.89      0.18      3.89      3.63      4.20    688.35      1.00\n",
      "a_cafe,b_cafe[10,1]     -0.92      0.14     -0.91     -1.13     -0.70    319.10      1.00\n",
      "a_cafe,b_cafe[11,0]      3.30      0.19      3.30      2.96      3.55    351.62      1.00\n",
      "a_cafe,b_cafe[11,1]     -0.85      0.16     -0.84     -1.11     -0.62    288.40      1.00\n",
      "a_cafe,b_cafe[12,0]      2.81      0.18      2.81      2.53      3.08    710.28      1.00\n",
      "a_cafe,b_cafe[12,1]     -0.83      0.15     -0.84     -1.05     -0.60    309.20      1.00\n",
      "a_cafe,b_cafe[13,0]      3.20      0.18      3.20      2.95      3.51    468.17      1.01\n",
      "a_cafe,b_cafe[13,1]     -0.74      0.18     -0.76     -0.98     -0.44    133.58      1.03\n",
      "a_cafe,b_cafe[14,0]      3.33      0.17      3.32      3.01      3.57    582.10      1.00\n",
      "a_cafe,b_cafe[14,1]     -0.84      0.15     -0.84     -1.05     -0.60    278.94      1.00\n",
      "a_cafe,b_cafe[15,0]      4.54      0.18      4.53      4.26      4.82    580.67      1.00\n",
      "a_cafe,b_cafe[15,1]     -0.97      0.17     -0.96     -1.23     -0.70    298.50      1.00\n",
      "a_cafe,b_cafe[16,0]      5.36      0.20      5.35      5.06      5.67    455.52      1.00\n",
      "a_cafe,b_cafe[16,1]     -1.06      0.20     -1.04     -1.34     -0.72    236.64      1.01\n",
      "a_cafe,b_cafe[17,0]      4.23      0.20      4.23      3.94      4.56    127.01      1.01\n",
      "a_cafe,b_cafe[17,1]     -1.07      0.20     -1.02     -1.36     -0.76     70.05      1.02\n",
      "a_cafe,b_cafe[18,0]      2.34      0.19      2.34      2.07      2.66    443.97      1.00\n",
      "a_cafe,b_cafe[18,1]     -0.74      0.17     -0.76     -1.01     -0.49    177.94      1.01\n",
      "a_cafe,b_cafe[19,0]      3.57      0.18      3.57      3.26      3.84    530.12      1.00\n",
      "a_cafe,b_cafe[19,1]     -0.93      0.15     -0.91     -1.18     -0.70    179.35      1.00\n",
      "                  b     -0.87      0.08     -0.87     -1.00     -0.74    118.42      1.00\n",
      "           sigma[0]      0.52      0.03      0.52      0.48      0.57    637.68      1.00\n",
      "      sigma_cafe[0]      0.77      0.13      0.76      0.57      0.95    460.14      1.01\n",
      "      sigma_cafe[1]      0.16      0.08      0.16      0.03      0.26     42.23      1.06\n",
      "\n",
      "Number of divergences: 2\n"
     ]
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(\n",
    "    cafe = cafe_id, \n",
    "    wait = wait, \n",
    "    N_cafes = N_cafes\n",
    ")\n",
    "def model(cafe, wait, N_cafes):\n",
    "    a = dist.normal(\"a\", 5, 2)\n",
    "    b = dist.normal(\"b\", -1, 0.5)\n",
    "    sigma_cafe = dist.exponential('sigma_cafe', 1, sample_shape=[2])\n",
    "    sigma = dist.exponential('sigma', 1, sample_shape=[1])\n",
    "    Rho = dist.lkj(\"Rho\", 2, 2)\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = dist.multivariatenormal(\"a_cafe,b_cafe\",jnp.stack([a, b]), cov, sample_shape = [N_cafes])    \n",
    "\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    lk(\"y\", Normal(mu, sigma), obs=wait)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:39<00:00, 25.49it/s, 31 steps of size 1.32e-01. acc. prob=0.90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 39.7222 seconds\n",
      "BI took: 39.7995 seconds\n",
      "\n",
      "                         mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "           Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "           Rho[0,1]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,0]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,1]      1.00      0.00      1.00      1.00      1.00     61.24      1.00\n",
      "                  a      3.50      0.18      3.50      3.23      3.79    514.91      1.00\n",
      " a_cafe,b_cafe[0,0]      3.21      0.18      3.21      2.94      3.49    363.81      1.00\n",
      " a_cafe,b_cafe[0,1]     -0.83      0.15     -0.84     -1.05     -0.60    249.04      1.00\n",
      " a_cafe,b_cafe[1,0]      4.35      0.18      4.35      4.08      4.66    352.42      1.00\n",
      " a_cafe,b_cafe[1,1]     -0.97      0.17     -0.96     -1.20     -0.68    272.80      1.00\n",
      " a_cafe,b_cafe[2,0]      3.71      0.19      3.71      3.36      3.99    568.49      1.00\n",
      " a_cafe,b_cafe[2,1]     -0.85      0.16     -0.86     -1.08     -0.58    216.11      1.01\n",
      " a_cafe,b_cafe[3,0]      2.64      0.20      2.64      2.37      2.97    487.59      1.00\n",
      " a_cafe,b_cafe[3,1]     -0.70      0.18     -0.72     -0.98     -0.43    102.60      1.01\n",
      " a_cafe,b_cafe[4,0]      3.48      0.19      3.49      3.20      3.75    534.61      1.00\n",
      " a_cafe,b_cafe[4,1]     -0.84      0.15     -0.84     -1.05     -0.58    265.62      1.00\n",
      " a_cafe,b_cafe[5,0]      2.65      0.18      2.64      2.39      2.96    534.49      1.00\n",
      " a_cafe,b_cafe[5,1]     -0.79      0.17     -0.80     -1.01     -0.49    200.19      1.00\n",
      " a_cafe,b_cafe[6,0]      3.75      0.18      3.76      3.47      4.05    781.58      1.00\n",
      " a_cafe,b_cafe[6,1]     -0.82      0.16     -0.84     -1.06     -0.55    171.69      1.00\n",
      " a_cafe,b_cafe[7,0]      3.41      0.19      3.41      3.14      3.70    437.90      1.01\n",
      " a_cafe,b_cafe[7,1]     -0.81      0.15     -0.82     -1.04     -0.57    209.64      1.02\n",
      " a_cafe,b_cafe[8,0]      3.15      0.17      3.15      2.86      3.37    555.12      1.00\n",
      " a_cafe,b_cafe[8,1]     -0.87      0.14     -0.86     -1.10     -0.67    213.95      1.00\n",
      " a_cafe,b_cafe[9,0]      2.94      0.19      2.94      2.68      3.25    514.75      1.00\n",
      " a_cafe,b_cafe[9,1]     -0.85      0.17     -0.85     -1.09     -0.57    308.92      1.00\n",
      "a_cafe,b_cafe[10,0]      3.89      0.18      3.88      3.59      4.16    570.16      1.00\n",
      "a_cafe,b_cafe[10,1]     -0.92      0.15     -0.91     -1.14     -0.69    283.55      1.00\n",
      "a_cafe,b_cafe[11,0]      3.31      0.20      3.30      2.99      3.60    501.42      1.00\n",
      "a_cafe,b_cafe[11,1]     -0.84      0.17     -0.84     -1.08     -0.53    328.56      1.00\n",
      "a_cafe,b_cafe[12,0]      2.79      0.18      2.80      2.51      3.08    661.61      1.00\n",
      "a_cafe,b_cafe[12,1]     -0.82      0.16     -0.82     -1.06     -0.58    300.02      1.00\n",
      "a_cafe,b_cafe[13,0]      3.18      0.19      3.17      2.93      3.53    243.63      1.01\n",
      "a_cafe,b_cafe[13,1]     -0.73      0.19     -0.75     -0.99     -0.40     96.66      1.03\n",
      "a_cafe,b_cafe[14,0]      3.33      0.18      3.32      3.07      3.66    523.19      1.00\n",
      "a_cafe,b_cafe[14,1]     -0.83      0.15     -0.85     -1.05     -0.58    319.39      1.00\n",
      "a_cafe,b_cafe[15,0]      4.54      0.18      4.54      4.25      4.83    401.77      1.00\n",
      "a_cafe,b_cafe[15,1]     -0.98      0.17     -0.98     -1.23     -0.73    280.91      1.00\n",
      "a_cafe,b_cafe[16,0]      5.36      0.21      5.35      5.04      5.70    437.80      1.00\n",
      "a_cafe,b_cafe[16,1]     -1.08      0.23     -1.08     -1.45     -0.76    244.11      1.00\n",
      "a_cafe,b_cafe[17,0]      4.24      0.19      4.24      3.90      4.52    163.09      1.00\n",
      "a_cafe,b_cafe[17,1]     -1.09      0.21     -1.06     -1.41     -0.77     82.77      1.00\n",
      "a_cafe,b_cafe[18,0]      2.32      0.19      2.32      2.02      2.62    426.39      1.00\n",
      "a_cafe,b_cafe[18,1]     -0.72      0.18     -0.75     -0.96     -0.42    155.20      1.02\n",
      "a_cafe,b_cafe[19,0]      3.57      0.18      3.57      3.31      3.89    688.04      1.00\n",
      "a_cafe,b_cafe[19,1]     -0.93      0.17     -0.91     -1.21     -0.68    234.35      1.00\n",
      "                  b     -0.86      0.08     -0.86     -0.99     -0.75    174.01      1.00\n",
      "           sigma[0]      0.52      0.03      0.52      0.48      0.57    596.32      1.00\n",
      "      sigma_cafe[0]      0.77      0.13      0.76      0.58      1.00    566.72      1.00\n",
      "      sigma_cafe[1]      0.18      0.09      0.17      0.03      0.30     44.31      1.02\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(\n",
    "    cafe = cafe_id, \n",
    "    wait = wait, \n",
    "    N_cafes = N_cafes\n",
    ")\n",
    "def model(cafe, wait, N_cafes):\n",
    "    a = numpyro.sample(\"a\", dd.Normal(5, 2))\n",
    "    b = numpyro.sample(\"b\", dd.Normal(-1, 0.5))\n",
    "    sigma_cafe = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([2]))\n",
    "    sigma = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([1]))\n",
    "    Rho = numpyro.sample(\"Rho\", dd.LKJ(2, 2))\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = numpyro.sample(\n",
    "        \"a_cafe,b_cafe\", dd.MultivariateNormal(jnp.stack([a, b]), cov).expand([N_cafes])\n",
    "    )\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    lk(\"y\", dd.Normal(mu, sigma), obs=wait)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_4314cm3u/model_4xoavcff.stan', line 20, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.012288 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 122.88 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = 1.06425e+30, but Covariance matrix[2,1] = 1.06425e+30 (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 30, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 1715.6098 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "import numpy as np\n",
    "#try:\n",
    "#  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "#except:\n",
    "#  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    int len;\n",
    "    int N_cafes;\n",
    "    vector[len] wait;\n",
    "    array[len] int afternoon;\n",
    "    array[len] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[N_cafes] b_cafe;\n",
    "    vector[N_cafes] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[len] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[N_cafes] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:N_cafes ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:len ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "    'N_cafes' : N_cafes,\n",
    "    'len' : len(d['wait'].values)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Multiple random effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. STRABD example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import jax.numpy as jnp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Make data\n",
    "N_id = 100\n",
    "\n",
    "# Covariates\n",
    "Kinship = tfd.CholeskyLKJ(N_id, concentration=1.5).sample()\n",
    "Dominant = np.ceil(tfd.CholeskyLKJ(N_id, concentration=1.5).sample())\n",
    "Mass = tfd.Bernoulli(probs=0.4).sample(sample_shape=(N_id,))\n",
    "\n",
    "# Organize into list\n",
    "dyadic_preds = np.full((N_id, N_id, 3), np.nan)\n",
    "\n",
    "dyadic_preds[:, :, 0] = Kinship\n",
    "dyadic_preds[:, :, 1] = Dominant\n",
    "dyadic_preds[:, :, 2] = Kinship * Dominant\n",
    "\n",
    "# Set effect sizes\n",
    "sr_mu = tf.constant([0, 0])\n",
    "sr_sigma = tf.constant([2.2, 1.7])\n",
    "sr_rho = 0.55\n",
    "dr_mu = tf.constant([0, 0])\n",
    "dr_sigma = 1.5\n",
    "dr_rho = 0.6\n",
    "sr_effects_1 = tf.constant([1.9, 1.3])\n",
    "dr_effects_1 = tf.constant([1.2, 1.7, -2.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jax.numpy as jnp\n",
    "with open('STRAND.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['N_networktypes', 'N_id', 'N_responses', 'N_periods', 'N_individual_predictors', 'N_dyadic_predictors', 'outcomes', 'flows', 'individual_predictors', 'dyadic_predictors', 'N_block_predictors', 'N_groups_per_block_type', 'block_predictors', 'outcome_mode', 'exposure'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_networktypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_periods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_individual_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_dyadic_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0,  0,  0, ...,  1,  9, 19],\n",
       "       [ 1,  0,  0, ...,  0,  0,  2],\n",
       "       [ 0,  0,  0, ...,  0,  3, 11],\n",
       "       ...,\n",
       "       [ 4,  0,  0, ...,  0,  1,  0],\n",
       "       [ 3,  0,  0, ...,  0,  0,  9],\n",
       "       [10,  6,  3, ...,  0, 11,  0]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outcomes'] = jnp.array(data['outcomes']).reshape(data['N_id'],data['N_id'])\n",
    "data['outcomes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['flows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['individual_predictors'] = jnp.array(data['individual_predictors']['Mass'])\n",
    "data['individual_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.        ,  0.08778227, -0.1032394 , ...,  0.08142215,\n",
       "        -0.1223947 , -0.1078428 ],\n",
       "       [ 0.08778227,  1.        , -0.1504998 , ...,  0.06893802,\n",
       "        -0.1820744 , -0.00592948],\n",
       "       [-0.1032394 , -0.1504998 ,  1.        , ..., -0.1213151 ,\n",
       "         0.1459238 ,  0.1074177 ],\n",
       "       ...,\n",
       "       [ 0.08142215,  0.06893802, -0.1213151 , ...,  1.        ,\n",
       "        -0.1211644 , -0.03577805],\n",
       "       [-0.1223947 , -0.1820744 ,  0.1459238 , ..., -0.1211644 ,\n",
       "         1.        ,  0.03175739],\n",
       "       [-0.1078428 , -0.00592948,  0.1074177 , ..., -0.03577805,\n",
       "         0.03175739,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship']).reshape(data['N_id'],data['N_id'])\n",
    "Kinship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dominant = jnp.array(data['dyadic_predictors']['Dominant']).reshape(data['N_id'],data['N_id'])\n",
    "Dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_block_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N_groups_per_block_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['block_predictors'] = jnp.array(data['block_predictors'])\n",
    "data['block_predictors'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outcome_mode'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[14, 16, 16, ...,  8, 19, 21],\n",
       "       [13, 11, 16, ..., 15, 21, 26],\n",
       "       [14, 17, 13, ..., 17, 18, 14],\n",
       "       ...,\n",
       "       [22, 18, 15, ..., 14,  6, 13],\n",
       "       [15, 17, 11, ...,  6, 15, 20],\n",
       "       [10, 14, 19, ..., 16, 14, 15]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array(data['exposure']).reshape(data['N_id'],data['N_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.2 Rethinking example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:04<00:00, 244.77it/s, 63 steps of size 9.02e-02. acc. prob=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 8.1093 seconds\n",
      "\n",
      "                  mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "L_Rho_d[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "L_Rho_d[0,1]      0.00      0.00      0.00      0.00      0.00       nan       nan\n",
      "L_Rho_d[1,0]      0.88      0.04      0.88      0.82      0.93     53.74      1.02\n",
      "L_Rho_d[1,1]      0.47      0.07      0.48      0.36      0.57     54.94      1.02\n",
      " Rho_gr[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      " Rho_gr[0,1]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,0]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,1]      1.00      0.00      1.00      1.00      1.00    435.00      1.00\n",
      "        a[0]      0.53      0.17      0.52      0.27      0.79    153.88      1.00\n",
      "     gr[0,0]     -0.49      0.28     -0.48     -0.91     -0.03    252.20      1.01\n",
      "     gr[0,1]      0.21      0.22      0.21     -0.15      0.55    631.29      1.00\n",
      "     gr[1,0]      0.18      0.27      0.20     -0.25      0.62    235.24      1.00\n",
      "     gr[1,1]     -0.13      0.22     -0.13     -0.47      0.20    571.67      1.00\n",
      "     gr[2,0]      1.12      0.26      1.13      0.64      1.48    210.39      1.00\n",
      "     gr[2,1]     -0.33      0.23     -0.33     -0.71      0.04    406.51      1.00\n",
      "     gr[3,0]     -0.72      0.30     -0.72     -1.17     -0.26    256.68      1.00\n",
      "     gr[3,1]      0.34      0.24      0.34     -0.04      0.69    524.76      1.00\n",
      "     gr[4,0]     -0.46      0.27     -0.46     -0.88     -0.07    311.94      1.00\n",
      "     gr[4,1]      0.39      0.22      0.38      0.05      0.73    240.70      1.00\n",
      "     gr[5,0]     -0.96      0.32     -0.96     -1.41     -0.40    315.16      1.00\n",
      "     gr[5,1]      0.56      0.24      0.55      0.21      0.94    353.90      1.00\n",
      "     gr[6,0]     -0.56      0.32     -0.56     -1.05     -0.07    333.21      1.00\n",
      "     gr[6,1]      0.15      0.22      0.15     -0.22      0.49    490.87      1.00\n",
      "     gr[7,0]     -0.73      0.28     -0.73     -1.19     -0.31    233.56      1.00\n",
      "     gr[7,1]      0.25      0.21      0.25     -0.10      0.54    440.49      1.00\n",
      "     gr[8,0]      0.23      0.25      0.23     -0.18      0.61    272.17      1.00\n",
      "     gr[8,1]     -0.26      0.22     -0.26     -0.66      0.05    461.30      1.00\n",
      "     gr[9,0]      1.37      0.26      1.35      0.97      1.78    212.37      1.01\n",
      "     gr[9,1]     -0.43      0.24     -0.43     -0.83     -0.07    479.45      1.00\n",
      "    gr[10,0]     -0.93      0.32     -0.92     -1.47     -0.48    261.43      1.00\n",
      "    gr[10,1]      0.38      0.23      0.38      0.06      0.76    436.37      1.00\n",
      "    gr[11,0]     -0.70      0.31     -0.70     -1.23     -0.25    302.94      1.00\n",
      "    gr[11,1]     -0.09      0.23     -0.08     -0.45      0.29    673.00      1.00\n",
      "    gr[12,0]      0.98      0.27      0.99      0.56      1.42    228.46      1.01\n",
      "    gr[12,1]     -0.25      0.22     -0.25     -0.61      0.07    362.00      1.00\n",
      "    gr[13,0]      0.24      0.30      0.24     -0.15      0.79    200.18      1.00\n",
      "    gr[13,1]      0.24      0.23      0.24     -0.14      0.58    281.45      1.00\n",
      "    gr[14,0]     -0.74      0.30     -0.75     -1.23     -0.31    270.41      1.00\n",
      "    gr[14,1]      0.59      0.23      0.58      0.25      0.98    316.93      1.00\n",
      "    gr[15,0]      0.03      0.27      0.02     -0.36      0.48    239.98      1.00\n",
      "    gr[15,1]      0.47      0.24      0.44      0.15      0.89    238.07      1.00\n",
      "    gr[16,0]      0.57      0.27      0.55      0.17      1.05    167.80      1.00\n",
      "    gr[16,1]      0.19      0.22      0.18     -0.15      0.53    332.53      1.00\n",
      "    gr[17,0]     -0.31      0.31     -0.31     -0.84      0.16    270.13      1.00\n",
      "    gr[17,1]     -0.61      0.28     -0.60     -0.99     -0.08    453.87      1.00\n",
      "    gr[18,0]      0.09      0.29      0.07     -0.41      0.54    257.63      1.00\n",
      "    gr[18,1]      0.02      0.21      0.02     -0.31      0.35    431.74      1.00\n",
      "    gr[19,0]      0.90      0.27      0.88      0.53      1.37    243.69      1.00\n",
      "    gr[19,1]     -0.42      0.23     -0.42     -0.78     -0.04    503.12      1.00\n",
      "    gr[20,0]      1.42      0.25      1.40      1.03      1.85    205.85      1.00\n",
      "    gr[20,1]     -0.37      0.22     -0.37     -0.73      0.01    389.14      1.00\n",
      "    gr[21,0]      0.26      0.28      0.27     -0.20      0.67    237.98      1.00\n",
      "    gr[21,1]     -0.33      0.23     -0.34     -0.70      0.05    334.85      1.00\n",
      "    gr[22,0]      1.13      0.27      1.12      0.73      1.57    226.02      1.00\n",
      "    gr[22,1]     -0.57      0.22     -0.56     -0.92     -0.21    411.56      1.00\n",
      "    gr[23,0]     -0.24      0.28     -0.23     -0.64      0.27    322.79      1.00\n",
      "    gr[23,1]     -0.19      0.22     -0.19     -0.53      0.18    245.26      1.01\n",
      "    gr[24,0]     -1.07      0.33     -1.08     -1.55     -0.55    374.00      1.00\n",
      "    gr[24,1]      0.18      0.23      0.19     -0.20      0.52    360.96      1.00\n",
      "  sigma_d[0]      1.10      0.05      1.10      1.02      1.18    340.08      1.01\n",
      " sigma_gr[0]      0.83      0.14      0.81      0.63      1.05    412.62      1.00\n",
      " sigma_gr[1]      0.43      0.09      0.43      0.29      0.56    255.29      1.00\n",
      "      z[0,0]     -0.17      0.59     -0.21     -1.05      0.76    634.46      1.00\n",
      "      z[0,1]      1.59      0.41      1.59      1.01      2.27    620.52      1.00\n",
      "      z[0,2]      0.56      0.45      0.58     -0.14      1.22    645.43      1.00\n",
      "      z[0,3]      0.57      0.44      0.56     -0.09      1.25    410.03      1.00\n",
      "      z[0,4]      1.11      0.42      1.11      0.47      1.81    519.89      1.00\n",
      "      z[0,5]      0.11      0.53      0.13     -0.59      1.12   1137.88      1.00\n",
      "      z[0,6]      0.03      0.56      0.02     -0.77      0.96   1519.90      1.00\n",
      "      z[0,7]     -0.82      0.65     -0.80     -1.85      0.16    740.06      1.00\n",
      "      z[0,8]      2.31      0.37      2.30      1.69      2.86    603.31      1.00\n",
      "      z[0,9]     -0.55      0.65     -0.51     -1.43      0.54   1341.70      1.00\n",
      "     z[0,10]     -1.00      0.73     -0.96     -2.08      0.17    790.39      1.00\n",
      "     z[0,11]     -0.28      0.58     -0.26     -1.08      0.74    756.81      1.00\n",
      "     z[0,12]      0.50      0.47      0.51     -0.31      1.18    709.48      1.01\n",
      "     z[0,13]      0.66      0.45      0.67      0.05      1.41    655.68      1.00\n",
      "     z[0,14]     -0.90      0.67     -0.86     -2.06      0.06    654.51      1.00\n",
      "     z[0,15]     -0.40      0.54     -0.38     -1.24      0.45    736.60      1.00\n",
      "     z[0,16]     -0.96      0.73     -0.95     -2.17      0.07    889.27      1.00\n",
      "     z[0,17]     -0.54      0.60     -0.53     -1.46      0.46   1240.12      1.00\n",
      "     z[0,18]     -1.36      0.58     -1.38     -2.36     -0.53    512.19      1.00\n",
      "     z[0,19]     -0.41      0.56     -0.42     -1.23      0.49    790.24      1.00\n",
      "     z[0,20]     -1.15      0.75     -1.12     -2.24      0.13   1020.15      1.00\n",
      "     z[0,21]      0.24      0.52      0.24     -0.51      1.08    534.78      1.00\n",
      "     z[0,22]     -1.04      0.73     -1.00     -2.13      0.14   1238.56      1.00\n",
      "     z[0,23]      2.08      0.36      2.10      1.39      2.54    458.14      1.00\n",
      "     z[0,24]     -0.40      0.56     -0.39     -1.18      0.55    817.79      1.00\n",
      "     z[0,25]     -0.25      0.49     -0.21     -1.10      0.47    871.11      1.00\n",
      "     z[0,26]     -0.97      0.56     -0.94     -1.73      0.02    957.89      1.00\n",
      "     z[0,27]     -0.33      0.54     -0.29     -1.10      0.55    643.73      1.00\n",
      "     z[0,28]     -0.85      0.67     -0.80     -1.94      0.25    802.36      1.00\n",
      "     z[0,29]      2.50      0.29      2.48      2.06      2.96    350.11      1.00\n",
      "     z[0,30]      0.80      0.39      0.79      0.17      1.40    612.99      1.00\n",
      "     z[0,31]     -1.21      0.65     -1.16     -2.18     -0.12    733.72      1.00\n",
      "     z[0,32]     -0.81      0.59     -0.78     -1.75      0.05    861.18      1.00\n",
      "     z[0,33]     -1.12      0.69     -1.11     -2.14     -0.04    537.52      1.00\n",
      "     z[0,34]     -0.52      0.56     -0.52     -1.40      0.36    702.57      1.00\n",
      "     z[0,35]     -0.94      0.63     -0.91     -1.82      0.13    819.48      1.00\n",
      "     z[0,36]     -0.65      0.61     -0.62     -1.55      0.34    512.48      1.00\n",
      "     z[0,37]      0.09      0.41      0.10     -0.55      0.69    435.42      1.00\n",
      "     z[0,38]      1.88      0.31      1.90      1.35      2.35    423.23      1.00\n",
      "     z[0,39]     -0.20      0.62     -0.19     -1.20      0.74    902.43      1.00\n",
      "     z[0,40]      0.99      0.36      0.99      0.42      1.57    769.30      1.00\n",
      "     z[0,41]     -0.31      0.52     -0.31     -1.14      0.50    591.50      1.00\n",
      "     z[0,42]     -0.49      0.54     -0.50     -1.40      0.32    656.80      1.00\n",
      "     z[0,43]      2.02      0.34      2.01      1.50      2.57    397.03      1.00\n",
      "     z[0,44]      0.19      0.52      0.21     -0.55      1.09    804.65      1.00\n",
      "     z[0,45]      0.71      0.45      0.72     -0.00      1.38    608.11      1.00\n",
      "     z[0,46]     -0.71      0.64     -0.67     -1.78      0.25    730.98      1.00\n",
      "     z[0,47]      0.52      0.34      0.52     -0.01      1.03    389.15      1.00\n",
      "     z[0,48]      0.93      0.32      0.92      0.47      1.45    376.19      1.00\n",
      "     z[0,49]      1.50      0.28      1.50      1.11      2.02    289.02      1.00\n",
      "     z[0,50]     -0.12      0.44     -0.11     -0.84      0.58    619.12      1.00\n",
      "     z[0,51]     -0.71      0.46     -0.68     -1.35      0.06    530.12      1.00\n",
      "     z[0,52]     -1.48      0.64     -1.43     -2.50     -0.53    811.14      1.00\n",
      "     z[0,53]     -0.11      0.45     -0.10     -0.81      0.58    477.71      1.00\n",
      "     z[0,54]      0.26      0.36      0.27     -0.22      0.90    353.65      1.00\n",
      "     z[0,55]      0.19      0.40      0.20     -0.43      0.75    574.87      1.00\n",
      "     z[0,56]      0.25      0.41      0.28     -0.45      0.85    456.88      1.00\n",
      "     z[0,57]      0.46      0.35      0.45     -0.08      0.98    467.26      1.01\n",
      "     z[0,58]      0.79      0.33      0.78      0.27      1.32    326.67      1.00\n",
      "     z[0,59]     -0.44      0.40     -0.42     -1.14      0.17    528.47      1.00\n",
      "     z[0,60]      0.42      0.33      0.44     -0.16      0.90    350.05      1.00\n",
      "     z[0,61]     -1.30      0.71     -1.28     -2.47     -0.22    806.36      1.00\n",
      "     z[0,62]     -0.45      0.47     -0.42     -1.25      0.29    745.56      1.00\n",
      "     z[0,63]     -0.35      0.48     -0.35     -1.12      0.41    612.22      1.00\n",
      "     z[0,64]     -0.80      0.53     -0.76     -1.54      0.01    517.87      1.01\n",
      "     z[0,65]     -0.53      0.55     -0.49     -1.35      0.38    872.99      1.00\n",
      "     z[0,66]      1.36      0.35      1.36      0.78      1.87    412.75      1.00\n",
      "     z[0,67]     -0.75      0.49     -0.75     -1.32      0.13    718.89      1.00\n",
      "     z[0,68]      0.21      0.38      0.22     -0.36      0.84    533.37      1.00\n",
      "     z[0,69]      0.60      0.48      0.61     -0.16      1.37    591.38      1.00\n",
      "     z[0,70]      2.14      0.35      2.16      1.61      2.69    433.51      1.00\n",
      "     z[0,71]     -0.60      0.68     -0.55     -1.73      0.41    868.17      1.00\n",
      "     z[0,72]     -1.08      0.75     -1.05     -2.26      0.07    761.69      1.00\n",
      "     z[0,73]     -0.82      0.65     -0.76     -1.78      0.22    898.74      1.00\n",
      "     z[0,74]     -0.05      0.55     -0.06     -0.84      0.86    850.49      1.00\n",
      "     z[0,75]     -0.12      0.62     -0.09     -0.98      0.94    410.24      1.00\n",
      "     z[0,76]      0.37      0.56      0.38     -0.55      1.19    619.05      1.00\n",
      "     z[0,77]      0.30      0.55      0.31     -0.61      1.11    648.78      1.00\n",
      "     z[0,78]     -0.04      0.57     -0.00     -0.94      0.81    634.05      1.00\n",
      "     z[0,79]      0.14      0.59      0.17     -0.70      1.08    616.42      1.00\n",
      "     z[0,80]      1.47      0.39      1.47      0.83      2.08    542.98      1.00\n",
      "     z[0,81]     -0.24      0.56     -0.25     -1.00      0.65    577.46      1.00\n",
      "     z[0,82]     -0.54      0.66     -0.52     -1.67      0.42   1290.45      1.00\n",
      "     z[0,83]     -0.58      0.66     -0.53     -1.63      0.42   1047.78      1.00\n",
      "     z[0,84]     -0.85      0.66     -0.84     -1.91      0.16    921.49      1.00\n",
      "     z[0,85]     -0.66      0.59     -0.64     -1.52      0.39    874.25      1.00\n",
      "     z[0,86]     -0.55      0.68     -0.56     -1.55      0.60   1276.49      1.00\n",
      "     z[0,87]      0.41      0.47      0.42     -0.36      1.11    702.88      1.00\n",
      "     z[0,88]     -0.51      0.68     -0.46     -1.68      0.61    792.95      1.00\n",
      "     z[0,89]     -0.08      0.64     -0.06     -1.01      0.92   1083.74      1.00\n",
      "     z[0,90]      1.82      0.38      1.83      1.22      2.42    390.53      1.00\n",
      "     z[0,91]      0.12      0.54      0.16     -0.62      1.06    724.75      1.00\n",
      "     z[0,92]     -1.05      0.75     -1.01     -2.31     -0.00   1129.76      1.00\n",
      "     z[0,93]     -0.66      0.66     -0.61     -1.81      0.35    587.81      1.00\n",
      "     z[0,94]      0.58      0.48      0.58     -0.13      1.41    771.92      1.00\n",
      "     z[0,95]      0.07      0.54      0.07     -0.80      0.90    966.07      1.00\n",
      "     z[0,96]      0.52      0.50      0.51     -0.38      1.27    770.78      1.00\n",
      "     z[0,97]      0.74      0.45      0.75      0.07      1.51    455.98      1.00\n",
      "     z[0,98]     -0.40      0.57     -0.36     -1.36      0.46    608.50      1.00\n",
      "     z[0,99]      0.44      0.48      0.43     -0.36      1.20    497.35      1.00\n",
      "    z[0,100]      0.55      0.45      0.56     -0.15      1.29    528.00      1.00\n",
      "    z[0,101]     -0.34      0.57     -0.30     -1.24      0.53    851.20      1.00\n",
      "    z[0,102]     -1.01      0.83     -0.94     -2.27      0.27    971.05      1.00\n",
      "    z[0,103]     -0.49      0.66     -0.45     -1.54      0.46    711.43      1.00\n",
      "    z[0,104]      0.22      0.55      0.22     -0.68      1.06    400.30      1.00\n",
      "    z[0,105]     -0.66      0.58     -0.66     -1.60      0.23    826.71      1.00\n",
      "    z[0,106]      0.19      0.53      0.22     -0.67      0.98    716.75      1.00\n",
      "    z[0,107]     -0.00      0.51      0.01     -0.78      0.81    863.90      1.00\n",
      "    z[0,108]     -0.74      0.65     -0.69     -1.80      0.22   1386.78      1.00\n",
      "    z[0,109]      0.42      0.50      0.47     -0.34      1.18    970.45      1.00\n",
      "    z[0,110]     -0.37      0.67     -0.34     -1.29      0.86    669.88      1.00\n",
      "    z[0,111]     -1.01      0.80     -0.97     -2.30      0.29    923.15      1.00\n",
      "    z[0,112]     -1.21      0.73     -1.15     -2.27     -0.00    916.09      1.00\n",
      "    z[0,113]      0.49      0.45      0.50     -0.19      1.20    548.90      1.00\n",
      "    z[0,114]      0.83      0.49      0.83     -0.06      1.51    540.14      1.00\n",
      "    z[0,115]     -0.52      0.66     -0.47     -1.65      0.44   1124.47      1.00\n",
      "    z[0,116]     -0.10      0.57     -0.11     -1.09      0.69    786.89      1.00\n",
      "    z[0,117]      1.53      0.45      1.53      0.79      2.18    487.80      1.00\n",
      "    z[0,118]     -0.39      0.62     -0.37     -1.35      0.55    821.07      1.00\n",
      "    z[0,119]     -0.65      0.67     -0.59     -1.77      0.31    592.30      1.00\n",
      "    z[0,120]     -0.26      0.60     -0.23     -1.15      0.74    557.28      1.00\n",
      "    z[0,121]     -1.04      0.83     -0.99     -2.43      0.19   1635.89      1.00\n",
      "    z[0,122]     -0.59      0.64     -0.57     -1.63      0.40    783.15      1.00\n",
      "    z[0,123]     -1.17      0.64     -1.16     -2.19     -0.16    816.31      1.00\n",
      "    z[0,124]     -0.62      0.62     -0.62     -1.65      0.30    889.83      1.00\n",
      "    z[0,125]     -0.70      0.67     -0.71     -1.72      0.40    788.14      1.00\n",
      "    z[0,126]      1.69      0.41      1.69      0.93      2.24    896.64      1.00\n",
      "    z[0,127]     -1.09      0.75     -1.02     -2.16      0.12    656.49      1.00\n",
      "    z[0,128]      0.31      0.59      0.31     -0.68      1.18   1170.97      1.00\n",
      "    z[0,129]     -0.60      0.63     -0.57     -1.68      0.31   1060.75      1.00\n",
      "    z[0,130]      0.06      0.54      0.10     -0.74      0.91    647.01      1.00\n",
      "    z[0,131]     -0.67      0.61     -0.66     -1.71      0.18    471.98      1.00\n",
      "    z[0,132]      0.51      0.48      0.54     -0.17      1.37    813.64      1.00\n",
      "    z[0,133]     -0.21      0.58     -0.22     -1.10      0.71    994.70      1.00\n",
      "    z[0,134]      0.57      0.49      0.61     -0.25      1.27    594.30      1.00\n",
      "    z[0,135]     -0.12      0.55     -0.15     -0.85      0.86    563.03      1.00\n",
      "    z[0,136]      0.59      0.47      0.62     -0.11      1.34    599.37      1.00\n",
      "    z[0,137]      1.17      0.39      1.18      0.61      1.89    540.88      1.00\n",
      "    z[0,138]      0.17      0.54      0.20     -0.74      0.94    600.46      1.00\n",
      "    z[0,139]     -0.50      0.66     -0.45     -1.44      0.47   1113.30      1.00\n",
      "    z[0,140]     -1.14      0.68     -1.13     -2.22     -0.04   1172.11      1.00\n",
      "    z[0,141]      0.03      0.52      0.02     -0.83      0.83    644.73      1.00\n",
      "    z[0,142]      0.28      0.50      0.32     -0.52      1.05    768.58      1.00\n",
      "    z[0,143]     -0.76      0.71     -0.77     -1.87      0.32   1141.37      1.00\n",
      "    z[0,144]     -0.12      0.53     -0.12     -1.03      0.67    812.73      1.00\n",
      "    z[0,145]      1.05      0.44      1.04      0.37      1.73    437.59      1.01\n",
      "    z[0,146]      0.41      0.53      0.46     -0.40      1.28    618.34      1.00\n",
      "    z[0,147]      0.61      0.52      0.61     -0.27      1.39    589.82      1.00\n",
      "    z[0,148]     -0.68      0.60     -0.64     -1.64      0.25    647.19      1.00\n",
      "    z[0,149]     -0.07      0.61     -0.05     -1.05      0.83    849.63      1.00\n",
      "    z[0,150]      0.03      0.64      0.04     -0.93      1.05    775.99      1.00\n",
      "    z[0,151]     -0.33      0.58     -0.30     -1.19      0.59    636.23      1.00\n",
      "    z[0,152]      0.63      0.45      0.62     -0.01      1.39    568.32      1.00\n",
      "    z[0,153]     -0.59      0.67     -0.56     -1.66      0.43    546.03      1.00\n",
      "    z[0,154]      0.02      0.55      0.06     -0.71      0.95    475.82      1.00\n",
      "    z[0,155]      0.85      0.44      0.86      0.18      1.59    701.34      1.00\n",
      "    z[0,156]     -0.20      0.64     -0.19     -1.38      0.69    830.18      1.00\n",
      "    z[0,157]      0.67      0.48      0.68     -0.01      1.50    809.46      1.00\n",
      "    z[0,158]      0.26      0.54      0.27     -0.60      1.07    959.02      1.00\n",
      "    z[0,159]     -0.72      0.64     -0.72     -1.77      0.18    821.02      1.00\n",
      "    z[0,160]      1.10      0.46      1.10      0.40      1.84    527.33      1.01\n",
      "    z[0,161]     -0.19      0.53     -0.20     -1.02      0.61   1105.28      1.00\n",
      "    z[0,162]      0.06      0.59      0.09     -0.94      0.95    775.66      1.00\n",
      "    z[0,163]     -0.16      0.62     -0.11     -1.01      0.92    625.16      1.00\n",
      "    z[0,164]     -1.49      0.73     -1.49     -2.59     -0.34    874.07      1.00\n",
      "    z[0,165]     -1.26      0.69     -1.22     -2.28     -0.17    889.81      1.00\n",
      "    z[0,166]     -0.64      0.64     -0.63     -1.56      0.39    497.15      1.00\n",
      "    z[0,167]     -0.63      0.54     -0.59     -1.47      0.26    410.23      1.00\n",
      "    z[0,168]     -0.67      0.61     -0.62     -1.59      0.30    818.60      1.00\n",
      "    z[0,169]      0.56      0.40      0.57     -0.04      1.17    459.27      1.00\n",
      "    z[0,170]      0.84      0.36      0.85      0.28      1.40    424.70      1.00\n",
      "    z[0,171]      1.19      0.35      1.20      0.71      1.83    444.47      1.00\n",
      "    z[0,172]      0.79      0.49      0.84      0.12      1.68    751.80      1.00\n",
      "    z[0,173]      1.05      0.36      1.04      0.51      1.67    503.59      1.00\n",
      "    z[0,174]      1.02      0.40      1.03      0.36      1.58    699.47      1.00\n",
      "    z[0,175]      0.66      0.41      0.67     -0.00      1.27    935.70      1.00\n",
      "    z[0,176]     -0.05      0.53     -0.03     -0.97      0.70    595.79      1.00\n",
      "    z[0,177]     -0.43      0.56     -0.42     -1.24      0.47    713.89      1.00\n",
      "    z[0,178]      3.35      0.31      3.34      2.91      3.88    321.11      1.01\n",
      "    z[0,179]     -1.16      0.70     -1.15     -2.27     -0.13   1030.45      1.00\n",
      "    z[0,180]      0.39      0.34      0.37     -0.17      0.91    396.79      1.00\n",
      "    z[0,181]      0.70      0.37      0.72      0.09      1.25    409.37      1.00\n",
      "    z[0,182]      0.68      0.36      0.68      0.11      1.24    375.00      1.01\n",
      "    z[0,183]      0.37      0.35      0.37     -0.20      0.90    319.08      1.01\n",
      "    z[0,184]      0.24      0.34      0.24     -0.26      0.82    395.43      1.00\n",
      "    z[0,185]      0.33      0.33      0.35     -0.27      0.82    374.30      1.00\n",
      "    z[0,186]      0.06      0.38      0.08     -0.52      0.65    277.64      1.02\n",
      "    z[0,187]     -0.61      0.52     -0.58     -1.49      0.14    671.37      1.00\n",
      "    z[0,188]     -0.58      0.46     -0.55     -1.31      0.16    622.67      1.00\n",
      "    z[0,189]     -0.63      0.51     -0.60     -1.43      0.21    600.92      1.00\n",
      "    z[0,190]      0.14      0.38      0.13     -0.42      0.82    493.54      1.00\n",
      "    z[0,191]      0.05      0.44      0.07     -0.77      0.62    552.97      1.00\n",
      "    z[0,192]     -0.06      0.46     -0.04     -0.74      0.67    610.33      1.00\n",
      "    z[0,193]     -0.88      0.59     -0.86     -1.75      0.07    608.99      1.00\n",
      "    z[0,194]      1.65      0.29      1.66      1.20      2.12    270.15      1.00\n",
      "    z[0,195]      3.15      0.37      3.13      2.51      3.68    521.79      1.00\n",
      "    z[0,196]      2.12      0.41      2.12      1.49      2.80    597.32      1.00\n",
      "    z[0,197]      0.78      0.47      0.77      0.09      1.62    514.96      1.00\n",
      "    z[0,198]     -0.26      0.64     -0.25     -1.08      0.84    966.59      1.00\n",
      "    z[0,199]     -0.05      0.54     -0.07     -0.86      0.85    582.51      1.00\n",
      "    z[0,200]     -0.76      0.62     -0.73     -1.73      0.22    726.35      1.00\n",
      "    z[0,201]     -0.99      0.82     -1.00     -2.49      0.21    838.98      1.00\n",
      "    z[0,202]     -0.81      0.68     -0.79     -1.83      0.33    618.75      1.00\n",
      "    z[0,203]     -0.83      0.63     -0.82     -1.79      0.17    581.28      1.00\n",
      "    z[0,204]     -0.52      0.56     -0.53     -1.44      0.37    987.87      1.00\n",
      "    z[0,205]     -1.13      0.78     -1.16     -2.28      0.14    914.81      1.00\n",
      "    z[0,206]      0.19      0.54      0.19     -0.72      1.00    625.47      1.01\n",
      "    z[0,207]      0.09      0.56      0.12     -0.83      0.96    558.69      1.00\n",
      "    z[0,208]     -0.34      0.71     -0.34     -1.46      0.72    936.21      1.00\n",
      "    z[0,209]      1.95      0.39      1.95      1.33      2.55    736.58      1.00\n",
      "    z[0,210]      0.11      0.57      0.12     -0.82      1.04    976.36      1.00\n",
      "    z[0,211]     -0.53      0.63     -0.48     -1.49      0.54   1868.17      1.00\n",
      "    z[0,212]     -0.50      0.58     -0.50     -1.33      0.46   1108.42      1.00\n",
      "    z[0,213]     -1.24      0.78     -1.21     -2.38      0.10   1002.83      1.00\n",
      "    z[0,214]     -0.85      0.77     -0.83     -2.09      0.34   1131.52      1.00\n",
      "    z[0,215]     -0.67      0.64     -0.66     -1.63      0.40    852.69      1.00\n",
      "    z[0,216]     -0.91      0.68     -0.89     -2.00      0.17   1007.51      1.00\n",
      "    z[0,217]      0.01      0.54      0.05     -0.85      0.87    649.16      1.00\n",
      "    z[0,218]     -1.06      0.80     -1.02     -2.24      0.28    876.30      1.00\n",
      "    z[0,219]     -0.21      0.56     -0.23     -1.14      0.57    611.49      1.00\n",
      "    z[0,220]     -0.53      0.71     -0.48     -1.71      0.43    726.45      1.00\n",
      "    z[0,221]     -0.36      0.66     -0.35     -1.42      0.68    701.02      1.00\n",
      "    z[0,222]      1.98      0.30      2.00      1.55      2.47    363.57      1.00\n",
      "    z[0,223]     -0.42      0.44     -0.40     -1.18      0.23    757.96      1.00\n",
      "    z[0,224]     -0.00      0.38     -0.02     -0.54      0.63    250.71      1.00\n",
      "    z[0,225]     -1.71      0.63     -1.68     -2.78     -0.82    470.91      1.00\n",
      "    z[0,226]     -1.28      0.72     -1.24     -2.39     -0.05    865.41      1.00\n",
      "    z[0,227]     -0.85      0.59     -0.83     -1.86      0.02    611.60      1.00\n",
      "    z[0,228]      0.99      0.36      0.99      0.48      1.59    394.74      1.00\n",
      "    z[0,229]     -0.91      0.55     -0.89     -1.74      0.01    938.58      1.00\n",
      "    z[0,230]     -1.42      0.67     -1.37     -2.39     -0.41    898.47      1.00\n",
      "    z[0,231]     -0.43      0.57     -0.40     -1.28      0.52    898.61      1.00\n",
      "    z[0,232]     -0.54      0.56     -0.50     -1.47      0.25    754.87      1.00\n",
      "    z[0,233]      0.51      0.38      0.52     -0.11      1.04    470.55      1.00\n",
      "    z[0,234]      0.32      0.43      0.34     -0.29      1.04    546.42      1.00\n",
      "    z[0,235]     -0.93      0.53     -0.87     -1.78     -0.18    542.63      1.01\n",
      "    z[0,236]      0.46      0.44      0.49     -0.25      1.16    542.44      1.00\n",
      "    z[0,237]     -0.45      0.58     -0.44     -1.27      0.55    811.08      1.00\n",
      "    z[0,238]     -0.06      0.47     -0.05     -0.85      0.64    335.08      1.00\n",
      "    z[0,239]      0.43      0.45      0.42     -0.28      1.12    636.78      1.00\n",
      "    z[0,240]      0.21      0.45      0.24     -0.47      0.91    711.48      1.00\n",
      "    z[0,241]     -0.98      0.62     -0.96     -2.00     -0.05    807.30      1.00\n",
      "    z[0,242]      0.11      0.50      0.12     -0.63      0.96    667.13      1.00\n",
      "    z[0,243]     -0.48      0.56     -0.42     -1.36      0.39    571.87      1.00\n",
      "    z[0,244]     -1.24      0.65     -1.23     -2.20     -0.23    753.54      1.00\n",
      "    z[0,245]      1.90      0.37      1.90      1.38      2.53    323.03      1.00\n",
      "    z[0,246]     -0.20      0.53     -0.13     -1.22      0.47    572.12      1.00\n",
      "    z[0,247]     -0.35      0.67     -0.33     -1.29      0.84    707.25      1.00\n",
      "    z[0,248]     -0.49      0.60     -0.49     -1.41      0.47    801.34      1.00\n",
      "    z[0,249]      0.38      0.53      0.35     -0.41      1.22    768.09      1.00\n",
      "    z[0,250]      0.96      0.46      0.98      0.33      1.68    706.51      1.00\n",
      "    z[0,251]      0.68      0.48      0.67     -0.10      1.47    590.42      1.00\n",
      "    z[0,252]     -0.90      0.62     -0.90     -1.86      0.14    842.54      1.00\n",
      "    z[0,253]     -0.23      0.62     -0.21     -1.17      0.85    855.32      1.00\n",
      "    z[0,254]     -0.28      0.65     -0.30     -1.39      0.63    731.80      1.00\n",
      "    z[0,255]     -0.32      0.52     -0.31     -1.21      0.38    824.24      1.00\n",
      "    z[0,256]      0.10      0.53      0.11     -0.70      1.01    889.76      1.00\n",
      "    z[0,257]      0.46      0.45      0.47     -0.26      1.16    632.18      1.00\n",
      "    z[0,258]      0.21      0.46      0.23     -0.52      0.96    613.23      1.00\n",
      "    z[0,259]      0.72      0.44      0.71      0.04      1.40    532.79      1.00\n",
      "    z[0,260]     -0.06      0.48     -0.03     -0.76      0.75    957.00      1.00\n",
      "    z[0,261]     -0.01      0.53      0.00     -0.82      0.89    640.34      1.00\n",
      "    z[0,262]     -0.58      0.56     -0.55     -1.42      0.25    738.04      1.00\n",
      "    z[0,263]     -0.12      0.53     -0.10     -0.91      0.72    516.45      1.00\n",
      "    z[0,264]      0.51      0.47      0.52     -0.24      1.27    608.18      1.00\n",
      "    z[0,265]      0.89      0.36      0.88      0.31      1.45    533.97      1.00\n",
      "    z[0,266]      0.71      0.37      0.73      0.12      1.28    578.76      1.00\n",
      "    z[0,267]      0.12      0.43      0.13     -0.55      0.81    540.68      1.00\n",
      "    z[0,268]      1.25      0.35      1.25      0.73      1.86    359.43      1.00\n",
      "    z[0,269]     -0.56      0.52     -0.54     -1.34      0.28    537.63      1.00\n",
      "    z[0,270]      0.65      0.40      0.66      0.05      1.29    717.62      1.00\n",
      "    z[0,271]     -0.37      0.51     -0.30     -1.18      0.42    479.27      1.00\n",
      "    z[0,272]      0.37      0.59      0.38     -0.61      1.26    998.14      1.00\n",
      "    z[0,273]      0.05      0.57      0.05     -0.95      0.88    411.31      1.00\n",
      "    z[0,274]      2.49      0.37      2.51      1.88      3.01    458.86      1.00\n",
      "    z[0,275]     -0.17      0.69     -0.11     -1.26      0.94    605.58      1.00\n",
      "    z[0,276]     -0.82      0.70     -0.84     -1.76      0.51    942.16      1.00\n",
      "    z[0,277]      1.01      0.43      1.01      0.21      1.60    399.46      1.01\n",
      "    z[0,278]     -0.43      0.70     -0.40     -1.74      0.52    703.05      1.00\n",
      "    z[0,279]      0.52      0.48      0.54     -0.24      1.25    837.36      1.00\n",
      "    z[0,280]      0.94      0.40      0.96      0.33      1.57    557.48      1.00\n",
      "    z[0,281]      1.71      0.37      1.71      1.14      2.28    390.09      1.00\n",
      "    z[0,282]     -0.69      0.59     -0.67     -1.58      0.21    681.78      1.00\n",
      "    z[0,283]     -0.02      0.55      0.03     -0.86      0.81   1050.93      1.00\n",
      "    z[0,284]      0.30      0.48      0.33     -0.51      1.05    576.71      1.00\n",
      "    z[0,285]      0.91      0.36      0.91      0.40      1.50    419.41      1.00\n",
      "    z[0,286]     -0.01      0.44      0.01     -0.68      0.67    588.96      1.00\n",
      "    z[0,287]      0.35      0.44      0.35     -0.41      0.99    506.43      1.00\n",
      "    z[0,288]      1.13      0.32      1.10      0.62      1.63    475.75      1.00\n",
      "    z[0,289]     -1.52      0.72     -1.46     -2.64     -0.41    829.40      1.00\n",
      "    z[0,290]      1.10      0.34      1.12      0.55      1.62    354.55      1.00\n",
      "    z[0,291]      0.42      0.39      0.44     -0.26      0.99    675.68      1.00\n",
      "    z[0,292]     -1.62      0.64     -1.59     -2.50     -0.49    670.25      1.00\n",
      "    z[0,293]      0.06      0.36      0.07     -0.59      0.55    453.66      1.00\n",
      "    z[0,294]     -0.61      0.61     -0.54     -1.60      0.29    695.27      1.00\n",
      "    z[0,295]     -0.76      0.69     -0.69     -1.71      0.47    858.41      1.00\n",
      "    z[0,296]     -0.41      0.60     -0.39     -1.31      0.52    766.99      1.00\n",
      "    z[0,297]     -0.71      0.52     -0.72     -1.46      0.21    688.42      1.00\n",
      "    z[0,298]     -0.44      0.46     -0.43     -1.10      0.32    575.33      1.00\n",
      "    z[0,299]     -0.11      0.59     -0.09     -1.09      0.75    649.17      1.00\n",
      "      z[1,0]      0.48      0.93      0.45     -0.96      1.81   1179.23      1.00\n",
      "      z[1,1]      0.05      0.68      0.04     -1.10      1.01   1315.97      1.00\n",
      "      z[1,2]      0.92      0.82      0.95     -0.31      2.24    845.90      1.00\n",
      "      z[1,3]     -0.18      0.86     -0.20     -1.53      1.18   1015.42      1.00\n",
      "      z[1,4]     -0.19      0.83     -0.16     -1.53      1.12   1125.25      1.00\n",
      "      z[1,5]     -0.21      0.90     -0.22     -1.44      1.40    725.40      1.00\n",
      "      z[1,6]      0.32      0.87      0.31     -0.84      1.85   1021.15      1.00\n",
      "      z[1,7]     -0.18      0.95     -0.16     -1.61      1.36   1355.13      1.00\n",
      "      z[1,8]      0.67      0.62      0.68     -0.38      1.60    901.72      1.00\n",
      "      z[1,9]     -0.27      0.89     -0.32     -1.71      1.06   1780.82      1.00\n",
      "     z[1,10]     -0.24      0.97     -0.27     -1.57      1.29   1212.74      1.00\n",
      "     z[1,11]      0.26      0.85      0.25     -1.00      1.56    697.54      1.00\n",
      "     z[1,12]      1.17      0.78      1.19      0.07      2.60   1265.76      1.00\n",
      "     z[1,13]     -0.69      0.86     -0.70     -1.95      0.72    934.22      1.00\n",
      "     z[1,14]     -0.07      0.88     -0.08     -1.38      1.40   1115.40      1.00\n",
      "     z[1,15]      0.35      0.83      0.35     -0.98      1.61   1002.01      1.00\n",
      "     z[1,16]     -0.29      0.89     -0.24     -1.75      1.11   1059.24      1.00\n",
      "     z[1,17]      0.11      0.86      0.11     -1.13      1.57    721.41      1.00\n",
      "     z[1,18]     -0.65      0.90     -0.62     -1.93      0.82    906.81      1.00\n",
      "     z[1,19]      0.17      0.91      0.15     -1.26      1.51   1311.56      1.00\n",
      "     z[1,20]     -0.49      0.98     -0.47     -1.81      1.13    959.11      1.00\n",
      "     z[1,21]      0.64      0.90      0.60     -0.74      1.99    762.35      1.00\n",
      "     z[1,22]     -0.30      1.04     -0.30     -2.09      1.29   1009.67      1.00\n",
      "     z[1,23]     -0.89      0.79     -0.88     -2.13      0.29    832.07      1.00\n",
      "     z[1,24]     -0.18      0.89     -0.16     -1.57      1.15   2097.97      1.00\n",
      "     z[1,25]      0.14      0.85      0.12     -1.33      1.33   1122.71      1.00\n",
      "     z[1,26]      0.25      0.99      0.30     -1.26      1.75   1700.64      1.00\n",
      "     z[1,27]     -0.22      0.93     -0.21     -1.58      1.30    825.07      1.00\n",
      "     z[1,28]      0.19      0.92      0.20     -0.99      1.79   1489.28      1.00\n",
      "     z[1,29]      0.26      0.72      0.27     -0.89      1.28   1023.20      1.00\n",
      "     z[1,30]     -0.09      0.81     -0.09     -1.31      1.18    854.20      1.00\n",
      "     z[1,31]     -0.45      0.94     -0.44     -1.87      1.12    762.36      1.00\n",
      "     z[1,32]     -0.18      0.89     -0.18     -1.63      1.27   1554.03      1.00\n",
      "     z[1,33]     -0.14      0.91     -0.15     -1.41      1.48    996.62      1.00\n",
      "     z[1,34]     -0.25      0.79     -0.18     -1.58      0.87   1426.69      1.00\n",
      "     z[1,35]     -0.42      0.95     -0.38     -1.99      0.94   1037.27      1.00\n",
      "     z[1,36]     -0.26      0.92     -0.20     -1.73      1.09   1006.10      1.00\n",
      "     z[1,37]     -0.01      0.78     -0.02     -1.34      1.13    811.88      1.00\n",
      "     z[1,38]     -0.08      0.62     -0.08     -1.19      0.82   1327.69      1.00\n",
      "     z[1,39]     -0.01      0.90     -0.02     -1.39      1.28   1116.29      1.00\n",
      "     z[1,40]      0.88      0.83      0.88     -0.38      2.16   1015.54      1.00\n",
      "     z[1,41]      0.53      0.85      0.56     -0.80      1.96    807.14      1.00\n",
      "     z[1,42]     -0.32      0.83     -0.26     -1.60      1.00   1371.08      1.00\n",
      "     z[1,43]      1.00      0.63      1.03      0.11      2.14    503.99      1.01\n",
      "     z[1,44]     -0.17      0.81     -0.19     -1.42      1.07    869.92      1.00\n",
      "     z[1,45]     -0.20      0.89     -0.18     -1.75      0.99   1194.30      1.00\n",
      "     z[1,46]     -0.19      0.88     -0.20     -1.74      1.04   1369.59      1.00\n",
      "     z[1,47]     -0.45      0.99     -0.44     -1.94      1.14   1118.05      1.00\n",
      "     z[1,48]     -0.03      0.76     -0.05     -1.11      1.21    785.52      1.00\n",
      "     z[1,49]      0.54      0.85      0.57     -0.70      1.88    902.79      1.01\n",
      "     z[1,50]     -0.35      0.95     -0.34     -1.82      1.12   1096.67      1.00\n",
      "     z[1,51]     -0.20      0.96     -0.20     -1.71      1.14   1512.09      1.00\n",
      "     z[1,52]     -0.23      0.97     -0.24     -1.74      1.25    816.80      1.00\n",
      "     z[1,53]      0.68      0.80      0.63     -0.53      2.08    948.94      1.00\n",
      "     z[1,54]      0.14      0.89      0.17     -1.33      1.53    963.43      1.00\n",
      "     z[1,55]     -0.40      0.92     -0.38     -1.94      0.96   1856.25      1.00\n",
      "     z[1,56]     -0.67      0.88     -0.64     -2.03      0.75   1433.28      1.00\n",
      "     z[1,57]     -0.19      0.84     -0.16     -1.53      1.22    998.35      1.00\n",
      "     z[1,58]      0.94      0.82      0.97     -0.29      2.28    559.85      1.00\n",
      "     z[1,59]      0.01      0.92      0.02     -1.40      1.43   1209.23      1.00\n",
      "     z[1,60]      0.42      0.72      0.41     -0.74      1.57   1459.65      1.00\n",
      "     z[1,61]     -0.19      0.97     -0.16     -1.75      1.42    878.27      1.00\n",
      "     z[1,62]     -0.42      0.90     -0.42     -1.74      1.09   1497.51      1.00\n",
      "     z[1,63]     -0.43      0.82     -0.43     -1.77      0.80    784.83      1.00\n",
      "     z[1,64]     -0.56      0.87     -0.53     -2.01      0.72    771.69      1.00\n",
      "     z[1,65]     -0.05      0.87     -0.02     -1.26      1.47    947.38      1.00\n",
      "     z[1,66]      0.98      0.64      0.96     -0.17      1.90    908.91      1.01\n",
      "     z[1,67]     -0.29      0.93     -0.30     -1.82      1.17   2854.89      1.00\n",
      "     z[1,68]     -0.30      1.03     -0.34     -2.06      1.20    961.27      1.00\n",
      "     z[1,69]      1.29      0.79      1.24      0.14      2.62   1089.39      1.00\n",
      "     z[1,70]     -0.69      0.72     -0.69     -1.87      0.38    976.75      1.00\n",
      "     z[1,71]      0.07      0.99      0.09     -1.41      1.73   1240.68      1.00\n",
      "     z[1,72]     -0.26      0.91     -0.24     -1.51      1.29   1568.77      1.00\n",
      "     z[1,73]     -0.23      0.92     -0.24     -1.48      1.46   1061.82      1.00\n",
      "     z[1,74]     -0.23      0.89     -0.20     -1.56      1.27   1271.39      1.00\n",
      "     z[1,75]     -0.44      0.91     -0.41     -1.96      0.88   1250.05      1.00\n",
      "     z[1,76]      0.39      0.91      0.38     -1.06      1.80   1139.97      1.00\n",
      "     z[1,77]      0.25      0.80      0.21     -0.93      1.60    813.34      1.00\n",
      "     z[1,78]      0.66      0.89      0.70     -0.80      1.86   1136.88      1.00\n",
      "     z[1,79]      0.13      1.01      0.12     -1.45      1.79    921.57      1.00\n",
      "     z[1,80]      0.79      0.74      0.75     -0.30      2.08   1767.00      1.00\n",
      "     z[1,81]     -0.18      0.81     -0.18     -1.62      0.97   1385.07      1.00\n",
      "     z[1,82]     -0.09      0.86     -0.16     -1.36      1.35    942.63      1.00\n",
      "     z[1,83]      0.06      0.88      0.10     -1.43      1.42    863.34      1.00\n",
      "     z[1,84]     -0.30      0.89     -0.32     -1.77      1.16    782.39      1.00\n",
      "     z[1,85]     -0.15      0.93     -0.19     -1.44      1.43    895.78      1.00\n",
      "     z[1,86]     -0.03      0.90     -0.02     -1.64      1.22   1327.11      1.00\n",
      "     z[1,87]      0.14      0.82      0.12     -1.04      1.47    899.56      1.00\n",
      "     z[1,88]     -0.57      0.93     -0.57     -2.28      0.82    677.92      1.00\n",
      "     z[1,89]     -0.03      0.92     -0.02     -1.36      1.36   1652.08      1.00\n",
      "     z[1,90]      1.69      0.69      1.69      0.46      2.65    769.02      1.00\n",
      "     z[1,91]      0.38      0.91      0.37     -1.12      1.72   1421.08      1.00\n",
      "     z[1,92]     -0.26      0.99     -0.28     -1.75      1.23   1112.67      1.00\n",
      "     z[1,93]     -0.02      0.89      0.01     -1.52      1.27    703.39      1.00\n",
      "     z[1,94]     -0.04      0.83     -0.05     -1.30      1.26   1592.68      1.00\n",
      "     z[1,95]      0.61      0.85      0.66     -0.70      1.95   1493.87      1.00\n",
      "     z[1,96]      0.78      0.87      0.80     -0.53      2.13    886.70      1.00\n",
      "     z[1,97]      0.48      0.77      0.50     -0.74      1.64    655.08      1.00\n",
      "     z[1,98]     -0.16      0.87     -0.15     -1.65      1.19   1487.88      1.00\n",
      "     z[1,99]     -0.02      0.84     -0.01     -1.30      1.33   1900.81      1.00\n",
      "    z[1,100]      0.47      0.73      0.46     -0.71      1.55   1161.21      1.00\n",
      "    z[1,101]     -0.15      0.92     -0.19     -1.53      1.25   1091.10      1.00\n",
      "    z[1,102]     -0.41      0.99     -0.42     -1.78      1.26   1680.23      1.00\n",
      "    z[1,103]     -0.37      1.04     -0.45     -2.03      1.30   1873.72      1.00\n",
      "    z[1,104]     -0.96      0.85     -0.98     -2.17      0.47    799.58      1.00\n",
      "    z[1,105]     -0.65      0.85     -0.66     -1.95      0.62    835.60      1.00\n",
      "    z[1,106]      0.16      0.85      0.18     -1.22      1.44   1276.39      1.00\n",
      "    z[1,107]      0.45      0.82      0.44     -0.73      1.88   1345.00      1.00\n",
      "    z[1,108]     -0.12      0.99     -0.10     -1.90      1.22   1071.95      1.00\n",
      "    z[1,109]     -0.24      0.84     -0.24     -1.48      1.10   1371.93      1.00\n",
      "    z[1,110]      0.16      0.96      0.20     -1.22      1.84   1356.36      1.00\n",
      "    z[1,111]     -0.29      0.95     -0.29     -1.77      1.24   1722.37      1.00\n",
      "    z[1,112]     -0.59      0.94     -0.62     -2.14      0.78   1826.95      1.00\n",
      "    z[1,113]      0.73      0.73      0.76     -0.41      1.86    917.86      1.00\n",
      "    z[1,114]      0.29      0.82      0.27     -1.07      1.46   1012.90      1.00\n",
      "    z[1,115]     -0.06      0.93     -0.10     -1.63      1.31   1018.82      1.00\n",
      "    z[1,116]      0.24      0.88      0.23     -1.09      1.70   1285.20      1.00\n",
      "    z[1,117]      0.65      0.74      0.66     -0.64      1.74    895.20      1.00\n",
      "    z[1,118]      0.37      0.90      0.38     -1.07      1.74   2977.97      1.00\n",
      "    z[1,119]      0.09      0.87      0.11     -1.21      1.44   1298.33      1.00\n",
      "    z[1,120]      0.34      0.93      0.36     -1.02      1.84   1049.97      1.00\n",
      "    z[1,121]     -0.43      0.94     -0.43     -1.83      1.19   1200.26      1.00\n",
      "    z[1,122]     -0.04      0.89     -0.07     -1.52      1.25    799.84      1.00\n",
      "    z[1,123]     -0.56      0.87     -0.60     -1.87      0.83   1018.20      1.00\n",
      "    z[1,124]     -0.18      0.92     -0.20     -1.50      1.50   1429.93      1.00\n",
      "    z[1,125]     -0.82      0.92     -0.80     -2.23      0.63    803.25      1.00\n",
      "    z[1,126]      0.09      0.77      0.05     -1.08      1.32    858.53      1.00\n",
      "    z[1,127]     -0.46      0.97     -0.44     -1.90      1.11    755.30      1.00\n",
      "    z[1,128]     -0.21      0.96     -0.20     -1.79      1.16   1407.34      1.00\n",
      "    z[1,129]      0.17      0.93      0.19     -1.26      1.61   1019.42      1.00\n",
      "    z[1,130]      0.61      0.76      0.63     -0.51      1.85   1252.22      1.00\n",
      "    z[1,131]     -0.17      0.91     -0.17     -1.64      1.16    818.11      1.00\n",
      "    z[1,132]      0.17      0.83      0.15     -1.26      1.40   1124.08      1.00\n",
      "    z[1,133]      0.44      0.84      0.43     -0.84      1.71   1242.94      1.00\n",
      "    z[1,134]     -0.58      0.76     -0.58     -1.73      0.66    688.39      1.00\n",
      "    z[1,135]     -0.51      0.85     -0.54     -1.90      0.68   1731.88      1.00\n",
      "    z[1,136]      0.73      0.84      0.74     -0.66      1.89    880.16      1.00\n",
      "    z[1,137]     -0.54      0.77     -0.54     -1.93      0.53   1010.52      1.00\n",
      "    z[1,138]     -0.14      0.86     -0.10     -1.31      1.33    850.29      1.00\n",
      "    z[1,139]     -0.02      0.88     -0.00     -1.47      1.34   1094.61      1.00\n",
      "    z[1,140]     -0.39      0.93     -0.44     -1.64      1.14   1852.65      1.00\n",
      "    z[1,141]      0.50      0.84      0.56     -0.71      1.92    849.62      1.00\n",
      "    z[1,142]      0.83      0.84      0.83     -0.39      2.28   1057.57      1.00\n",
      "    z[1,143]     -0.14      0.94     -0.12     -1.57      1.31    882.73      1.00\n",
      "    z[1,144]      0.24      0.85      0.27     -1.14      1.57   1030.59      1.00\n",
      "    z[1,145]     -0.11      0.80     -0.13     -1.25      1.21   1489.05      1.00\n",
      "    z[1,146]      0.29      0.87      0.28     -0.92      1.73   1111.02      1.00\n",
      "    z[1,147]     -0.09      0.86     -0.07     -1.54      1.16   1260.78      1.00\n",
      "    z[1,148]     -0.18      0.96     -0.16     -1.62      1.42   1078.06      1.00\n",
      "    z[1,149]     -0.40      0.97     -0.44     -2.08      1.10    901.00      1.00\n",
      "    z[1,150]     -0.53      0.93     -0.57     -2.03      0.97    862.60      1.00\n",
      "    z[1,151]     -0.43      0.86     -0.43     -1.75      0.95    922.43      1.00\n",
      "    z[1,152]      0.51      0.78      0.47     -0.85      1.66    933.06      1.00\n",
      "    z[1,153]     -0.31      0.90     -0.29     -1.78      1.00   1462.70      1.00\n",
      "    z[1,154]     -0.21      0.78     -0.19     -1.37      1.03   1008.56      1.00\n",
      "    z[1,155]      0.89      0.81      0.88     -0.41      2.08   1463.21      1.00\n",
      "    z[1,156]      0.22      0.94      0.26     -1.10      1.83   1187.79      1.00\n",
      "    z[1,157]      1.00      0.77      0.96     -0.29      2.24    710.09      1.00\n",
      "    z[1,158]      0.59      0.84      0.56     -0.76      1.88   1988.77      1.00\n",
      "    z[1,159]     -0.16      0.94     -0.18     -1.62      1.31    721.11      1.00\n",
      "    z[1,160]     -0.48      0.80     -0.47     -1.72      0.70   1218.43      1.00\n",
      "    z[1,161]      0.21      0.80      0.17     -0.97      1.67    813.36      1.00\n",
      "    z[1,162]     -0.04      0.92     -0.06     -1.42      1.33    999.76      1.00\n",
      "    z[1,163]      0.47      0.89      0.51     -1.03      1.84   1042.63      1.00\n",
      "    z[1,164]     -0.55      0.93     -0.54     -1.81      1.16   1388.45      1.00\n",
      "    z[1,165]     -0.10      0.88     -0.12     -1.30      1.56   1334.81      1.00\n",
      "    z[1,166]     -0.17      0.93     -0.17     -1.44      1.56   1032.04      1.00\n",
      "    z[1,167]      0.27      0.83      0.31     -1.10      1.53   1205.36      1.00\n",
      "    z[1,168]     -0.02      0.87     -0.01     -1.46      1.27   1334.26      1.00\n",
      "    z[1,169]     -0.51      0.97     -0.50     -2.11      0.97   1890.36      1.00\n",
      "    z[1,170]     -0.09      0.88     -0.07     -1.52      1.16    987.36      1.00\n",
      "    z[1,171]      0.08      0.68      0.08     -0.92      1.17    665.96      1.00\n",
      "    z[1,172]     -0.10      0.82     -0.07     -1.51      1.08   1420.17      1.00\n",
      "    z[1,173]     -0.33      0.81     -0.29     -1.71      0.84    813.83      1.00\n",
      "    z[1,174]      1.55      0.78      1.56      0.39      2.91    829.01      1.00\n",
      "    z[1,175]      0.54      0.72      0.54     -0.75      1.50   1314.25      1.00\n",
      "    z[1,176]      0.45      0.90      0.48     -0.95      1.90    809.52      1.00\n",
      "    z[1,177]     -0.26      0.82     -0.24     -1.52      1.05    761.27      1.00\n",
      "    z[1,178]     -0.10      0.65     -0.08     -1.04      0.97    765.03      1.00\n",
      "    z[1,179]     -0.13      1.03     -0.17     -1.97      1.38   1340.84      1.00\n",
      "    z[1,180]      0.13      0.96      0.12     -1.30      1.68   1419.33      1.00\n",
      "    z[1,181]     -0.52      0.90     -0.53     -1.99      0.97   1525.19      1.00\n",
      "    z[1,182]      0.69      0.72      0.71     -0.33      1.94    733.35      1.00\n",
      "    z[1,183]      0.27      0.77      0.29     -1.00      1.48    787.94      1.00\n",
      "    z[1,184]      0.11      0.98      0.08     -1.33      1.66   1070.13      1.00\n",
      "    z[1,185]      0.12      0.94      0.14     -1.51      1.48   1753.79      1.00\n",
      "    z[1,186]      0.23      0.85      0.30     -1.14      1.43    778.50      1.00\n",
      "    z[1,187]     -0.24      1.01     -0.21     -1.69      1.53   1192.18      1.00\n",
      "    z[1,188]     -0.34      0.97     -0.34     -2.09      1.03    966.64      1.00\n",
      "    z[1,189]     -0.65      0.88     -0.67     -2.05      0.66    928.85      1.01\n",
      "    z[1,190]     -0.08      0.68     -0.06     -1.14      0.99    931.69      1.00\n",
      "    z[1,191]     -0.29      0.90     -0.27     -1.78      1.08    970.38      1.00\n",
      "    z[1,192]     -0.14      0.78     -0.13     -1.43      0.97    949.81      1.00\n",
      "    z[1,193]     -0.21      0.90     -0.22     -1.70      1.19   1924.44      1.00\n",
      "    z[1,194]      1.41      0.80      1.44      0.26      2.76    646.03      1.00\n",
      "    z[1,195]      0.56      0.64      0.55     -0.41      1.54    758.56      1.00\n",
      "    z[1,196]      1.03      0.69      1.03     -0.07      2.13    667.68      1.00\n",
      "    z[1,197]      0.50      0.83      0.49     -0.73      1.84   1121.02      1.00\n",
      "    z[1,198]     -0.08      0.94     -0.08     -1.37      1.57    894.77      1.00\n",
      "    z[1,199]      0.11      0.88      0.10     -1.18      1.64    750.35      1.00\n",
      "    z[1,200]     -0.15      0.83     -0.15     -1.44      1.15    906.29      1.00\n",
      "    z[1,201]     -0.41      0.90     -0.42     -1.64      1.10   1222.40      1.00\n",
      "    z[1,202]     -0.25      0.98     -0.33     -1.95      1.07   1117.86      1.00\n",
      "    z[1,203]     -0.36      0.88     -0.38     -1.70      1.05    924.32      1.00\n",
      "    z[1,204]     -0.11      0.91     -0.13     -1.69      1.11   1643.04      1.00\n",
      "    z[1,205]     -0.54      0.88     -0.56     -1.93      0.87    712.38      1.00\n",
      "    z[1,206]      0.44      0.88      0.46     -0.97      1.76    953.96      1.01\n",
      "    z[1,207]      0.47      0.92      0.52     -0.77      2.26    905.01      1.00\n",
      "    z[1,208]     -0.34      0.96     -0.34     -1.90      1.31   2539.57      1.00\n",
      "    z[1,209]      0.99      0.68      0.98      0.02      2.10    724.99      1.00\n",
      "    z[1,210]     -0.85      0.90     -0.79     -2.16      0.65   1270.51      1.00\n",
      "    z[1,211]     -0.25      0.96     -0.19     -1.79      1.19   1093.82      1.00\n",
      "    z[1,212]      0.33      0.93      0.33     -1.18      1.75    897.85      1.00\n",
      "    z[1,213]     -0.43      0.98     -0.41     -2.26      0.97   1354.35      1.00\n",
      "    z[1,214]     -0.34      0.94     -0.36     -1.79      1.12   1391.44      1.00\n",
      "    z[1,215]     -0.01      0.91     -0.01     -1.37      1.58   1449.60      1.00\n",
      "    z[1,216]     -0.29      1.02     -0.26     -1.98      1.23    917.41      1.00\n",
      "    z[1,217]     -0.17      0.90     -0.18     -1.83      1.01   1231.46      1.00\n",
      "    z[1,218]     -0.39      0.96     -0.40     -1.83      1.01    755.58      1.00\n",
      "    z[1,219]      0.14      0.83      0.12     -1.12      1.43   1021.19      1.00\n",
      "    z[1,220]      0.02      0.91      0.02     -1.54      1.29   1180.54      1.00\n",
      "    z[1,221]     -0.22      0.95     -0.21     -1.70      1.17   1713.27      1.00\n",
      "    z[1,222]      1.42      0.61      1.42      0.45      2.32    990.51      1.00\n",
      "    z[1,223]      0.21      0.84      0.24     -0.92      1.75   1272.59      1.00\n",
      "    z[1,224]     -0.19      0.83     -0.23     -1.40      1.22   1125.45      1.00\n",
      "    z[1,225]     -0.30      1.13     -0.28     -2.14      1.35   1334.10      1.00\n",
      "    z[1,226]     -0.20      0.99     -0.26     -1.63      1.43   1167.07      1.00\n",
      "    z[1,227]     -0.33      0.95     -0.31     -1.80      1.25   1737.70      1.00\n",
      "    z[1,228]      0.17      0.74      0.16     -0.96      1.32   1347.22      1.00\n",
      "    z[1,229]     -0.84      0.88     -0.85     -2.34      0.48   2053.82      1.00\n",
      "    z[1,230]     -0.31      0.97     -0.28     -1.97      1.02   1322.33      1.00\n",
      "    z[1,231]     -0.31      0.90     -0.29     -1.82      1.04   1085.84      1.00\n",
      "    z[1,232]      0.47      0.89      0.46     -0.98      1.82    652.97      1.00\n",
      "    z[1,233]     -0.37      0.86     -0.38     -1.87      0.91    699.47      1.00\n",
      "    z[1,234]      0.17      0.87      0.21     -1.29      1.51   1307.48      1.00\n",
      "    z[1,235]      0.37      0.85      0.36     -1.03      1.61    844.73      1.00\n",
      "    z[1,236]      0.17      0.80      0.16     -1.02      1.53   1557.84      1.00\n",
      "    z[1,237]      0.29      0.87      0.29     -0.96      1.86   2309.23      1.00\n",
      "    z[1,238]      0.19      0.86      0.18     -1.19      1.58    860.28      1.00\n",
      "    z[1,239]      0.54      0.79      0.54     -0.63      1.84    905.79      1.00\n",
      "    z[1,240]      0.22      0.73      0.21     -1.09      1.29    921.44      1.00\n",
      "    z[1,241]     -0.11      0.90     -0.16     -1.48      1.21   1185.52      1.00\n",
      "    z[1,242]      0.35      0.81      0.37     -0.95      1.53   1280.23      1.00\n",
      "    z[1,243]     -0.08      0.99     -0.08     -1.67      1.47   1075.97      1.00\n",
      "    z[1,244]     -0.21      1.17     -0.16     -1.92      1.67   1710.79      1.00\n",
      "    z[1,245]      0.93      0.67      0.93     -0.03      2.06   1095.26      1.00\n",
      "    z[1,246]      0.50      0.76      0.51     -0.64      1.74    916.36      1.00\n",
      "    z[1,247]      0.09      0.96      0.12     -1.33      1.70    959.67      1.00\n",
      "    z[1,248]     -0.46      0.88     -0.46     -1.77      0.90   1020.26      1.00\n",
      "    z[1,249]      0.18      0.83      0.17     -1.04      1.50   1085.20      1.00\n",
      "    z[1,250]      0.32      0.79      0.36     -0.99      1.49   1071.23      1.00\n",
      "    z[1,251]     -0.04      0.77      0.00     -1.26      1.20    942.70      1.00\n",
      "    z[1,252]     -0.34      0.89     -0.33     -1.78      1.14    905.47      1.00\n",
      "    z[1,253]      0.23      0.92      0.21     -1.08      1.81   1551.57      1.00\n",
      "    z[1,254]      0.40      0.96      0.39     -1.24      1.80    678.46      1.00\n",
      "    z[1,255]     -0.24      0.79     -0.25     -1.47      0.98    896.10      1.00\n",
      "    z[1,256]      0.12      0.83      0.11     -1.07      1.46    870.01      1.00\n",
      "    z[1,257]      0.45      0.75      0.43     -0.90      1.54   1020.55      1.00\n",
      "    z[1,258]     -0.10      0.83     -0.11     -1.36      1.21    920.20      1.00\n",
      "    z[1,259]      0.93      0.75      0.90     -0.23      2.21    925.03      1.00\n",
      "    z[1,260]      0.76      0.84      0.79     -0.73      1.87    910.99      1.00\n",
      "    z[1,261]      0.02      0.89      0.03     -1.39      1.36    962.45      1.00\n",
      "    z[1,262]      0.20      0.88      0.22     -1.35      1.43    851.99      1.00\n",
      "    z[1,263]      0.00      0.91      0.02     -1.62      1.41   1588.40      1.00\n",
      "    z[1,264]     -0.23      0.89     -0.23     -1.45      1.36   1149.90      1.00\n",
      "    z[1,265]      0.78      0.77      0.81     -0.42      1.96    887.01      1.00\n",
      "    z[1,266]      0.67      0.68      0.68     -0.53      1.66   1004.08      1.00\n",
      "    z[1,267]     -0.16      0.75     -0.14     -1.42      0.97    975.83      1.00\n",
      "    z[1,268]      1.15      0.71      1.17      0.12      2.28    911.49      1.00\n",
      "    z[1,269]     -0.26      0.81     -0.23     -1.47      1.10   1083.05      1.00\n",
      "    z[1,270]      0.44      0.87      0.41     -0.84      1.87    892.22      1.00\n",
      "    z[1,271]     -0.31      1.00     -0.31     -1.83      1.37   1367.42      1.00\n",
      "    z[1,272]     -0.27      0.94     -0.32     -1.74      1.28    968.25      1.00\n",
      "    z[1,273]     -0.56      0.87     -0.56     -1.89      0.80    951.80      1.00\n",
      "    z[1,274]      0.65      0.67      0.67     -0.42      1.61   1054.36      1.00\n",
      "    z[1,275]     -0.11      0.97     -0.08     -1.77      1.34   1240.38      1.00\n",
      "    z[1,276]     -0.22      0.92     -0.20     -1.72      1.14   1235.74      1.00\n",
      "    z[1,277]      0.26      0.84      0.27     -1.05      1.54   1032.10      1.00\n",
      "    z[1,278]     -0.18      0.98     -0.14     -1.72      1.35   1905.65      1.00\n",
      "    z[1,279]      1.09      0.84      1.07     -0.21      2.40   1483.67      1.00\n",
      "    z[1,280]     -0.10      0.71     -0.08     -1.32      0.90    715.18      1.00\n",
      "    z[1,281]      0.34      0.71      0.32     -0.65      1.52    765.59      1.00\n",
      "    z[1,282]      0.01      0.88      0.01     -1.55      1.18   1166.81      1.00\n",
      "    z[1,283]     -0.20      0.88     -0.21     -1.71      1.05   1171.14      1.00\n",
      "    z[1,284]      0.38      0.93      0.36     -1.13      1.78   1103.59      1.00\n",
      "    z[1,285]      0.08      0.68      0.08     -1.00      1.11    958.46      1.00\n",
      "    z[1,286]      0.12      0.86      0.14     -1.42      1.26   1046.08      1.00\n",
      "    z[1,287]      0.56      0.78      0.55     -0.52      1.85   1162.72      1.00\n",
      "    z[1,288]      0.07      0.75      0.07     -1.10      1.28    944.09      1.00\n",
      "    z[1,289]     -0.08      1.00     -0.06     -1.55      1.42   1797.60      1.00\n",
      "    z[1,290]      0.11      0.71      0.14     -1.16      1.13    804.68      1.00\n",
      "    z[1,291]     -1.20      0.85     -1.21     -2.46      0.23   1015.27      1.00\n",
      "    z[1,292]     -0.11      0.98     -0.12     -1.61      1.44   2452.43      1.00\n",
      "    z[1,293]      0.22      0.91      0.24     -1.18      1.68    923.44      1.00\n",
      "    z[1,294]     -0.50      0.79     -0.52     -1.72      0.73    651.79      1.00\n",
      "    z[1,295]      0.14      1.00      0.17     -1.46      1.66   2007.70      1.00\n",
      "    z[1,296]     -0.21      0.99     -0.19     -1.80      1.37   1498.16      1.00\n",
      "    z[1,297]     -0.23      1.01     -0.24     -1.78      1.38   1611.28      1.00\n",
      "    z[1,298]     -0.16      1.03     -0.14     -1.81      1.38   1482.56      1.00\n",
      "    z[1,299]     -0.25      0.90     -0.24     -1.58      1.11   1445.89      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "kl_dyads  = pd.read_csv('/home/sosa/BI/data/kl_dyads')\n",
    "d2 = pd.read_csv('/home/sosa/BI/data/kl_households'\"\", index_col=0)\n",
    "kl_data = dict(\n",
    "    N=kl_dyads.shape[0],\n",
    "    N_households=kl_dyads.hidB.max(),\n",
    "    did=kl_dyads.did.values - 1,\n",
    "    hidA=kl_dyads.hidA.values - 1,\n",
    "    hidB=kl_dyads.hidB.values - 1,\n",
    "    giftsAB=kl_dyads.giftsAB.values,\n",
    "    giftsBA=kl_dyads.giftsBA.values,\n",
    ")\n",
    "m.data = kl_data\n",
    "\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = lkj(\"Rho_gr\", [], 2, 4)\n",
    "    sigma_gr = exponential(\"sigma_gr\", [2], 1)\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = multivariatenormal(\"gr\", [N_households], 0, cov)\n",
    "\n",
    "    # dyad effects\n",
    "    z = normal(\"z\",[2, N], 0, 1)\n",
    "    L_Rho_d = lkjcholesky(\"L_Rho_d\",[], 2, 8)\n",
    "    sigma_d = exponential(\"sigma_d\",[1], 1)\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = normal('a', [1], 0, 1)\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    sample(\"giftsAB\", Poisson(lambdaAB), obs=giftsAB)\n",
    "    sample(\"giftsBA\", Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = numpyro.sample(\"Rho_gr\", dist.LKJ(2, 4))\n",
    "    sigma_gr = numpyro.sample(\"sigma_gr\", dist.Exponential(1).expand([2]))\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = numpyro.sample(\"gr\", dist.MultivariateNormal(0, cov).expand([N_households]))\n",
    "\n",
    "    # dyad effects\n",
    "    z = numpyro.sample(\"z\", dist.Normal(0, 1).expand([2, N]))\n",
    "    L_Rho_d = numpyro.sample(\"L_Rho_d\", dist.LKJCholesky(2, 8))\n",
    "    sigma_d = numpyro.sample(\"sigma_d\", dist.Exponential(1))\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    numpyro.sample(\"giftsAB\", dist.Poisson(lambdaAB), obs=giftsAB)\n",
    "    numpyro.sample(\"giftsBA\", dist.Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "\n",
    "m14_7 = MCMC(NUTS(model), num_warmup=1000, num_samples=1000, num_chains=4)\n",
    "m14_7.run(random.PRNGKey(0), **kl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 768.14it/s, 127 steps of size 3.22e-02. acc. prob=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9520 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.33      0.90      1.11      0.15      2.60    394.53      1.02\n",
      "      b[0]      0.28      0.09      0.28      0.13      0.41    209.03      1.00\n",
      "  etasq[0]      0.20      0.20      0.14      0.01      0.42    280.91      1.00\n",
      "      g[0]      0.59      0.59      0.43      0.02      1.23    302.88      1.02\n",
      "  rhosq[0]      1.38      1.72      0.75      0.02      3.37    329.98      1.00\n",
      "      z[0]     -0.49      0.79     -0.46     -1.53      0.84    241.76      1.00\n",
      "      z[1]      0.37      0.76      0.39     -0.86      1.49    502.49      1.00\n",
      "      z[2]     -0.26      0.76     -0.21     -1.73      0.68    636.05      1.00\n",
      "      z[3]      0.93      0.65      0.95     -0.12      1.84    255.45      1.00\n",
      "      z[4]      0.30      0.61      0.28     -0.52      1.37    330.08      1.00\n",
      "      z[5]     -1.09      0.72     -1.02     -2.20     -0.05    271.82      1.00\n",
      "      z[6]      0.37      0.62      0.33     -0.64      1.30    371.45      1.00\n",
      "      z[7]     -0.37      0.70     -0.39     -1.51      0.65    501.95      1.00\n",
      "      z[8]      0.77      0.63      0.75     -0.31      1.69    333.48      1.00\n",
      "      z[9]     -0.46      0.77     -0.48     -1.78      0.70    299.46      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "Kline2 = pd.read_csv('/home/sosa/BI/data/Kline2.csv', sep=\";\")\n",
    "islandsDistMatrix = pd.read_csv('/home/sosa/BI/data/islandsDistMatrix.csv'\"\", index_col=0)\n",
    "d = Kline2\n",
    "d[\"society\"] = range(1, 11)  # index observations\n",
    "\n",
    "dat_list = dict(\n",
    "    T=d.total_tools.values,\n",
    "    P=d.population.values,\n",
    "    society=d.society.values - 1,\n",
    "    Dmat=islandsDistMatrix.values,\n",
    ")\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m14_8 = bi(platform='cpu')\n",
    "m14_8.data = dat_list\n",
    "\n",
    "@jit\n",
    "def cov_GPL2(x, sq_eta, sq_rho, sq_sigma):\n",
    "    N = x.shape[0]\n",
    "    K = sq_eta * jnp.exp(-sq_rho * jnp.square(x))\n",
    "    K = K.at[jnp.diag_indices(N)].add(sq_sigma)\n",
    "    return K\n",
    "\n",
    "\n",
    "def model(Dmat, P, society, T):\n",
    "    a = exponential('a', [1], 1)\n",
    "    b = exponential('b',[1],1)\n",
    "    g = exponential('g',[1],1)\n",
    "    etasq = exponential('etasq',[1],2)\n",
    "    rhosq = exponential('rhosq',[1],0.5)\n",
    "\n",
    "    # non-centered Gaussian Process prior\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, 0.01)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = normal('z', [10], 0, 1)\n",
    "    k = (L_SIGMA @ z[..., None])[..., 0]\n",
    "    lambda_ = a * P**b / g * jnp.exp(k[society])\n",
    "    sample(\"T\", Poisson(lambda_), obs=T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m14_8.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "m14_8.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Howell1.csv', sep=';') \n",
    "m.data = m.data[m.data .age > 18]\n",
    "m.data.weight = m.data.weight - m.data.weight.mean()\n",
    "m.data.age = m.data.age - m.data.age.mean()\n",
    "weight = jnp.array(m.data.weight.values)\n",
    "height = jnp.array(m.data.height.values)\n",
    "# TODO: use jax arrays with hugging face package\n",
    "# TODO: Add scale function\n",
    "m.data = dict(height = height, weight = weight)\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s = uniform('s', [1], 0, 50)\n",
    "    a = normal('a', [1], 178, 20)\n",
    "    b = normal('b', [1], 0, 1)  \n",
    "    sample(\"y\", Normal(a + b * weight, s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['N_networktypes', 'N_id', 'N_responses', 'N_periods', 'N_individual_predictors', 'N_dyadic_predictors', 'outcomes', 'flows', 'individual_predictors', 'dyadic_predictors', 'N_block_predictors', 'N_groups_per_block_type', 'block_predictors', 'outcome_mode', 'exposure'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import jax.numpy as jnp\n",
    "with open('OUTPUT STRAND.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_networktypes: \n",
      "[1]\n",
      "N_id : \n",
      "[100]\n",
      "N_responses : \n",
      "[1]\n",
      "N_periods : \n",
      "[0]\n",
      "N_periods : \n",
      "[0]\n",
      "N_individual_predictors : \n",
      "[1]\n",
      "N_dyadic_predictors : \n",
      "[2]\n",
      "flows : \n",
      "[0]\n",
      "individual_predictors : \n",
      "[0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
      "outcome_mode : \n",
      "[2]\n",
      "[{'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 2, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}, {'Intercept': 1, 'Merica': 1, 'Quantum': 1}, {'Intercept': 1, 'Merica': 2, 'Quantum': 2}, {'Intercept': 1, 'Merica': 3, 'Quantum': 1}, {'Intercept': 1, 'Merica': 1, 'Quantum': 2}]\n",
      "outcome_mode : \n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(\"N_networktypes: \")\n",
    "print(data['N_networktypes'])\n",
    "print(\"N_id : \")\n",
    "print(data['N_id'])\n",
    "print(\"N_responses : \")\n",
    "print(data['N_responses'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_individual_predictors : \" )\n",
    "print(data['N_individual_predictors'])\n",
    "print(\"N_dyadic_predictors : \")\n",
    "print(data['N_dyadic_predictors'])\n",
    "print(\"flows : \")\n",
    "print(data['flows'])\n",
    "data['individual_predictors'] = jnp.array([item['Mass'] for item in data['individual_predictors']])\n",
    "print(\"individual_predictors : \")\n",
    "print(data['individual_predictors'])\n",
    "#print(\"N_block_predictors : \")\n",
    "#print(data['N_block_predictors'])\n",
    "#print(\"N_groups_per_block_type : \")\n",
    "#print(data['N_groups_per_block_type'])\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )\n",
    "#data['block_predictors'] = jnp.array(data['block_predictors'])\n",
    "#print(\"block_predictors : \")\n",
    "print(data['block_predictors'] )\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "print(Kinship.shape)\n",
    "Dominant = jnp.array(data['dyadic_predictors']['Dominant'])\n",
    "print(Dominant.shape)\n",
    "exposure = jnp.array(data['exposure'])[:,:,1]\n",
    "print(exposure.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4950, 2)\n",
      "4950.0\n"
     ]
    }
   ],
   "source": [
    "# Matrices to edgelist\n",
    "result_dom = get_triangle(Dominant, 'both', 1)\n",
    "result_dom.shape\n",
    "result_kin = get_triangle(Kinship, 'both', 1)\n",
    "result_kin\n",
    "data['outcomes'] = jnp.array(data['outcomes'])\n",
    "result_outcomes = get_triangle(data['outcomes'], 'both', 1)[:,:,1]\n",
    "print(result_outcomes.shape)\n",
    "\n",
    "N_id = data['individual_predictors'].shape[0]\n",
    "print((N_id*(N_id-1))/2)\n",
    "focal_individual_predictors = data['individual_predictors']\n",
    "target_individual_predictors = data['individual_predictors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.01467597, -0.        ],\n",
       "       [ 0.01725011, -0.        ],\n",
       "       [ 0.01850375, -0.        ],\n",
       "       ...,\n",
       "       [ 0.02025885, -0.16715223],\n",
       "       [ 0.00598405, -0.        ],\n",
       "       [-0.00531544, -0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from samplers import sampler\n",
    "sample = sampler()\n",
    "dyad_effects = sample.normal(0,1,sample_shape = [], seed = 2)\n",
    "jnp.dot(jnp.column_stack([result_kin[:,1], result_dom[:,1]]),dyad_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.        , -0.        , -0.16715223, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.16715223, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.16715223, -0.16715223,\n",
       "       -0.        , -0.16715223, -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.16715223, -0.        , -0.        , -0.16715223,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.16715223, -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.16715223, -0.16715223, -0.16715223, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.16715223, -0.16715223, -0.        ,\n",
       "       -0.        , -0.        , -0.16715223, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.16715223, -0.        , -0.        , -0.        , -0.16715223,\n",
       "       -0.        , -0.16715223, -0.16715223, -0.16715223, -0.16715223,\n",
       "       -0.        , -0.        , -0.        , -0.16715223, -0.16715223,\n",
       "       -0.16715223, -0.        , -0.16715223, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.16715223, -0.        , -0.16715223,\n",
       "       -0.16715223, -0.16715223, -0.        , -0.        , -0.        ,\n",
       "       -0.16715223, -0.16715223, -0.16715223, -0.16715223, -0.        ,\n",
       "       -0.        , -0.16715223, -0.16715223, -0.16715223, -0.16715223,\n",
       "       -0.        , -0.        , -0.16715223, -0.16715223, -0.16715223],      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_matrix_vector_multiplication(dyad_effects,focal_individual_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-3.0e+00,  1.5e+00],\n",
       "       [ 3.0e+00,  1.5e+00],\n",
       "       [-1.5e+00,  1.0e+00],\n",
       "       [ 1.0e+00,  0.0e+00],\n",
       "       [ 1.0e+00,  0.0e+00],\n",
       "       [ 1.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 1.0e-01,  2.5e+00],\n",
       "       [ 1.0e-02,  2.5e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00],\n",
       "       [ 1.0e+00,  0.0e+00],\n",
       "       [ 1.0e+00,  0.0e+00],\n",
       "       [ 2.5e+00,  0.0e+00],\n",
       "       [ 2.5e+00,  0.0e+00],\n",
       "       [ 1.5e+00,  0.0e+00],\n",
       "       [ 3.0e+00,  1.0e+00],\n",
       "       [ 2.0e+00,  0.0e+00],\n",
       "       [ 3.0e+00,  1.2e+01]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:07<00:00, 126.52it/s, 3 steps of size 3.83e-02. acc. prob=0.74]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building model and sampling it ------------------\n",
    "def model(N_id, result_outcomes, result_kin, focal_individual_predictors, target_individual_predictors):\n",
    "\n",
    "    # Block\n",
    "    B = numpyro.sample('block', numpyro.distributions.Normal(0.1, 2.5).expand([1]))/jnp.sqrt(N_id)\n",
    "    # SR term\n",
    "    focal_effects =  numpyro.sample('focal_effects', numpyro.distributions.Normal(0,1).expand([1]))\n",
    "    target_effects =  numpyro.sample('target_effects', numpyro.distributions.Normal(0,1).expand([1]))\n",
    "    sr_raw = numpyro.sample('sr_raw', numpyro.distributions.Normal(0,1).expand([N_id, 2]))\n",
    "    sr_sigma = numpyro.sample('sr_sigma', numpyro.distributions.Exponential(1).expand([2]))\n",
    "    sr_L = numpyro.sample(\"sr_L\", numpyro.distributions.LKJ(2, 4))\n",
    "\n",
    "    ## SR term computation\n",
    "    X = batch_matrix_vector_multiplication(sr_L @ jnp.diag(sr_sigma), sr_raw)\n",
    "    terms = jnp.stack([batch_matrix_vector_multiplication(focal_effects, focal_individual_predictors), \n",
    "                       batch_matrix_vector_multiplication(target_effects, target_individual_predictors)], axis = -1)\n",
    "    sr = terms + X\n",
    "    sr = sr_to_dr_shape(sr) # To compute the log probability, we need to reshape `sr` and `outcomes` to fit `dr`. A matrix approach should be possible or convert `sr` and `dr` to matrices.\n",
    "  \n",
    "    # Dyadic term\n",
    "    dyad_effects = numpyro.sample('dyad_effects', numpyro.distributions.Normal(0,1).expand([1]))\n",
    "    terms2 = batch_matrix_vector_multiplication(dyad_effects, result_kin)\n",
    "    dr_raw = numpyro.sample('dr_raw', numpyro.distributions.Normal(0,1).expand([terms2.shape[0],2]))\n",
    "    dr_sigma = numpyro.sample('dr_sigma', numpyro.distributions.Exponential(1).expand([1]))\n",
    "    dr_L = numpyro.sample(\"dr_L\", numpyro.distributions.LKJ(2, 4))\n",
    "    X2 = batch_matrix_vector_multiplication(dr_L, dr_raw) * jnp.repeat(dr_sigma,2)\n",
    "    dr = X2 + terms2\n",
    "\n",
    "    numpyro.sample('Y', numpyro.distributions.Poisson(B + sr + dr), obs=result_outcomes)\n",
    "\n",
    "dat = dict(\n",
    "    N_id = N_id,\n",
    "    result_outcomes = result_outcomes,\n",
    "    result_kin = result_kin, \n",
    "    focal_individual_predictors = focal_individual_predictors,\n",
    "    target_individual_predictors = target_individual_predictors\n",
    ")\n",
    "m = MCMC(NUTS(model, init_strategy = numpyro.infer.init_to_median()), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(10), extra_fields=[\"diverging\"], **dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = az.from_numpyro(m)\n",
    "#df = az.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block\n",
      "dr_L\n",
      "dr_raw\n",
      "dr_sigma\n",
      "dyad_effects\n",
      "focal_effects\n",
      "sr_L\n",
      "sr_raw\n",
      "sr_sigma\n",
      "target_effects\n"
     ]
    }
   ],
   "source": [
    "for k in res['posterior']:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2.6900437]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['dr_sigma']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0741405, 1.332891 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['sr_sigma']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.        , -0.12285003],\n",
       "       [-0.12285003,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['sr_L'][0]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.347522], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['dyad_effects']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.0741405, 1.332891 ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['sr_sigma'][0,:,:]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.303898]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['target_effects']), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.3581899]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array(res['posterior']['focal_effects']), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ones_column = np.ones((len(data[\"individual_predictors\"]), 1))\n",
    "\n",
    "# Reshape the vector to be a column vector\n",
    "vector_column = data[\"individual_predictors\"].reshape(-1, 1)\n",
    "\n",
    "# Concatenate the two columns horizontally\n",
    "focal_set = np.concatenate((ones_column, vector_column), axis=1)\n",
    "\n",
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "print(Kinship.shape)\n",
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "# Get the shape of the existing array\n",
    "shape = Kinship.shape\n",
    "\n",
    "# Create a new array with the same shape, filled with 1's\n",
    "ones_array = jnp.ones(shape, dtype=int)\n",
    "ones_array\n",
    "\n",
    "d = [\n",
    "    [-3.00, 1.5],\n",
    "    [ 3.00, 1.5],\n",
    "    [-1.50, 1.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.10, 2.5],\n",
    "    [ 0.01, 2.5],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 2.50, 0.0],\n",
    "    [ 2.50, 0.0],\n",
    "    [ 1.50, 0.0],\n",
    "    [ 3.00, 1.0],\n",
    "    [ 2.00, 0.0],\n",
    "    [ 3.00, 12.0]\n",
    "]\n",
    "\n",
    "# Convert the list to a JAX array\n",
    "priors = jnp.array(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter target_effects has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter sr_sigma has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter sr_L has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter focal_effects has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter dyad_effects has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter dr_sigma has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter dr_L has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter B has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/4000)\n",
      "Sampling:   0% (2/4000)\n",
      "Sampling:   0% (3/4000)\n",
      "Sampling:   0% (4/4000)\n",
      "Sampling:   3% (103/4000)\n",
      "Sampling:   5% (202/4000)\n",
      "Sampling:   8% (301/4000)\n",
      "Sampling:  10% (400/4000)\n",
      "Sampling:  12% (500/4000)\n",
      "Sampling:  15% (600/4000)\n",
      "Sampling:  18% (700/4000)\n",
      "Sampling:  20% (800/4000)\n",
      "Sampling:  22% (900/4000)\n",
      "Sampling:  25% (1000/4000)\n",
      "Sampling:  28% (1100/4000)\n",
      "Sampling:  30% (1200/4000)\n",
      "Sampling:  32% (1300/4000)\n",
      "Sampling:  35% (1400/4000)\n",
      "Sampling:  38% (1500/4000)\n",
      "Sampling:  40% (1600/4000)\n",
      "Sampling:  42% (1700/4000)\n",
      "Sampling:  43% (1701/4000)\n",
      "Sampling:  45% (1801/4000)\n",
      "Sampling:  45% (1802/4000)\n",
      "Sampling:  48% (1903/4000)\n",
      "Sampling:  50% (2003/4000)\n",
      "Sampling:  50% (2004/4000)\n",
      "Sampling:  53% (2103/4000)\n",
      "Sampling:  55% (2202/4000)\n",
      "Sampling:  58% (2301/4000)\n",
      "Sampling:  60% (2400/4000)\n",
      "Sampling:  62% (2500/4000)\n",
      "Sampling:  65% (2600/4000)\n",
      "Sampling:  68% (2700/4000)\n",
      "Sampling:  70% (2800/4000)\n",
      "Sampling:  72% (2900/4000)\n",
      "Sampling:  75% (3000/4000)\n",
      "Sampling:  78% (3100/4000)\n",
      "Sampling:  80% (3200/4000)\n",
      "Sampling:  82% (3300/4000)\n",
      "Sampling:  85% (3400/4000)\n",
      "Sampling:  88% (3500/4000)\n",
      "Sampling:  90% (3600/4000)\n",
      "Sampling:  92% (3700/4000)\n",
      "Sampling:  95% (3800/4000)\n",
      "Sampling:  98% (3900/4000)\n",
      "Sampling: 100% (4000/4000)\n",
      "Sampling: 100% (4000/4000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.004469 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 44.69 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 95, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.00409 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 40.9 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.004677 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 46.77 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 95, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 95, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 95, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 95, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.004755 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 47.55 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_0snrv7ep/model_rsoigopj.stan', line 81, column 4 to column 43)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 2602.3774 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{\n",
    "    int N_networktypes;                                               \n",
    "    int N_id;                                                                                                            \n",
    "    int N_responses;        \n",
    "\n",
    "    array[3] int N_params;                                          \n",
    "                                             \n",
    "    array[N_id,N_id,N_responses] int outcomes;  \n",
    "    array[N_id,N_id,N_responses] int exposure;                              \n",
    "\n",
    "    matrix[N_id, N_params[1]] focal_set;\n",
    "    matrix[N_id, N_params[2]] target_set;\n",
    "\n",
    "    array[N_id, N_id, N_params[3]] real dyad_set;\n",
    "\n",
    "    matrix [22, 2] priors;\n",
    "    \n",
    "    int export_network;\n",
    "    int outcome_mode;                           \n",
    "}\n",
    "\n",
    "transformed data{\n",
    " matrix[N_id, N_params[1]-1] focal_individual_predictors; \n",
    " matrix[N_id, N_params[2]-1] target_individual_predictors; \n",
    "\n",
    " array[N_id, N_id, N_params[3]-1] real dyad_individual_predictors; \n",
    "\n",
    "//# Make pruned data\n",
    "  \n",
    "  if(N_params[1]>1){\n",
    "  for(i in 2:N_params[1]){\n",
    "  focal_individual_predictors[ , i-1] = focal_set[,i];  \n",
    "   }}\n",
    "\n",
    "  if(N_params[2]>1){\n",
    "  for(i in 2:N_params[2]){\n",
    "  target_individual_predictors[ , i-1] = target_set[,i];  \n",
    "   }}\n",
    "\n",
    "  if(N_params[3]>1){\n",
    "  for(i in 2:N_params[3]){\n",
    "  dyad_individual_predictors[ , , i-1] = dyad_set[,,i];  \n",
    "   }}\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    //########################################################### Latent Netowrk\n",
    "    matrix[1,1] B;\n",
    "\n",
    "    vector<lower=0>[2] sr_sigma;  //# Variation of sender-receiver effects\n",
    "    cholesky_factor_corr[2] sr_L;\n",
    "    array[N_id] vector[2] sr_raw;\n",
    "\n",
    "    real<lower=0> dr_sigma;     //# Variation of dyadic effects\n",
    "    cholesky_factor_corr[2] dr_L;\n",
    "    matrix[N_id, N_id] dr_raw;\n",
    "\n",
    "    //# Effects of covariate\n",
    "    vector[N_params[1]-1] focal_effects;\n",
    "    vector[N_params[2]-1] target_effects;\n",
    "    vector[N_params[3]-1] dyad_effects;  \n",
    "}\n",
    "\n",
    "model{\n",
    "  array[N_id] vector[2] sr;\n",
    "  matrix[N_id, N_id] dr;\n",
    "\n",
    "  vector[2] scrap;\n",
    "\n",
    "    //# Priors on effects of covariates\n",
    "     focal_effects ~ normal(priors[12,1], priors[12,2]);\n",
    "     target_effects ~ normal(priors[13,1], priors[13,2]);\n",
    "     dyad_effects ~ normal(priors[14,1], priors[14,2]);\n",
    "\n",
    "    //# Sender-receiver priors for social relations model\n",
    "    for(i in 1:N_id)\n",
    "    sr_raw[i] ~ normal(0,1);\n",
    "\n",
    "    sr_sigma ~ exponential(priors[15,1]);    \n",
    "    sr_L ~ lkj_corr_cholesky(priors[17,1]);\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     vector[2] sr_terms;\n",
    "\n",
    "     sr_terms[1] = dot_product(focal_effects,  to_vector(focal_individual_predictors[i]));\n",
    "     sr_terms[2] = dot_product(target_effects,  to_vector(target_individual_predictors[i]));  \n",
    "\n",
    "     sr[i] = diag_pre_multiply(sr_sigma, sr_L) * sr_raw[i] + sr_terms;\n",
    "     }\n",
    "\n",
    "    //# Dyadic priors for social relations model\n",
    "    to_vector(dr_raw) ~ normal(0,1);\n",
    "    dr_sigma ~ exponential(priors[16,1]);\n",
    "    dr_L ~ lkj_corr_cholesky(priors[18,1]);\n",
    "\n",
    "    for(i in 1:(N_id-1)){\n",
    "    for(j in (i+1):N_id){\n",
    "     scrap[1] = dr_raw[i,j];\n",
    "     scrap[2] = dr_raw[j,i];\n",
    "     scrap = rep_vector(dr_sigma, 2) .* (dr_L*scrap);\n",
    "     dr[i,j] = scrap[1] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[i, j, ]));\n",
    "     dr[j,i] = scrap[2] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[j, i, ]));\n",
    "     }\n",
    "     }\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     dr[i,i] = -99; //# ignore this :)\n",
    "    }\n",
    "\n",
    "    //# priors for \n",
    "    B[1,1] ~ normal(logit(priors[10,1]/sqrt(N_id)), priors[10,2]);\n",
    "\n",
    "\n",
    "    //# likelihood\n",
    "    for ( i in 1:N_id ) {\n",
    "     for ( j in 1:N_id ) {\n",
    "       if ( i != j ) {\n",
    "\n",
    "      if(outcome_mode==1){\n",
    "      outcomes[i,j,1] ~ bernoulli_logit(B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "      if(outcome_mode==2){\n",
    "      outcomes[i,j,1] ~ binomial_logit(exposure[i,j,1], B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "      if(outcome_mode==3){\n",
    "      outcomes[i,j,1] ~ poisson_log(B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "\n",
    "       }\n",
    "      }\n",
    "     }\n",
    "\n",
    "\n",
    " }\n",
    "\n",
    "\n",
    "generated quantities{\n",
    "    //# compute posterior prob of each network tie\n",
    "    matrix[N_id*export_network, N_id*export_network] p;\n",
    "    array[N_id*export_network] vector[2*export_network] sr;\n",
    "    matrix[N_id*export_network, N_id*export_network] dr;\n",
    " \n",
    "    if(export_network==1){                \n",
    "     vector[2] terms;\n",
    "     int tie;\n",
    "     vector[2] scrap;\n",
    "            \n",
    "    for(i in 1:N_id){\n",
    "     vector[2] sr_terms;\n",
    "\n",
    "     sr_terms[1] = dot_product(focal_effects,  to_vector(focal_individual_predictors[i]));\n",
    "     sr_terms[2] = dot_product(target_effects,  to_vector(target_individual_predictors[i]));  \n",
    "\n",
    "     sr[i] = diag_pre_multiply(sr_sigma, sr_L) * sr_raw[i] + sr_terms;\n",
    "     }\n",
    "\n",
    "    for(i in 1:(N_id-1)){\n",
    "    for(j in (i+1):N_id){\n",
    "     scrap[1] = dr_raw[i,j];\n",
    "     scrap[2] = dr_raw[j,i];\n",
    "     scrap = rep_vector(dr_sigma, 2) .* (dr_L*scrap);\n",
    "     dr[i,j] = scrap[1] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[i, j, ])) + B[1, 1];\n",
    "     dr[j,i] = scrap[2] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[j, i, ])) + B[1, 1];\n",
    "    }\n",
    "    }\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     dr[i,i] = -99; //# ignore this :)\n",
    "    }\n",
    "\n",
    "\n",
    "    for ( i in 1:N_id ) {\n",
    "        for ( j in 1:N_id ) {\n",
    "            if ( i != j ) {\n",
    "      // consider each possible state of true tie and compute prob of data\n",
    "      if(outcome_mode==1){\n",
    "       p[i,j] = inv_logit( sr[i,1] + sr[j,2] + dr[i,j]);\n",
    "       }\n",
    "      if(outcome_mode==2){\n",
    "       p[i,j] = inv_logit( sr[i,1] + sr[j,2] + dr[i,j]);\n",
    "       }\n",
    "      if(outcome_mode==3){\n",
    "       p[i,j] = exp(sr[i,1] + sr[j,2] + dr[i,j]);  \n",
    "       }\n",
    "            }\n",
    "        }//j\n",
    "    }//i\n",
    "\n",
    "  for ( i in 1:N_id ) {\n",
    "   p[i,i] = 0; \n",
    "   }\n",
    " }\n",
    "}\n",
    "\"\"\"\n",
    "d = {\n",
    "    'N_networktypes' : int(1),\n",
    "    \"N_id\": int(100),\n",
    "    \"N_responses\" : int(1),\n",
    "    \"N_params\": np.array([2,2,2]),\n",
    "\n",
    "\n",
    "    \"outcomes\": np.array(data[\"outcomes\"]),\n",
    "    \"exposure\":  np.array(data[\"exposure\"]),\n",
    "\n",
    "    \"focal_set\":  np.array(focal_set),\n",
    "    \"target_set\":  np.array(focal_set),\n",
    "\n",
    "    \"dyad_set\":  np.array(jnp.stack((Kinship, ones_array), axis=2)),\n",
    "    \"priors\":  np.array(priors),\n",
    "    \"outcome_mode\": int(3),\n",
    "    \"export_network\": int(0),\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = d)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['block']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['sr_sigma.1'].mean())\n",
    "print(df['sr_sigma.2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[0.62318146 1.5452635 ]]\n",
      "STRAND:\n",
      "-0.7206629127188772\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['sr_sigma']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['B.1.1'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[0.3366838]]\n",
      "STRAND:\n",
      "0.45419551780220374\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['target_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['target_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[0.88471144]]\n",
      "STRAND:\n",
      "0.6129801670716482\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['focal_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['focal_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[0.28606898]\n",
      "STRAND:\n",
      "0.6120251010130783\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['dyad_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['dyad_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Multinomial with centered random factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "    \n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4146024105,  967050713], dtype=uint32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init_key = jnp.array(init_key)\n",
    "init_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import os\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, set_matplotlib_formats\n",
    "from matplotlib.patches import Ellipse, transforms\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(30)\n",
    "\n",
    "\n",
    "# Simulation ---------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "Y2 = jnp.array(Y2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:01<00:00, 1386.84it/s, 1023 steps of size 1.50e-07. acc. prob=0.79]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building model and sampling it ------------------\n",
    "def model(NY, NV, Y2):\n",
    "    means =  numpyro.sample('means', numpyro.distributions.Normal(0,1).expand([NY]))\n",
    "    offset =  numpyro.sample('offset', numpyro.distributions.Normal(0,1).expand([NV,1]))\n",
    "    sigma =  numpyro.sample('sigma', numpyro.distributions.Exponential(1).expand([NY])) \n",
    "    tmp = jnp.tile(means, (NV, 1)).reshape(NV,NY)  \n",
    "    mu_l = tmp + offset \n",
    "    numpyro.sample('Y2', numpyro.distributions.Normal(mu_l, jnp.tile(sigma, [NV, 1])), obs=Y2)\n",
    "\n",
    "dat = dict(\n",
    "    NY = NY,\n",
    "    NV = NV,\n",
    "    Y2 = Y2\n",
    ")\n",
    "m = MCMC(NUTS(model, init_strategy = numpyro.infer.init_to_median()), num_warmup=1000, num_samples=1000, num_chains=1)\n",
    "m.run(random.PRNGKey(0), extra_fields=[\"diverging\"], **dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 1000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>means[0]</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[1]</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[2]</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[3]</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[0, 0]</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[1, 0]</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[2, 0]</th>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[3, 0]</th>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.077</td>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[4, 0]</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[5, 0]</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[6, 0]</th>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[7, 0]</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[1]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[2]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[3]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean   sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "means[0]      0.519  0.0   0.519    0.519        0.0      0.0    1000.0   \n",
       "means[1]      0.191  0.0   0.191    0.191        0.0      0.0    1000.0   \n",
       "means[2]      0.657  0.0   0.657    0.657        0.0      0.0    1000.0   \n",
       "means[3]     -0.613  0.0  -0.613   -0.613        0.0      0.0    1000.0   \n",
       "offset[0, 0]  0.530  0.0   0.530    0.530        0.0      0.0    1000.0   \n",
       "offset[1, 0]  0.812  0.0   0.812    0.812        0.0      0.0    1000.0   \n",
       "offset[2, 0] -0.366  0.0  -0.366   -0.366        0.0      0.0    1000.0   \n",
       "offset[3, 0]  2.077  0.0   2.077    2.077        0.0      0.0    1000.0   \n",
       "offset[4, 0]  0.988  0.0   0.988    0.988        0.0      0.0    1000.0   \n",
       "offset[5, 0]  0.342  0.0   0.342    0.342        0.0      0.0    1000.0   \n",
       "offset[6, 0]  1.198  0.0   1.198    1.198        0.0      0.0    1000.0   \n",
       "offset[7, 0]  0.697  0.0   0.697    0.697        0.0      0.0    1000.0   \n",
       "sigma[0]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[1]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[2]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[3]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "\n",
       "              ess_tail  r_hat  \n",
       "means[0]        1000.0    NaN  \n",
       "means[1]        1000.0    NaN  \n",
       "means[2]        1000.0    NaN  \n",
       "means[3]        1000.0    NaN  \n",
       "offset[0, 0]    1000.0    NaN  \n",
       "offset[1, 0]    1000.0    NaN  \n",
       "offset[2, 0]    1000.0    NaN  \n",
       "offset[3, 0]    1000.0    NaN  \n",
       "offset[4, 0]    1000.0    NaN  \n",
       "offset[5, 0]    1000.0    NaN  \n",
       "offset[6, 0]    1000.0    NaN  \n",
       "offset[7, 0]    1000.0    NaN  \n",
       "sigma[0]        1000.0    NaN  \n",
       "sigma[1]        1000.0    NaN  \n",
       "sigma[2]        1000.0    NaN  \n",
       "sigma[3]        1000.0    NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arviz as az\n",
    "data = az.from_numpyro(m)\n",
    "az.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28912305, 0.96183663, 1.42779941, 0.15728591])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random centered effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.7328625  0.13674371 0.13039377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.66280484 0.1774538  0.15974137]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    print(L_individual.shape)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = ((Sigma_individual[..., None] * L_individual) @ z_individual)\n",
    "    print(alpha.shape)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1, chain_method='vectorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bi' object has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39marray(a))) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumpypro estimation:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bi' object has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.006054 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 60.54 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[26] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[89] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: log1m: x is 1, but must be less than or equal to 1.000000 (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 12, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 432.2593 seconds\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#################################### Pustan Model  #############################\n",
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "tmp = dat\n",
    "tmp['y'] = np.array(tmp['y'])\n",
    "tmp['i_ID'] = np.array(tmp['i_ID']+1)\n",
    "tmp['ni'] = tmp['ni']\n",
    "tmp['K'] = tmp['K']\n",
    "tmp['N'] = int(N)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "    int<lower=0>  N;             // number of observations\n",
    "    int<lower=0>  K;             // number of occupations\n",
    "    int ni;                     // NUmber of Unique Individauls\n",
    "    array[N, K] int y;           // array of observed occupation indicators\n",
    "    array[N]int<lower=0>  i_ID;     // village indicator for each individual\n",
    "}\n",
    "parameters {\n",
    "    vector[K] a;                    // intercept for each occupation\n",
    "    matrix[ni, K]  z_individual;    // raw random effect for household \n",
    "    cholesky_factor_corr[ni] L_individual; // Cholesky factor for \n",
    "    vector<lower=0>[ni] Sigma_individual;\n",
    "\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[ni, K] b_individual;\n",
    "    b_individual = diag_pre_multiply(Sigma_individual, L_individual) * z_individual;\n",
    "}\n",
    "model{\n",
    "    array[N] vector[K] p;\n",
    "    matrix[N, K] random_effects;\n",
    "    to_vector(a) ~ normal(0, 1);\n",
    "    L_individual ~   lkj_corr_cholesky(2);\n",
    "    Sigma_individual ~ exponential(1);\n",
    "    to_vector(z_individual) ~ normal(0, 1);\n",
    "    // Likelihood for\n",
    "    for (k in 1:K) {\n",
    "        for (i in 1:N) {\n",
    "          random_effects[i, k] = b_individual[i_ID[i], k];\n",
    "          p[i,k] =  a[k] + random_effects[i, k];\n",
    "      }\n",
    "    }\n",
    "    for (i in 1:(N)) {\n",
    "        y[i,] ~ dirichlet_multinomial(exp(p[i,]));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = tmp)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500, init = [{'L_individual': np.zeros((tmp['ni'], tmp['ni']))}])\n",
    "end = tm.time()    \n",
    "#df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Estimation Multinomial:\n",
      "[0.79368174 0.11202765 0.0942907 ]\n",
      "Estimation DirichletMultinomial:\n",
      "Pytstan estimation\n",
      "[0.7914235  0.11247264 0.09610377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(np.array([3,1,1])))) \n",
    "print('Estimation Multinomial:')\n",
    "post = m.sampler.get_samples()\n",
    "print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "print('Estimation DirichletMultinomial:')\n",
    "#post = m2.sampler.get_samples()\n",
    "#print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "df = fit.to_frame()\n",
    "print('Pytstan estimation')\n",
    "print(jax.nn.softmax(jnp.array([df['a.1'].mean(),df['a.2'].mean(),df['a.3'].mean()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance matrix \n",
    "L = jnp.arange(1,11)\n",
    "m = jnp.abs(L[:, None] - L[None, :])\n",
    "\n",
    "# Kernel\n",
    "@jit\n",
    "def sq_exp_gp(m, sq_alpha = .5, sq_rho = .1, delta = 0):\n",
    "    N = m.shape[0]\n",
    "    K = jnp.full((N,N),  sq_alpha + delta)\n",
    "    K = K + sq_alpha * jnp.exp(-sq_rho * m * m )\n",
    "\n",
    "    mask = jnp.triu(jnp.ones_like(K, dtype=bool))\n",
    "    cov = jnp.where(mask, K, 0)\n",
    "    return K, cov\n",
    "\n",
    "r = sq_exp_gp(m)\n",
    "Z = Normal(0,1).sample(10)\n",
    "a = r[1] @ jnp.transpose(r[1]) @ Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine latent, random and gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent + random = random + latent[village[i]] with village being village ID\n",
    "# gaussian simulation \n",
    "# 1. non linear function to generate gaussian proces for each parameters\n",
    "# model 2 = random + latent[village[i]] + gaussian_process\n",
    "# model 3  = model 2 + interaction effect\n",
    "#interaction effect = non linear function where input is hhmembers[i]*offsets[vilage[i]] with new coefficients params\n",
    "# Within model we need to change offset ouput as an integer so we do bxi*hhmembers[i]*offset[v_ID[i]]+ bxIsq*(hhmembers[i]*offset[v_ID[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    #individual \n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 50)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha_individual = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "\n",
    "    #household \n",
    "    Sigma_household = exponential('Sigma_household', [ni], 1 )\n",
    "    L_household = lkjcholesky('L_household', [], ni, 50)\n",
    "    z_household = normal('z_household', [ni,K], 0, 1)\n",
    "    alpha_household = random_centered2(Sigma_household, L_household, z_household)\n",
    "\n",
    "    #village \n",
    "    Sigma_village = exponential('Sigma_village', [ni], 1 )\n",
    "    L_village = lkjcholesky('L_village', [], ni, 50)\n",
    "    z_village = normal('z_village', [ni,K], 0, 1)\n",
    "    alpha_village = random_centered2(Sigma_village, L_village, z_village)\n",
    "\n",
    "    #LK\n",
    "    random_factors = alpha_individual[i_ID] + alpha_household[i_ID] + alpha_village[i_ID]\n",
    "    numpyro.sample(\"y\", dist.DirichletMultinomial(a + random_factors[i_ID], int(12083)), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test parallelized random centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "Sigma_i = Exponential(1).sample(init_key, [ni,])\n",
    "L_i= LKJCholesky(ni, 1).sample(init_key, [])\n",
    "z_i= Normal(0, 1).sample([ni,K])\n",
    "alpha = random_centered(Sigma_i, L_i, z_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$Sigma_i = exponential(1)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import display, Latex\n",
    "greek_symbols = {\n",
    "    'alpha': '\\\\alpha',\n",
    "    'beta': '\\\\beta',\n",
    "    'gamma': '\\\\gamma',\n",
    "    'delta': '\\\\delta',\n",
    "    'epsilon': '\\\\epsilon',\n",
    "    'zeta': '\\\\zeta',\n",
    "    'eta': '\\\\eta',\n",
    "    'theta': '\\\\theta',\n",
    "    'iota': '\\\\iota',\n",
    "    'kappa': '\\\\kappa',\n",
    "    'lambda': '\\\\lambda',\n",
    "    'mu': '\\\\mu',\n",
    "    'nu': '\\\\nu',\n",
    "    'xi': '\\\\xi',\n",
    "    'omicron': 'o',  # No direct LaTeX symbol for omicron, using \"o\"\n",
    "    'pi': '\\\\pi',\n",
    "    'rho': '\\\\rho',\n",
    "    'sigma': '\\\\sigma',\n",
    "    'tau': '\\\\tau',\n",
    "    'upsilon': '\\\\upsilon',\n",
    "    'phi': '\\\\phi',\n",
    "    'chi': '\\\\chi',\n",
    "    'psi': '\\\\psi',\n",
    "    'omega': '\\\\omega'\n",
    "}\n",
    "\n",
    "def convert_to_greek(var_name):\n",
    "    # Convert variable name to lowercase for case-insensitive matching\n",
    "    var_name_lower = var_name.lower()\n",
    "    # Check if the variable name has a corresponding Greek symbol\n",
    "    if var_name_lower in greek_symbols:\n",
    "        return greek_symbols[var_name_lower]\n",
    "    else:\n",
    "        return var_name\n",
    "\n",
    "def extract_latex(command):\n",
    "    # Define a regular expression pattern to match the desired parts of the command\n",
    "    pattern = r\"(\\w+)\\s*=\\s*(\\w+)\\([^,]+,\\s*[^,]+,\\s*(.*)\\)\"\n",
    "    match = re.match(pattern, command)\n",
    "    \n",
    "    if match:\n",
    "        var_name = match.group(1)\n",
    "        func_name = match.group(2)\n",
    "        params = match.group(3)\n",
    "        # Convert var_name to Greek symbol if applicable\n",
    "        var_name_latex = convert_to_greek(var_name)\n",
    "        # Construct the desired LaTeX text\n",
    "        latex_text = f\"{var_name_latex} = {func_name}({params})\"\n",
    "        return latex_text\n",
    "    else:\n",
    "        return None\n",
    "# Example usage\n",
    "command = \"Sigma_i = exponential('Sigma_individual', [ni], 1)\"\n",
    "latex_text = extract_latex(command)\n",
    "display(Latex(f'''${latex_text}$'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of concept : function for multiple priors at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Howell1.csv', sep=';') \n",
    "m.data = m.data[m.data .age > 18]\n",
    "m.data.weight = m.data.weight - m.data.weight.mean()\n",
    "m.data.age = m.data.age - m.data.age.mean()\n",
    "weight = jnp.array(m.data.weight.values)\n",
    "height = jnp.array(m.data.height.values)\n",
    "# TODO: use jax arrays with hugging face package\n",
    "\n",
    "m.data = dict(height = height, weight = weight)\n",
    "\n",
    "def regression_priors():\n",
    "    s = uniform('s', [1], 0, 50)\n",
    "    a = normal('a', [1], 178, 20)\n",
    "    b = normal('b', [1], 0, 1)  \n",
    "    return s, a, b\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s, a, b = regression_priors()\n",
    "    sample(\"y\", Normal(a + b * weight, s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
