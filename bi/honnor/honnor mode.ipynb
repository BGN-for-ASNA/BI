{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "from main import *\n",
    "from functools import partial\n",
    "import time as tm\n",
    "m = bi(platform='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability distributions creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dist.exponential of <dists.Dist object at 0x7f195bf47fd0>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampler for pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.5420704], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.exponential(sample_shape = (1,), seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random centered factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Mutils.Mrandom at 0x7f18f46cd720>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussian related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Mutils.Mgaussian at 0x7f18f46cd780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network related function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Network.netUtils at 0x7f195bf64040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "mat = jnp.array([[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8],\n",
    "                [9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "@jit\n",
    "def diag_pre_multiply(v, m):\n",
    "    return jnp.matmul(jnp.diag(v), m)#\n",
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors #\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k#\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]]\n",
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]\n",
      " [4 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "@partial(jit, static_argnums=(1, 2,))\n",
    "def vec_to_mat(arr, N, K):\n",
    "    return jnp.reshape(arr, (N, K))\n",
    "\n",
    "vec = jnp.array([1,2,3,4])\n",
    "\n",
    "receiver = jnp.tile(vec, (4,1))\n",
    "sender = receiver.T\n",
    "print(receiver)\n",
    "print(sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "N_id = 4\n",
    "sr_raw =  sample.normal(0, 1, sample_shape=(N_id, 2))\n",
    "sr_sigma =  sample.exponential(1, sample_shape= (2,))\n",
    "sr_L = sample.lkjcholesky(2, 4)\n",
    "rf_sr = vmap(lambda x: random_centered(sr_sigma, sr_L, x))(sr_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.29007038, -2.0102808 ],\n",
       "       [ 0.10813467,  0.8829876 ],\n",
       "       [-0.09551398,  1.19697   ],\n",
       "       [ 0.11215734, -3.4375284 ],\n",
       "       [-0.05224978, -1.5608484 ],\n",
       "       [-0.165471  ,  0.574221  ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_raw =  sample.normal(0, 1, sample_shape=(int(N_id*(N_id-1)/2), 2))\n",
    "dr_sigma =  sample.exponential(1, sample_shape= (2,))\n",
    "dr_L = sample.lkjcholesky(2, 4)\n",
    "rf_dr = vmap(lambda x: random_centered(dr_sigma, dr_L, x))(dr_raw)\n",
    "rf_dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.        , -2.0102808 ,  0.8829876 ,  1.19697   ],\n",
       "       [ 0.29007038,  0.        , -3.4375284 , -1.5608484 ],\n",
       "       [ 0.10813467,  0.11215734,  0.        ,  0.574221  ],\n",
       "       [-0.09551398, -0.05224978, -0.165471  ,  0.        ]],      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edgl_to_mat(edgl, N_id):\n",
    "    m = jnp.zeros((N_id,N_id))\n",
    "    urows, ucols   = jnp.triu_indices(N_id, 1)\n",
    "    m = m.at[(urows, ucols)].set(edgl[:,0])\n",
    "    m = m.T\n",
    "    m2 = m.at[(urows, ucols)].set(edgl[:,1])\n",
    "    return m2\n",
    "edgl_to_mat(rf_dr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[nan,  1.,  1.,  1.],\n",
       "       [ 1., nan,  1.,  1.],\n",
       "       [ 1.,  1., nan,  1.],\n",
       "       [ 1.,  1.,  1., nan]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = jnp.ones((4,4))\n",
    "output = output.at[jnp.diag_indices(4)].set(jnp.nan)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.        , -2.0102808 ,  0.8829876 ,  1.19697   ],\n",
       "       [ 0.29007038,  0.        , -3.4375284 , -1.5608484 ],\n",
       "       [ 0.10813467,  0.11215734,  0.        ,  0.574221  ],\n",
       "       [-0.09551398, -0.05224978, -0.165471  ,  0.        ]],      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgl_to_mat(rf_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n",
      "sr ok \n",
      "dr ok \n",
      "sr ok \n",
      "dr ok \n",
      "sr ok \n",
      "dr ok \n",
      "sr ok \n",
      "dr ok \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4026878/4042951325.py:34: UserWarning: Site Y: Out-of-support values provided to log prob method. The value argument should be within the support.\n",
      "  m.run(random.PRNGKey(0), **dat)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot find valid initial parameters. Please check your model again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 34\u001b[0m\n\u001b[1;32m     28\u001b[0m dat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     29\u001b[0m     N_id \u001b[38;5;241m=\u001b[39m N_id,\n\u001b[1;32m     30\u001b[0m     result_outcomes \u001b[38;5;241m=\u001b[39m output,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m m \u001b[38;5;241m=\u001b[39m MCMC(NUTS(model), num_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, num_chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m res \u001b[38;5;241m=\u001b[39m az\u001b[38;5;241m.\u001b[39mfrom_numpyro(m)\n\u001b[1;32m     36\u001b[0m res\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:644\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m map_args \u001b[38;5;241m=\u001b[39m (rng_key, init_state, init_params)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 644\u001b[0m     states_flat, last_state \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     states \u001b[38;5;241m=\u001b[39m tree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[jnp\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], states_flat)\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:426\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Check if _sample_fn is None, then we need to initialize the sampler.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sample_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 426\u001b[0m     new_init_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     init_state \u001b[38;5;241m=\u001b[39m new_init_state \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m init_state\n\u001b[1;32m    434\u001b[0m sample_fn, postprocess_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cached_fns()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:743\u001b[0m, in \u001b[0;36mHMC.init\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# vectorized\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     rng_key, rng_key_init_model \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mswapaxes(\n\u001b[1;32m    741\u001b[0m         vmap(random\u001b[38;5;241m.\u001b[39msplit)(rng_key), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    742\u001b[0m     )\n\u001b[0;32m--> 743\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_key_init_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn \u001b[38;5;129;01mand\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid value of `init_params` must be provided with\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `potential_fn`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:687\u001b[0m, in \u001b[0;36mHMC._init_state\u001b[0;34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         (\n\u001b[1;32m    683\u001b[0m             new_init_params,\n\u001b[1;32m    684\u001b[0m             potential_fn,\n\u001b[1;32m    685\u001b[0m             postprocess_fn,\n\u001b[1;32m    686\u001b[0m             model_trace,\n\u001b[0;32m--> 687\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforward_mode_differentiation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_mode_differentiation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m             init_params \u001b[38;5;241m=\u001b[39m new_init_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/util.py:748\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[1;32m    735\u001b[0m                             w\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    736\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSite \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    737\u001b[0m                                     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], w\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    738\u001b[0m                                 ),\n\u001b[1;32m    739\u001b[0m                             ) \u001b[38;5;241m+\u001b[39m w\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    740\u001b[0m                             warnings\u001b[38;5;241m.\u001b[39mshowwarning(\n\u001b[1;32m    741\u001b[0m                                 w\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m    742\u001b[0m                                 w\u001b[38;5;241m.\u001b[39mcategory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m                                 line\u001b[38;5;241m=\u001b[39mw\u001b[38;5;241m.\u001b[39mline,\n\u001b[1;32m    747\u001b[0m                             )\n\u001b[0;32m--> 748\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find valid initial parameters. Please check your model again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m         )\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\n\u001b[1;32m    752\u001b[0m     ParamInfo(init_params, pe, grad), potential_fn, postprocess_fn, model_trace\n\u001b[1;32m    753\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot find valid initial parameters. Please check your model again."
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "from main import *\n",
    "from functools import partial\n",
    "import time as tm\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "N_id = 4\n",
    "def model(N_id, result_outcomes):\n",
    "    # sr-----------------------------------------------------------------------------------\n",
    "    sr_raw =  dist.normal('sr_raw', 0, 1, sample_shape=(N_id, 2))\n",
    "    sr_sigma =  dist.exponential('sr_sigma', 1, sample_shape= (2,))\n",
    "    sr_L = dist.lkjcholesky('sr_L', 2, 4)\n",
    "    rf_sr = vmap(lambda x: random_centered(sr_sigma, sr_L, x))(sr_raw)\n",
    "\n",
    "    rf_receiver = jnp.tile(rf_sr[:,0], (4,1))\n",
    "    rf_sender = jnp.tile(rf_sr[:,1], (4,1))\n",
    "    print('sr ok ')\n",
    "\n",
    "    # dr -----------------------------------------------------------------------------------\n",
    "    dr_raw =  dist.normal('dr_raw', 0, 1, sample_shape=(int(N_id*(N_id-1)/2), 2))\n",
    "    dr_sigma =  dist.exponential('dr_sigma', 1, sample_shape= (2,))\n",
    "    dr_L = dist.lkjcholesky('dr_L', 2, 4)\n",
    "    rf_dr = vmap(lambda x: random_centered(dr_sigma, dr_L, x))(dr_raw)\n",
    "    print('dr ok ')\n",
    "\n",
    "    lk('Y', Bernoulli(logits = 1 +  rf_receiver + rf_sender + edgl_to_mat(rf_dr)), obs=result_outcomes)\n",
    "\n",
    "dat = dict(\n",
    "    N_id = N_id,\n",
    "    result_outcomes = output,\n",
    ")\n",
    "\n",
    "m = MCMC(NUTS(model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        lk('Y', Poisson(jnp.exp(B[0] + sr + dr)), obs=result_outcomes)\n",
    "\n",
    "dat = dict(\n",
    "    N_id = N_id,\n",
    "    result_outcomes = result_outcomes,\n",
    "    d_s = d_s, d_r = d_r,\n",
    "    focal_individual_predictors = focal_individual_predictors,\n",
    "    target_individual_predictors = target_individual_predictors,\n",
    "    outcome_mode = int(3),\n",
    "    exposure = mat_to_edgl(exposure)\n",
    ")\n",
    "m = MCMC(NUTS(model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "#init_key = jnp.array(init_key)\n",
    "\n",
    "@partial(jit, static_argnums=(1, 2,))\n",
    "def vec_to_mat(arr, N, K):\n",
    "    return jnp.reshape(arr, (N, K))\n",
    "\n",
    "@jit\n",
    "def jax_LinearOperatorDiag(s, cov):    \n",
    "    def multiply_with_s(a):\n",
    "        return jnp.multiply(a, s)\n",
    "    vectorized_multiply = vmap(multiply_with_s)\n",
    "    return jnp.transpose(vectorized_multiply(cov))\n",
    "import jax.numpy as jnp\n",
    "\n",
    "@jit\n",
    "def diag_pre_multiply(v, m):\n",
    "    return jnp.matmul(jnp.diag(v), m)\n",
    "\n",
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.random as jaxr\n",
    "\n",
    "@jit\n",
    "def logit(x):\n",
    "    return jnp.log(x / (1 - x))\n",
    "\n",
    "\n",
    "@jit\n",
    "def apply_row_dotproduct(A, v):\n",
    "    \"\"\"\n",
    "    Perform matrix-vector multiplication for each row of the array v.\n",
    "\n",
    "    Parameters:\n",
    "    A (jax.numpy.ndarray): A 2x2 matrix.\n",
    "    v (jax.numpy.ndarray): An array of shape (n, 2) where each row is a 2-vector.\n",
    "\n",
    "    Returns:\n",
    "    jax.numpy.ndarray: An array of shape (n, 2) where each row is the result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "    # Define a function that performs the matrix-vector multiplication\n",
    "    def dotvec(A, v):\n",
    "        return jnp.dot(A, v)\n",
    "    \n",
    "    # Vectorize the function using jax.vmap\n",
    "    vmap_dotvec = jax.vmap(lambda v: dotvec(A, v))\n",
    "    \n",
    "    # Apply the vectorized function to the array of vectors\n",
    "    result = vmap_dotvec(v)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def apply_row_matmul(v, A):\n",
    "    \"\"\"\n",
    "    Perform matrix-vector multiplication for each row of the array v.\n",
    "\n",
    "    Parameters:\n",
    "    A (jax.numpy.ndarray): A 2x2 matrix.\n",
    "    v (jax.numpy.ndarray): An array of shape (n, 2) where each row is a 2-vector.\n",
    "\n",
    "    Returns:\n",
    "    jax.numpy.ndarray: An array of shape (n, 2) where each row is the result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "    # Define a function that performs the matrix-vector multiplication\n",
    "    def matvec(A, v):\n",
    "        return A * v\n",
    "    \n",
    "    # Vectorize the function using jax.vmap\n",
    "    vmap_matvec = jax.vmap(lambda v: matvec(A, v))\n",
    "    \n",
    "    # Apply the vectorized function to the array of vectors\n",
    "    result = vmap_matvec(v)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def transform_matrix(X):\n",
    "    Y = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if i != j:\n",
    "                Y.append(jnp.array([X[i, j], X[j, i]]))\n",
    "    return jnp.concatenate(Y).reshape(-1, 2)\n",
    "\n",
    "# vec_to_mat ------------------------------------------------------------------\n",
    "@jit\n",
    "def vec_to_mat(vec):\n",
    "    # Repeat the array to fill a 10x10 matrix\n",
    "    m = jnp.transpose(jnp.tile(vec, (vec.shape[0] , 1)))\n",
    "    m = jnp.where(jnp.eye(m.shape[0], dtype=bool), 0, m)\n",
    "    return m\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "print(\"vec_to_mat: \")\n",
    "v = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(vec_to_mat(v))\n",
    "\n",
    "\n",
    "# Triangles ------------------------------------------------------------------\n",
    "def upper_tri(array, diag=1):\n",
    "    \"\"\"Extracts the upper triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "    \"\"\"\n",
    "    upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "    upper_triangle_elements = array[upper_triangle_indices]\n",
    "    return upper_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_upper_tri = jit(upper_tri, static_argnums=(1,))\n",
    "\n",
    "\n",
    "def lower_tri(array, diag=-1):\n",
    "    \"\"\"Extracts the lower triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=0 includes the diagonal, diag=-1 excludes it.\n",
    "    \"\"\"\n",
    "    lower_triangle_indices = jnp.tril_indices(array.shape[0], k=diag)\n",
    "    lower_triangle_elements = array[lower_triangle_indices]\n",
    "    return lower_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_lower_tri = jit(lower_tri, static_argnums=(1,))\n",
    "\n",
    "def get_tri(array, type='upper', diag=0):\n",
    "    \"\"\"Extracts the upper, lower, or both triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        type (str): A string indicating which part of the triangle to extract.\n",
    "                    It can be 'upper', 'lower', or 'both'.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "\n",
    "    Returns:\n",
    "        If argument type is 'upper', 'lower', it return a 1D JAX array containing the requested triangle elements.\n",
    "        If argument type is 'both', it return a 2D JAX array containing the the first column the lower triangle and in the second ecolumn the upper triangle\n",
    "    \"\"\"\n",
    "    if type == 'upper':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        triangle_elements = array[upper_triangle_indices]\n",
    "    elif type == 'lower':\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        triangle_elements = array[lower_triangle_indices]\n",
    "    elif type == 'both':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        upper_triangle_elements = array[upper_triangle_indices]\n",
    "        lower_triangle_elements = array[lower_triangle_indices]\n",
    "        triangle_elements = jnp.stack((upper_triangle_elements,lower_triangle_elements), axis = 1)\n",
    "    else:\n",
    "        raise ValueError(\"type must be 'upper', 'lower', or 'both'\")\n",
    "\n",
    "    return triangle_elements\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "array = jnp.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "print(\"get_upper_tri: \")\n",
    "result1 = get_upper_tri(array, 1)\n",
    "print(result1)\n",
    "\n",
    "print(\"get_lower_tri: \")\n",
    "result2 = get_lower_tri(array, -1)  # Change diag to -1 to exclude the diagonal\n",
    "print(result2)\n",
    "\n",
    "# JIT compile the function with static_argnums\n",
    "get_triangle = jit(get_tri, static_argnames=('type', 'diag'))\n",
    "\n",
    "print(\"On function for upper,  lower and both triangles: \")\n",
    "# Test the function\n",
    "result_upper = get_triangle(array, 'upper', 1)\n",
    "print(\"Upper triangle elements (excluding diagonal):\", result_upper)\n",
    "\n",
    "result_lower = get_triangle(array, 'lower', 1)\n",
    "print(\"Lower triangle elements (excluding diagonal):\", result_lower)\n",
    "\n",
    "result_both = get_triangle(array, 'both', 1)\n",
    "print(\"Both triangle elements (excluding diagonal):\", result_both)\n",
    "\n",
    "\n",
    "# Dot product betwee matrix and 2x2 cov mat-----------------------------\n",
    "# Compute the result matrix\n",
    "@jit\n",
    "def dot_mat_cov(mat, cov):\n",
    "    \"\"\"dot productbetween [sr_raw_M[i,j],sr_raw_M[j,i]] and diag for each combinations of i and j. where M is a 2x2 matrix of shape 10x10 and diag a 2x2x matrix of 2x2. The return object should be a matrix of shape equal to M.\n",
    "\n",
    "    Args:\n",
    "        mat (2d jax array): _description_\n",
    "        cov (2d jax array): _description_\n",
    "    \"\"\"\n",
    "    def compute_ij(i, j):\n",
    "        # Create the 2x2 tensor from sr_raw_M for indices (i, j)\n",
    "        tensor_2 = jnp.array([[mat[i, j], mat[j, i]]])\n",
    "        \n",
    "        # Perform the dot product with cov\n",
    "        return jnp.einsum('ij,ij->',tensor_2 , cov)\n",
    "    \n",
    "    # Create a result matrix with the same shape as sr_raw_M\n",
    "    result_matrix = jnp.zeros_like(mat)\n",
    "    \n",
    "    # Vectorized computation using broadcasting\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            result_matrix = result_matrix.at[i, j].set(compute_ij(i, j))\n",
    "    \n",
    "    return result_matrix\n",
    "\n",
    "# Compute the result matrix\n",
    "#result_matrix = dot_mat_cov(sr_raw_M, diag)\n",
    "\n",
    "# Display the resulting matrix\n",
    "print(\"Dot product betwee matrix and 2x2 cov mat\")\n",
    "#print(result_matrix)\n",
    "\n",
    "\n",
    "# vec_node_to_edgle-----------------------------\n",
    "@jit\n",
    "def vec_node_to_edgle(sr):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sr (2D array): Each column represent an characteristic or effect and  each row represent the value of i for the characteristic of the given column\n",
    "\n",
    "    Returns:\n",
    "        (2D array): return and edgelist of all dyads combination (excluding diagonal).\n",
    "        First column represent the value fo individual i  in the first column of argument sr, the second column the value of j in the second column of argument sr\n",
    "    \"\"\"\n",
    "    N = sr.shape[0]\n",
    "    lrows, lcols   = jnp.tril_indices(N, k=-1)\n",
    "    urows, ucols   = jnp.triu_indices(N, k=1)\n",
    "    ft = sr[urows,0]\n",
    "    tf = sr[ucols, 1]\n",
    "    return jnp.stack([ft, tf], axis = -1)\n",
    "\n",
    "print(\"vec_node_to_edgle:\")\n",
    "id = jnp.stack([jnp.arange(0,4), jnp.arange(0,4)], axis= 1)\n",
    "print(vec_node_to_edgle(id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def mat_to_edgl(mat):\n",
    "    N = mat.shape[0]\n",
    "    # From to \n",
    "    urows, ucols   = jnp.triu_indices(N, k=1)\n",
    "    ft = mat[(urows,ucols)]\n",
    "\n",
    "    m2 = jnp.transpose(mat)\n",
    "    tf = m2[(urows,ucols)]\n",
    "    return jnp.stack([ft, tf], axis = -1)\n",
    "\n",
    "\n",
    "mat = jnp.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12],\n",
    "                   [13, 14, 15, 16]])\n",
    "edgl = mat_to_edgl(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRAND function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sender receiver and dyadic terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def prerpare_dyadic_effect(list_mat):\n",
    "    if len(list_mat.shape) == 2:\n",
    "        d = mat_to_edgl(list_mat)\n",
    "        d_s = d[:,0]\n",
    "        d_r = d[:,1]\n",
    "\n",
    "    elif len(list_mat.shape) == 3:\n",
    "        dyadic_effects = vmap(mat_to_edgl)(list_mat) \n",
    "        d_s = dyadic_effects[:,:,0].T\n",
    "        d_r = dyadic_effects[:,:,1].T\n",
    "        return d_s, d_r\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a 2D or 3D array\")   \n",
    "    return d_s, d_r\n",
    "\n",
    "## Examples \n",
    "#list_mat =  jnp.array([Kinship, Dominant] ) # user give a 3d jax array \n",
    "#prerpare_dyadic_effect(list_mat)\n",
    "#prerpare_dyadic_effect(Kinship)\n",
    "\n",
    "@jit\n",
    "def prepare_outcome_effects(list_mat):\n",
    "    return prerpare_dyadic_effect(list_mat)\n",
    "\n",
    "def nodes_random_effects(N_id, sr_mu = 0, sr_sd = 1, sr_sigma = 1, cholesky_dim = 2, cholesky_density = 2 ):\n",
    "    sr_raw =  dist.normal('sr_raw', sr_mu, sr_sd, sample_shape=[N_id, 2])\n",
    "    sr_sigma =  dist.exponential('sr_sigma', sr_sigma, sample_shape= [2])\n",
    "    sr_L = dist.lkjcholesky(\"sr_L\", cholesky_dim, cholesky_density)\n",
    "    rf = vmap(lambda x: random_centered(sr_sigma, sr_L, x))(sr_raw)\n",
    "    return rf, sr_raw, sr_sigma, sr_L # we return everything to get posterior distributions for each parameters\n",
    "\n",
    "def nodes_terms(N_var, focal_individual_predictors, target_individual_predictors,\n",
    "                s_mu = 0, s_sd = 1, r_mu = 0, r_sd = 1 ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        focal_individual_predictors (2D jax array): each column represent node characteristics.\n",
    "        target_individual_predictors (2D jax array): each column represent node characteristics.\n",
    "        s_mu (int, optional): Default mean prior for focal_effect, defaults to 0.\n",
    "        s_sd (int, optional): Default sd prior for focal_effect, defaults to 1.\n",
    "        r_mu (int, optional): Default mean prior for target_effect, defaults to 0.\n",
    "        r_sd (int, optional): Default sd prior for target_effect, defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        _type_: terms, focal_effects, target_effects\n",
    "    \"\"\"\n",
    "    focal_effects = dist.normal('focal_effects', s_mu, s_sd, sample_shape=[N_var,])\n",
    "    target_effects =  dist.normal('target_effects', r_mu, r_sd, sample_shape=[N_var,])\n",
    "    terms = jnp.stack([apply_row_dotproduct(focal_effects, focal_individual_predictors)[:,0],\n",
    "               apply_row_dotproduct(target_effects, target_individual_predictors)[:,0]], axis = -1)\n",
    "    return terms, focal_effects, target_effects # we return everything to get posterior distributions for each parameters\n",
    "\n",
    "def dyadic_random_effects(N_id, dr_mu = 0, dr_sd = 1, dr_sigma = 1, cholesky_dim = 2, cholesky_density = 2):\n",
    "    dr_raw =  dist.normal('dr_raw',0,1, sample_shape=[N_id,2])\n",
    "    dr_sigma = dist.exponential('dr_sigma',1, sample_shape=[1])\n",
    "    dr_L = dist.lkjcholesky(\"dr_L\", cholesky_dim, cholesky_density)\n",
    "    rf = vmap(lambda x: random_centered(jnp.repeat(dr_sigma,2), dr_L, x))(dr_raw)\n",
    "    return rf, dr_raw, dr_sigma, dr_L # we return everything to get posterior distributions for each parameters\n",
    "\n",
    "def dyadic_terms(d_s, d_r, d_m = 0, d_sd = 1):\n",
    "    dyad_effects = dist.normal('dyad_effects', d_m, d_sd)\n",
    "    terms1 = apply_row_dotproduct(dyad_effects,  d_s)\n",
    "    terms2 = apply_row_dotproduct(dyad_effects,  d_r)\n",
    "    rf = jnp.stack([terms1, terms2], axis = 1)\n",
    "    return rf, dyad_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block model terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_set1 = sample.binomial(1, probs= 0.5, sample_shape=(4,))\n",
    "block_set2 = sample.binomial(4, probs= 0.5, sample_shape=(4,))\n",
    "block_set = jnp.stack([block_set1, block_set2], axis = 1)  # Dataframe holding the group ID codes for each person (rows) for each variable type (cols)\n",
    "block_effects = jnp.zeros_like(block_set) # Block effects, stored as a vector to save space\n",
    "\n",
    "block_indexes = [0] \n",
    "block_param_size = 0\n",
    "max_N_groups = 0 # Max number of group labels in any variable\n",
    "N_groups_per_var = [] # Number of group labels, per variable type\n",
    "N_group_vars = block_set.shape[1] # Number of block structure variables\n",
    "N_per_group = []\n",
    "\n",
    "for i in range(block_set.shape[1]):\n",
    "    N_grp = len(jnp.unique(block_set[:, i]))\n",
    "    N_groups_per_var.append(N_grp)\n",
    "    N_per_group.append(jnp.zeros((N_grp, int(block_effects.shape[0]))))\n",
    "    if N_grp > max_N_groups:\n",
    "        max_N_groups = N_grp\n",
    "\n",
    "    block_param_size = block_param_size + N_grp * N_grp\n",
    "    block_indexes.append( block_indexes[i] + N_grp * N_grp)\n",
    "\n",
    "def node_grp_to_mat(vec):\n",
    "    unique_values, inverse_indices = jnp.unique(vec, return_inverse=True)\n",
    "    return jnp.eye(len(unique_values))[inverse_indices].T\n",
    "\n",
    "node_grp_to_mat(block_set[:,0]) \n",
    "r = []\n",
    "for i in range(block_set.shape[1]):\n",
    "    r.append(node_grp_to_mat(block_set[:,i]) )\n",
    "\n",
    "block_effects = sample.normal(0, 1, sample_shape=(block_param_size,)) # Block effects, stored as a vector to save space\n",
    "\n",
    "B = jnp.zeros((N_group_vars, max_N_groups,max_N_groups)) # Block effects, in array form\n",
    "\n",
    "# Sum of block effects per dyad  \n",
    "br = jnp.zeros((N_group_vars,))\n",
    "\n",
    "# The first step, is to transform the vector of block effects into a list of matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_model_prior(N_grp, \n",
    "                      b_ij_mean = 0.01, b_ij_sd = 2.5, \n",
    "                      b_ii_mean = 0.1, b_ii_sd = 2.5,\n",
    "                      name_b_ij = 'b_ij', name_b_ii = 'b_ii'):\n",
    "    \"\"\"Build block model prior matrix for within and between group links probabilities#\n",
    "    Args:\n",
    "        N_grp (int): Number of blocks\n",
    "        b_ij_mean (float, optional): mean prior for between groups. Defaults to 0.01.\n",
    "        b_ij_sd (float, optional): sd prior for between groups. Defaults to 2.5.\n",
    "        b_ii_mean (float, optional): mean prior for within groups. Defaults to 0.01.\n",
    "        b_ii_sd (float, optional): sd prior for between groups. Defaults to 2.5.#\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    b_ij = dist.normal(name_b_ij, logit(b_ij_mean/jnp.sqrt(N_grp*0.5 + N_grp*0.5)), b_ij_sd, sample_shape=(N_grp, N_grp)) # transfers more likely within groups\n",
    "    b_ii = dist.normal(name_b_ii, logit(b_ii_mean/jnp.sqrt(N_grp)), b_ii_sd, sample_shape=(N_grp, )) # transfers less likely between groups\n",
    "    b = b_ij\n",
    "    b = b.at[jnp.diag_indices_from(b)].set(b_ii)\n",
    "    return b, b_ij, b_ii#\n",
    "def block_prior_to_edglelist(v, b):\n",
    "    \"\"\"Convert block vector id group belonging to edgelist of i->j group values#\n",
    "    Args:\n",
    "        v (1D array):  Vector of id group belonging\n",
    "        b (2D array): Matrix of block model prior matrix#\n",
    "    Returns:\n",
    "        _type_: 1D array representing the probability of links from i-> j \n",
    "    \"\"\"\n",
    "    v = jnp.stack([v, v], axis= 1)\n",
    "    v = vec_node_to_edgle(jnp.stack([block_set[:,0],block_set[:,0]], axis = 1))\n",
    "    return b[(v[:,0], v[:,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#def index(df, cols = 'all'):\n",
    "#    index_map = {}\n",
    "#    if cols == 'all':\n",
    "#        colCat = list(df.select_dtypes(['object']).columns)    \n",
    "#        for a in range(len(colCat)):                \n",
    "#            df[\"index_\"+ colCat[a]] =  df.loc[:,colCat[a]].astype(\"category\").cat.codes\n",
    "#            df[\"index_\"+ colCat[a]] = df[\"index_\"+ colCat[a]].astype(np.int64)\n",
    "#            index_map[colCat[a]] = dict(enumerate(df[colCat[a]].astype(\"category\").cat.categories ) )\n",
    "#    else:\n",
    "#        if isinstance(cols, list) == False:\n",
    "#            cols = [cols]\n",
    "#        for a in range(len(cols)):\n",
    "#            df[\"index_\"+ cols[a]] =  df.loc[:,cols[a]].astype(\"category\").cat.codes\n",
    "#            df[\"index_\"+ cols[a]] = df[\"index_\"+ cols[a]].astype(np.int64)\n",
    "#            index_map[cols[a]] = dict(enumerate(df[cols[a]].astype(\"category\").cat.categories ) )\n",
    "#    df.columns = df.columns.str.replace('.', '_')\n",
    "#    df.columns = df.columns.str.replace(' ', '_')\n",
    "#    \n",
    "#    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Continuous variable: Model (model 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1235.69it/s, 7 steps of size 7.33e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.0534 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]    154.65      0.28    154.66    154.21    155.07    542.38      1.00\n",
      "      b[0]      0.90      0.04      0.90      0.84      0.97    532.56      1.00\n",
      "      s[0]      5.15      0.20      5.14      4.81      5.44    484.57      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Howell1.csv', sep=';') \n",
    "m.df = m.df[m.df.age > 18]\n",
    "m.scale(['weight'])\n",
    "# TODO: use jax arrays with hugging face package\n",
    "m.data_to_model(['weight', 'height'])\n",
    "#m.list = dict(height =  jnp.array(m.df.height), weight =  jnp.array(m.df.weight))\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s = dist.uniform('s', 0, 50, sample_shape= [1])\n",
    "    a = dist.normal('a', 178, 20, sample_shape= [1])\n",
    "    b = dist.normal('b',  0, 1, sample_shape= [1])  \n",
    "    lk(\"y\", Normal(a + b * weight, s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable: Model (model 5.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1104.27it/s, 1023 steps of size 1.13e-03. acc. prob=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3880 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.00      0.03      0.00     -0.04      0.04     43.50      1.02\n",
      "      s[0]      0.16      0.02      0.16      0.13      0.20     14.04      1.02\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/milk.csv', sep=';') \n",
    "m.index([\"clade\"])\n",
    "m.scale(['kcal_per_g'])\n",
    "\n",
    "def model(kcal_per_g, index_clade):\n",
    "    s = dist.exponential('s', 1, sample_shape=[1])\n",
    "    a = dist.normal('a', 0, 0.5, sample_shape=[1])\n",
    "    m = a[index_clade]\n",
    "    lk(\"y\", Normal(m, s), obs=kcal_per_g)\n",
    "\n",
    "m.data_to_model(['kcal_per_g', \"index_clade\"])\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1192.19it/s, 3 steps of size 8.21e-01. acc. prob=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.5765 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         a      0.51      0.23      0.51      0.17      0.87    569.19      1.00\n",
      "        bs     -0.03      0.24     -0.02     -0.48      0.31    606.63      1.00\n",
      "        bw      0.03      0.27      0.03     -0.40      0.44    432.09      1.00\n",
      "       bws     -0.00      0.26      0.00     -0.43      0.40    494.42      1.00\n",
      "     sigma     53.18      3.78     52.99     47.04     58.66    828.84      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/tulips.csv', sep=';') \n",
    "m.scale(['blooms', 'water', 'shade'])\n",
    "m.data_to_model(['blooms', 'water', 'shade'])\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(blooms,shade, water):\n",
    "    sigma = dist.exponential('sigma',  1)\n",
    "    bws = dist.normal('bws',  0, 0.25)\n",
    "    bs = dist.normal('bs', 0, 0.25)\n",
    "    bw = dist.normal('bw',  0, 0.25)\n",
    "    a = dist.normal('a',  0.5, 0.25)\n",
    "    mu = a + bw*water + bs*shade + bws*water*shade\n",
    "    lk(\"y\", Normal(mu, sigma), obs=blooms)\n",
    "\n",
    "# Run sampler ------------------------------------------------ \n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial (model 11.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1551.35it/s, 1 steps of size 9.55e-01. acc. prob=0.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 0.6785 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         a      0.33      0.08      0.33      0.19      0.47    206.41      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/chimpanzees.csv', sep=';') \n",
    "m.df['treatment'] =  1 + m.df.prosoc_left + 2 * m.df.condition\n",
    "m.df[\"side\"] = m.df.prosoc_left  # right 0, left 1\n",
    "m.df[\"cond\"] = m.df.condition  # no partner 0, partner 1\n",
    "m.data_to_model(['pulled_left', ])\n",
    "\n",
    "def model(pulled_left):\n",
    "    a = dist.normal('a', 0, 10)\n",
    "    lk(\"y\", Binomial(logits=a), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model, init_strategy = numpyro.infer.initialization.init_to_mean()) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices (model 11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:03<00:00, 287.18it/s, 1023 steps of size 6.48e-04. acc. prob=0.80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.5981 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.46      1.30      0.36     -1.82      2.12      5.02      1.39\n",
      "      a[1]      0.07      0.26      0.08     -0.31      0.52      6.16      1.36\n",
      "      a[2]      3.73      0.45      3.71      3.02      4.40     22.51      1.03\n",
      "      a[3]     -0.11      0.20     -0.12     -0.41      0.22     17.17      1.00\n",
      "      a[4]     -0.01      0.21     -0.03     -0.32      0.31      6.31      1.00\n",
      "      a[5]      0.10      0.15      0.12     -0.15      0.33     26.70      1.01\n",
      "      a[6]      1.69      0.18      1.67      1.41      1.99     11.01      1.00\n",
      "      b[0]      0.22      0.46      0.17     -0.44      0.97      8.12      1.18\n",
      "      b[1]     -0.62      0.24     -0.63     -0.97     -0.22      6.81      1.11\n",
      "      b[2]     -0.08      0.24     -0.11     -0.48      0.23     11.00      1.00\n",
      "      b[3]     -0.51      0.19     -0.52     -0.80     -0.21      8.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "m.data('/home/sosa/BI/data/chimpanzees.csv', sep=';') \n",
    "m.df['treatment'] =  1 + m.df.prosoc_left + 2 * m.df.condition\n",
    "m.data_to_model(['actor', 'treatment', 'pulled_left'])\n",
    "m.data_on_model['n_actor'] = len(jnp.unique(jnp.array(m.df[\"actor\"]))) # adding additional information on the dictionary\n",
    "m.data_on_model['n_treatment'] = len(jnp.unique(jnp.array(m.df[\"treatment\"])))\n",
    "def model(n_actor, n_treatment, actor, treatment, pulled_left):\n",
    "    a = dist.normal('a', 0, 1.5, sample_shape = [n_actor])\n",
    "    b = dist.normal('b', 0, 0.5, sample_shape = [n_treatment])\n",
    "    p = a[actor] + b[treatment]\n",
    "    lk(\"y\", Binomial(1, logits=p), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson (model 11.10) PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 08:34:02.002555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1000.27it/s, 511 steps of size 1.04e-03. acc. prob=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3989 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      3.49      0.06      3.49      3.40      3.57     15.07      1.07\n",
      "      b[0]      0.34      0.05      0.34      0.26      0.41     14.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Kline.csv', sep=';') \n",
    "m.data[\"P\"] = m.data.population.apply(math.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "m.data[\"contact_id\"] = (m.data.contact == \"high\").astype(int)\n",
    "m.data = dict(total_tools=m.data.total_tools.values, P=m.data.P.values, cid=m.data.contact_id.values)\n",
    "def model(cid, P, total_tools):\n",
    "    a = dist.normal('a', 3, 0.5, sample_shape= [1])\n",
    "    b = dist.normal('b', 0, 0.2, sample_shape=[1])\n",
    "    l = jnp.exp(a[cid] + b[cid]*P)\n",
    "    lk(\"y\", Poisson(l), obs=total_tools)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (model 11.12) (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>days</th>\n",
       "      <th>monastery</th>\n",
       "      <th>log_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y  days  monastery  log_days\n",
       "0   3.0     1          0   0.00000\n",
       "1   1.0     1          0   0.00000\n",
       "2   2.0     1          0   0.00000\n",
       "3   0.0     1          0   0.00000\n",
       "4   1.0     1          0   0.00000\n",
       "5   0.0     1          0   0.00000\n",
       "6   0.0     1          0   0.00000\n",
       "7   4.0     1          0   0.00000\n",
       "8   0.0     1          0   0.00000\n",
       "9   1.0     1          0   0.00000\n",
       "10  2.0     1          0   0.00000\n",
       "11  3.0     1          0   0.00000\n",
       "12  1.0     1          0   0.00000\n",
       "13  1.0     1          0   0.00000\n",
       "14  2.0     1          0   0.00000\n",
       "15  1.0     1          0   0.00000\n",
       "16  4.0     1          0   0.00000\n",
       "17  0.0     1          0   0.00000\n",
       "18  2.0     1          0   0.00000\n",
       "19  1.0     1          0   0.00000\n",
       "20  0.0     1          0   0.00000\n",
       "21  3.0     1          0   0.00000\n",
       "22  0.0     1          0   0.00000\n",
       "23  1.0     1          0   0.00000\n",
       "24  2.0     1          0   0.00000\n",
       "25  1.0     1          0   0.00000\n",
       "26  0.0     1          0   0.00000\n",
       "27  2.0     1          0   0.00000\n",
       "28  0.0     1          0   0.00000\n",
       "29  3.0     1          0   0.00000\n",
       "30  6.0     7          1   1.94591\n",
       "31  2.0     7          1   1.94591\n",
       "32  2.0     7          1   1.94591\n",
       "33  4.0     7          1   1.94591"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 999.13it/s, 1 steps of size 7.80e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3327 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.34      0.20      1.33      1.02      1.66    305.67      1.00\n",
      "      b[0]      0.24      0.65      0.21     -0.69      1.41    437.33      1.01\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data = dict(\n",
    "    log_days = jnp.array(d.log_days.values),\n",
    "    monastery = jnp.array(d.monastery.values),\n",
    "    output = jnp.array(d.y.values)\n",
    ")\n",
    "\n",
    "def model(log_days, monastery, output):\n",
    "    a = dist.normal('a', 0, 1, sample_shape=[1])\n",
    "    b = dist.normal('b', 0, 1, sample_shape=[1])\n",
    "    l = log_days + a +  b * monastery\n",
    "    lk(\"y\", Poisson(rate = l), obs=output)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial (model 11.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = jnp.array(tf.nn.softmax(score))\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = tfd.Categorical(probs=p).sample(seed = init_key, sample_shape = N)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)\n",
    "career = jnp.array(d.career.values)\n",
    "career_income = jnp.array(d.income.values)\n",
    "income = jnp.array(income)\n",
    "m.data = dict(\n",
    "    income = income,\n",
    "    career = career\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 884.31it/s, 7 steps of size 3.60e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.1022 seconds\n",
      "BI took: 1.9814 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      2.49      0.84      2.48      1.21      3.75    262.84      1.00\n",
      "      a[1]     -2.54      0.82     -2.54     -3.71     -1.20    238.09      1.00\n",
      "      b[0]      0.23      0.19      0.18      0.00      0.47    233.57      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "def model(income, career):\n",
    "    a = dist.normal('a', 0, 1, sample_shape= [2])\n",
    "    b = dist.halfnormal('b', 0.5, sample_shape=[1])\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = a[0] + b * income[0]\n",
    "    p = jax.nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    lk(\"y\", Categorical(probs =  p[career]), obs=career)\n",
    "\n",
    "# Run sampler ------------------------------------------------ \n",
    "m.run(model)  \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (model m12.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 780.97it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.3123 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/UCBadmit.csv', sep=';') \n",
    "m.data[\"gid\"] = (m.data[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.data[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.data[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.data[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential('phi', 1, sample_shape=[1])\n",
    "    alpha = dist.normal('alpha', 0., 1.5, sample_shape=[2])\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 802.72it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3364 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/UCBadmit.csv', sep=';') \n",
    "m.data[\"gid\"] = (m.data[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.data[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.data[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.data[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential('phi', 1, sample_shape=[1])\n",
    "    alpha = dist.normal('alpha', 0., 1.5, sample_shape=[2])\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1112.76it/s, 15 steps of size 5.52e-01. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3915 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "        al      0.12      0.08      0.12     -0.02      0.24    196.44      1.00\n",
      "        ap     -1.35      0.32     -1.33     -1.82     -0.86    266.48      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "from jax.scipy.special import expit\n",
    "r.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "\n",
    "m.data = dict(\n",
    "    y = jnp.array(y)\n",
    ")\n",
    "\n",
    "def model(y):\n",
    "    al = dist.normal('al', 1, 0.5, [1])\n",
    "    ap = dist.normal('ap', -1.5, 1, [1])\n",
    "    p = expit(ap)\n",
    "    lambda_ = jnp.exp(al)\n",
    "    lk(\"y\", ZeroInflatedPoisson(p, lambda_), obs=y)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. OrderedLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    }
   ],
   "source": [
    "import numpyro.distributions as dist\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Trolley.csv', sep=';') \n",
    "d = m.data\n",
    "# discrete proportion of each response value\n",
    "pr_k = d.response.value_counts().sort_index().values / d.shape[0]\n",
    "# cumsum converts to cumulative proportions\n",
    "cum_pr_k = jnp.cumsum(pr_k, -1)\n",
    "logit = lambda x: jnp.log(x / (1 - x))  # convenience function\n",
    "lco = logit(cum_pr_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions.transforms import OrderedTransform\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(response = jnp.array(d.response.values - 1))\n",
    "def model(response):\n",
    "    cutpoints = numpyro.sample(\n",
    "        \n",
    "        dist.transformeddistribution(\"cutpoints\",\n",
    "            dist.Normal(0, 1.5, sample_shape = [6]), OrderedTransform()\n",
    "        ),\n",
    "    )\n",
    "    numpyro.sample(\"R\", dist.OrderedLogistic(0, cutpoints), obs=response)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying interceps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 939.01it/s, 15 steps of size 1.06e-01. acc. prob=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9784 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  a_bar[0]      0.83      0.90      0.92     -0.12      2.42     28.91      1.08\n",
      "  alpha[0]      0.83      0.07      0.84      0.72      0.92    152.28      1.01\n",
      "  alpha[1]      0.80      1.55      0.89     -1.53      3.38     82.40      1.03\n",
      "  alpha[2]      0.82      1.86      0.90     -1.22      3.84     89.87      1.03\n",
      "  alpha[3]      0.83      1.53      0.90     -1.36      3.15    109.65      1.01\n",
      "  alpha[4]      0.84      1.78      0.89     -2.14      3.17    108.21      1.02\n",
      "  alpha[5]      0.87      1.54      0.98     -1.71      3.08     67.36      1.03\n",
      "  alpha[6]      0.77      1.78      0.85     -1.66      3.43     85.76      1.02\n",
      "  alpha[7]      0.90      1.52      1.05     -1.68      2.92     73.27      1.05\n",
      "  alpha[8]      0.79      1.57      0.89     -1.19      3.30     76.00      1.04\n",
      "  alpha[9]      0.83      1.51      0.87     -1.21      2.83     75.38      1.02\n",
      " alpha[10]      0.79      1.71      0.96     -1.14      3.65     82.64      1.03\n",
      " alpha[11]      0.82      1.57      0.91     -1.17      3.07     84.09      1.02\n",
      " alpha[12]      0.85      1.73      0.90     -1.58      3.60     74.53      1.04\n",
      " alpha[13]      0.79      1.68      0.86     -1.60      3.24    163.52      1.02\n",
      " alpha[14]      0.85      1.58      0.94     -0.94      3.83     89.79      1.02\n",
      " alpha[15]      0.87      1.63      0.89     -1.28      3.15    102.49      1.01\n",
      " alpha[16]      0.84      1.59      0.96     -1.42      3.11     76.68      1.03\n",
      " alpha[17]      0.91      1.70      0.91     -1.63      3.38     89.86      1.02\n",
      " alpha[18]      0.88      1.62      0.99     -1.49      3.20     79.28      1.03\n",
      " alpha[19]      0.85      1.60      0.91     -1.43      3.48     79.63      1.03\n",
      " alpha[20]      0.87      1.70      0.96     -1.08      3.32     98.30      1.02\n",
      " alpha[21]      0.80      1.60      0.89     -1.63      3.33     91.41      1.02\n",
      " alpha[22]      0.88      1.52      0.94     -1.27      3.35     88.01      1.03\n",
      " alpha[23]      0.87      1.60      0.95     -1.06      3.59    133.47      1.01\n",
      " alpha[24]      0.76      1.80      0.93     -0.87      3.87     95.39      1.03\n",
      " alpha[25]      0.81      1.74      0.91     -1.85      3.51     82.99      1.02\n",
      " alpha[26]      0.86      1.76      0.90     -1.31      3.65     66.97      1.02\n",
      " alpha[27]      0.77      1.67      0.93     -2.01      3.29     82.09      1.03\n",
      " alpha[28]      0.83      1.62      0.92     -0.63      3.88     83.88      1.02\n",
      " alpha[29]      0.70      1.89      0.91     -1.41      3.62     85.67      1.05\n",
      " alpha[30]      0.82      1.49      0.90     -1.02      3.21     82.11      1.02\n",
      " alpha[31]      0.85      1.41      0.94     -0.88      2.74     74.49      1.03\n",
      " alpha[32]      0.80      1.60      0.88     -1.55      3.14     93.61      1.02\n",
      " alpha[33]      0.92      1.67      0.94     -1.64      3.46     95.65      1.00\n",
      " alpha[34]      0.86      1.67      0.92     -1.48      3.25     62.73      1.02\n",
      " alpha[35]      0.79      1.73      0.93     -1.72      3.39    106.68      1.03\n",
      " alpha[36]      0.88      1.47      1.00     -0.94      3.26     68.86      1.04\n",
      " alpha[37]      0.85      1.72      0.92     -2.14      3.07    106.00      1.02\n",
      " alpha[38]      0.87      1.47      0.89     -1.24      3.12     77.45      1.03\n",
      " alpha[39]      0.75      1.86      0.96     -1.97      3.44     85.08      1.03\n",
      " alpha[40]      0.78      1.87      1.03     -1.32      3.91     84.61      1.02\n",
      " alpha[41]      0.72      1.93      0.84     -1.27      4.30    109.55      1.02\n",
      " alpha[42]      0.84      1.79      0.94     -1.24      3.23     90.72      1.02\n",
      " alpha[43]      0.86      1.54      0.97     -1.45      3.30     89.63      1.02\n",
      " alpha[44]      0.92      1.66      1.09     -1.12      3.76    111.30      1.01\n",
      " alpha[45]      0.89      1.70      0.93     -1.15      3.43    229.84      1.01\n",
      " alpha[46]      0.90      1.52      0.91     -1.55      2.76     85.47      1.01\n",
      " alpha[47]      0.77      1.82      0.87     -1.34      3.97     87.19      1.03\n",
      "  sigma[0]      1.11      0.87      0.85      0.29      2.14     11.96      1.11\n",
      "\n",
      "Number of divergences: 3\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/reedfrogs.csv', sep=';') \n",
    "m.data[\"tank\"] = np.arange(m.data.shape[0])\n",
    "tank = jnp.array(m.data[\"tank\"].astype('int32').values)\n",
    "density = jnp.array(m.data[\"density\"].astype('float32').values)\n",
    "surv = jnp.array(m.data[\"surv\"].astype('int32').values)\n",
    "m.data = dict(\n",
    "    tank = tank,\n",
    "    surv = surv\n",
    ")\n",
    "\n",
    "def model(tank, surv):\n",
    "    sigma = dist.exponential('sigma', 1, sample_shape= [1])\n",
    "    a_bar = dist.normal('a_bar', 0., 1.5, sample_shape= [1])\n",
    "    alpha = dist.normal('alpha', a_bar, sigma, sample_shape= [48])\n",
    "    p = jnp.squeeze(alpha[tank])[0]\n",
    "    lk(\"y\", Binomial(total_count = density, logits = p), obs=surv)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Varying effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dd\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "jnp.array([1, 2, 3, 4]).reshape(2, 2).T\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = sample.multivariatenormal(Mu, Sigma, sample_shape=(N_cafes,))\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = sample.normal(mu, sigma)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:37<00:00, 26.80it/s, 31 steps of size 1.35e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 37.5668 seconds\n",
      "BI took: 37.6322 seconds\n",
      "\n",
      "                         mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "           Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "           Rho[0,1]     -0.46      0.33     -0.50     -0.95     -0.00    245.91      1.00\n",
      "           Rho[1,0]     -0.46      0.33     -0.50     -0.95     -0.00    245.91      1.00\n",
      "           Rho[1,1]      1.00      0.00      1.00      1.00      1.00     18.97      1.00\n",
      "                  a      3.50      0.17      3.50      3.20      3.74    273.45      1.00\n",
      " a_cafe,b_cafe[0,0]      3.22      0.18      3.21      2.94      3.48    416.72      1.00\n",
      " a_cafe,b_cafe[0,1]     -0.83      0.14     -0.84     -1.06     -0.62    187.79      1.00\n",
      " a_cafe,b_cafe[1,0]      4.34      0.19      4.34      4.01      4.60    479.57      1.00\n",
      " a_cafe,b_cafe[1,1]     -0.97      0.17     -0.96     -1.25     -0.72    355.66      1.00\n",
      " a_cafe,b_cafe[2,0]      3.71      0.19      3.72      3.42      4.00    439.08      1.00\n",
      " a_cafe,b_cafe[2,1]     -0.85      0.16     -0.87     -1.09     -0.62    255.08      1.00\n",
      " a_cafe,b_cafe[3,0]      2.65      0.19      2.65      2.38      2.95    345.45      1.00\n",
      " a_cafe,b_cafe[3,1]     -0.73      0.17     -0.74     -0.99     -0.48    108.57      1.01\n",
      " a_cafe,b_cafe[4,0]      3.48      0.19      3.50      3.17      3.74    534.37      1.00\n",
      " a_cafe,b_cafe[4,1]     -0.84      0.15     -0.85     -1.06     -0.60    258.23      1.00\n",
      " a_cafe,b_cafe[5,0]      2.65      0.18      2.65      2.39      2.93    346.10      1.00\n",
      " a_cafe,b_cafe[5,1]     -0.80      0.16     -0.81     -1.06     -0.57    202.30      1.00\n",
      " a_cafe,b_cafe[6,0]      3.76      0.19      3.75      3.43      4.04    540.90      1.00\n",
      " a_cafe,b_cafe[6,1]     -0.82      0.15     -0.83     -1.06     -0.57    172.70      1.00\n",
      " a_cafe,b_cafe[7,0]      3.41      0.18      3.40      3.11      3.69    624.66      1.00\n",
      " a_cafe,b_cafe[7,1]     -0.82      0.16     -0.83     -1.05     -0.60    242.48      1.02\n",
      " a_cafe,b_cafe[8,0]      3.16      0.17      3.15      2.86      3.39    306.17      1.00\n",
      " a_cafe,b_cafe[8,1]     -0.87      0.13     -0.85     -1.09     -0.69    173.76      1.00\n",
      " a_cafe,b_cafe[9,0]      2.94      0.18      2.94      2.68      3.22    502.99      1.00\n",
      " a_cafe,b_cafe[9,1]     -0.85      0.14     -0.84     -1.08     -0.63    287.16      1.00\n",
      "a_cafe,b_cafe[10,0]      3.89      0.18      3.89      3.63      4.20    688.35      1.00\n",
      "a_cafe,b_cafe[10,1]     -0.92      0.14     -0.91     -1.13     -0.70    319.10      1.00\n",
      "a_cafe,b_cafe[11,0]      3.30      0.19      3.30      2.96      3.55    351.62      1.00\n",
      "a_cafe,b_cafe[11,1]     -0.85      0.16     -0.84     -1.11     -0.62    288.40      1.00\n",
      "a_cafe,b_cafe[12,0]      2.81      0.18      2.81      2.53      3.08    710.28      1.00\n",
      "a_cafe,b_cafe[12,1]     -0.83      0.15     -0.84     -1.05     -0.60    309.20      1.00\n",
      "a_cafe,b_cafe[13,0]      3.20      0.18      3.20      2.95      3.51    468.17      1.01\n",
      "a_cafe,b_cafe[13,1]     -0.74      0.18     -0.76     -0.98     -0.44    133.58      1.03\n",
      "a_cafe,b_cafe[14,0]      3.33      0.17      3.32      3.01      3.57    582.10      1.00\n",
      "a_cafe,b_cafe[14,1]     -0.84      0.15     -0.84     -1.05     -0.60    278.94      1.00\n",
      "a_cafe,b_cafe[15,0]      4.54      0.18      4.53      4.26      4.82    580.67      1.00\n",
      "a_cafe,b_cafe[15,1]     -0.97      0.17     -0.96     -1.23     -0.70    298.50      1.00\n",
      "a_cafe,b_cafe[16,0]      5.36      0.20      5.35      5.06      5.67    455.52      1.00\n",
      "a_cafe,b_cafe[16,1]     -1.06      0.20     -1.04     -1.34     -0.72    236.64      1.01\n",
      "a_cafe,b_cafe[17,0]      4.23      0.20      4.23      3.94      4.56    127.01      1.01\n",
      "a_cafe,b_cafe[17,1]     -1.07      0.20     -1.02     -1.36     -0.76     70.05      1.02\n",
      "a_cafe,b_cafe[18,0]      2.34      0.19      2.34      2.07      2.66    443.97      1.00\n",
      "a_cafe,b_cafe[18,1]     -0.74      0.17     -0.76     -1.01     -0.49    177.94      1.01\n",
      "a_cafe,b_cafe[19,0]      3.57      0.18      3.57      3.26      3.84    530.12      1.00\n",
      "a_cafe,b_cafe[19,1]     -0.93      0.15     -0.91     -1.18     -0.70    179.35      1.00\n",
      "                  b     -0.87      0.08     -0.87     -1.00     -0.74    118.42      1.00\n",
      "           sigma[0]      0.52      0.03      0.52      0.48      0.57    637.68      1.00\n",
      "      sigma_cafe[0]      0.77      0.13      0.76      0.57      0.95    460.14      1.01\n",
      "      sigma_cafe[1]      0.16      0.08      0.16      0.03      0.26     42.23      1.06\n",
      "\n",
      "Number of divergences: 2\n"
     ]
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(\n",
    "    cafe = cafe_id, \n",
    "    wait = wait, \n",
    "    N_cafes = N_cafes\n",
    ")\n",
    "def model(cafe, wait, N_cafes):\n",
    "    a = dist.normal(\"a\", 5, 2)\n",
    "    b = dist.normal(\"b\", -1, 0.5)\n",
    "    sigma_cafe = dist.exponential('sigma_cafe', 1, sample_shape=[2])\n",
    "    sigma = dist.exponential('sigma', 1, sample_shape=[1])\n",
    "    Rho = dist.lkj(\"Rho\", 2, 2)\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = dist.multivariatenormal(\"a_cafe,b_cafe\",jnp.stack([a, b]), cov, sample_shape = [N_cafes])    \n",
    "\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    lk(\"y\", Normal(mu, sigma), obs=wait)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:39<00:00, 25.49it/s, 31 steps of size 1.32e-01. acc. prob=0.90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 39.7222 seconds\n",
      "BI took: 39.7995 seconds\n",
      "\n",
      "                         mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "           Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "           Rho[0,1]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,0]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,1]      1.00      0.00      1.00      1.00      1.00     61.24      1.00\n",
      "                  a      3.50      0.18      3.50      3.23      3.79    514.91      1.00\n",
      " a_cafe,b_cafe[0,0]      3.21      0.18      3.21      2.94      3.49    363.81      1.00\n",
      " a_cafe,b_cafe[0,1]     -0.83      0.15     -0.84     -1.05     -0.60    249.04      1.00\n",
      " a_cafe,b_cafe[1,0]      4.35      0.18      4.35      4.08      4.66    352.42      1.00\n",
      " a_cafe,b_cafe[1,1]     -0.97      0.17     -0.96     -1.20     -0.68    272.80      1.00\n",
      " a_cafe,b_cafe[2,0]      3.71      0.19      3.71      3.36      3.99    568.49      1.00\n",
      " a_cafe,b_cafe[2,1]     -0.85      0.16     -0.86     -1.08     -0.58    216.11      1.01\n",
      " a_cafe,b_cafe[3,0]      2.64      0.20      2.64      2.37      2.97    487.59      1.00\n",
      " a_cafe,b_cafe[3,1]     -0.70      0.18     -0.72     -0.98     -0.43    102.60      1.01\n",
      " a_cafe,b_cafe[4,0]      3.48      0.19      3.49      3.20      3.75    534.61      1.00\n",
      " a_cafe,b_cafe[4,1]     -0.84      0.15     -0.84     -1.05     -0.58    265.62      1.00\n",
      " a_cafe,b_cafe[5,0]      2.65      0.18      2.64      2.39      2.96    534.49      1.00\n",
      " a_cafe,b_cafe[5,1]     -0.79      0.17     -0.80     -1.01     -0.49    200.19      1.00\n",
      " a_cafe,b_cafe[6,0]      3.75      0.18      3.76      3.47      4.05    781.58      1.00\n",
      " a_cafe,b_cafe[6,1]     -0.82      0.16     -0.84     -1.06     -0.55    171.69      1.00\n",
      " a_cafe,b_cafe[7,0]      3.41      0.19      3.41      3.14      3.70    437.90      1.01\n",
      " a_cafe,b_cafe[7,1]     -0.81      0.15     -0.82     -1.04     -0.57    209.64      1.02\n",
      " a_cafe,b_cafe[8,0]      3.15      0.17      3.15      2.86      3.37    555.12      1.00\n",
      " a_cafe,b_cafe[8,1]     -0.87      0.14     -0.86     -1.10     -0.67    213.95      1.00\n",
      " a_cafe,b_cafe[9,0]      2.94      0.19      2.94      2.68      3.25    514.75      1.00\n",
      " a_cafe,b_cafe[9,1]     -0.85      0.17     -0.85     -1.09     -0.57    308.92      1.00\n",
      "a_cafe,b_cafe[10,0]      3.89      0.18      3.88      3.59      4.16    570.16      1.00\n",
      "a_cafe,b_cafe[10,1]     -0.92      0.15     -0.91     -1.14     -0.69    283.55      1.00\n",
      "a_cafe,b_cafe[11,0]      3.31      0.20      3.30      2.99      3.60    501.42      1.00\n",
      "a_cafe,b_cafe[11,1]     -0.84      0.17     -0.84     -1.08     -0.53    328.56      1.00\n",
      "a_cafe,b_cafe[12,0]      2.79      0.18      2.80      2.51      3.08    661.61      1.00\n",
      "a_cafe,b_cafe[12,1]     -0.82      0.16     -0.82     -1.06     -0.58    300.02      1.00\n",
      "a_cafe,b_cafe[13,0]      3.18      0.19      3.17      2.93      3.53    243.63      1.01\n",
      "a_cafe,b_cafe[13,1]     -0.73      0.19     -0.75     -0.99     -0.40     96.66      1.03\n",
      "a_cafe,b_cafe[14,0]      3.33      0.18      3.32      3.07      3.66    523.19      1.00\n",
      "a_cafe,b_cafe[14,1]     -0.83      0.15     -0.85     -1.05     -0.58    319.39      1.00\n",
      "a_cafe,b_cafe[15,0]      4.54      0.18      4.54      4.25      4.83    401.77      1.00\n",
      "a_cafe,b_cafe[15,1]     -0.98      0.17     -0.98     -1.23     -0.73    280.91      1.00\n",
      "a_cafe,b_cafe[16,0]      5.36      0.21      5.35      5.04      5.70    437.80      1.00\n",
      "a_cafe,b_cafe[16,1]     -1.08      0.23     -1.08     -1.45     -0.76    244.11      1.00\n",
      "a_cafe,b_cafe[17,0]      4.24      0.19      4.24      3.90      4.52    163.09      1.00\n",
      "a_cafe,b_cafe[17,1]     -1.09      0.21     -1.06     -1.41     -0.77     82.77      1.00\n",
      "a_cafe,b_cafe[18,0]      2.32      0.19      2.32      2.02      2.62    426.39      1.00\n",
      "a_cafe,b_cafe[18,1]     -0.72      0.18     -0.75     -0.96     -0.42    155.20      1.02\n",
      "a_cafe,b_cafe[19,0]      3.57      0.18      3.57      3.31      3.89    688.04      1.00\n",
      "a_cafe,b_cafe[19,1]     -0.93      0.17     -0.91     -1.21     -0.68    234.35      1.00\n",
      "                  b     -0.86      0.08     -0.86     -0.99     -0.75    174.01      1.00\n",
      "           sigma[0]      0.52      0.03      0.52      0.48      0.57    596.32      1.00\n",
      "      sigma_cafe[0]      0.77      0.13      0.76      0.58      1.00    566.72      1.00\n",
      "      sigma_cafe[1]      0.18      0.09      0.17      0.03      0.30     44.31      1.02\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi()\n",
    "m.data = dict(\n",
    "    cafe = cafe_id, \n",
    "    wait = wait, \n",
    "    N_cafes = N_cafes\n",
    ")\n",
    "def model(cafe, wait, N_cafes):\n",
    "    a = numpyro.sample(\"a\", dd.Normal(5, 2))\n",
    "    b = numpyro.sample(\"b\", dd.Normal(-1, 0.5))\n",
    "    sigma_cafe = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([2]))\n",
    "    sigma = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([1]))\n",
    "    Rho = numpyro.sample(\"Rho\", dd.LKJ(2, 2))\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = numpyro.sample(\n",
    "        \"a_cafe,b_cafe\", dd.MultivariateNormal(jnp.stack([a, b]), cov).expand([N_cafes])\n",
    "    )\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    lk(\"y\", dd.Normal(mu, sigma), obs=wait)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_4314cm3u/model_4xoavcff.stan', line 20, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.012288 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 122.88 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = 1.06425e+30, but Covariance matrix[2,1] = 1.06425e+30 (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 30, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 1715.6098 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "import numpy as np\n",
    "#try:\n",
    "#  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "#except:\n",
    "#  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    int len;\n",
    "    int N_cafes;\n",
    "    vector[len] wait;\n",
    "    array[len] int afternoon;\n",
    "    array[len] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[N_cafes] b_cafe;\n",
    "    vector[N_cafes] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[len] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[N_cafes] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:N_cafes ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:len ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "    'N_cafes' : N_cafes,\n",
    "    'len' : len(d['wait'].values)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Multiple random effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:04<00:00, 244.77it/s, 63 steps of size 9.02e-02. acc. prob=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 8.1093 seconds\n",
      "\n",
      "                  mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "L_Rho_d[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "L_Rho_d[0,1]      0.00      0.00      0.00      0.00      0.00       nan       nan\n",
      "L_Rho_d[1,0]      0.88      0.04      0.88      0.82      0.93     53.74      1.02\n",
      "L_Rho_d[1,1]      0.47      0.07      0.48      0.36      0.57     54.94      1.02\n",
      " Rho_gr[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      " Rho_gr[0,1]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,0]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,1]      1.00      0.00      1.00      1.00      1.00    435.00      1.00\n",
      "        a[0]      0.53      0.17      0.52      0.27      0.79    153.88      1.00\n",
      "     gr[0,0]     -0.49      0.28     -0.48     -0.91     -0.03    252.20      1.01\n",
      "     gr[0,1]      0.21      0.22      0.21     -0.15      0.55    631.29      1.00\n",
      "     gr[1,0]      0.18      0.27      0.20     -0.25      0.62    235.24      1.00\n",
      "     gr[1,1]     -0.13      0.22     -0.13     -0.47      0.20    571.67      1.00\n",
      "     gr[2,0]      1.12      0.26      1.13      0.64      1.48    210.39      1.00\n",
      "     gr[2,1]     -0.33      0.23     -0.33     -0.71      0.04    406.51      1.00\n",
      "     gr[3,0]     -0.72      0.30     -0.72     -1.17     -0.26    256.68      1.00\n",
      "     gr[3,1]      0.34      0.24      0.34     -0.04      0.69    524.76      1.00\n",
      "     gr[4,0]     -0.46      0.27     -0.46     -0.88     -0.07    311.94      1.00\n",
      "     gr[4,1]      0.39      0.22      0.38      0.05      0.73    240.70      1.00\n",
      "     gr[5,0]     -0.96      0.32     -0.96     -1.41     -0.40    315.16      1.00\n",
      "     gr[5,1]      0.56      0.24      0.55      0.21      0.94    353.90      1.00\n",
      "     gr[6,0]     -0.56      0.32     -0.56     -1.05     -0.07    333.21      1.00\n",
      "     gr[6,1]      0.15      0.22      0.15     -0.22      0.49    490.87      1.00\n",
      "     gr[7,0]     -0.73      0.28     -0.73     -1.19     -0.31    233.56      1.00\n",
      "     gr[7,1]      0.25      0.21      0.25     -0.10      0.54    440.49      1.00\n",
      "     gr[8,0]      0.23      0.25      0.23     -0.18      0.61    272.17      1.00\n",
      "     gr[8,1]     -0.26      0.22     -0.26     -0.66      0.05    461.30      1.00\n",
      "     gr[9,0]      1.37      0.26      1.35      0.97      1.78    212.37      1.01\n",
      "     gr[9,1]     -0.43      0.24     -0.43     -0.83     -0.07    479.45      1.00\n",
      "    gr[10,0]     -0.93      0.32     -0.92     -1.47     -0.48    261.43      1.00\n",
      "    gr[10,1]      0.38      0.23      0.38      0.06      0.76    436.37      1.00\n",
      "    gr[11,0]     -0.70      0.31     -0.70     -1.23     -0.25    302.94      1.00\n",
      "    gr[11,1]     -0.09      0.23     -0.08     -0.45      0.29    673.00      1.00\n",
      "    gr[12,0]      0.98      0.27      0.99      0.56      1.42    228.46      1.01\n",
      "    gr[12,1]     -0.25      0.22     -0.25     -0.61      0.07    362.00      1.00\n",
      "    gr[13,0]      0.24      0.30      0.24     -0.15      0.79    200.18      1.00\n",
      "    gr[13,1]      0.24      0.23      0.24     -0.14      0.58    281.45      1.00\n",
      "    gr[14,0]     -0.74      0.30     -0.75     -1.23     -0.31    270.41      1.00\n",
      "    gr[14,1]      0.59      0.23      0.58      0.25      0.98    316.93      1.00\n",
      "    gr[15,0]      0.03      0.27      0.02     -0.36      0.48    239.98      1.00\n",
      "    gr[15,1]      0.47      0.24      0.44      0.15      0.89    238.07      1.00\n",
      "    gr[16,0]      0.57      0.27      0.55      0.17      1.05    167.80      1.00\n",
      "    gr[16,1]      0.19      0.22      0.18     -0.15      0.53    332.53      1.00\n",
      "    gr[17,0]     -0.31      0.31     -0.31     -0.84      0.16    270.13      1.00\n",
      "    gr[17,1]     -0.61      0.28     -0.60     -0.99     -0.08    453.87      1.00\n",
      "    gr[18,0]      0.09      0.29      0.07     -0.41      0.54    257.63      1.00\n",
      "    gr[18,1]      0.02      0.21      0.02     -0.31      0.35    431.74      1.00\n",
      "    gr[19,0]      0.90      0.27      0.88      0.53      1.37    243.69      1.00\n",
      "    gr[19,1]     -0.42      0.23     -0.42     -0.78     -0.04    503.12      1.00\n",
      "    gr[20,0]      1.42      0.25      1.40      1.03      1.85    205.85      1.00\n",
      "    gr[20,1]     -0.37      0.22     -0.37     -0.73      0.01    389.14      1.00\n",
      "    gr[21,0]      0.26      0.28      0.27     -0.20      0.67    237.98      1.00\n",
      "    gr[21,1]     -0.33      0.23     -0.34     -0.70      0.05    334.85      1.00\n",
      "    gr[22,0]      1.13      0.27      1.12      0.73      1.57    226.02      1.00\n",
      "    gr[22,1]     -0.57      0.22     -0.56     -0.92     -0.21    411.56      1.00\n",
      "    gr[23,0]     -0.24      0.28     -0.23     -0.64      0.27    322.79      1.00\n",
      "    gr[23,1]     -0.19      0.22     -0.19     -0.53      0.18    245.26      1.01\n",
      "    gr[24,0]     -1.07      0.33     -1.08     -1.55     -0.55    374.00      1.00\n",
      "    gr[24,1]      0.18      0.23      0.19     -0.20      0.52    360.96      1.00\n",
      "  sigma_d[0]      1.10      0.05      1.10      1.02      1.18    340.08      1.01\n",
      " sigma_gr[0]      0.83      0.14      0.81      0.63      1.05    412.62      1.00\n",
      " sigma_gr[1]      0.43      0.09      0.43      0.29      0.56    255.29      1.00\n",
      "      z[0,0]     -0.17      0.59     -0.21     -1.05      0.76    634.46      1.00\n",
      "      z[0,1]      1.59      0.41      1.59      1.01      2.27    620.52      1.00\n",
      "      z[0,2]      0.56      0.45      0.58     -0.14      1.22    645.43      1.00\n",
      "      z[0,3]      0.57      0.44      0.56     -0.09      1.25    410.03      1.00\n",
      "      z[0,4]      1.11      0.42      1.11      0.47      1.81    519.89      1.00\n",
      "      z[0,5]      0.11      0.53      0.13     -0.59      1.12   1137.88      1.00\n",
      "      z[0,6]      0.03      0.56      0.02     -0.77      0.96   1519.90      1.00\n",
      "      z[0,7]     -0.82      0.65     -0.80     -1.85      0.16    740.06      1.00\n",
      "      z[0,8]      2.31      0.37      2.30      1.69      2.86    603.31      1.00\n",
      "      z[0,9]     -0.55      0.65     -0.51     -1.43      0.54   1341.70      1.00\n",
      "     z[0,10]     -1.00      0.73     -0.96     -2.08      0.17    790.39      1.00\n",
      "     z[0,11]     -0.28      0.58     -0.26     -1.08      0.74    756.81      1.00\n",
      "     z[0,12]      0.50      0.47      0.51     -0.31      1.18    709.48      1.01\n",
      "     z[0,13]      0.66      0.45      0.67      0.05      1.41    655.68      1.00\n",
      "     z[0,14]     -0.90      0.67     -0.86     -2.06      0.06    654.51      1.00\n",
      "     z[0,15]     -0.40      0.54     -0.38     -1.24      0.45    736.60      1.00\n",
      "     z[0,16]     -0.96      0.73     -0.95     -2.17      0.07    889.27      1.00\n",
      "     z[0,17]     -0.54      0.60     -0.53     -1.46      0.46   1240.12      1.00\n",
      "     z[0,18]     -1.36      0.58     -1.38     -2.36     -0.53    512.19      1.00\n",
      "     z[0,19]     -0.41      0.56     -0.42     -1.23      0.49    790.24      1.00\n",
      "     z[0,20]     -1.15      0.75     -1.12     -2.24      0.13   1020.15      1.00\n",
      "     z[0,21]      0.24      0.52      0.24     -0.51      1.08    534.78      1.00\n",
      "     z[0,22]     -1.04      0.73     -1.00     -2.13      0.14   1238.56      1.00\n",
      "     z[0,23]      2.08      0.36      2.10      1.39      2.54    458.14      1.00\n",
      "     z[0,24]     -0.40      0.56     -0.39     -1.18      0.55    817.79      1.00\n",
      "     z[0,25]     -0.25      0.49     -0.21     -1.10      0.47    871.11      1.00\n",
      "     z[0,26]     -0.97      0.56     -0.94     -1.73      0.02    957.89      1.00\n",
      "     z[0,27]     -0.33      0.54     -0.29     -1.10      0.55    643.73      1.00\n",
      "     z[0,28]     -0.85      0.67     -0.80     -1.94      0.25    802.36      1.00\n",
      "     z[0,29]      2.50      0.29      2.48      2.06      2.96    350.11      1.00\n",
      "     z[0,30]      0.80      0.39      0.79      0.17      1.40    612.99      1.00\n",
      "     z[0,31]     -1.21      0.65     -1.16     -2.18     -0.12    733.72      1.00\n",
      "     z[0,32]     -0.81      0.59     -0.78     -1.75      0.05    861.18      1.00\n",
      "     z[0,33]     -1.12      0.69     -1.11     -2.14     -0.04    537.52      1.00\n",
      "     z[0,34]     -0.52      0.56     -0.52     -1.40      0.36    702.57      1.00\n",
      "     z[0,35]     -0.94      0.63     -0.91     -1.82      0.13    819.48      1.00\n",
      "     z[0,36]     -0.65      0.61     -0.62     -1.55      0.34    512.48      1.00\n",
      "     z[0,37]      0.09      0.41      0.10     -0.55      0.69    435.42      1.00\n",
      "     z[0,38]      1.88      0.31      1.90      1.35      2.35    423.23      1.00\n",
      "     z[0,39]     -0.20      0.62     -0.19     -1.20      0.74    902.43      1.00\n",
      "     z[0,40]      0.99      0.36      0.99      0.42      1.57    769.30      1.00\n",
      "     z[0,41]     -0.31      0.52     -0.31     -1.14      0.50    591.50      1.00\n",
      "     z[0,42]     -0.49      0.54     -0.50     -1.40      0.32    656.80      1.00\n",
      "     z[0,43]      2.02      0.34      2.01      1.50      2.57    397.03      1.00\n",
      "     z[0,44]      0.19      0.52      0.21     -0.55      1.09    804.65      1.00\n",
      "     z[0,45]      0.71      0.45      0.72     -0.00      1.38    608.11      1.00\n",
      "     z[0,46]     -0.71      0.64     -0.67     -1.78      0.25    730.98      1.00\n",
      "     z[0,47]      0.52      0.34      0.52     -0.01      1.03    389.15      1.00\n",
      "     z[0,48]      0.93      0.32      0.92      0.47      1.45    376.19      1.00\n",
      "     z[0,49]      1.50      0.28      1.50      1.11      2.02    289.02      1.00\n",
      "     z[0,50]     -0.12      0.44     -0.11     -0.84      0.58    619.12      1.00\n",
      "     z[0,51]     -0.71      0.46     -0.68     -1.35      0.06    530.12      1.00\n",
      "     z[0,52]     -1.48      0.64     -1.43     -2.50     -0.53    811.14      1.00\n",
      "     z[0,53]     -0.11      0.45     -0.10     -0.81      0.58    477.71      1.00\n",
      "     z[0,54]      0.26      0.36      0.27     -0.22      0.90    353.65      1.00\n",
      "     z[0,55]      0.19      0.40      0.20     -0.43      0.75    574.87      1.00\n",
      "     z[0,56]      0.25      0.41      0.28     -0.45      0.85    456.88      1.00\n",
      "     z[0,57]      0.46      0.35      0.45     -0.08      0.98    467.26      1.01\n",
      "     z[0,58]      0.79      0.33      0.78      0.27      1.32    326.67      1.00\n",
      "     z[0,59]     -0.44      0.40     -0.42     -1.14      0.17    528.47      1.00\n",
      "     z[0,60]      0.42      0.33      0.44     -0.16      0.90    350.05      1.00\n",
      "     z[0,61]     -1.30      0.71     -1.28     -2.47     -0.22    806.36      1.00\n",
      "     z[0,62]     -0.45      0.47     -0.42     -1.25      0.29    745.56      1.00\n",
      "     z[0,63]     -0.35      0.48     -0.35     -1.12      0.41    612.22      1.00\n",
      "     z[0,64]     -0.80      0.53     -0.76     -1.54      0.01    517.87      1.01\n",
      "     z[0,65]     -0.53      0.55     -0.49     -1.35      0.38    872.99      1.00\n",
      "     z[0,66]      1.36      0.35      1.36      0.78      1.87    412.75      1.00\n",
      "     z[0,67]     -0.75      0.49     -0.75     -1.32      0.13    718.89      1.00\n",
      "     z[0,68]      0.21      0.38      0.22     -0.36      0.84    533.37      1.00\n",
      "     z[0,69]      0.60      0.48      0.61     -0.16      1.37    591.38      1.00\n",
      "     z[0,70]      2.14      0.35      2.16      1.61      2.69    433.51      1.00\n",
      "     z[0,71]     -0.60      0.68     -0.55     -1.73      0.41    868.17      1.00\n",
      "     z[0,72]     -1.08      0.75     -1.05     -2.26      0.07    761.69      1.00\n",
      "     z[0,73]     -0.82      0.65     -0.76     -1.78      0.22    898.74      1.00\n",
      "     z[0,74]     -0.05      0.55     -0.06     -0.84      0.86    850.49      1.00\n",
      "     z[0,75]     -0.12      0.62     -0.09     -0.98      0.94    410.24      1.00\n",
      "     z[0,76]      0.37      0.56      0.38     -0.55      1.19    619.05      1.00\n",
      "     z[0,77]      0.30      0.55      0.31     -0.61      1.11    648.78      1.00\n",
      "     z[0,78]     -0.04      0.57     -0.00     -0.94      0.81    634.05      1.00\n",
      "     z[0,79]      0.14      0.59      0.17     -0.70      1.08    616.42      1.00\n",
      "     z[0,80]      1.47      0.39      1.47      0.83      2.08    542.98      1.00\n",
      "     z[0,81]     -0.24      0.56     -0.25     -1.00      0.65    577.46      1.00\n",
      "     z[0,82]     -0.54      0.66     -0.52     -1.67      0.42   1290.45      1.00\n",
      "     z[0,83]     -0.58      0.66     -0.53     -1.63      0.42   1047.78      1.00\n",
      "     z[0,84]     -0.85      0.66     -0.84     -1.91      0.16    921.49      1.00\n",
      "     z[0,85]     -0.66      0.59     -0.64     -1.52      0.39    874.25      1.00\n",
      "     z[0,86]     -0.55      0.68     -0.56     -1.55      0.60   1276.49      1.00\n",
      "     z[0,87]      0.41      0.47      0.42     -0.36      1.11    702.88      1.00\n",
      "     z[0,88]     -0.51      0.68     -0.46     -1.68      0.61    792.95      1.00\n",
      "     z[0,89]     -0.08      0.64     -0.06     -1.01      0.92   1083.74      1.00\n",
      "     z[0,90]      1.82      0.38      1.83      1.22      2.42    390.53      1.00\n",
      "     z[0,91]      0.12      0.54      0.16     -0.62      1.06    724.75      1.00\n",
      "     z[0,92]     -1.05      0.75     -1.01     -2.31     -0.00   1129.76      1.00\n",
      "     z[0,93]     -0.66      0.66     -0.61     -1.81      0.35    587.81      1.00\n",
      "     z[0,94]      0.58      0.48      0.58     -0.13      1.41    771.92      1.00\n",
      "     z[0,95]      0.07      0.54      0.07     -0.80      0.90    966.07      1.00\n",
      "     z[0,96]      0.52      0.50      0.51     -0.38      1.27    770.78      1.00\n",
      "     z[0,97]      0.74      0.45      0.75      0.07      1.51    455.98      1.00\n",
      "     z[0,98]     -0.40      0.57     -0.36     -1.36      0.46    608.50      1.00\n",
      "     z[0,99]      0.44      0.48      0.43     -0.36      1.20    497.35      1.00\n",
      "    z[0,100]      0.55      0.45      0.56     -0.15      1.29    528.00      1.00\n",
      "    z[0,101]     -0.34      0.57     -0.30     -1.24      0.53    851.20      1.00\n",
      "    z[0,102]     -1.01      0.83     -0.94     -2.27      0.27    971.05      1.00\n",
      "    z[0,103]     -0.49      0.66     -0.45     -1.54      0.46    711.43      1.00\n",
      "    z[0,104]      0.22      0.55      0.22     -0.68      1.06    400.30      1.00\n",
      "    z[0,105]     -0.66      0.58     -0.66     -1.60      0.23    826.71      1.00\n",
      "    z[0,106]      0.19      0.53      0.22     -0.67      0.98    716.75      1.00\n",
      "    z[0,107]     -0.00      0.51      0.01     -0.78      0.81    863.90      1.00\n",
      "    z[0,108]     -0.74      0.65     -0.69     -1.80      0.22   1386.78      1.00\n",
      "    z[0,109]      0.42      0.50      0.47     -0.34      1.18    970.45      1.00\n",
      "    z[0,110]     -0.37      0.67     -0.34     -1.29      0.86    669.88      1.00\n",
      "    z[0,111]     -1.01      0.80     -0.97     -2.30      0.29    923.15      1.00\n",
      "    z[0,112]     -1.21      0.73     -1.15     -2.27     -0.00    916.09      1.00\n",
      "    z[0,113]      0.49      0.45      0.50     -0.19      1.20    548.90      1.00\n",
      "    z[0,114]      0.83      0.49      0.83     -0.06      1.51    540.14      1.00\n",
      "    z[0,115]     -0.52      0.66     -0.47     -1.65      0.44   1124.47      1.00\n",
      "    z[0,116]     -0.10      0.57     -0.11     -1.09      0.69    786.89      1.00\n",
      "    z[0,117]      1.53      0.45      1.53      0.79      2.18    487.80      1.00\n",
      "    z[0,118]     -0.39      0.62     -0.37     -1.35      0.55    821.07      1.00\n",
      "    z[0,119]     -0.65      0.67     -0.59     -1.77      0.31    592.30      1.00\n",
      "    z[0,120]     -0.26      0.60     -0.23     -1.15      0.74    557.28      1.00\n",
      "    z[0,121]     -1.04      0.83     -0.99     -2.43      0.19   1635.89      1.00\n",
      "    z[0,122]     -0.59      0.64     -0.57     -1.63      0.40    783.15      1.00\n",
      "    z[0,123]     -1.17      0.64     -1.16     -2.19     -0.16    816.31      1.00\n",
      "    z[0,124]     -0.62      0.62     -0.62     -1.65      0.30    889.83      1.00\n",
      "    z[0,125]     -0.70      0.67     -0.71     -1.72      0.40    788.14      1.00\n",
      "    z[0,126]      1.69      0.41      1.69      0.93      2.24    896.64      1.00\n",
      "    z[0,127]     -1.09      0.75     -1.02     -2.16      0.12    656.49      1.00\n",
      "    z[0,128]      0.31      0.59      0.31     -0.68      1.18   1170.97      1.00\n",
      "    z[0,129]     -0.60      0.63     -0.57     -1.68      0.31   1060.75      1.00\n",
      "    z[0,130]      0.06      0.54      0.10     -0.74      0.91    647.01      1.00\n",
      "    z[0,131]     -0.67      0.61     -0.66     -1.71      0.18    471.98      1.00\n",
      "    z[0,132]      0.51      0.48      0.54     -0.17      1.37    813.64      1.00\n",
      "    z[0,133]     -0.21      0.58     -0.22     -1.10      0.71    994.70      1.00\n",
      "    z[0,134]      0.57      0.49      0.61     -0.25      1.27    594.30      1.00\n",
      "    z[0,135]     -0.12      0.55     -0.15     -0.85      0.86    563.03      1.00\n",
      "    z[0,136]      0.59      0.47      0.62     -0.11      1.34    599.37      1.00\n",
      "    z[0,137]      1.17      0.39      1.18      0.61      1.89    540.88      1.00\n",
      "    z[0,138]      0.17      0.54      0.20     -0.74      0.94    600.46      1.00\n",
      "    z[0,139]     -0.50      0.66     -0.45     -1.44      0.47   1113.30      1.00\n",
      "    z[0,140]     -1.14      0.68     -1.13     -2.22     -0.04   1172.11      1.00\n",
      "    z[0,141]      0.03      0.52      0.02     -0.83      0.83    644.73      1.00\n",
      "    z[0,142]      0.28      0.50      0.32     -0.52      1.05    768.58      1.00\n",
      "    z[0,143]     -0.76      0.71     -0.77     -1.87      0.32   1141.37      1.00\n",
      "    z[0,144]     -0.12      0.53     -0.12     -1.03      0.67    812.73      1.00\n",
      "    z[0,145]      1.05      0.44      1.04      0.37      1.73    437.59      1.01\n",
      "    z[0,146]      0.41      0.53      0.46     -0.40      1.28    618.34      1.00\n",
      "    z[0,147]      0.61      0.52      0.61     -0.27      1.39    589.82      1.00\n",
      "    z[0,148]     -0.68      0.60     -0.64     -1.64      0.25    647.19      1.00\n",
      "    z[0,149]     -0.07      0.61     -0.05     -1.05      0.83    849.63      1.00\n",
      "    z[0,150]      0.03      0.64      0.04     -0.93      1.05    775.99      1.00\n",
      "    z[0,151]     -0.33      0.58     -0.30     -1.19      0.59    636.23      1.00\n",
      "    z[0,152]      0.63      0.45      0.62     -0.01      1.39    568.32      1.00\n",
      "    z[0,153]     -0.59      0.67     -0.56     -1.66      0.43    546.03      1.00\n",
      "    z[0,154]      0.02      0.55      0.06     -0.71      0.95    475.82      1.00\n",
      "    z[0,155]      0.85      0.44      0.86      0.18      1.59    701.34      1.00\n",
      "    z[0,156]     -0.20      0.64     -0.19     -1.38      0.69    830.18      1.00\n",
      "    z[0,157]      0.67      0.48      0.68     -0.01      1.50    809.46      1.00\n",
      "    z[0,158]      0.26      0.54      0.27     -0.60      1.07    959.02      1.00\n",
      "    z[0,159]     -0.72      0.64     -0.72     -1.77      0.18    821.02      1.00\n",
      "    z[0,160]      1.10      0.46      1.10      0.40      1.84    527.33      1.01\n",
      "    z[0,161]     -0.19      0.53     -0.20     -1.02      0.61   1105.28      1.00\n",
      "    z[0,162]      0.06      0.59      0.09     -0.94      0.95    775.66      1.00\n",
      "    z[0,163]     -0.16      0.62     -0.11     -1.01      0.92    625.16      1.00\n",
      "    z[0,164]     -1.49      0.73     -1.49     -2.59     -0.34    874.07      1.00\n",
      "    z[0,165]     -1.26      0.69     -1.22     -2.28     -0.17    889.81      1.00\n",
      "    z[0,166]     -0.64      0.64     -0.63     -1.56      0.39    497.15      1.00\n",
      "    z[0,167]     -0.63      0.54     -0.59     -1.47      0.26    410.23      1.00\n",
      "    z[0,168]     -0.67      0.61     -0.62     -1.59      0.30    818.60      1.00\n",
      "    z[0,169]      0.56      0.40      0.57     -0.04      1.17    459.27      1.00\n",
      "    z[0,170]      0.84      0.36      0.85      0.28      1.40    424.70      1.00\n",
      "    z[0,171]      1.19      0.35      1.20      0.71      1.83    444.47      1.00\n",
      "    z[0,172]      0.79      0.49      0.84      0.12      1.68    751.80      1.00\n",
      "    z[0,173]      1.05      0.36      1.04      0.51      1.67    503.59      1.00\n",
      "    z[0,174]      1.02      0.40      1.03      0.36      1.58    699.47      1.00\n",
      "    z[0,175]      0.66      0.41      0.67     -0.00      1.27    935.70      1.00\n",
      "    z[0,176]     -0.05      0.53     -0.03     -0.97      0.70    595.79      1.00\n",
      "    z[0,177]     -0.43      0.56     -0.42     -1.24      0.47    713.89      1.00\n",
      "    z[0,178]      3.35      0.31      3.34      2.91      3.88    321.11      1.01\n",
      "    z[0,179]     -1.16      0.70     -1.15     -2.27     -0.13   1030.45      1.00\n",
      "    z[0,180]      0.39      0.34      0.37     -0.17      0.91    396.79      1.00\n",
      "    z[0,181]      0.70      0.37      0.72      0.09      1.25    409.37      1.00\n",
      "    z[0,182]      0.68      0.36      0.68      0.11      1.24    375.00      1.01\n",
      "    z[0,183]      0.37      0.35      0.37     -0.20      0.90    319.08      1.01\n",
      "    z[0,184]      0.24      0.34      0.24     -0.26      0.82    395.43      1.00\n",
      "    z[0,185]      0.33      0.33      0.35     -0.27      0.82    374.30      1.00\n",
      "    z[0,186]      0.06      0.38      0.08     -0.52      0.65    277.64      1.02\n",
      "    z[0,187]     -0.61      0.52     -0.58     -1.49      0.14    671.37      1.00\n",
      "    z[0,188]     -0.58      0.46     -0.55     -1.31      0.16    622.67      1.00\n",
      "    z[0,189]     -0.63      0.51     -0.60     -1.43      0.21    600.92      1.00\n",
      "    z[0,190]      0.14      0.38      0.13     -0.42      0.82    493.54      1.00\n",
      "    z[0,191]      0.05      0.44      0.07     -0.77      0.62    552.97      1.00\n",
      "    z[0,192]     -0.06      0.46     -0.04     -0.74      0.67    610.33      1.00\n",
      "    z[0,193]     -0.88      0.59     -0.86     -1.75      0.07    608.99      1.00\n",
      "    z[0,194]      1.65      0.29      1.66      1.20      2.12    270.15      1.00\n",
      "    z[0,195]      3.15      0.37      3.13      2.51      3.68    521.79      1.00\n",
      "    z[0,196]      2.12      0.41      2.12      1.49      2.80    597.32      1.00\n",
      "    z[0,197]      0.78      0.47      0.77      0.09      1.62    514.96      1.00\n",
      "    z[0,198]     -0.26      0.64     -0.25     -1.08      0.84    966.59      1.00\n",
      "    z[0,199]     -0.05      0.54     -0.07     -0.86      0.85    582.51      1.00\n",
      "    z[0,200]     -0.76      0.62     -0.73     -1.73      0.22    726.35      1.00\n",
      "    z[0,201]     -0.99      0.82     -1.00     -2.49      0.21    838.98      1.00\n",
      "    z[0,202]     -0.81      0.68     -0.79     -1.83      0.33    618.75      1.00\n",
      "    z[0,203]     -0.83      0.63     -0.82     -1.79      0.17    581.28      1.00\n",
      "    z[0,204]     -0.52      0.56     -0.53     -1.44      0.37    987.87      1.00\n",
      "    z[0,205]     -1.13      0.78     -1.16     -2.28      0.14    914.81      1.00\n",
      "    z[0,206]      0.19      0.54      0.19     -0.72      1.00    625.47      1.01\n",
      "    z[0,207]      0.09      0.56      0.12     -0.83      0.96    558.69      1.00\n",
      "    z[0,208]     -0.34      0.71     -0.34     -1.46      0.72    936.21      1.00\n",
      "    z[0,209]      1.95      0.39      1.95      1.33      2.55    736.58      1.00\n",
      "    z[0,210]      0.11      0.57      0.12     -0.82      1.04    976.36      1.00\n",
      "    z[0,211]     -0.53      0.63     -0.48     -1.49      0.54   1868.17      1.00\n",
      "    z[0,212]     -0.50      0.58     -0.50     -1.33      0.46   1108.42      1.00\n",
      "    z[0,213]     -1.24      0.78     -1.21     -2.38      0.10   1002.83      1.00\n",
      "    z[0,214]     -0.85      0.77     -0.83     -2.09      0.34   1131.52      1.00\n",
      "    z[0,215]     -0.67      0.64     -0.66     -1.63      0.40    852.69      1.00\n",
      "    z[0,216]     -0.91      0.68     -0.89     -2.00      0.17   1007.51      1.00\n",
      "    z[0,217]      0.01      0.54      0.05     -0.85      0.87    649.16      1.00\n",
      "    z[0,218]     -1.06      0.80     -1.02     -2.24      0.28    876.30      1.00\n",
      "    z[0,219]     -0.21      0.56     -0.23     -1.14      0.57    611.49      1.00\n",
      "    z[0,220]     -0.53      0.71     -0.48     -1.71      0.43    726.45      1.00\n",
      "    z[0,221]     -0.36      0.66     -0.35     -1.42      0.68    701.02      1.00\n",
      "    z[0,222]      1.98      0.30      2.00      1.55      2.47    363.57      1.00\n",
      "    z[0,223]     -0.42      0.44     -0.40     -1.18      0.23    757.96      1.00\n",
      "    z[0,224]     -0.00      0.38     -0.02     -0.54      0.63    250.71      1.00\n",
      "    z[0,225]     -1.71      0.63     -1.68     -2.78     -0.82    470.91      1.00\n",
      "    z[0,226]     -1.28      0.72     -1.24     -2.39     -0.05    865.41      1.00\n",
      "    z[0,227]     -0.85      0.59     -0.83     -1.86      0.02    611.60      1.00\n",
      "    z[0,228]      0.99      0.36      0.99      0.48      1.59    394.74      1.00\n",
      "    z[0,229]     -0.91      0.55     -0.89     -1.74      0.01    938.58      1.00\n",
      "    z[0,230]     -1.42      0.67     -1.37     -2.39     -0.41    898.47      1.00\n",
      "    z[0,231]     -0.43      0.57     -0.40     -1.28      0.52    898.61      1.00\n",
      "    z[0,232]     -0.54      0.56     -0.50     -1.47      0.25    754.87      1.00\n",
      "    z[0,233]      0.51      0.38      0.52     -0.11      1.04    470.55      1.00\n",
      "    z[0,234]      0.32      0.43      0.34     -0.29      1.04    546.42      1.00\n",
      "    z[0,235]     -0.93      0.53     -0.87     -1.78     -0.18    542.63      1.01\n",
      "    z[0,236]      0.46      0.44      0.49     -0.25      1.16    542.44      1.00\n",
      "    z[0,237]     -0.45      0.58     -0.44     -1.27      0.55    811.08      1.00\n",
      "    z[0,238]     -0.06      0.47     -0.05     -0.85      0.64    335.08      1.00\n",
      "    z[0,239]      0.43      0.45      0.42     -0.28      1.12    636.78      1.00\n",
      "    z[0,240]      0.21      0.45      0.24     -0.47      0.91    711.48      1.00\n",
      "    z[0,241]     -0.98      0.62     -0.96     -2.00     -0.05    807.30      1.00\n",
      "    z[0,242]      0.11      0.50      0.12     -0.63      0.96    667.13      1.00\n",
      "    z[0,243]     -0.48      0.56     -0.42     -1.36      0.39    571.87      1.00\n",
      "    z[0,244]     -1.24      0.65     -1.23     -2.20     -0.23    753.54      1.00\n",
      "    z[0,245]      1.90      0.37      1.90      1.38      2.53    323.03      1.00\n",
      "    z[0,246]     -0.20      0.53     -0.13     -1.22      0.47    572.12      1.00\n",
      "    z[0,247]     -0.35      0.67     -0.33     -1.29      0.84    707.25      1.00\n",
      "    z[0,248]     -0.49      0.60     -0.49     -1.41      0.47    801.34      1.00\n",
      "    z[0,249]      0.38      0.53      0.35     -0.41      1.22    768.09      1.00\n",
      "    z[0,250]      0.96      0.46      0.98      0.33      1.68    706.51      1.00\n",
      "    z[0,251]      0.68      0.48      0.67     -0.10      1.47    590.42      1.00\n",
      "    z[0,252]     -0.90      0.62     -0.90     -1.86      0.14    842.54      1.00\n",
      "    z[0,253]     -0.23      0.62     -0.21     -1.17      0.85    855.32      1.00\n",
      "    z[0,254]     -0.28      0.65     -0.30     -1.39      0.63    731.80      1.00\n",
      "    z[0,255]     -0.32      0.52     -0.31     -1.21      0.38    824.24      1.00\n",
      "    z[0,256]      0.10      0.53      0.11     -0.70      1.01    889.76      1.00\n",
      "    z[0,257]      0.46      0.45      0.47     -0.26      1.16    632.18      1.00\n",
      "    z[0,258]      0.21      0.46      0.23     -0.52      0.96    613.23      1.00\n",
      "    z[0,259]      0.72      0.44      0.71      0.04      1.40    532.79      1.00\n",
      "    z[0,260]     -0.06      0.48     -0.03     -0.76      0.75    957.00      1.00\n",
      "    z[0,261]     -0.01      0.53      0.00     -0.82      0.89    640.34      1.00\n",
      "    z[0,262]     -0.58      0.56     -0.55     -1.42      0.25    738.04      1.00\n",
      "    z[0,263]     -0.12      0.53     -0.10     -0.91      0.72    516.45      1.00\n",
      "    z[0,264]      0.51      0.47      0.52     -0.24      1.27    608.18      1.00\n",
      "    z[0,265]      0.89      0.36      0.88      0.31      1.45    533.97      1.00\n",
      "    z[0,266]      0.71      0.37      0.73      0.12      1.28    578.76      1.00\n",
      "    z[0,267]      0.12      0.43      0.13     -0.55      0.81    540.68      1.00\n",
      "    z[0,268]      1.25      0.35      1.25      0.73      1.86    359.43      1.00\n",
      "    z[0,269]     -0.56      0.52     -0.54     -1.34      0.28    537.63      1.00\n",
      "    z[0,270]      0.65      0.40      0.66      0.05      1.29    717.62      1.00\n",
      "    z[0,271]     -0.37      0.51     -0.30     -1.18      0.42    479.27      1.00\n",
      "    z[0,272]      0.37      0.59      0.38     -0.61      1.26    998.14      1.00\n",
      "    z[0,273]      0.05      0.57      0.05     -0.95      0.88    411.31      1.00\n",
      "    z[0,274]      2.49      0.37      2.51      1.88      3.01    458.86      1.00\n",
      "    z[0,275]     -0.17      0.69     -0.11     -1.26      0.94    605.58      1.00\n",
      "    z[0,276]     -0.82      0.70     -0.84     -1.76      0.51    942.16      1.00\n",
      "    z[0,277]      1.01      0.43      1.01      0.21      1.60    399.46      1.01\n",
      "    z[0,278]     -0.43      0.70     -0.40     -1.74      0.52    703.05      1.00\n",
      "    z[0,279]      0.52      0.48      0.54     -0.24      1.25    837.36      1.00\n",
      "    z[0,280]      0.94      0.40      0.96      0.33      1.57    557.48      1.00\n",
      "    z[0,281]      1.71      0.37      1.71      1.14      2.28    390.09      1.00\n",
      "    z[0,282]     -0.69      0.59     -0.67     -1.58      0.21    681.78      1.00\n",
      "    z[0,283]     -0.02      0.55      0.03     -0.86      0.81   1050.93      1.00\n",
      "    z[0,284]      0.30      0.48      0.33     -0.51      1.05    576.71      1.00\n",
      "    z[0,285]      0.91      0.36      0.91      0.40      1.50    419.41      1.00\n",
      "    z[0,286]     -0.01      0.44      0.01     -0.68      0.67    588.96      1.00\n",
      "    z[0,287]      0.35      0.44      0.35     -0.41      0.99    506.43      1.00\n",
      "    z[0,288]      1.13      0.32      1.10      0.62      1.63    475.75      1.00\n",
      "    z[0,289]     -1.52      0.72     -1.46     -2.64     -0.41    829.40      1.00\n",
      "    z[0,290]      1.10      0.34      1.12      0.55      1.62    354.55      1.00\n",
      "    z[0,291]      0.42      0.39      0.44     -0.26      0.99    675.68      1.00\n",
      "    z[0,292]     -1.62      0.64     -1.59     -2.50     -0.49    670.25      1.00\n",
      "    z[0,293]      0.06      0.36      0.07     -0.59      0.55    453.66      1.00\n",
      "    z[0,294]     -0.61      0.61     -0.54     -1.60      0.29    695.27      1.00\n",
      "    z[0,295]     -0.76      0.69     -0.69     -1.71      0.47    858.41      1.00\n",
      "    z[0,296]     -0.41      0.60     -0.39     -1.31      0.52    766.99      1.00\n",
      "    z[0,297]     -0.71      0.52     -0.72     -1.46      0.21    688.42      1.00\n",
      "    z[0,298]     -0.44      0.46     -0.43     -1.10      0.32    575.33      1.00\n",
      "    z[0,299]     -0.11      0.59     -0.09     -1.09      0.75    649.17      1.00\n",
      "      z[1,0]      0.48      0.93      0.45     -0.96      1.81   1179.23      1.00\n",
      "      z[1,1]      0.05      0.68      0.04     -1.10      1.01   1315.97      1.00\n",
      "      z[1,2]      0.92      0.82      0.95     -0.31      2.24    845.90      1.00\n",
      "      z[1,3]     -0.18      0.86     -0.20     -1.53      1.18   1015.42      1.00\n",
      "      z[1,4]     -0.19      0.83     -0.16     -1.53      1.12   1125.25      1.00\n",
      "      z[1,5]     -0.21      0.90     -0.22     -1.44      1.40    725.40      1.00\n",
      "      z[1,6]      0.32      0.87      0.31     -0.84      1.85   1021.15      1.00\n",
      "      z[1,7]     -0.18      0.95     -0.16     -1.61      1.36   1355.13      1.00\n",
      "      z[1,8]      0.67      0.62      0.68     -0.38      1.60    901.72      1.00\n",
      "      z[1,9]     -0.27      0.89     -0.32     -1.71      1.06   1780.82      1.00\n",
      "     z[1,10]     -0.24      0.97     -0.27     -1.57      1.29   1212.74      1.00\n",
      "     z[1,11]      0.26      0.85      0.25     -1.00      1.56    697.54      1.00\n",
      "     z[1,12]      1.17      0.78      1.19      0.07      2.60   1265.76      1.00\n",
      "     z[1,13]     -0.69      0.86     -0.70     -1.95      0.72    934.22      1.00\n",
      "     z[1,14]     -0.07      0.88     -0.08     -1.38      1.40   1115.40      1.00\n",
      "     z[1,15]      0.35      0.83      0.35     -0.98      1.61   1002.01      1.00\n",
      "     z[1,16]     -0.29      0.89     -0.24     -1.75      1.11   1059.24      1.00\n",
      "     z[1,17]      0.11      0.86      0.11     -1.13      1.57    721.41      1.00\n",
      "     z[1,18]     -0.65      0.90     -0.62     -1.93      0.82    906.81      1.00\n",
      "     z[1,19]      0.17      0.91      0.15     -1.26      1.51   1311.56      1.00\n",
      "     z[1,20]     -0.49      0.98     -0.47     -1.81      1.13    959.11      1.00\n",
      "     z[1,21]      0.64      0.90      0.60     -0.74      1.99    762.35      1.00\n",
      "     z[1,22]     -0.30      1.04     -0.30     -2.09      1.29   1009.67      1.00\n",
      "     z[1,23]     -0.89      0.79     -0.88     -2.13      0.29    832.07      1.00\n",
      "     z[1,24]     -0.18      0.89     -0.16     -1.57      1.15   2097.97      1.00\n",
      "     z[1,25]      0.14      0.85      0.12     -1.33      1.33   1122.71      1.00\n",
      "     z[1,26]      0.25      0.99      0.30     -1.26      1.75   1700.64      1.00\n",
      "     z[1,27]     -0.22      0.93     -0.21     -1.58      1.30    825.07      1.00\n",
      "     z[1,28]      0.19      0.92      0.20     -0.99      1.79   1489.28      1.00\n",
      "     z[1,29]      0.26      0.72      0.27     -0.89      1.28   1023.20      1.00\n",
      "     z[1,30]     -0.09      0.81     -0.09     -1.31      1.18    854.20      1.00\n",
      "     z[1,31]     -0.45      0.94     -0.44     -1.87      1.12    762.36      1.00\n",
      "     z[1,32]     -0.18      0.89     -0.18     -1.63      1.27   1554.03      1.00\n",
      "     z[1,33]     -0.14      0.91     -0.15     -1.41      1.48    996.62      1.00\n",
      "     z[1,34]     -0.25      0.79     -0.18     -1.58      0.87   1426.69      1.00\n",
      "     z[1,35]     -0.42      0.95     -0.38     -1.99      0.94   1037.27      1.00\n",
      "     z[1,36]     -0.26      0.92     -0.20     -1.73      1.09   1006.10      1.00\n",
      "     z[1,37]     -0.01      0.78     -0.02     -1.34      1.13    811.88      1.00\n",
      "     z[1,38]     -0.08      0.62     -0.08     -1.19      0.82   1327.69      1.00\n",
      "     z[1,39]     -0.01      0.90     -0.02     -1.39      1.28   1116.29      1.00\n",
      "     z[1,40]      0.88      0.83      0.88     -0.38      2.16   1015.54      1.00\n",
      "     z[1,41]      0.53      0.85      0.56     -0.80      1.96    807.14      1.00\n",
      "     z[1,42]     -0.32      0.83     -0.26     -1.60      1.00   1371.08      1.00\n",
      "     z[1,43]      1.00      0.63      1.03      0.11      2.14    503.99      1.01\n",
      "     z[1,44]     -0.17      0.81     -0.19     -1.42      1.07    869.92      1.00\n",
      "     z[1,45]     -0.20      0.89     -0.18     -1.75      0.99   1194.30      1.00\n",
      "     z[1,46]     -0.19      0.88     -0.20     -1.74      1.04   1369.59      1.00\n",
      "     z[1,47]     -0.45      0.99     -0.44     -1.94      1.14   1118.05      1.00\n",
      "     z[1,48]     -0.03      0.76     -0.05     -1.11      1.21    785.52      1.00\n",
      "     z[1,49]      0.54      0.85      0.57     -0.70      1.88    902.79      1.01\n",
      "     z[1,50]     -0.35      0.95     -0.34     -1.82      1.12   1096.67      1.00\n",
      "     z[1,51]     -0.20      0.96     -0.20     -1.71      1.14   1512.09      1.00\n",
      "     z[1,52]     -0.23      0.97     -0.24     -1.74      1.25    816.80      1.00\n",
      "     z[1,53]      0.68      0.80      0.63     -0.53      2.08    948.94      1.00\n",
      "     z[1,54]      0.14      0.89      0.17     -1.33      1.53    963.43      1.00\n",
      "     z[1,55]     -0.40      0.92     -0.38     -1.94      0.96   1856.25      1.00\n",
      "     z[1,56]     -0.67      0.88     -0.64     -2.03      0.75   1433.28      1.00\n",
      "     z[1,57]     -0.19      0.84     -0.16     -1.53      1.22    998.35      1.00\n",
      "     z[1,58]      0.94      0.82      0.97     -0.29      2.28    559.85      1.00\n",
      "     z[1,59]      0.01      0.92      0.02     -1.40      1.43   1209.23      1.00\n",
      "     z[1,60]      0.42      0.72      0.41     -0.74      1.57   1459.65      1.00\n",
      "     z[1,61]     -0.19      0.97     -0.16     -1.75      1.42    878.27      1.00\n",
      "     z[1,62]     -0.42      0.90     -0.42     -1.74      1.09   1497.51      1.00\n",
      "     z[1,63]     -0.43      0.82     -0.43     -1.77      0.80    784.83      1.00\n",
      "     z[1,64]     -0.56      0.87     -0.53     -2.01      0.72    771.69      1.00\n",
      "     z[1,65]     -0.05      0.87     -0.02     -1.26      1.47    947.38      1.00\n",
      "     z[1,66]      0.98      0.64      0.96     -0.17      1.90    908.91      1.01\n",
      "     z[1,67]     -0.29      0.93     -0.30     -1.82      1.17   2854.89      1.00\n",
      "     z[1,68]     -0.30      1.03     -0.34     -2.06      1.20    961.27      1.00\n",
      "     z[1,69]      1.29      0.79      1.24      0.14      2.62   1089.39      1.00\n",
      "     z[1,70]     -0.69      0.72     -0.69     -1.87      0.38    976.75      1.00\n",
      "     z[1,71]      0.07      0.99      0.09     -1.41      1.73   1240.68      1.00\n",
      "     z[1,72]     -0.26      0.91     -0.24     -1.51      1.29   1568.77      1.00\n",
      "     z[1,73]     -0.23      0.92     -0.24     -1.48      1.46   1061.82      1.00\n",
      "     z[1,74]     -0.23      0.89     -0.20     -1.56      1.27   1271.39      1.00\n",
      "     z[1,75]     -0.44      0.91     -0.41     -1.96      0.88   1250.05      1.00\n",
      "     z[1,76]      0.39      0.91      0.38     -1.06      1.80   1139.97      1.00\n",
      "     z[1,77]      0.25      0.80      0.21     -0.93      1.60    813.34      1.00\n",
      "     z[1,78]      0.66      0.89      0.70     -0.80      1.86   1136.88      1.00\n",
      "     z[1,79]      0.13      1.01      0.12     -1.45      1.79    921.57      1.00\n",
      "     z[1,80]      0.79      0.74      0.75     -0.30      2.08   1767.00      1.00\n",
      "     z[1,81]     -0.18      0.81     -0.18     -1.62      0.97   1385.07      1.00\n",
      "     z[1,82]     -0.09      0.86     -0.16     -1.36      1.35    942.63      1.00\n",
      "     z[1,83]      0.06      0.88      0.10     -1.43      1.42    863.34      1.00\n",
      "     z[1,84]     -0.30      0.89     -0.32     -1.77      1.16    782.39      1.00\n",
      "     z[1,85]     -0.15      0.93     -0.19     -1.44      1.43    895.78      1.00\n",
      "     z[1,86]     -0.03      0.90     -0.02     -1.64      1.22   1327.11      1.00\n",
      "     z[1,87]      0.14      0.82      0.12     -1.04      1.47    899.56      1.00\n",
      "     z[1,88]     -0.57      0.93     -0.57     -2.28      0.82    677.92      1.00\n",
      "     z[1,89]     -0.03      0.92     -0.02     -1.36      1.36   1652.08      1.00\n",
      "     z[1,90]      1.69      0.69      1.69      0.46      2.65    769.02      1.00\n",
      "     z[1,91]      0.38      0.91      0.37     -1.12      1.72   1421.08      1.00\n",
      "     z[1,92]     -0.26      0.99     -0.28     -1.75      1.23   1112.67      1.00\n",
      "     z[1,93]     -0.02      0.89      0.01     -1.52      1.27    703.39      1.00\n",
      "     z[1,94]     -0.04      0.83     -0.05     -1.30      1.26   1592.68      1.00\n",
      "     z[1,95]      0.61      0.85      0.66     -0.70      1.95   1493.87      1.00\n",
      "     z[1,96]      0.78      0.87      0.80     -0.53      2.13    886.70      1.00\n",
      "     z[1,97]      0.48      0.77      0.50     -0.74      1.64    655.08      1.00\n",
      "     z[1,98]     -0.16      0.87     -0.15     -1.65      1.19   1487.88      1.00\n",
      "     z[1,99]     -0.02      0.84     -0.01     -1.30      1.33   1900.81      1.00\n",
      "    z[1,100]      0.47      0.73      0.46     -0.71      1.55   1161.21      1.00\n",
      "    z[1,101]     -0.15      0.92     -0.19     -1.53      1.25   1091.10      1.00\n",
      "    z[1,102]     -0.41      0.99     -0.42     -1.78      1.26   1680.23      1.00\n",
      "    z[1,103]     -0.37      1.04     -0.45     -2.03      1.30   1873.72      1.00\n",
      "    z[1,104]     -0.96      0.85     -0.98     -2.17      0.47    799.58      1.00\n",
      "    z[1,105]     -0.65      0.85     -0.66     -1.95      0.62    835.60      1.00\n",
      "    z[1,106]      0.16      0.85      0.18     -1.22      1.44   1276.39      1.00\n",
      "    z[1,107]      0.45      0.82      0.44     -0.73      1.88   1345.00      1.00\n",
      "    z[1,108]     -0.12      0.99     -0.10     -1.90      1.22   1071.95      1.00\n",
      "    z[1,109]     -0.24      0.84     -0.24     -1.48      1.10   1371.93      1.00\n",
      "    z[1,110]      0.16      0.96      0.20     -1.22      1.84   1356.36      1.00\n",
      "    z[1,111]     -0.29      0.95     -0.29     -1.77      1.24   1722.37      1.00\n",
      "    z[1,112]     -0.59      0.94     -0.62     -2.14      0.78   1826.95      1.00\n",
      "    z[1,113]      0.73      0.73      0.76     -0.41      1.86    917.86      1.00\n",
      "    z[1,114]      0.29      0.82      0.27     -1.07      1.46   1012.90      1.00\n",
      "    z[1,115]     -0.06      0.93     -0.10     -1.63      1.31   1018.82      1.00\n",
      "    z[1,116]      0.24      0.88      0.23     -1.09      1.70   1285.20      1.00\n",
      "    z[1,117]      0.65      0.74      0.66     -0.64      1.74    895.20      1.00\n",
      "    z[1,118]      0.37      0.90      0.38     -1.07      1.74   2977.97      1.00\n",
      "    z[1,119]      0.09      0.87      0.11     -1.21      1.44   1298.33      1.00\n",
      "    z[1,120]      0.34      0.93      0.36     -1.02      1.84   1049.97      1.00\n",
      "    z[1,121]     -0.43      0.94     -0.43     -1.83      1.19   1200.26      1.00\n",
      "    z[1,122]     -0.04      0.89     -0.07     -1.52      1.25    799.84      1.00\n",
      "    z[1,123]     -0.56      0.87     -0.60     -1.87      0.83   1018.20      1.00\n",
      "    z[1,124]     -0.18      0.92     -0.20     -1.50      1.50   1429.93      1.00\n",
      "    z[1,125]     -0.82      0.92     -0.80     -2.23      0.63    803.25      1.00\n",
      "    z[1,126]      0.09      0.77      0.05     -1.08      1.32    858.53      1.00\n",
      "    z[1,127]     -0.46      0.97     -0.44     -1.90      1.11    755.30      1.00\n",
      "    z[1,128]     -0.21      0.96     -0.20     -1.79      1.16   1407.34      1.00\n",
      "    z[1,129]      0.17      0.93      0.19     -1.26      1.61   1019.42      1.00\n",
      "    z[1,130]      0.61      0.76      0.63     -0.51      1.85   1252.22      1.00\n",
      "    z[1,131]     -0.17      0.91     -0.17     -1.64      1.16    818.11      1.00\n",
      "    z[1,132]      0.17      0.83      0.15     -1.26      1.40   1124.08      1.00\n",
      "    z[1,133]      0.44      0.84      0.43     -0.84      1.71   1242.94      1.00\n",
      "    z[1,134]     -0.58      0.76     -0.58     -1.73      0.66    688.39      1.00\n",
      "    z[1,135]     -0.51      0.85     -0.54     -1.90      0.68   1731.88      1.00\n",
      "    z[1,136]      0.73      0.84      0.74     -0.66      1.89    880.16      1.00\n",
      "    z[1,137]     -0.54      0.77     -0.54     -1.93      0.53   1010.52      1.00\n",
      "    z[1,138]     -0.14      0.86     -0.10     -1.31      1.33    850.29      1.00\n",
      "    z[1,139]     -0.02      0.88     -0.00     -1.47      1.34   1094.61      1.00\n",
      "    z[1,140]     -0.39      0.93     -0.44     -1.64      1.14   1852.65      1.00\n",
      "    z[1,141]      0.50      0.84      0.56     -0.71      1.92    849.62      1.00\n",
      "    z[1,142]      0.83      0.84      0.83     -0.39      2.28   1057.57      1.00\n",
      "    z[1,143]     -0.14      0.94     -0.12     -1.57      1.31    882.73      1.00\n",
      "    z[1,144]      0.24      0.85      0.27     -1.14      1.57   1030.59      1.00\n",
      "    z[1,145]     -0.11      0.80     -0.13     -1.25      1.21   1489.05      1.00\n",
      "    z[1,146]      0.29      0.87      0.28     -0.92      1.73   1111.02      1.00\n",
      "    z[1,147]     -0.09      0.86     -0.07     -1.54      1.16   1260.78      1.00\n",
      "    z[1,148]     -0.18      0.96     -0.16     -1.62      1.42   1078.06      1.00\n",
      "    z[1,149]     -0.40      0.97     -0.44     -2.08      1.10    901.00      1.00\n",
      "    z[1,150]     -0.53      0.93     -0.57     -2.03      0.97    862.60      1.00\n",
      "    z[1,151]     -0.43      0.86     -0.43     -1.75      0.95    922.43      1.00\n",
      "    z[1,152]      0.51      0.78      0.47     -0.85      1.66    933.06      1.00\n",
      "    z[1,153]     -0.31      0.90     -0.29     -1.78      1.00   1462.70      1.00\n",
      "    z[1,154]     -0.21      0.78     -0.19     -1.37      1.03   1008.56      1.00\n",
      "    z[1,155]      0.89      0.81      0.88     -0.41      2.08   1463.21      1.00\n",
      "    z[1,156]      0.22      0.94      0.26     -1.10      1.83   1187.79      1.00\n",
      "    z[1,157]      1.00      0.77      0.96     -0.29      2.24    710.09      1.00\n",
      "    z[1,158]      0.59      0.84      0.56     -0.76      1.88   1988.77      1.00\n",
      "    z[1,159]     -0.16      0.94     -0.18     -1.62      1.31    721.11      1.00\n",
      "    z[1,160]     -0.48      0.80     -0.47     -1.72      0.70   1218.43      1.00\n",
      "    z[1,161]      0.21      0.80      0.17     -0.97      1.67    813.36      1.00\n",
      "    z[1,162]     -0.04      0.92     -0.06     -1.42      1.33    999.76      1.00\n",
      "    z[1,163]      0.47      0.89      0.51     -1.03      1.84   1042.63      1.00\n",
      "    z[1,164]     -0.55      0.93     -0.54     -1.81      1.16   1388.45      1.00\n",
      "    z[1,165]     -0.10      0.88     -0.12     -1.30      1.56   1334.81      1.00\n",
      "    z[1,166]     -0.17      0.93     -0.17     -1.44      1.56   1032.04      1.00\n",
      "    z[1,167]      0.27      0.83      0.31     -1.10      1.53   1205.36      1.00\n",
      "    z[1,168]     -0.02      0.87     -0.01     -1.46      1.27   1334.26      1.00\n",
      "    z[1,169]     -0.51      0.97     -0.50     -2.11      0.97   1890.36      1.00\n",
      "    z[1,170]     -0.09      0.88     -0.07     -1.52      1.16    987.36      1.00\n",
      "    z[1,171]      0.08      0.68      0.08     -0.92      1.17    665.96      1.00\n",
      "    z[1,172]     -0.10      0.82     -0.07     -1.51      1.08   1420.17      1.00\n",
      "    z[1,173]     -0.33      0.81     -0.29     -1.71      0.84    813.83      1.00\n",
      "    z[1,174]      1.55      0.78      1.56      0.39      2.91    829.01      1.00\n",
      "    z[1,175]      0.54      0.72      0.54     -0.75      1.50   1314.25      1.00\n",
      "    z[1,176]      0.45      0.90      0.48     -0.95      1.90    809.52      1.00\n",
      "    z[1,177]     -0.26      0.82     -0.24     -1.52      1.05    761.27      1.00\n",
      "    z[1,178]     -0.10      0.65     -0.08     -1.04      0.97    765.03      1.00\n",
      "    z[1,179]     -0.13      1.03     -0.17     -1.97      1.38   1340.84      1.00\n",
      "    z[1,180]      0.13      0.96      0.12     -1.30      1.68   1419.33      1.00\n",
      "    z[1,181]     -0.52      0.90     -0.53     -1.99      0.97   1525.19      1.00\n",
      "    z[1,182]      0.69      0.72      0.71     -0.33      1.94    733.35      1.00\n",
      "    z[1,183]      0.27      0.77      0.29     -1.00      1.48    787.94      1.00\n",
      "    z[1,184]      0.11      0.98      0.08     -1.33      1.66   1070.13      1.00\n",
      "    z[1,185]      0.12      0.94      0.14     -1.51      1.48   1753.79      1.00\n",
      "    z[1,186]      0.23      0.85      0.30     -1.14      1.43    778.50      1.00\n",
      "    z[1,187]     -0.24      1.01     -0.21     -1.69      1.53   1192.18      1.00\n",
      "    z[1,188]     -0.34      0.97     -0.34     -2.09      1.03    966.64      1.00\n",
      "    z[1,189]     -0.65      0.88     -0.67     -2.05      0.66    928.85      1.01\n",
      "    z[1,190]     -0.08      0.68     -0.06     -1.14      0.99    931.69      1.00\n",
      "    z[1,191]     -0.29      0.90     -0.27     -1.78      1.08    970.38      1.00\n",
      "    z[1,192]     -0.14      0.78     -0.13     -1.43      0.97    949.81      1.00\n",
      "    z[1,193]     -0.21      0.90     -0.22     -1.70      1.19   1924.44      1.00\n",
      "    z[1,194]      1.41      0.80      1.44      0.26      2.76    646.03      1.00\n",
      "    z[1,195]      0.56      0.64      0.55     -0.41      1.54    758.56      1.00\n",
      "    z[1,196]      1.03      0.69      1.03     -0.07      2.13    667.68      1.00\n",
      "    z[1,197]      0.50      0.83      0.49     -0.73      1.84   1121.02      1.00\n",
      "    z[1,198]     -0.08      0.94     -0.08     -1.37      1.57    894.77      1.00\n",
      "    z[1,199]      0.11      0.88      0.10     -1.18      1.64    750.35      1.00\n",
      "    z[1,200]     -0.15      0.83     -0.15     -1.44      1.15    906.29      1.00\n",
      "    z[1,201]     -0.41      0.90     -0.42     -1.64      1.10   1222.40      1.00\n",
      "    z[1,202]     -0.25      0.98     -0.33     -1.95      1.07   1117.86      1.00\n",
      "    z[1,203]     -0.36      0.88     -0.38     -1.70      1.05    924.32      1.00\n",
      "    z[1,204]     -0.11      0.91     -0.13     -1.69      1.11   1643.04      1.00\n",
      "    z[1,205]     -0.54      0.88     -0.56     -1.93      0.87    712.38      1.00\n",
      "    z[1,206]      0.44      0.88      0.46     -0.97      1.76    953.96      1.01\n",
      "    z[1,207]      0.47      0.92      0.52     -0.77      2.26    905.01      1.00\n",
      "    z[1,208]     -0.34      0.96     -0.34     -1.90      1.31   2539.57      1.00\n",
      "    z[1,209]      0.99      0.68      0.98      0.02      2.10    724.99      1.00\n",
      "    z[1,210]     -0.85      0.90     -0.79     -2.16      0.65   1270.51      1.00\n",
      "    z[1,211]     -0.25      0.96     -0.19     -1.79      1.19   1093.82      1.00\n",
      "    z[1,212]      0.33      0.93      0.33     -1.18      1.75    897.85      1.00\n",
      "    z[1,213]     -0.43      0.98     -0.41     -2.26      0.97   1354.35      1.00\n",
      "    z[1,214]     -0.34      0.94     -0.36     -1.79      1.12   1391.44      1.00\n",
      "    z[1,215]     -0.01      0.91     -0.01     -1.37      1.58   1449.60      1.00\n",
      "    z[1,216]     -0.29      1.02     -0.26     -1.98      1.23    917.41      1.00\n",
      "    z[1,217]     -0.17      0.90     -0.18     -1.83      1.01   1231.46      1.00\n",
      "    z[1,218]     -0.39      0.96     -0.40     -1.83      1.01    755.58      1.00\n",
      "    z[1,219]      0.14      0.83      0.12     -1.12      1.43   1021.19      1.00\n",
      "    z[1,220]      0.02      0.91      0.02     -1.54      1.29   1180.54      1.00\n",
      "    z[1,221]     -0.22      0.95     -0.21     -1.70      1.17   1713.27      1.00\n",
      "    z[1,222]      1.42      0.61      1.42      0.45      2.32    990.51      1.00\n",
      "    z[1,223]      0.21      0.84      0.24     -0.92      1.75   1272.59      1.00\n",
      "    z[1,224]     -0.19      0.83     -0.23     -1.40      1.22   1125.45      1.00\n",
      "    z[1,225]     -0.30      1.13     -0.28     -2.14      1.35   1334.10      1.00\n",
      "    z[1,226]     -0.20      0.99     -0.26     -1.63      1.43   1167.07      1.00\n",
      "    z[1,227]     -0.33      0.95     -0.31     -1.80      1.25   1737.70      1.00\n",
      "    z[1,228]      0.17      0.74      0.16     -0.96      1.32   1347.22      1.00\n",
      "    z[1,229]     -0.84      0.88     -0.85     -2.34      0.48   2053.82      1.00\n",
      "    z[1,230]     -0.31      0.97     -0.28     -1.97      1.02   1322.33      1.00\n",
      "    z[1,231]     -0.31      0.90     -0.29     -1.82      1.04   1085.84      1.00\n",
      "    z[1,232]      0.47      0.89      0.46     -0.98      1.82    652.97      1.00\n",
      "    z[1,233]     -0.37      0.86     -0.38     -1.87      0.91    699.47      1.00\n",
      "    z[1,234]      0.17      0.87      0.21     -1.29      1.51   1307.48      1.00\n",
      "    z[1,235]      0.37      0.85      0.36     -1.03      1.61    844.73      1.00\n",
      "    z[1,236]      0.17      0.80      0.16     -1.02      1.53   1557.84      1.00\n",
      "    z[1,237]      0.29      0.87      0.29     -0.96      1.86   2309.23      1.00\n",
      "    z[1,238]      0.19      0.86      0.18     -1.19      1.58    860.28      1.00\n",
      "    z[1,239]      0.54      0.79      0.54     -0.63      1.84    905.79      1.00\n",
      "    z[1,240]      0.22      0.73      0.21     -1.09      1.29    921.44      1.00\n",
      "    z[1,241]     -0.11      0.90     -0.16     -1.48      1.21   1185.52      1.00\n",
      "    z[1,242]      0.35      0.81      0.37     -0.95      1.53   1280.23      1.00\n",
      "    z[1,243]     -0.08      0.99     -0.08     -1.67      1.47   1075.97      1.00\n",
      "    z[1,244]     -0.21      1.17     -0.16     -1.92      1.67   1710.79      1.00\n",
      "    z[1,245]      0.93      0.67      0.93     -0.03      2.06   1095.26      1.00\n",
      "    z[1,246]      0.50      0.76      0.51     -0.64      1.74    916.36      1.00\n",
      "    z[1,247]      0.09      0.96      0.12     -1.33      1.70    959.67      1.00\n",
      "    z[1,248]     -0.46      0.88     -0.46     -1.77      0.90   1020.26      1.00\n",
      "    z[1,249]      0.18      0.83      0.17     -1.04      1.50   1085.20      1.00\n",
      "    z[1,250]      0.32      0.79      0.36     -0.99      1.49   1071.23      1.00\n",
      "    z[1,251]     -0.04      0.77      0.00     -1.26      1.20    942.70      1.00\n",
      "    z[1,252]     -0.34      0.89     -0.33     -1.78      1.14    905.47      1.00\n",
      "    z[1,253]      0.23      0.92      0.21     -1.08      1.81   1551.57      1.00\n",
      "    z[1,254]      0.40      0.96      0.39     -1.24      1.80    678.46      1.00\n",
      "    z[1,255]     -0.24      0.79     -0.25     -1.47      0.98    896.10      1.00\n",
      "    z[1,256]      0.12      0.83      0.11     -1.07      1.46    870.01      1.00\n",
      "    z[1,257]      0.45      0.75      0.43     -0.90      1.54   1020.55      1.00\n",
      "    z[1,258]     -0.10      0.83     -0.11     -1.36      1.21    920.20      1.00\n",
      "    z[1,259]      0.93      0.75      0.90     -0.23      2.21    925.03      1.00\n",
      "    z[1,260]      0.76      0.84      0.79     -0.73      1.87    910.99      1.00\n",
      "    z[1,261]      0.02      0.89      0.03     -1.39      1.36    962.45      1.00\n",
      "    z[1,262]      0.20      0.88      0.22     -1.35      1.43    851.99      1.00\n",
      "    z[1,263]      0.00      0.91      0.02     -1.62      1.41   1588.40      1.00\n",
      "    z[1,264]     -0.23      0.89     -0.23     -1.45      1.36   1149.90      1.00\n",
      "    z[1,265]      0.78      0.77      0.81     -0.42      1.96    887.01      1.00\n",
      "    z[1,266]      0.67      0.68      0.68     -0.53      1.66   1004.08      1.00\n",
      "    z[1,267]     -0.16      0.75     -0.14     -1.42      0.97    975.83      1.00\n",
      "    z[1,268]      1.15      0.71      1.17      0.12      2.28    911.49      1.00\n",
      "    z[1,269]     -0.26      0.81     -0.23     -1.47      1.10   1083.05      1.00\n",
      "    z[1,270]      0.44      0.87      0.41     -0.84      1.87    892.22      1.00\n",
      "    z[1,271]     -0.31      1.00     -0.31     -1.83      1.37   1367.42      1.00\n",
      "    z[1,272]     -0.27      0.94     -0.32     -1.74      1.28    968.25      1.00\n",
      "    z[1,273]     -0.56      0.87     -0.56     -1.89      0.80    951.80      1.00\n",
      "    z[1,274]      0.65      0.67      0.67     -0.42      1.61   1054.36      1.00\n",
      "    z[1,275]     -0.11      0.97     -0.08     -1.77      1.34   1240.38      1.00\n",
      "    z[1,276]     -0.22      0.92     -0.20     -1.72      1.14   1235.74      1.00\n",
      "    z[1,277]      0.26      0.84      0.27     -1.05      1.54   1032.10      1.00\n",
      "    z[1,278]     -0.18      0.98     -0.14     -1.72      1.35   1905.65      1.00\n",
      "    z[1,279]      1.09      0.84      1.07     -0.21      2.40   1483.67      1.00\n",
      "    z[1,280]     -0.10      0.71     -0.08     -1.32      0.90    715.18      1.00\n",
      "    z[1,281]      0.34      0.71      0.32     -0.65      1.52    765.59      1.00\n",
      "    z[1,282]      0.01      0.88      0.01     -1.55      1.18   1166.81      1.00\n",
      "    z[1,283]     -0.20      0.88     -0.21     -1.71      1.05   1171.14      1.00\n",
      "    z[1,284]      0.38      0.93      0.36     -1.13      1.78   1103.59      1.00\n",
      "    z[1,285]      0.08      0.68      0.08     -1.00      1.11    958.46      1.00\n",
      "    z[1,286]      0.12      0.86      0.14     -1.42      1.26   1046.08      1.00\n",
      "    z[1,287]      0.56      0.78      0.55     -0.52      1.85   1162.72      1.00\n",
      "    z[1,288]      0.07      0.75      0.07     -1.10      1.28    944.09      1.00\n",
      "    z[1,289]     -0.08      1.00     -0.06     -1.55      1.42   1797.60      1.00\n",
      "    z[1,290]      0.11      0.71      0.14     -1.16      1.13    804.68      1.00\n",
      "    z[1,291]     -1.20      0.85     -1.21     -2.46      0.23   1015.27      1.00\n",
      "    z[1,292]     -0.11      0.98     -0.12     -1.61      1.44   2452.43      1.00\n",
      "    z[1,293]      0.22      0.91      0.24     -1.18      1.68    923.44      1.00\n",
      "    z[1,294]     -0.50      0.79     -0.52     -1.72      0.73    651.79      1.00\n",
      "    z[1,295]      0.14      1.00      0.17     -1.46      1.66   2007.70      1.00\n",
      "    z[1,296]     -0.21      0.99     -0.19     -1.80      1.37   1498.16      1.00\n",
      "    z[1,297]     -0.23      1.01     -0.24     -1.78      1.38   1611.28      1.00\n",
      "    z[1,298]     -0.16      1.03     -0.14     -1.81      1.38   1482.56      1.00\n",
      "    z[1,299]     -0.25      0.90     -0.24     -1.58      1.11   1445.89      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "kl_dyads  = pd.read_csv('/home/sosa/BI/data/kl_dyads')\n",
    "d2 = pd.read_csv('/home/sosa/BI/data/kl_households'\"\", index_col=0)\n",
    "kl_data = dict(\n",
    "    N=kl_dyads.shape[0],\n",
    "    N_households=kl_dyads.hidB.max(),\n",
    "    did=kl_dyads.did.values - 1,\n",
    "    hidA=kl_dyads.hidA.values - 1,\n",
    "    hidB=kl_dyads.hidB.values - 1,\n",
    "    giftsAB=kl_dyads.giftsAB.values,\n",
    "    giftsBA=kl_dyads.giftsBA.values,\n",
    ")\n",
    "m.data = kl_data\n",
    "\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = lkj(\"Rho_gr\", [], 2, 4)\n",
    "    sigma_gr = exponential(\"sigma_gr\", [2], 1)\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = multivariatenormal(\"gr\", [N_households], 0, cov)\n",
    "\n",
    "    # dyad effects\n",
    "    z = normal(\"z\",[2, N], 0, 1)\n",
    "    L_Rho_d = lkjcholesky(\"L_Rho_d\",[], 2, 8)\n",
    "    sigma_d = exponential(\"sigma_d\",[1], 1)\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = normal('a', [1], 0, 1)\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    sample(\"giftsAB\", Poisson(lambdaAB), obs=giftsAB)\n",
    "    sample(\"giftsBA\", Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = numpyro.sample(\"Rho_gr\", dist.LKJ(2, 4))\n",
    "    sigma_gr = numpyro.sample(\"sigma_gr\", dist.Exponential(1).expand([2]))\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = numpyro.sample(\"gr\", dist.MultivariateNormal(0, cov).expand([N_households]))\n",
    "\n",
    "    # dyad effects\n",
    "    z = numpyro.sample(\"z\", dist.Normal(0, 1).expand([2, N]))\n",
    "    L_Rho_d = numpyro.sample(\"L_Rho_d\", dist.LKJCholesky(2, 8))\n",
    "    sigma_d = numpyro.sample(\"sigma_d\", dist.Exponential(1))\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    numpyro.sample(\"giftsAB\", dist.Poisson(lambdaAB), obs=giftsAB)\n",
    "    numpyro.sample(\"giftsBA\", dist.Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "\n",
    "m14_7 = MCMC(NUTS(model), num_warmup=1000, num_samples=1000, num_chains=4)\n",
    "m14_7.run(random.PRNGKey(0), **kl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 768.14it/s, 127 steps of size 3.22e-02. acc. prob=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9520 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.33      0.90      1.11      0.15      2.60    394.53      1.02\n",
      "      b[0]      0.28      0.09      0.28      0.13      0.41    209.03      1.00\n",
      "  etasq[0]      0.20      0.20      0.14      0.01      0.42    280.91      1.00\n",
      "      g[0]      0.59      0.59      0.43      0.02      1.23    302.88      1.02\n",
      "  rhosq[0]      1.38      1.72      0.75      0.02      3.37    329.98      1.00\n",
      "      z[0]     -0.49      0.79     -0.46     -1.53      0.84    241.76      1.00\n",
      "      z[1]      0.37      0.76      0.39     -0.86      1.49    502.49      1.00\n",
      "      z[2]     -0.26      0.76     -0.21     -1.73      0.68    636.05      1.00\n",
      "      z[3]      0.93      0.65      0.95     -0.12      1.84    255.45      1.00\n",
      "      z[4]      0.30      0.61      0.28     -0.52      1.37    330.08      1.00\n",
      "      z[5]     -1.09      0.72     -1.02     -2.20     -0.05    271.82      1.00\n",
      "      z[6]      0.37      0.62      0.33     -0.64      1.30    371.45      1.00\n",
      "      z[7]     -0.37      0.70     -0.39     -1.51      0.65    501.95      1.00\n",
      "      z[8]      0.77      0.63      0.75     -0.31      1.69    333.48      1.00\n",
      "      z[9]     -0.46      0.77     -0.48     -1.78      0.70    299.46      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "Kline2 = pd.read_csv('/home/sosa/BI/data/Kline2.csv', sep=\";\")\n",
    "islandsDistMatrix = pd.read_csv('/home/sosa/BI/data/islandsDistMatrix.csv'\"\", index_col=0)\n",
    "d = Kline2\n",
    "d[\"society\"] = range(1, 11)  # index observations\n",
    "\n",
    "dat_list = dict(\n",
    "    T=d.total_tools.values,\n",
    "    P=d.population.values,\n",
    "    society=d.society.values - 1,\n",
    "    Dmat=islandsDistMatrix.values,\n",
    ")\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m14_8 = bi(platform='cpu')\n",
    "m14_8.data = dat_list\n",
    "\n",
    "@jit\n",
    "def cov_GPL2(x, sq_eta, sq_rho, sq_sigma):\n",
    "    N = x.shape[0]\n",
    "    K = sq_eta * jnp.exp(-sq_rho * jnp.square(x))\n",
    "    K = K.at[jnp.diag_indices(N)].add(sq_sigma)\n",
    "    return K\n",
    "\n",
    "\n",
    "def model(Dmat, P, society, T):\n",
    "    a = exponential('a', [1], 1)\n",
    "    b = exponential('b',[1],1)\n",
    "    g = exponential('g',[1],1)\n",
    "    etasq = exponential('etasq',[1],2)\n",
    "    rhosq = exponential('rhosq',[1],0.5)\n",
    "\n",
    "    # non-centered Gaussian Process prior\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, 0.01)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = normal('z', [10], 0, 1)\n",
    "    k = (L_SIGMA @ z[..., None])[..., 0]\n",
    "    lambda_ = a * P**b / g * jnp.exp(k[society])\n",
    "    sample(\"T\", Poisson(lambda_), obs=T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m14_8.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "m14_8.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rethinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "kl_dyads  = pd.read_csv('/home/sosa/BI/data/kl_dyads')\n",
    "d2 = pd.read_csv('/home/sosa/BI/data/kl_households'\"\", index_col=0)\n",
    "kl_data = dict(\n",
    "    N=kl_dyads.shape[0],\n",
    "    N_households=kl_dyads.hidB.max(),\n",
    "    did=kl_dyads.did.values - 1,\n",
    "    hidA=kl_dyads.hidA.values - 1,\n",
    "    hidB=kl_dyads.hidB.values - 1,\n",
    "    giftsAB=kl_dyads.giftsAB.values,\n",
    "    giftsBA=kl_dyads.giftsBA.values,\n",
    ")\n",
    "m.data = kl_data\n",
    "\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = lkj(\"Rho_gr\", [], 2, 4)\n",
    "    sigma_gr = exponential(\"sigma_gr\", [2], 1)\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = multivariatenormal(\"gr\", [N_households], 0, cov)\n",
    "\n",
    "    # dyad effects\n",
    "    z = normal(\"z\",[2, N], 0, 1)\n",
    "    L_Rho_d = lkjcholesky(\"L_Rho_d\",[], 2, 8)\n",
    "    sigma_d = exponential(\"sigma_d\",[1], 1)\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = normal('a', [1], 0, 1)\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    sample(\"giftsAB\", Poisson(lambdaAB), obs=giftsAB)\n",
    "    sample(\"giftsBA\", Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['N_networktypes', 'N_id', 'N_responses', 'N_periods', 'N_individual_predictors', 'N_dyadic_predictors', 'outcomes', 'flows', 'individual_predictors', 'dyadic_predictors', 'N_block_predictors', 'N_groups_per_block_type', 'block_predictors', 'outcome_mode', 'exposure'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import jax.numpy as jnp\n",
    "with open('OUTPUT STRAND block.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_networktypes: \n",
      "[1]\n",
      "N_id : \n",
      "[100]\n",
      "N_responses : \n",
      "[1]\n",
      "N_periods : \n",
      "[0]\n",
      "N_periods : \n",
      "[0]\n",
      "N_individual_predictors : \n",
      "[1]\n",
      "N_dyadic_predictors : \n",
      "[2]\n",
      "flows : \n",
      "[0]\n",
      "individual_predictors : \n",
      "[1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "N_block_predictors : \n",
      "[3]\n",
      "N_groups_per_block_type : \n",
      "[1, 3, 2]\n",
      "outcome_mode : \n",
      "[3]\n",
      "block_predictors : \n",
      "[1 1 3 2 1 3 1 1 1 3 3 1 2 2 2 1 3 1 1 1 1 3 3 1 2 1 3 3 2 3 1 1 3 3 3 2 2\n",
      " 1 1 2 1 1 2 3 2 1 2 3 3 2 2 3 2 2 1 2 1 1 1 1 3 2 2 3 1 3 1 3 2 3 3 2 1 2\n",
      " 2 1 3 1 1 1 2 2 3 2 3 2 2 2 3 1 2 2 3 3 3 3 2 2 2 3]\n",
      "outcome_mode : \n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(\"N_networktypes: \")\n",
    "print(data['N_networktypes'])\n",
    "print(\"N_id : \")\n",
    "print(data['N_id'])\n",
    "print(\"N_responses : \")\n",
    "print(data['N_responses'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_individual_predictors : \" )\n",
    "print(data['N_individual_predictors'])\n",
    "print(\"N_dyadic_predictors : \")\n",
    "print(data['N_dyadic_predictors'])\n",
    "print(\"flows : \")\n",
    "print(data['flows'])\n",
    "data['individual_predictors'] = jnp.array([item['Mass'] for item in data['individual_predictors']])\n",
    "print(\"individual_predictors : \")\n",
    "print(data['individual_predictors'])\n",
    "print(\"N_block_predictors : \")\n",
    "print(data['N_block_predictors'])\n",
    "print(\"N_groups_per_block_type : \")\n",
    "print(data['N_groups_per_block_type'])\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )\n",
    "data['block_predictors'] = jnp.array([item['Merica'] for item in data['block_predictors']])\n",
    "print(\"block_predictors : \")\n",
    "print(data['block_predictors'] )\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(4950, 2)\n",
      "4950.0\n"
     ]
    }
   ],
   "source": [
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "print(Kinship.shape)\n",
    "Dominant = jnp.array(data['dyadic_predictors']['Dominant'])\n",
    "print(Dominant.shape)\n",
    "exposure = jnp.array(data['exposure'])[:,:,1]\n",
    "print(exposure.shape)\n",
    "\n",
    "# Matrices to edgelist\n",
    "result_dom = mat_to_edgl(Dominant)\n",
    "result_dom.shape\n",
    "result_kin = mat_to_edgl(Kinship)\n",
    "result_kin\n",
    "data['outcomes'] = jnp.array(data['outcomes'])\n",
    "result_outcomes = mat_to_edgl(data['outcomes'][:,:,0])\n",
    "print(result_outcomes.shape)\n",
    "\n",
    "N_id = data['individual_predictors'].shape[0]\n",
    "print((N_id*(N_id-1))/2)\n",
    "focal_individual_predictors = data['individual_predictors']\n",
    "target_individual_predictors = data['individual_predictors']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_id2 = 4\n",
    "B = sample.normal(0.1/jnp.sqrt(N_id2),2.5 ,sample_shape = (1,))\n",
    "focal_effects = sample.normal(0, 1,sample_shape = (1,))\n",
    "target_effects = sample.normal(0, 1,sample_shape = (1,))\n",
    "sr_raw = sample.normal(1,sample_shape = (N_id2, 2))\n",
    "sr_sigma = sample.exponential(1,sample_shape = (2,))\n",
    "sr_L = sample.lkjcholesky(2,2)\n",
    "focal_individual_predictors2 = focal_individual_predictors[0:N_id2]\n",
    "target_individual_predictors2 = target_individual_predictors[0:N_id2]\n",
    "\n",
    "X = apply_row_dotproduct(diag_pre_multiply(sr_sigma, sr_L),  sr_raw)\n",
    "\n",
    "terms = jnp.stack([apply_row_dotproduct(focal_effects, focal_individual_predictors2)[:,0],\n",
    "                   apply_row_dotproduct(target_effects, target_individual_predictors2)[:,0]], axis = -1)\n",
    "sr = terms + X\n",
    "backup = sr\n",
    "sr = vec_node_to_edgle(sr)\n",
    "\n",
    "dyad_effects = sample.normal(0,1, sample_shape= (1,))\n",
    "result_kin2 = mat_to_edgl(Kinship[0:N_id2, 0:N_id2])\n",
    "terms2 = dyad_effects * result_kin2\n",
    "dr_raw =  sample.normal(0,1, sample_shape=(terms2.shape[0],2))\n",
    "dr_sigma = sample.exponential(1, sample_shape=(1,))\n",
    "dr_L =sample.lkjcholesky( 2, 2)\n",
    "X2 = jnp.repeat(dr_sigma,2) * apply_row_dotproduct(dr_L, dr_raw)\n",
    "dr = X2 + terms2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block\n",
    "B = sample.normal(0.1/jnp.sqrt(N_id),2.5 ,sample_shape = (1,))\n",
    "\n",
    "# SR term\n",
    "focal_effects = sample.normal(0, 1,sample_shape = (1,)) # size adapted to the number of variables\n",
    "target_effects = sample.normal(0, 1,sample_shape = (1,))# size adapted to the number of variables\n",
    "sr_raw = sample.normal(1,sample_shape = (N_id, 2))\n",
    "sr_sigma = sample.exponential(1,sample_shape = (2,))\n",
    "sr_L = sample.lkjcholesky(2,2)\n",
    "\n",
    "## SR term computation\n",
    "X = apply_row_dotproduct(diag_pre_multiply(sr_sigma, sr_L),sr_raw)\n",
    "terms = jnp.stack([apply_row_dotproduct(focal_effects, focal_individual_predictors)[:,0],\n",
    "               apply_row_dotproduct(target_effects, target_individual_predictors)[:,0]], axis = -1)\n",
    "sr = terms + X\n",
    "sr = vec_node_to_edgle(sr)\n",
    "\n",
    "# Dyadic term\n",
    "dyad_effects = sample.normal(0,1, sample_shape= (1,))\n",
    "terms2 = dyad_effects *  result_kin # if multiple dyadic effect this is false and require dot prod\n",
    "\n",
    "dr_raw =  sample.normal(0,1, sample_shape=(terms2.shape[0],2))\n",
    "dr_sigma = sample.exponential(1, sample_shape=(1,))\n",
    "dr_L =sample.lkjcholesky( 2, 2)\n",
    "X2 = jnp.repeat(dr_sigma,2) * apply_row_dotproduct(dr_L, dr_raw)\n",
    "dr = X2 + terms2 \n",
    "terms2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sr terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = jnp.zeros((N_id2, 2))\n",
    "for i in range(0, N_id):\n",
    "    sr1 = jnp.dot(focal_effects, focal_individual_predictors[i])\n",
    "    sr2 = jnp.dot(target_effects, target_individual_predictors[i])\n",
    "    t = jnp.dot(diag_pre_multiply(sr_sigma, sr_L), sr_raw[i, :])\n",
    "    sr = sr.at[i].set(t + jnp.array([sr1, sr2])[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = apply_row_dotproduct(diag_pre_multiply(sr_sigma, sr_L),sr_raw)\n",
    "terms = jnp.stack([apply_row_dotproduct(focal_effects, focal_individual_predictors)[:,0],\n",
    "               apply_row_dotproduct(target_effects, target_individual_predictors)[:,0]], axis = -1)\n",
    "sr2 = terms + X\n",
    "jnp.array_equal(sr, sr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr =  jnp.zeros_like(Kinship)\n",
    "for i in range(0, (N_id-1)):\n",
    "    for j in range((i+1), N_id):\n",
    "        sr1 = dr_raw[i,j]\n",
    "        sr2 = dr_raw[j,i]\n",
    "        scrap = jnp.array([sr1, sr2])\n",
    "        print(scrap)\n",
    "        t = jnp.dot(jnp.repeat(dr_sigma, 2), dr_L * scrap)        \n",
    "        dr = dr.at[i,j].set((t[1] + jnp.dot(dyad_effects, Kinship[i, j]))[0])\n",
    "        dr = dr.at[i,j].set((t[2] + jnp.dot(dyad_effects, Kinship[j, i])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = jnp.zeros_like(Kinship)\n",
    "for  i in range(1,N_id) :\n",
    "    for  j in range(1,N_id)  :\n",
    "        likelihood  = likelihood.at[i,j].set( B[0] + sr[i,1] + sr[j,2] + dr[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [03:39<00:00,  4.55it/s, 1023 steps of size 4.98e-03. acc. prob=0.91]\n"
     ]
    }
   ],
   "source": [
    "# Building model and sampling it ------------------\n",
    "d_s, d_r = prerpare_dyadic_effect(Kinship)\n",
    "def model(N_id, result_outcomes,d_s, d_r, focal_individual_predictors, target_individual_predictors, outcome_mode, exposure):\n",
    "    # Block ---------------------------------------\n",
    "    B = dist.normal('block', logit(0.1/jnp.sqrt(N_id)), 2.5, sample_shape=[1,])\n",
    "\n",
    "    ## SR ---------------------------------------\n",
    "    sr_terms, focal_effects, target_effects = nodes_terms(1, \n",
    "                                                          focal_individual_predictors, \n",
    "                                                          target_individual_predictors)\n",
    "    sr_rf, sr_raw, sr_sigma, sr_L = nodes_random_effects(sr_terms.shape[0])\n",
    "\n",
    "    sr = vec_node_to_edgle(sr_terms + sr_rf)\n",
    "  \n",
    "    # Dyadic--------------------------------------  \n",
    "    dr_terms, dyad_effects = dyadic_terms(d_s, d_r)\n",
    "    rf, dr_raw, dr_sigma, dr_L = dyadic_random_effects(dr_terms.shape[0])\n",
    "    dr = dr_terms + rf\n",
    "\n",
    "    # Likelihood\n",
    "    if outcome_mode == 1:\n",
    "        lk('Y', Poisson(B[0] + sr + dr), obs=result_outcomes)\n",
    "\n",
    "    elif outcome_mode == 2:\n",
    "        lk('Y', Binomial(total_count = exposure, logits= B[0] + sr + dr), obs=result_outcomes)\n",
    "        \n",
    "    elif outcome_mode == 3:\n",
    "        lk('Y', Poisson(jnp.exp(B[0] + sr + dr)), obs=result_outcomes)\n",
    "\n",
    "dat = dict(\n",
    "    N_id = N_id,\n",
    "    result_outcomes = result_outcomes,\n",
    "    d_s = d_s, d_r = d_r,\n",
    "    focal_individual_predictors = focal_individual_predictors,\n",
    "    target_individual_predictors = target_individual_predictors,\n",
    "    outcome_mode = int(3),\n",
    "    exposure = mat_to_edgl(exposure)\n",
    ")\n",
    "m = MCMC(NUTS(model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PjitFunction of <function edgl_to_mat at 0x7f0f9817bbe0>>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgl_to_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outcomes'][:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_raw =  sample.normal(0, 1, sample_shape=(int(N_id*(N_id-1)/2), 2))\n",
    "edgl_to_mat(sr_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[  0,   0, 183, ...,   0,   0,  90],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  4,   1,   0, ...,   0,   0,   0],\n",
       "       [  0, 153,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.at[jnp.diag_indices(output.shape[0])].set(jnp.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m N_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcomes\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mat[jnp\u001b[38;5;241m.\u001b[39mdiag_indices(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\u001b[38;5;241m.\u001b[39mset(\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m jnp\u001b[38;5;241m.\u001b[39mdiag(output)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "N_id = 100\n",
    "output = data['outcomes'][:,:,0]\n",
    "output = output.at[jnp.diag_indices(output.shape[0])].set(jnp.nan())\n",
    "output.at[jnp.diag_indices(4)].set(jnp.nan)\n",
    "jnp.diag(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integer scalar arrays can be converted to a scalar index.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtm\u001b[39;00m\n\u001b[1;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcomes\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mat[\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m]\u001b[38;5;241m.\u001b[39mset(jnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(N_id, result_outcomes):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# sr-----------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     sr_raw \u001b[38;5;241m=\u001b[39m  dist\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msr_raw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, sample_shape\u001b[38;5;241m=\u001b[39m(N_id, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3506\u001b[0m, in \u001b[0;36mdiag_indices\u001b[0;34m(n, ndim)\u001b[0m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mimplements(np\u001b[38;5;241m.\u001b[39mdiag_indices)\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiag_indices\u001b[39m(n: \u001b[38;5;28mint\u001b[39m, ndim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Array, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m-> 3506\u001b[0m   n \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcrete_or_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m argument of jnp.diag_indices()\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3507\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mconcrete_or_error(operator\u001b[38;5;241m.\u001b[39mindex, ndim, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument of jnp.diag_indices()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:1494\u001b[0m, in \u001b[0;36mconcrete_or_error\u001b[0;34m(force, val, context)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConcretizationTypeError(val, context)\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1494\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/array.py:283\u001b[0m, in \u001b[0;36mArrayImpl.__index__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__index__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m   \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_integer_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:616\u001b[0m, in \u001b[0;36mcheck_integer_conversion\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_integer_conversion\u001b[39m(arr: Array):\n\u001b[1;32m    615\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly integer scalar arrays can be converted to a scalar index.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integer scalar arrays can be converted to a scalar index."
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "from main import *\n",
    "from functools import partial\n",
    "import time as tm\n",
    "\n",
    "output = data['outcomes'][:,:,0]\n",
    "output = output.at[jnp.diag_indices(output)].set(jnp.nan)\n",
    "\n",
    "def model(N_id, result_outcomes):\n",
    "    # sr-----------------------------------------------------------------------------------\n",
    "    sr_raw =  dist.normal('sr_raw', 0, 1, sample_shape=(N_id, 2))\n",
    "    sr_sigma =  dist.exponential('sr_sigma', 1, sample_shape= (2,))\n",
    "    sr_L = dist.lkjcholesky('sr_L', 2, 4)\n",
    "    rf_sr = vmap(lambda x: random_centered(sr_sigma, sr_L, x))(sr_raw)\n",
    "    rf_receiver = jnp.tile(rf_sr[:,0], (N_id,1))\n",
    "    rf_sender = jnp.tile(rf_sr[:,1], (N_id, 1))\n",
    "    \n",
    "    # dr -----------------------------------------------------------------------------------\n",
    "    dr_raw =  dist.normal('dr_raw', 0, 1, sample_shape=(int(N_id*(N_id-1)/2), 2))\n",
    "    dr_sigma =  dist.exponential('dr_sigma', 1, sample_shape= (2,))\n",
    "    dr_L = dist.lkjcholesky('dr_L', 2, 4)\n",
    "    rf_dr = vmap(lambda x: random_centered(dr_sigma, dr_L, x))(dr_raw)\n",
    "\n",
    "\n",
    "    lk('Y', Poisson(jnp.exp(1 +  rf_receiver + rf_sender + edgl_to_mat(rf_dr, N_id))), obs=result_outcomes)\n",
    "\n",
    "dat = dict(\n",
    "    N_id = N_id,\n",
    "    result_outcomes = output,\n",
    ")\n",
    "\n",
    "m = MCMC(NUTS(model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAN comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ones_column = np.ones((len(data[\"individual_predictors\"]), 1))\n",
    "\n",
    "# Reshape the vector to be a column vector\n",
    "vector_column = data[\"individual_predictors\"].reshape(-1, 1)\n",
    "\n",
    "# Concatenate the two columns horizontally\n",
    "focal_set = np.concatenate((ones_column, vector_column), axis=1)\n",
    "\n",
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "print(Kinship.shape)\n",
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship'])\n",
    "# Get the shape of the existing array\n",
    "shape = Kinship.shape\n",
    "\n",
    "# Create a new array with the same shape, filled with 1's\n",
    "ones_array = jnp.ones(shape, dtype=int)\n",
    "ones_array\n",
    "\n",
    "d = [\n",
    "    [-3.00, 1.5],\n",
    "    [ 3.00, 1.5],\n",
    "    [-1.50, 1.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.10, 2.5],\n",
    "    [ 0.01, 2.5],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 0.00, 1.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 1.00, 0.0],\n",
    "    [ 2.50, 0.0],\n",
    "    [ 2.50, 0.0],\n",
    "    [ 1.50, 0.0],\n",
    "    [ 3.00, 1.0],\n",
    "    [ 2.00, 0.0],\n",
    "    [ 3.00, 12.0]\n",
    "]\n",
    "\n",
    "# Convert the list to a JAX array\n",
    "priors = jnp.array(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "stan_code = \"\"\"\n",
    "data{                                           \n",
    "    int N_id;                                                                                                            \n",
    "    int N_responses;        \n",
    "\n",
    "    array[3] int N_params;                                          \n",
    "                                             \n",
    "    array[N_id,N_id,N_responses] int outcomes;  \n",
    "    array[N_id,N_id,N_responses] int exposure;                              \n",
    "\n",
    "    matrix[N_id, N_params[1]] focal_set;\n",
    "    matrix[N_id, N_params[2]] target_set;\n",
    "\n",
    "    array[N_id, N_id, N_params[3]] real dyad_set;\n",
    "\n",
    "    matrix [22, 2] priors;\n",
    "    \n",
    "    int export_network;\n",
    "    int outcome_mode;                           \n",
    "}\n",
    "\n",
    "transformed data{\n",
    " matrix[N_id, N_params[1]-1] focal_individual_predictors; \n",
    " matrix[N_id, N_params[2]-1] target_individual_predictors; \n",
    "\n",
    " array[N_id, N_id, N_params[3]-1] real dyad_individual_predictors; \n",
    "\n",
    "//# Make pruned data\n",
    "  \n",
    "  if(N_params[1]>1){\n",
    "  for(i in 2:N_params[1]){\n",
    "  focal_individual_predictors[ , i-1] = focal_set[,i];  \n",
    "   }}\n",
    "\n",
    "  if(N_params[2]>1){\n",
    "  for(i in 2:N_params[2]){\n",
    "  target_individual_predictors[ , i-1] = target_set[,i];  \n",
    "   }}\n",
    "\n",
    "  if(N_params[3]>1){\n",
    "  for(i in 2:N_params[3]){\n",
    "  dyad_individual_predictors[ , , i-1] = dyad_set[,,i];  \n",
    "   }}\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    //########################################################### Latent Netowrk\n",
    "    matrix[1,1] B;\n",
    "\n",
    "    vector<lower=0>[2] sr_sigma;  //# Variation of sender-receiver effects\n",
    "    cholesky_factor_corr[2] sr_L;\n",
    "    array[N_id] vector[2] sr_raw;\n",
    "\n",
    "    real<lower=0> dr_sigma;     //# Variation of dyadic effects\n",
    "    cholesky_factor_corr[2] dr_L;\n",
    "    matrix[N_id, N_id] dr_raw;\n",
    "\n",
    "    //# Effects of covariate\n",
    "    vector[N_params[1]-1] focal_effects;\n",
    "    vector[N_params[2]-1] target_effects;\n",
    "    vector[N_params[3]-1] dyad_effects;  \n",
    "}\n",
    "\n",
    "model{\n",
    "  array[N_id] vector[2] sr;\n",
    "  matrix[N_id, N_id] dr;\n",
    "\n",
    "  vector[2] scrap;\n",
    "\n",
    "    //# Priors on effects of covariates\n",
    "     focal_effects ~ normal(priors[12,1], priors[12,2]);\n",
    "     target_effects ~ normal(priors[13,1], priors[13,2]);\n",
    "     dyad_effects ~ normal(priors[14,1], priors[14,2]);\n",
    "\n",
    "    //# Sender-receiver priors for social relations model\n",
    "    for(i in 1:N_id)\n",
    "    sr_raw[i] ~ normal(0,1);\n",
    "\n",
    "    sr_sigma ~ exponential(priors[15,1]);    \n",
    "    sr_L ~ lkj_corr_cholesky(priors[17,1]);\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     vector[2] sr_terms;\n",
    "\n",
    "     sr_terms[1] = dot_product(focal_effects,  to_vector(focal_individual_predictors[i]));\n",
    "     sr_terms[2] = dot_product(target_effects,  to_vector(target_individual_predictors[i]));  \n",
    "\n",
    "     sr[i] = diag_pre_multiply(sr_sigma, sr_L) * sr_raw[i] + sr_terms;\n",
    "     }\n",
    "\n",
    "    //# Dyadic priors for social relations model\n",
    "    to_vector(dr_raw) ~ normal(0,1);\n",
    "    dr_sigma ~ exponential(priors[16,1]);\n",
    "    dr_L ~ lkj_corr_cholesky(priors[18,1]);\n",
    "\n",
    "    for(i in 1:(N_id-1)){\n",
    "    for(j in (i+1):N_id){\n",
    "     scrap[1] = dr_raw[i,j];\n",
    "     scrap[2] = dr_raw[j,i];\n",
    "     scrap = rep_vector(dr_sigma, 2) .* (dr_L*scrap);\n",
    "     dr[i,j] = scrap[1] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[i, j, ]));\n",
    "     dr[j,i] = scrap[2] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[j, i, ]));\n",
    "     }\n",
    "     }\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     dr[i,i] = -99; //# ignore this :)\n",
    "    }\n",
    "\n",
    "    //# priors for \n",
    "    B[1,1] ~ normal(logit(priors[10,1]/sqrt(N_id)), priors[10,2]);\n",
    "\n",
    "\n",
    "    //# likelihood\n",
    "    for ( i in 1:N_id ) {\n",
    "     for ( j in 1:N_id ) {\n",
    "       if ( i != j ) {\n",
    "\n",
    "      if(outcome_mode==1){\n",
    "      outcomes[i,j,1] ~ bernoulli_logit(B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "      if(outcome_mode==2){\n",
    "      outcomes[i,j,1] ~ binomial_logit(exposure[i,j,1], B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "      if(outcome_mode==3){\n",
    "      outcomes[i,j,1] ~ poisson_log(B[1,1] + sr[i,1] + sr[j,2] + dr[i,j]);  //# Then model the outcomes\n",
    "       }\n",
    "\n",
    "       }\n",
    "      }\n",
    "     }\n",
    "\n",
    "\n",
    " }\n",
    "\n",
    "\n",
    "generated quantities{\n",
    "    //# compute posterior prob of each network tie\n",
    "    matrix[N_id*export_network, N_id*export_network] p;\n",
    "    array[N_id*export_network] vector[2*export_network] sr;\n",
    "    matrix[N_id*export_network, N_id*export_network] dr;\n",
    " \n",
    "    if(export_network==1){                \n",
    "     vector[2] terms;\n",
    "     int tie;\n",
    "     vector[2] scrap;\n",
    "            \n",
    "    for(i in 1:N_id){\n",
    "     vector[2] sr_terms;\n",
    "\n",
    "     sr_terms[1] = dot_product(focal_effects,  to_vector(focal_individual_predictors[i]));\n",
    "     sr_terms[2] = dot_product(target_effects,  to_vector(target_individual_predictors[i]));  \n",
    "\n",
    "     sr[i] = diag_pre_multiply(sr_sigma, sr_L) * sr_raw[i] + sr_terms;\n",
    "     }\n",
    "\n",
    "    for(i in 1:(N_id-1)){\n",
    "    for(j in (i+1):N_id){\n",
    "     scrap[1] = dr_raw[i,j];\n",
    "     scrap[2] = dr_raw[j,i];\n",
    "     scrap = rep_vector(dr_sigma, 2) .* (dr_L*scrap);\n",
    "     dr[i,j] = scrap[1] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[i, j, ])) + B[1, 1];\n",
    "     dr[j,i] = scrap[2] + dot_product(dyad_effects,  to_vector(dyad_individual_predictors[j, i, ])) + B[1, 1];\n",
    "    }\n",
    "    }\n",
    "\n",
    "    for(i in 1:N_id){\n",
    "     dr[i,i] = -99; //# ignore this :)\n",
    "    }\n",
    "\n",
    "\n",
    "    for ( i in 1:N_id ) {\n",
    "        for ( j in 1:N_id ) {\n",
    "            if ( i != j ) {\n",
    "      // consider each possible state of true tie and compute prob of data\n",
    "      if(outcome_mode==1){\n",
    "       p[i,j] = inv_logit( sr[i,1] + sr[j,2] + dr[i,j]);\n",
    "       }\n",
    "      if(outcome_mode==2){\n",
    "       p[i,j] = inv_logit( sr[i,1] + sr[j,2] + dr[i,j]);\n",
    "       }\n",
    "      if(outcome_mode==3){\n",
    "       p[i,j] = exp(sr[i,1] + sr[j,2] + dr[i,j]);  \n",
    "       }\n",
    "            }\n",
    "        }//j\n",
    "    }//i\n",
    "\n",
    "  for ( i in 1:N_id ) {\n",
    "   p[i,i] = 0; \n",
    "   }\n",
    " }\n",
    "}\n",
    "\"\"\"\n",
    "d = {\n",
    "    \"N_id\": int(100), # N id\n",
    "    \"N_responses\" : int(1), #outcome\n",
    "    \"N_params\": np.array([2,2,2]),\n",
    "\n",
    "\n",
    "    \"outcomes\": np.array(data[\"outcomes\"]),\n",
    "    \"exposure\":  np.array(data[\"exposure\"]),\n",
    "\n",
    "    \"focal_set\":  np.array(focal_set),\n",
    "    \"target_set\":  np.array(focal_set),\n",
    "\n",
    "    \"dyad_set\":  np.array(jnp.stack((ones_array, Kinship), axis=2)),\n",
    "    \"priors\":  np.array(priors),\n",
    "    \"outcome_mode\": int(3),\n",
    "    \"export_network\": int(0),\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = d)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[-3.3090353]]\n",
      "STRAND:\n",
      "-3.749545834690872\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['block']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['B.1.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[2.1194768 2.194276 ]]\n",
      "STRAND:\n",
      "2.4054208987202457\n",
      "1.6809626960648432\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['sr_sigma']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['sr_sigma.1'].mean())\n",
    "print(df['sr_sigma.2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[0.81983185]]\n",
      "STRAND:\n",
      "0.6006863165962325\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['target_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['target_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[[1.0385544]]\n",
      "STRAND:\n",
      "1.2256935526088442\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['focal_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['focal_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI:\n",
      "[0.92806756]\n",
      "STRAND:\n",
      "0.8799381260413195\n"
     ]
    }
   ],
   "source": [
    "print('BI:')\n",
    "print(jnp.mean(jnp.array(res['posterior']['dyad_effects']), axis = 1))\n",
    "print('STRAND:')\n",
    "print(df['dyad_effects.1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "install.packages(\"githubinstall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BISONR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Multinomial with centered random factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "    \n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4146024105,  967050713], dtype=uint32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init_key = jnp.array(init_key)\n",
    "init_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import os\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, set_matplotlib_formats\n",
    "from matplotlib.patches import Ellipse, transforms\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(30)\n",
    "\n",
    "\n",
    "# Simulation ---------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "Y2 = jnp.array(Y2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:01<00:00, 1386.84it/s, 1023 steps of size 1.50e-07. acc. prob=0.79]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building model and sampling it ------------------\n",
    "def model(NY, NV, Y2):\n",
    "    means =  numpyro.sample('means', numpyro.distributions.Normal(0,1).expand([NY]))\n",
    "    offset =  numpyro.sample('offset', numpyro.distributions.Normal(0,1).expand([NV,1]))\n",
    "    sigma =  numpyro.sample('sigma', numpyro.distributions.Exponential(1).expand([NY])) \n",
    "    tmp = jnp.tile(means, (NV, 1)).reshape(NV,NY)  \n",
    "    mu_l = tmp + offset \n",
    "    numpyro.sample('Y2', numpyro.distributions.Normal(mu_l, jnp.tile(sigma, [NV, 1])), obs=Y2)\n",
    "\n",
    "dat = dict(\n",
    "    NY = NY,\n",
    "    NV = NV,\n",
    "    Y2 = Y2\n",
    ")\n",
    "m = MCMC(NUTS(model, init_strategy = numpyro.infer.init_to_median()), num_warmup=1000, num_samples=1000, num_chains=1)\n",
    "m.run(random.PRNGKey(0), extra_fields=[\"diverging\"], **dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 1000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>means[0]</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[1]</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[2]</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[3]</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[0, 0]</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[1, 0]</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[2, 0]</th>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[3, 0]</th>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.077</td>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[4, 0]</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[5, 0]</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[6, 0]</th>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[7, 0]</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[1]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[2]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[3]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean   sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "means[0]      0.519  0.0   0.519    0.519        0.0      0.0    1000.0   \n",
       "means[1]      0.191  0.0   0.191    0.191        0.0      0.0    1000.0   \n",
       "means[2]      0.657  0.0   0.657    0.657        0.0      0.0    1000.0   \n",
       "means[3]     -0.613  0.0  -0.613   -0.613        0.0      0.0    1000.0   \n",
       "offset[0, 0]  0.530  0.0   0.530    0.530        0.0      0.0    1000.0   \n",
       "offset[1, 0]  0.812  0.0   0.812    0.812        0.0      0.0    1000.0   \n",
       "offset[2, 0] -0.366  0.0  -0.366   -0.366        0.0      0.0    1000.0   \n",
       "offset[3, 0]  2.077  0.0   2.077    2.077        0.0      0.0    1000.0   \n",
       "offset[4, 0]  0.988  0.0   0.988    0.988        0.0      0.0    1000.0   \n",
       "offset[5, 0]  0.342  0.0   0.342    0.342        0.0      0.0    1000.0   \n",
       "offset[6, 0]  1.198  0.0   1.198    1.198        0.0      0.0    1000.0   \n",
       "offset[7, 0]  0.697  0.0   0.697    0.697        0.0      0.0    1000.0   \n",
       "sigma[0]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[1]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[2]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[3]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "\n",
       "              ess_tail  r_hat  \n",
       "means[0]        1000.0    NaN  \n",
       "means[1]        1000.0    NaN  \n",
       "means[2]        1000.0    NaN  \n",
       "means[3]        1000.0    NaN  \n",
       "offset[0, 0]    1000.0    NaN  \n",
       "offset[1, 0]    1000.0    NaN  \n",
       "offset[2, 0]    1000.0    NaN  \n",
       "offset[3, 0]    1000.0    NaN  \n",
       "offset[4, 0]    1000.0    NaN  \n",
       "offset[5, 0]    1000.0    NaN  \n",
       "offset[6, 0]    1000.0    NaN  \n",
       "offset[7, 0]    1000.0    NaN  \n",
       "sigma[0]        1000.0    NaN  \n",
       "sigma[1]        1000.0    NaN  \n",
       "sigma[2]        1000.0    NaN  \n",
       "sigma[3]        1000.0    NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arviz as az\n",
    "data = az.from_numpyro(m)\n",
    "az.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28912305, 0.96183663, 1.42779941, 0.15728591])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random centered effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.7328625  0.13674371 0.13039377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.66280484 0.1774538  0.15974137]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    print(L_individual.shape)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = ((Sigma_individual[..., None] * L_individual) @ z_individual)\n",
    "    print(alpha.shape)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1, chain_method='vectorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bi' object has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39marray(a))) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumpypro estimation:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bi' object has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.006054 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 60.54 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[26] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[89] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: log1m: x is 1, but must be less than or equal to 1.000000 (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 12, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 432.2593 seconds\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#################################### Pustan Model  #############################\n",
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "tmp = dat\n",
    "tmp['y'] = np.array(tmp['y'])\n",
    "tmp['i_ID'] = np.array(tmp['i_ID']+1)\n",
    "tmp['ni'] = tmp['ni']\n",
    "tmp['K'] = tmp['K']\n",
    "tmp['N'] = int(N)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "    int<lower=0>  N;             // number of observations\n",
    "    int<lower=0>  K;             // number of occupations\n",
    "    int ni;                     // NUmber of Unique Individauls\n",
    "    array[N, K] int y;           // array of observed occupation indicators\n",
    "    array[N]int<lower=0>  i_ID;     // village indicator for each individual\n",
    "}\n",
    "parameters {\n",
    "    vector[K] a;                    // intercept for each occupation\n",
    "    matrix[ni, K]  z_individual;    // raw random effect for household \n",
    "    cholesky_factor_corr[ni] L_individual; // Cholesky factor for \n",
    "    vector<lower=0>[ni] Sigma_individual;\n",
    "\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[ni, K] b_individual;\n",
    "    b_individual = diag_pre_multiply(Sigma_individual, L_individual) * z_individual;\n",
    "}\n",
    "model{\n",
    "    array[N] vector[K] p;\n",
    "    matrix[N, K] random_effects;\n",
    "    to_vector(a) ~ normal(0, 1);\n",
    "    L_individual ~   lkj_corr_cholesky(2);\n",
    "    Sigma_individual ~ exponential(1);\n",
    "    to_vector(z_individual) ~ normal(0, 1);\n",
    "    // Likelihood for\n",
    "    for (k in 1:K) {\n",
    "        for (i in 1:N) {\n",
    "          random_effects[i, k] = b_individual[i_ID[i], k];\n",
    "          p[i,k] =  a[k] + random_effects[i, k];\n",
    "      }\n",
    "    }\n",
    "    for (i in 1:(N)) {\n",
    "        y[i,] ~ dirichlet_multinomial(exp(p[i,]));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = tmp)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500, init = [{'L_individual': np.zeros((tmp['ni'], tmp['ni']))}])\n",
    "end = tm.time()    \n",
    "#df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Estimation Multinomial:\n",
      "[0.79368174 0.11202765 0.0942907 ]\n",
      "Estimation DirichletMultinomial:\n",
      "Pytstan estimation\n",
      "[0.7914235  0.11247264 0.09610377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(np.array([3,1,1])))) \n",
    "print('Estimation Multinomial:')\n",
    "post = m.sampler.get_samples()\n",
    "print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "print('Estimation DirichletMultinomial:')\n",
    "#post = m2.sampler.get_samples()\n",
    "#print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "df = fit.to_frame()\n",
    "print('Pytstan estimation')\n",
    "print(jax.nn.softmax(jnp.array([df['a.1'].mean(),df['a.2'].mean(),df['a.3'].mean()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mutils import Mgaussian, cov_GPL2\n",
    "gaus = Mgaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.uniform(-4,4, sample_shape=(100,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f688fb5e0>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.arange(0,100), jnp.sort(sample.uniform(-4,4, sample_shape=(100,))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[6.95772032e-05, 7.05757775e-05, 7.08340522e-05, 1.01038408e-04,\n",
       "        1.37485302e-04, 2.52640137e-04, 4.07964544e-04, 4.44900506e-04,\n",
       "        7.93327461e-04, 8.72423814e-04, 1.12472521e-03, 2.72971159e-03,\n",
       "        4.08034120e-03, 4.31750994e-03, 1.03412867e-02, 1.08558796e-02,\n",
       "        1.10393865e-02, 1.28583014e-02, 1.43270334e-02, 1.61640048e-02,\n",
       "        1.88681241e-02, 2.05343813e-02, 2.09783334e-02, 3.93685363e-02,\n",
       "        3.96588631e-02, 6.33478463e-02, 7.07632899e-02, 8.01612437e-02,\n",
       "        9.61879194e-02, 1.01117074e-01, 1.11219764e-01, 1.12579286e-01,\n",
       "        1.15933150e-01, 1.45289272e-01, 2.36076981e-01, 2.36480564e-01,\n",
       "        2.42862463e-01, 3.01742733e-01, 3.19371969e-01, 3.91090930e-01,\n",
       "        3.92093927e-01, 4.12615776e-01, 4.36588585e-01, 4.47528750e-01,\n",
       "        4.65556026e-01, 5.16811371e-01, 5.39710641e-01, 5.44671655e-01,\n",
       "        5.63465476e-01, 5.76749384e-01, 5.84535241e-01, 6.14403367e-01,\n",
       "        6.66804552e-01, 6.89325154e-01, 6.97346747e-01, 7.38322258e-01,\n",
       "        7.58048773e-01, 8.05146337e-01, 8.09990883e-01, 8.12245846e-01,\n",
       "        8.15193772e-01, 8.45978379e-01, 8.79453301e-01, 8.82207811e-01,\n",
       "        8.92019153e-01, 9.13788080e-01, 9.22370374e-01, 9.32368994e-01,\n",
       "        9.32909727e-01, 9.52199399e-01, 9.52801287e-01, 9.65356529e-01,\n",
       "        9.69953179e-01, 9.70696151e-01, 9.71720934e-01, 9.74734724e-01,\n",
       "        9.89800394e-01, 9.92271543e-01, 9.93310988e-01, 9.93890345e-01,\n",
       "        9.96312499e-01, 9.96454775e-01, 9.96596992e-01, 9.96621072e-01,\n",
       "        9.97508347e-01, 9.97612000e-01, 9.97972190e-01, 9.98649836e-01,\n",
       "        9.98774827e-01, 9.98964489e-01, 9.99084175e-01, 9.99806881e-01,\n",
       "        9.99833941e-01, 9.99848008e-01, 9.99864638e-01, 9.99880135e-01,\n",
       "        9.99889314e-01, 9.99890327e-01, 9.99940813e-01, 9.99957085e-01]],      dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f439fac20>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = sample.uniform(-4,4, sample_shape=(100,))\n",
    "raw  = jnp.sort(raw)\n",
    "sequence = jnp.array([i for i in range(1, 11) for _ in range(10)])\n",
    "unique = jnp.unique(jnp.array(sequence))\n",
    "result = []\n",
    "\n",
    "for i in range(0,len(unique)):  \n",
    "    result.append(jnp.mean(raw[jnp.where(sequence==(i + 1))], axis = 0))\n",
    "\n",
    "Dmat = gaus.distance_matrix(jnp.array(result))\n",
    "cdf_value = norm.cdf(raw , loc=0, scale=1)# to plot for after\n",
    "plt.plot(jnp.arange(0, 100), cdf_value)\n",
    "error = sample.normal(0, 0.1, sample_shape=(100,))\n",
    "y = cdf_value + error\n",
    "plt.plot(jnp.arange(0, 100), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [03:53<00:00,  4.29it/s, 191 steps of size 2.40e-02. acc. prob=0.92]\n"
     ]
    }
   ],
   "source": [
    "def gaus_model(Dmat, y ,sequence):\n",
    "    a = dist.normal('a', 0,1)\n",
    "    sigma = dist.exponential('s', 1)\n",
    "    etasq = dist.exponential(\"etasq\",2)\n",
    "    rhosq = dist.exponential(\"rhosq\",0.5)\n",
    "    sigmaq = dist.exponential(\"sigmaq\",2)\n",
    "\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, sigmaq)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = dist.normal('z', 0, 1, sample_shape= [10])\n",
    "    k = numpyro.deterministic(\"k\", (L_SIGMA @ z[..., None])[..., 0])\n",
    "    \n",
    "    mu = a + k[sequence]\n",
    "\n",
    "    lk('Y', Normal(mu, sigma), obs=y)\n",
    "\n",
    "dat = dict(\n",
    "    Dmat = Dmat,\n",
    "    y = y,\n",
    "    sequence = sequence - 1 \n",
    ")\n",
    "\n",
    "m = MCMC(NUTS(gaus_model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.27396825,  0.15240066, -0.08370425, -0.5535025 , -0.4566877 ,\n",
       "       -0.24475469, -0.5314296 , -0.5517882 ,  0.382401  ,  0.52221215],      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f41fe78b0>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.arange(0,10), jnp.mean(jnp.array(res['posterior']['k'][0,:,:]), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f686a8f40>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.arange(0,y.shape[0]), y)\n",
    "\n",
    "plt.plot(jnp.arange(0,cdf_value.shape[1]), cdf_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f7e2bb5b0>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.arange(0,10), jnp.mean(jnp.array(res['posterior']['k'][0,:,:]), axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine latent, random and gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent + random = random + latent[village[i]] with village being village ID\n",
    "# gaussian simulation \n",
    "# 1. non linear function to generate gaussian proces for each parameters\n",
    "# model 2 = random + latent[village[i]] + gaussian_process\n",
    "# model 3  = model 2 + interaction effect\n",
    "#interaction effect = non linear function where input is hhmembers[i]*offsets[vilage[i]] with new coefficients params\n",
    "# Within model we need to change offset ouput as an integer so we do bxi*hhmembers[i]*offset[v_ID[i]]+ bxIsq*(hhmembers[i]*offset[v_ID[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    #individual \n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 50)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha_individual = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "\n",
    "    #household \n",
    "    Sigma_household = exponential('Sigma_household', [ni], 1 )\n",
    "    L_household = lkjcholesky('L_household', [], ni, 50)\n",
    "    z_household = normal('z_household', [ni,K], 0, 1)\n",
    "    alpha_household = random_centered2(Sigma_household, L_household, z_household)\n",
    "\n",
    "    #village \n",
    "    Sigma_village = exponential('Sigma_village', [ni], 1 )\n",
    "    L_village = lkjcholesky('L_village', [], ni, 50)\n",
    "    z_village = normal('z_village', [ni,K], 0, 1)\n",
    "    alpha_village = random_centered2(Sigma_village, L_village, z_village)\n",
    "\n",
    "    #LK\n",
    "    random_factors = alpha_individual[i_ID] + alpha_household[i_ID] + alpha_village[i_ID]\n",
    "    numpyro.sample(\"y\", dist.DirichletMultinomial(a + random_factors[i_ID], int(12083)), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test parallelized random centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ni' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[487], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m init_key, sample_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;28mint\u001b[39m(r\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10000000\u001b[39m))))\n\u001b[1;32m      2\u001b[0m init_key \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(init_key)\n\u001b[0;32m----> 4\u001b[0m Sigma_i \u001b[38;5;241m=\u001b[39m Exponential(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msample(init_key, [\u001b[43mni\u001b[49m,])\n\u001b[1;32m      5\u001b[0m L_i\u001b[38;5;241m=\u001b[39m LKJCholesky(ni, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msample(init_key, [])\n\u001b[1;32m      6\u001b[0m z_i\u001b[38;5;241m=\u001b[39m Normal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msample([ni,K])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ni' is not defined"
     ]
    }
   ],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "Sigma_i = Exponential(1).sample(init_key, [ni,])\n",
    "L_i= LKJCholesky(ni, 1).sample(init_key, [])\n",
    "z_i= Normal(0, 1).sample([ni,K])\n",
    "alpha = random_centered(Sigma_i, L_i, z_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$Sigma_i = exponential(1)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import display, Latex\n",
    "greek_symbols = {\n",
    "    'alpha': '\\\\alpha',\n",
    "    'beta': '\\\\beta',\n",
    "    'gamma': '\\\\gamma',\n",
    "    'delta': '\\\\delta',\n",
    "    'epsilon': '\\\\epsilon',\n",
    "    'zeta': '\\\\zeta',\n",
    "    'eta': '\\\\eta',\n",
    "    'theta': '\\\\theta',\n",
    "    'iota': '\\\\iota',\n",
    "    'kappa': '\\\\kappa',\n",
    "    'lambda': '\\\\lambda',\n",
    "    'mu': '\\\\mu',\n",
    "    'nu': '\\\\nu',\n",
    "    'xi': '\\\\xi',\n",
    "    'omicron': 'o',  # No direct LaTeX symbol for omicron, using \"o\"\n",
    "    'pi': '\\\\pi',\n",
    "    'rho': '\\\\rho',\n",
    "    'sigma': '\\\\sigma',\n",
    "    'tau': '\\\\tau',\n",
    "    'upsilon': '\\\\upsilon',\n",
    "    'phi': '\\\\phi',\n",
    "    'chi': '\\\\chi',\n",
    "    'psi': '\\\\psi',\n",
    "    'omega': '\\\\omega'\n",
    "}\n",
    "\n",
    "def convert_to_greek(var_name):\n",
    "    # Convert variable name to lowercase for case-insensitive matching\n",
    "    var_name_lower = var_name.lower()\n",
    "    # Check if the variable name has a corresponding Greek symbol\n",
    "    if var_name_lower in greek_symbols:\n",
    "        return greek_symbols[var_name_lower]\n",
    "    else:\n",
    "        return var_name\n",
    "\n",
    "def extract_latex(command):\n",
    "    # Define a regular expression pattern to match the desired parts of the command\n",
    "    pattern = r\"(\\w+)\\s*=\\s*(\\w+)\\([^,]+,\\s*[^,]+,\\s*(.*)\\)\"\n",
    "    match = re.match(pattern, command)\n",
    "    \n",
    "    if match:\n",
    "        var_name = match.group(1)\n",
    "        func_name = match.group(2)\n",
    "        params = match.group(3)\n",
    "        # Convert var_name to Greek symbol if applicable\n",
    "        var_name_latex = convert_to_greek(var_name)\n",
    "        # Construct the desired LaTeX text\n",
    "        latex_text = f\"{var_name_latex} = {func_name}({params})\"\n",
    "        return latex_text\n",
    "    else:\n",
    "        return None\n",
    "# Example usage\n",
    "command = \"Sigma_i = exponential('Sigma_individual', [ni], 1)\"\n",
    "latex_text = extract_latex(command)\n",
    "display(Latex(f'''${latex_text}$'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of concept : function for multiple priors at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('/home/sosa/BI/data/Howell1.csv', sep=';') \n",
    "m.data = m.data[m.data .age > 18]\n",
    "m.data.weight = m.data.weight - m.data.weight.mean()\n",
    "m.data.age = m.data.age - m.data.age.mean()\n",
    "weight = jnp.array(m.data.weight.values)\n",
    "height = jnp.array(m.data.height.values)\n",
    "# TODO: use jax arrays with hugging face package\n",
    "\n",
    "m.data = dict(height = height, weight = weight)\n",
    "\n",
    "def regression_priors():\n",
    "    s = uniform('s', [1], 0, 50)\n",
    "    a = normal('a', [1], 178, 20)\n",
    "    b = normal('b', [1], 0, 1)  \n",
    "    return s, a, b\n",
    "\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s, a, b = regression_priors()\n",
    "    sample(\"y\", Normal(a + b * weight, s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
