{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "jax.local_device_count  16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfpLigth import*\n",
    "import os\n",
    "import re\n",
    "import jax\n",
    "device = 'cpu'\n",
    "if device == 'cpu':\n",
    "    platform = os.getenv(\"JAX_PLATFORM_NAME\", \"cpu\")\n",
    "    jax.config.update(\"jax_platform_name\", platform)\n",
    "    Ncores = os.cpu_count()    \n",
    "    xla_flags = os.getenv(\"XLA_FLAGS\", \"\")\n",
    "    xla_flags = re.sub(r\"--xla_force_host_platform_device_count=\\S+\", \"\", xla_flags).split()\n",
    "    os.environ[\"XLA_FLAGS\"] = \" \".join([\"--xla_force_host_platform_device_count={}\".format(Ncores)] + xla_flags)\n",
    "    jax.config.update(\"jax_platform_name\", platform)\n",
    "    print('jax.local_device_count ',jax.local_device_count(backend=None))\n",
    "elif device == 'gpu':\n",
    "    platform = os.getenv(\"JAX_PLATFORM_NAME\", \"gpu\")\n",
    "    jax.config.update(\"jax_platform_name\", platform)\n",
    "elif device == 'tpu':\n",
    "    platform = os.getenv(\"JAX_PLATFORM_NAME\", \"tpu\")\n",
    "    jax.config.update(\"jax_platform_name\", platform)\n",
    "else:\n",
    "    print(\"platform not handled\")\n",
    "jax.local_device_count(backend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "\n",
    "@partial(jit, static_argnums=(1, 2,))\n",
    "def vec_to_mat(arr, N, K):\n",
    "    return jnp.reshape(arr, (N, K))\n",
    "\n",
    "@jit\n",
    "def jax_LinearOperatorDiag(s, cov):    \n",
    "    def multiply_with_s(a):\n",
    "        return jnp.multiply(a, s)\n",
    "    vectorized_multiply = vmap(multiply_with_s)\n",
    "    return jnp.transpose(vectorized_multiply(cov))\n",
    "import jax.numpy as jnp\n",
    "\n",
    "@jit\n",
    "def diag_pre_multiply(v, m):\n",
    "    return jnp.matmul(jnp.diag(v), m)\n",
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)\n",
    "\n",
    "softmax_fn = vmap(jax.nn.softmax, in_axes=(0,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set tensorflow probability function in global environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "## Get all names defined in the jnp\n",
    "#all_names = dir(tfd)\n",
    "## Create a dictionary with all names\n",
    "#class_dict = {name: getattr(tfd, name) for name in all_names}\n",
    "#\n",
    "## Function to create new functions\n",
    "#def create_new_function(class_obj):\n",
    "#    def new_function(sample_shape=(), *args, **kwargs):\n",
    "#        return tfd.Sample(class_obj(*args, **kwargs), sample_shape)\n",
    "#    return new_function\n",
    "#\n",
    "## Create a Python file and write the functions to it\n",
    "#with open(\"generated_functions.py\", \"w\") as file:\n",
    "#    for key, value in class_dict.items():\n",
    "#        if callable(value):\n",
    "#            try:\n",
    "#                # Create the new function using the class object from class_dict\n",
    "#                func_name = key.lower()\n",
    "#                function_str = f\"def {func_name}(sample_shape=(), *args, **kwargs):\\n\"\n",
    "#                function_str += f\"    return root(tfd.Sample({value.__name__}(*args, **kwargs), sample_shape))\\n\"\n",
    "#                file.write(function_str)\n",
    "#            except Exception as e:\n",
    "#                print(f\"Error creating function for {key}: {e}\")\n",
    "#        else:\n",
    "#            print(f\"Ignoring non-callable object for key {key}: {value}\")\n",
    "#\n",
    "## Now all functions have been written to \"generated_functions.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def index(df, cols = 'all'):\n",
    "    index_map = {}\n",
    "    if cols == 'all':\n",
    "        colCat = list(df.select_dtypes(['object']).columns)    \n",
    "        for a in range(len(colCat)):                \n",
    "            df[\"index_\"+ colCat[a]] =  df.loc[:,colCat[a]].astype(\"category\").cat.codes\n",
    "            df[\"index_\"+ colCat[a]] = df[\"index_\"+ colCat[a]].astype(np.int64)\n",
    "            index_map[colCat[a]] = dict(enumerate(df[colCat[a]].astype(\"category\").cat.categories ) )\n",
    "    else:\n",
    "        if isinstance(cols, list) == False:\n",
    "            cols = [cols]\n",
    "        for a in range(len(cols)):\n",
    "            df[\"index_\"+ cols[a]] =  df.loc[:,cols[a]].astype(\"category\").cat.codes\n",
    "            df[\"index_\"+ cols[a]] = df[\"index_\"+ cols[a]].astype(np.int64)\n",
    "            index_map[cols[a]] = dict(enumerate(df[cols[a]].astype(\"category\").cat.categories ) )\n",
    "    df.columns = df.columns.str.replace('.', '_')\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inspect\n",
    "def tfp_trace_to_arviz(posterior, \n",
    "                       sample_stats,\n",
    "                       var_names=None, \n",
    "                       sample_stats_name=['target_log_prob','log_accept_ratio','has_divergence','energy']):\n",
    "    sample_stats = {k:jnp.transpose(v) for k, v in zip(sample_stats_name, sample_stats)}\n",
    "    trace = {}\n",
    "    for name, samp in zip(var_names, posterior):\n",
    "        if len(samp.shape) == 2:\n",
    "            transposed_shape = [1, 0]\n",
    "        elif len(samp.shape) == 3:\n",
    "            transposed_shape = [1, 0, 2]\n",
    "        else:\n",
    "            transposed_shape = [1, 0, 2, 3]\n",
    "        trace[name] = jnp.transpose(samp, transposed_shape)\n",
    "    trace = az.from_dict(posterior=trace, sample_stats=sample_stats)\n",
    "    return trace\n",
    "\n",
    "\n",
    "\n",
    "def get_distributions(model):\n",
    "    source_code = inspect.getsource(model)\n",
    "    lines = source_code.split('\\n')\n",
    "\n",
    "    variables = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if not line or line.startswith('def') or 'independent' in line.lower() or not 'yield' in line:\n",
    "            continue\n",
    "\n",
    "        # Split the line into key and value\n",
    "        key, value = line.split('=', 1)\n",
    "\n",
    "        # Remove leading and trailing whitespace\n",
    "        key = key.strip()\n",
    "\n",
    "        # Find all words before the brackets\n",
    "        words = re.findall(r'\\b\\w+\\b(?=\\()', value)\n",
    "\n",
    "        # Create a dictionary with 'distribution' as the key and words as the value\n",
    "        distribution = {\n",
    "            'distribution': words[0]\n",
    "        }\n",
    "\n",
    "        # Add the key-value pair to the dictionary\n",
    "        variables[key] = distribution\n",
    "\n",
    "    return variables\n",
    "\n",
    "def initialise(infos, init_params):\n",
    "    init_params2 = []\n",
    "    bijectors = []\n",
    "    i = 0\n",
    "    for key in infos.keys():  \n",
    "        tmp = infos[key]['distribution'].lower()\n",
    "        if 'lkj' in tmp:\n",
    "            infos[key]['shape'] = int(init_params[i].shape[0])\n",
    "            init_params2.append(jnp.array(jnp.eye(infos[key]['shape'])))            \n",
    "            bijectors.append(tfp.bijectors.CorrelationCholesky())\n",
    "        elif 'exponential' in tmp:\n",
    "             init_params2.append(jnp.array(jnp.ones_like(init_params[i])))\n",
    "             infos[key]['shape'] = init_params[i].shape\n",
    "             bijectors.append(tfp.bijectors.Exp())\n",
    "        else:\n",
    "            init_params2.append(jnp.array(jnp.ones_like(init_params[i])))\n",
    "            infos[key]['shape'] = init_params[i].shape\n",
    "            bijectors.append(tfp.bijectors.Identity())\n",
    "        i+=1\n",
    "    return init_params2, bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC function\n",
    "## NUTS alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "\n",
    "def NUTS(model,  obs,  n_chains = 1, init = None,\n",
    "         num_results = 500,\n",
    "         num_burnin_steps=500,\n",
    "         num_steps_between_results=0,\n",
    "         parallel_iterations = 10,\n",
    "         previous_kernel_results=None,\n",
    "         return_final_kernel_results=False,\n",
    "         seed=0,\n",
    "         name=None):\n",
    "\n",
    "    init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "    init_key = jnp.array(init_key)\n",
    "\n",
    "    tensor = JointDistributionCoroutine(model)\n",
    "    infos = get_distributions(model)\n",
    "    init_params = tensor.sample(seed = init_key)\n",
    "    \n",
    "    if init is None:\n",
    "        init_params =  list(init_params)[:-1]\n",
    "    else:\n",
    "        init_params, bijectors = init\n",
    "\n",
    "    names = infos.keys()\n",
    "\n",
    "    def trace_fn(_, pkr):\n",
    "        return (\n",
    "            pkr.target_log_prob,\n",
    "            pkr.leapfrogs_taken,\n",
    "            pkr.has_divergence,\n",
    "            pkr.energy,\n",
    "            pkr.log_accept_ratio\n",
    "        )\n",
    "\n",
    "    def target_log_prob(*params):\n",
    "        return tensor.log_prob(params + (obs,))\n",
    "    \n",
    "    @jit\n",
    "    def run_chain(key):\n",
    "        kernel = tfp.mcmc.NoUTurnSampler(target_log_prob, 1e-3)\n",
    "        return tfp.mcmc.sample_chain(num_results = num_results,\n",
    "            current_state= init_params,\n",
    "            kernel=kernel,\n",
    "            trace_fn=trace_fn,\n",
    "            num_burnin_steps=num_burnin_steps,\n",
    "            num_steps_between_results=num_steps_between_results,\n",
    "            parallel_iterations = parallel_iterations,\n",
    "            seed=key)\n",
    "\n",
    "\n",
    "    start = tm.time()  \n",
    "    rng_keys = jax.random.split(random.PRNGKey(0), n_chains)\n",
    "    posterior, sample_stats =  jax.pmap(run_chain)(rng_keys)\n",
    "    end = tm.time()    \n",
    "    print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "\n",
    "    return posterior, sample_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUTS + transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability\n",
    "def NUTSdual(model,  obs,  n_chains = 1, init = None,\n",
    "         num_results = 500,\n",
    "         num_burnin_steps=500,\n",
    "         num_steps_between_results=0,\n",
    "         parallel_iterations = 10,\n",
    "         previous_kernel_results=None,\n",
    "         return_final_kernel_results=False,\n",
    "         seed=0,\n",
    "         name=None):\n",
    "\n",
    "    init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "    init_key = jnp.array(init_key)\n",
    "\n",
    "    tensor = JointDistributionCoroutine(model)\n",
    "    infos = get_distributions(model)\n",
    "    init_params = tensor.sample(seed = init_key)\n",
    "    \n",
    "    _, bijectors = initialise(infos, init_params)\n",
    "    init_params = list(init_params)[:-1]\n",
    "\n",
    "    names = infos.keys()\n",
    "\n",
    "    def trace_fn(_, pkr):\n",
    "        return (\n",
    "            pkr.inner_results.target_log_prob,\n",
    "            pkr.inner_results.leapfrogs_taken,\n",
    "            pkr.inner_results.has_divergence,\n",
    "            pkr.inner_results.energy,\n",
    "            pkr.inner_results.log_accept_ratio\n",
    "        )\n",
    "    \n",
    "    def target_log_prob(*params):\n",
    "      return tensor.log_prob(params + (obs,))\n",
    "    \n",
    "    @jit\n",
    "    def run_chain(key):\n",
    "        inner_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "            target_log_prob,\n",
    "            step_size= 1e-3\n",
    "        )\n",
    "\n",
    "        kernel = tensorflow_probability.substrates.jax.mcmc.TransformedTransitionKernel(\n",
    "                inner_kernel=inner_kernel,\n",
    "                bijector=bijectors\n",
    "            )\n",
    "\n",
    "        return tfp.mcmc.sample_chain(num_results = num_results,\n",
    "                                     num_steps_between_results = num_steps_between_results,\n",
    "                                     current_state= init_params,\n",
    "                                     kernel=kernel,\n",
    "                                     trace_fn=trace_fn,\n",
    "                                     num_burnin_steps=num_burnin_steps,\n",
    "                                     parallel_iterations = parallel_iterations,\n",
    "                                     seed=key)\n",
    "    \n",
    "    start = tm.time()  \n",
    "    rng_keys = jax.random.split(random.PRNGKey(0), n_chains)\n",
    "    result =  jax.pmap(run_chain)(rng_keys)\n",
    "    end = tm.time()    \n",
    "    print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "    posterior, sample_stats = result\n",
    "\n",
    "    return posterior, sample_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUTS + transformed + Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability\n",
    "def NUTStrans(model,  obs,  n_chains = 1, init = None, target_log_prob_fn = None,\n",
    "         num_results = 500,\n",
    "         num_burnin_steps=500,\n",
    "         num_steps_between_results=0,\n",
    "         parallel_iterations = 10,\n",
    "         seed=0,\n",
    "         name=None):\n",
    "\n",
    "    init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "    init_key = jnp.array(init_key)\n",
    "\n",
    "    tensor = JointDistributionCoroutine(model)\n",
    "    infos = get_distributions(model)\n",
    "    init_params = tensor.sample(seed = init_key)\n",
    "    \n",
    "    _, bijectors = initialise(infos, init_params)\n",
    "    init_params = list(init_params)[:-1]\n",
    "\n",
    "    names = infos.keys()\n",
    "    def trace_fn(_, pkr):\n",
    "        return (\n",
    "            pkr.inner_results.inner_results.target_log_prob,\n",
    "            pkr.inner_results.inner_results.leapfrogs_taken,\n",
    "            pkr.inner_results.inner_results.has_divergence,\n",
    "            pkr.inner_results.inner_results.energy,\n",
    "            pkr.inner_results.inner_results.log_accept_ratio\n",
    "        )\n",
    "    \n",
    "    if target_log_prob_fn == None:\n",
    "        def target_log_prob(*params):\n",
    "            return tensor.log_prob(params + (obs,))\n",
    "    else:\n",
    "        def target_log_prob(*params):\n",
    "            return target_log_prob_fn(params + (obs,))\n",
    "    @jit\n",
    "    def run_chain(key):\n",
    "        inner_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "            target_log_prob,\n",
    "            step_size= 1e-3\n",
    "        )\n",
    "\n",
    "        kernel = tensorflow_probability.substrates.jax.mcmc.TransformedTransitionKernel(\n",
    "                inner_kernel=inner_kernel,\n",
    "                bijector=bijectors\n",
    "        )\n",
    "        \n",
    "        hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "            kernel,\n",
    "            target_accept_prob=.8,\n",
    "            num_adaptation_steps=int(0.8*500),\n",
    "            step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "                  inner_results=pkr.inner_results._replace(step_size=new_step_size)\n",
    "              ),\n",
    "            step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "            log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,\n",
    "        )\n",
    "        \n",
    "        return tfp.mcmc.sample_chain(num_results = num_results,\n",
    "                                     num_steps_between_results = num_steps_between_results,\n",
    "                                     current_state= init_params,\n",
    "                                     kernel=hmc,\n",
    "                                     trace_fn=trace_fn,\n",
    "                                     num_burnin_steps=num_burnin_steps,\n",
    "                                     parallel_iterations = parallel_iterations,\n",
    "                                     seed=key)\n",
    "    \n",
    "    Ndevices = jax.local_device_count(backend=None)\n",
    "    if(n_chains > Ndevices):\n",
    "        runs = jnp.ceil(n_chains/Ndevices)\n",
    "        print(runs)\n",
    "        result = []\n",
    "        for run in range(int(runs)):\n",
    "            rng_keys = jax.random.split(random.PRNGKey(0), Ndevices)\n",
    "            result.append(jax.pmap(run_chain)(rng_keys))\n",
    " \n",
    "        return result\n",
    "    else:\n",
    "        start = tm.time()  \n",
    "        rng_keys = jax.random.split(random.PRNGKey(0), n_chains)\n",
    "        result =  jax.pmap(run_chain)(rng_keys)\n",
    "        end = tm.time()    \n",
    "        print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "        posterior, sample_stats = result\n",
    "\n",
    "    return posterior, sample_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Continuous variable: Model (model 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('D:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\data\\Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot with regression line and confidence interval\n",
    "sns.regplot(x=d.weight.values, y=d.height.values, data=df, ci=95)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('weight')\n",
    "plt.title('Scatter Plot with Regression Line and Confidence Interval between weight and height')\n",
    "\n",
    "plt.savefig('plot0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.1109 seconds\n"
     ]
    }
   ],
   "source": [
    "## Model m4.3\n",
    "d = pd.read_csv('/home/sosa/BI/data/Howell1.csv', sep=';')\n",
    "d = d[d.age > 18]\n",
    "#self.df[\"weight.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d.weight = d.weight - d.weight.mean()\n",
    "d.age = d.age - d.age.mean()\n",
    "weight = jnp.array(d.weight.values)\n",
    "def model():\n",
    "    s = yield uniform(1, 0, 50)\n",
    "    a = yield normal(1, 178, 20)\n",
    "    b = yield normal(1, 0, 1)    \n",
    "    y = yield Independent(Normal(a+b*weight, s), reinterpreted_batch_ndims= 1)\n",
    "    \n",
    "posterior, sample_stats = NUTStrans(model, obs = jnp.array(d.height.values), n_chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1593432</td>\n",
       "      <td>5.144897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.62686</td>\n",
       "      <td>154.649662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9049445</td>\n",
       "      <td>0.904733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI      pystan\n",
       "0  5.1593432    5.144897\n",
       "1  154.62686  154.649662\n",
       "2  0.9049445    0.904733"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI\": [jnp.mean(posterior[0], axis = 1)[0][0] , jnp.mean(posterior[1], axis = 1)[0][0] , jnp.mean(posterior[2], axis = 1)[0][0] ],\n",
    "        \"pystan\": [5.144897,  154.649662, 0.904733]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable: Model (model 5.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 0.9042 seconds\n"
     ]
    }
   ],
   "source": [
    "#from src.main import*\n",
    "d = pd.read_csv('/home/sosa/BI/data/milk.csv', sep=';')\n",
    "d[\"K\"] = d[\"kcal.per.g\"].pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d = index(d, cols = \"clade\")\n",
    "index_clade = jnp.array(d.index_clade.values, dtype=jnp.int32)\n",
    "def model():\n",
    "    s = yield exponential(1, 1)\n",
    "    a = yield normal(4, 0, 0.5)  \n",
    "    m = a[index_clade]\n",
    "    y = yield tfd.Independent(tfd.Normal(m, s), reinterpreted_batch_ndims=1)\n",
    "    \n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.K.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801499</td>\n",
       "      <td>0.801640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.443672</td>\n",
       "      <td>-0.459873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.346701</td>\n",
       "      <td>0.353296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638811</td>\n",
       "      <td>0.636981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.568730</td>\n",
       "      <td>-0.547616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BI    pystan\n",
       "0  0.801499  0.801640\n",
       "1 -0.443672 -0.459873\n",
       "2  0.346701  0.353296\n",
       "3  0.638811  0.636981\n",
       "4 -0.568730 -0.547616"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0] , jnp.mean(posterior[1], axis = 1)[0]]),\n",
    "        \"pystan\": [0.801640, -0.459873,  0.353296, 0.636981, -0.547616]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.2564 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/tulips.csv', sep = ';')\n",
    "d[\"blooms_std\"] = d.blooms / d.blooms.max()\n",
    "d[\"water_cent\"] = d.water - d.water.mean()\n",
    "d[\"shade_cent\"] = d.shade - d.shade.mean()\n",
    "\n",
    "water_cent = jnp.array(d.water_cent.values)\n",
    "blooms_std = jnp.array(d.blooms_std.values)\n",
    "shade_cent = jnp.array(d.shade_cent.values)\n",
    "\n",
    "def model():\n",
    "    sigma = yield exponential(1, 1)\n",
    "    bws = yield normal(1,  0 , 0.25 )\n",
    "    bs = yield normal(1,  0 , 0.25 )\n",
    "    bw = yield normal(1,  0 , 0.25 )\n",
    "    a = yield normal(1,  0.5 , 0.25 )\n",
    "    mu = a + bw*water_cent + bs*shade_cent + bws*water_cent*shade_cent\n",
    "    y = yield tfd.Independent(tfd.Normal(mu, sigma), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.blooms_std.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145584</td>\n",
       "      <td>0.142327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.139439</td>\n",
       "      <td>-0.143176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112633</td>\n",
       "      <td>-0.112393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205490</td>\n",
       "      <td>0.206099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359399</td>\n",
       "      <td>0.358277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BI    pystan\n",
       "0  0.145584  0.142327\n",
       "1 -0.139439 -0.143176\n",
       "2 -0.112633 -0.112393\n",
       "3  0.205490  0.206099\n",
       "4  0.359399  0.358277"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0], \n",
    "                jnp.mean(posterior[1], axis = 1)[0], \n",
    "                jnp.mean(posterior[2], axis = 1)[0], \n",
    "                jnp.mean(posterior[3], axis = 1)[0], \n",
    "                jnp.mean(posterior[4], axis = 1)[0]]),\n",
    "        \"pystan\": [0.142327, -0.143176,  -0.112393, 0.206099,  0.358277]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial (model 11.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 0.8969 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1\n",
    "d_aggregated = (\n",
    "    d.groupby([\"treatment\", \"actor\", \"side\", \"cond\"])[\"pulled_left\"].sum().reset_index()\n",
    ")\n",
    "d_aggregated.rename(columns={\"pulled_left\": \"left_pulls\"}, inplace=True)\n",
    "d_aggregated[\"actor_id\"] = d_aggregated[\"actor\"].values - 1\n",
    "\n",
    "def model():\n",
    "    a = yield normal(1,  0 , 10)\n",
    "    y = yield Independent(Binomial(1, logits = a), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.pulled_left.values), seed= 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31404275</td>\n",
       "      <td>0.321119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tfp    pystan\n",
       "0  0.31404275  0.321119"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": [jnp.mean(posterior[0])],\n",
    "        \"pystan\": 0.321119\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices (model 11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.1508 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/chimpanzees.csv', sep = ';')\n",
    "d.actor = d.actor - 1\n",
    "d[\"treatment\"] = d.prosoc_left + 2 * d.condition\n",
    "treatment = jnp.array(d[\"treatment\"], dtype=jnp.int32)\n",
    "actor = jnp.array(d[\"actor\"] )\n",
    "n_actor = len(jnp.unique(actor))\n",
    "n_treatment= len(jnp.unique(treatment))\n",
    "\n",
    "def model():\n",
    "    a = yield normal(7, 0, 1.5)\n",
    "    b = yield normal(4, 0, 0.5)\n",
    "    p = a[actor] + b[treatment]\n",
    "    y = yield Independent(Binomial(1, logits = p), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.pulled_left.values), seed = 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.036575</td>\n",
       "      <td>-0.031648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.490967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.384034</td>\n",
       "      <td>-0.375165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.364707</td>\n",
       "      <td>0.376894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.442183</td>\n",
       "      <td>-0.455304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.083852</td>\n",
       "      <td>3.887521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.740911</td>\n",
       "      <td>1.189759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.758169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.450640</td>\n",
       "      <td>-0.459580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.478724</td>\n",
       "      <td>0.471230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.965564</td>\n",
       "      <td>1.946828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tfp    pystan\n",
       "0  -0.036575 -0.031648\n",
       "1   0.475207  0.490967\n",
       "2  -0.384034 -0.375165\n",
       "3   0.364707  0.376894\n",
       "4  -0.442183 -0.455304\n",
       "5   4.083852  3.887521\n",
       "6  -0.740911  1.189759\n",
       "7  -0.744570 -0.758169\n",
       "8  -0.450640 -0.459580\n",
       "9   0.478724  0.471230\n",
       "10  1.965564  1.946828"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": jnp.concatenate([jnp.mean(posterior[1], axis = 1)[0], jnp.mean(posterior[0], axis = 1)[0]]),\n",
    "        \"pystan\": [0.-0.031648,\n",
    "                   0.490967,\n",
    "                   -0.375165,\n",
    "                   0.376894,\n",
    "                   -0.455304,\n",
    "                   3.887521,\n",
    "                   1.946828\n",
    "                   -0.757069,\n",
    "                   -0.758169,\n",
    "                   -0.459580,\n",
    "                   0.471230,\n",
    "                   1.946828]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson (model 11.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 0.9352 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/Kline.csv', sep = ';')\n",
    "d[\"P\"] = d.population.pipe(np.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "d[\"cid\"] = (d.contact == \"high\").astype(int)\n",
    "d['pLog'] = tf.math.log(d.P).numpy()\n",
    "cid = jnp.array(d[\"cid\"])\n",
    "P = jnp.array(d[\"P\"] )\n",
    "\n",
    "def model():\n",
    "    a = yield normal(2, 3,0.5)\n",
    "    b = yield normal(2, 0,0.2)\n",
    "    l = a[cid] + b[cid]*P\n",
    "    y = yield Independent(Poisson(log_rate = l), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.total_tools.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.377975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181432</td>\n",
       "      <td>0.190583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.326719</td>\n",
       "      <td>3.319431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.608030</td>\n",
       "      <td>3.610163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfp    pystan\n",
       "0  0.375671  0.377975\n",
       "1  0.181432  0.190583\n",
       "2  3.326719  3.319431\n",
       "3  3.608030  3.610163"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": jnp.concatenate([jnp.mean(posterior[1], axis = 1)[0], jnp.mean(posterior[0], axis = 1)[0]]),\n",
    "        \"pystan\": [0.377975, 0.190583, 3.319431, 3.610163]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (model 11.12) (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)\n",
    "log_days = jnp.array(d[\"log_days\"].values)\n",
    "monastery  = jnp.array(d.monastery.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 0.9363 seconds\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    a = yield normal(1, 0, 1)\n",
    "    b = yield normal(1, 0, 1)\n",
    "    l = jnp.exp(log_days + a +  b * monastery)\n",
    "    y = yield Independent(Poisson(log_rate = l), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.772670</td>\n",
       "      <td>-0.866921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.505091</td>\n",
       "      <td>1.210285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfp    pystan\n",
       "0 -0.772670 -0.866921\n",
       "1  1.505091  1.210285"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0], jnp.mean(posterior[1], axis = 1)[0]]),\n",
    "        \"pystan\": [-0.866921, 1.210285]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial (model 11.13) (PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = jnp.array(tf.nn.softmax(score))\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = tfd.Categorical(probs=p).sample(seed = init_key, sample_shape = N)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)\n",
    "career = jnp.array(d.career.values)\n",
    "career_income = jnp.array(d.income.values)\n",
    "income = jnp.array(income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = jnp.array(tf.nn.softmax(score))\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = tfd.Categorical(probs=p).sample(seed = init_key, sample_shape = N)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)\n",
    "career = jnp.array(d.career.values)\n",
    "career_income = jnp.array(d.income.values)\n",
    "income = jnp.array(income)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(500,)\n",
      "(3,)\n",
      "(500,)\n",
      "(3,)\n",
      "(500,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sub got incompatible shapes for broadcasting: (500,), (2,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(p\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m Independent(Categorical(probs \u001b[38;5;241m=\u001b[39m  p))\n\u001b[0;32m---> 13\u001b[0m posterior, sample_stats \u001b[38;5;241m=\u001b[39m \u001b[43mNUTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcareer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[95], line 53\u001b[0m, in \u001b[0;36mNUTS\u001b[0;34m(model, obs, n_chains, init, num_results, num_burnin_steps, num_steps_between_results, parallel_iterations, previous_kernel_results, return_final_kernel_results, seed, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()  \n\u001b[1;32m     52\u001b[0m rng_keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), n_chains)\n\u001b[0;32m---> 53\u001b[0m posterior, sample_stats \u001b[38;5;241m=\u001b[39m  \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_chain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHonnorMode took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[95], line 41\u001b[0m, in \u001b[0;36mNUTS.<locals>.run_chain\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_chain\u001b[39m(key):\n\u001b[1;32m     40\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mmcmc\u001b[38;5;241m.\u001b[39mNoUTurnSampler(target_log_prob, \u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:330\u001b[0m, in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m current_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_state\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    328\u001b[0m     current_state)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_kernel_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m   previous_kernel_results \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;66;03m# It simplifies the logic to use a dummy function here.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   trace_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: ()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/mcmc/nuts.py:498\u001b[0m, in \u001b[0;36mNoUTurnSampler.bootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# Confirm that the step size is compatible with the state parts.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m _ \u001b[38;5;241m=\u001b[39m _prepare_step_size(\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size, current_target_log_prob\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mlen\u001b[39m(init_state))\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NUTSKernelResults(\n\u001b[1;32m    476\u001b[0m     target_log_prob\u001b[38;5;241m=\u001b[39mcurrent_target_log_prob,\n\u001b[1;32m    477\u001b[0m     grads_target_log_prob\u001b[38;5;241m=\u001b[39mcurrent_grads_log_prob,\n\u001b[1;32m    478\u001b[0m     step_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    480\u001b[0m             x,\n\u001b[1;32m    481\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mcurrent_target_log_prob\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    482\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size),\n\u001b[1;32m    484\u001b[0m     log_accept_ratio\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(current_target_log_prob,\n\u001b[1;32m    485\u001b[0m                                    name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_accept_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    486\u001b[0m     leapfrogs_taken\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(current_target_log_prob,\n\u001b[1;32m    487\u001b[0m                                   dtype\u001b[38;5;241m=\u001b[39mTREE_COUNT_DTYPE,\n\u001b[1;32m    488\u001b[0m                                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleapfrogs_taken\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    489\u001b[0m     is_accepted\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(current_target_log_prob,\n\u001b[1;32m    490\u001b[0m                               dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m    491\u001b[0m                               name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_accepted\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    492\u001b[0m     reach_max_depth\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(current_target_log_prob,\n\u001b[1;32m    493\u001b[0m                                   dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m    494\u001b[0m                                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach_max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    495\u001b[0m     has_divergence\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mzeros_like(current_target_log_prob,\n\u001b[1;32m    496\u001b[0m                                  dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m    497\u001b[0m                                  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas_divergence\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m--> 498\u001b[0m     energy\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_hamiltonian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_target_log_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_axis_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_shard_axis_names\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# Allow room for one_step's seed.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     seed\u001b[38;5;241m=\u001b[39msamplers\u001b[38;5;241m.\u001b[39mzeros_seed(),\n\u001b[1;32m    503\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/mcmc/nuts.py:1102\u001b[0m, in \u001b[0;36mcompute_hamiltonian\u001b[0;34m(target_log_prob, momentum_parts, shard_axis_names)\u001b[0m\n\u001b[1;32m   1096\u001b[0m momentum_sq_parts \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1097\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcast(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m         compute_sum_sq(m, axes),\n\u001b[1;32m   1099\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtarget_log_prob\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m, axes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(momentum_parts, shard_axis_names))\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO(jvdillon): Verify no broadcasting happening.\u001b[39;00m\n\u001b[0;32m-> 1102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget_log_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmomentum_sq_parts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:736\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 736\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:264\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    262\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/numpy/ufuncs.py:85\u001b[0m, in \u001b[0;36m_one_to_one_binop.<locals>.<lambda>\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     83\u001b[0m   fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2, \u001b[38;5;241m/\u001b[39m: lax_fn(\u001b[38;5;241m*\u001b[39mpromote_args_numeric(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m   fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2, \u001b[38;5;241m/\u001b[39m: \u001b[43mlax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpromote_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax.numpy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m fn \u001b[38;5;241m=\u001b[39m jit(fn, inline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/lax/lax.py:1660\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1658\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1660\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1661\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: sub got incompatible shapes for broadcasting: (500,), (2,)."
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    a = yield normal(2, 0, 1)\n",
    "    b = yield halfnormal(1,0.5)\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = [0]\n",
    "    p = nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    print(p.shape)\n",
    "    p = p[career] \n",
    "    print(p.shape)\n",
    "    y = yield Independent(Categorical(probs =  p))\n",
    "\n",
    "posterior, sample_stats = NUTS(model, obs = career)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_key, key = random.split(random.PRNGKey(int(51651)))\n",
    "init_key = jnp.array(init_key)\n",
    "tensor = JointDistributionCoroutine(model)\n",
    "infos = get_distributions(model)\n",
    "init_params = tensor.sample(seed = init_key)\n",
    "init_params =  list(init_params)[:-1]\n",
    "init_params\n",
    "init_params.append(jnp.array(d.career.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    a = yield normal(2, 0, 1)\n",
    "    b = yield HalfNormal(1, 0.5)\n",
    "    p = softmax_fn(a[career_income] + b[career_income])\n",
    "    print(p.shape)\n",
    "    y = yield tfd.Independent(Multinomial(1, probs = p))\n",
    "    \n",
    "posterior, sample_stats = NUTS(model, obs = jnp.array(d.career.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (model m12.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.3988 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/UCBadmit.csv', sep = ';')\n",
    "d[\"gid\"] = (d[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(d[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(d[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(d[\"admit\"].astype('float32').values)\n",
    "\n",
    "def model():\n",
    "    phi = yield exponential(1, 1)\n",
    "    #phi2 =  tfp.bijectors.Exp().forward(phi)\n",
    "    alpha = yield normal(2,0.,1.5)\n",
    "    theta = phi + 2\n",
    "    pbar = nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    y = yield Independent(BetaBinomial(applications, concentration1 = concentration1, concentration0 = concentration0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = admit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 2.6830 seconds\n"
     ]
    }
   ],
   "source": [
    "posterior2, sample_stats = NUTS(model, obs = admit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI NUTSdual</th>\n",
       "      <th>BI NUTS</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923973</td>\n",
       "      <td>0.523416</td>\n",
       "      <td>1.014828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.439733</td>\n",
       "      <td>-0.411268</td>\n",
       "      <td>-0.440553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.344476</td>\n",
       "      <td>-0.314011</td>\n",
       "      <td>-0.320719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI NUTSdual   BI NUTS    pystan\n",
       "0     0.923973  0.523416  1.014828\n",
       "1    -0.439733 -0.411268 -0.440553\n",
       "2    -0.344476 -0.314011 -0.320719"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI NUTSdual\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0], jnp.mean(posterior[1], axis = 1)[0]]),\n",
    "        \"BI NUTS\": jnp.concatenate([jnp.mean(posterior2[0], axis = 1)[0], jnp.mean(posterior2[1], axis = 1)[0]]),\n",
    "        \"pystan\": [1.014828, -0.440553, -0.320719]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 2.6745 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/UCBadmit.csv', sep = ';')\n",
    "d[\"gid\"] = (d[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(d[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(d[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(d[\"admit\"].astype('float32').values)\n",
    "\n",
    "def model():\n",
    "    phi = yield exponential(1, 1)\n",
    "    alpha = yield normal(2,0.,1.5)\n",
    "    theta = phi + 2\n",
    "    pbar = nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    y = yield Independent(BetaBinomial(applications, concentration1 = concentration1, concentration0 = concentration0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTS(model, obs = admit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes (PB estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "d = pd.DataFrame(y)\n",
    "\n",
    "def model():\n",
    "    al = yield normal(1, 1, 0.5)\n",
    "    ap = yield normal(1, -1.5 , 1)\n",
    "    y = yield Independent(ZeroInflatedNegativeBinomial(total_count = 365, inflated_loc_logits = al, logits = jnp.log(ap)), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTSdual(model, obs = jnp.array(d.iloc[:,0].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI NUTS</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613457</td>\n",
       "      <td>-1.370638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.104704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BI NUTS    pystan\n",
       "0  0.613457 -1.370638\n",
       "1  0.004344  0.104704"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI NUTS\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0], jnp.mean(posterior[1], axis = 1)[0]]),\n",
    "        \"pystan\": [-1.370638, 0.104704]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Varying interceps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 1.9781 seconds\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('/home/sosa/BI/data/reedfrogs.csv', sep = ';')\n",
    "d[\"tank\"] = np.arange(d.shape[0])\n",
    "tank = jnp.array(d[\"tank\"].astype('int32').values)\n",
    "density = jnp.array(d[\"density\"].astype('float32').values)\n",
    "def model():\n",
    "    sigma = yield exponential(1, 1)\n",
    "    a_bar = yield normal(1, 0, 1.5)\n",
    "    alpha = yield normal(48, a_bar, sigma)\n",
    "    p = jnp.squeeze(alpha[tank])[0]\n",
    "    y = yield Independent(Binomial(total_count = density, logits = p), reinterpreted_batch_ndims=1)\n",
    "\n",
    "posterior, sample_stats = NUTS(model, obs = jnp.array(d.surv.astype('float32').values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI NUTSdual</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.606676</td>\n",
       "      <td>1.621539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.354982</td>\n",
       "      <td>1.345123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.151212</td>\n",
       "      <td>2.140623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.352207</td>\n",
       "      <td>3.075581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.997040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.919931</td>\n",
       "      <td>3.067604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.964355</td>\n",
       "      <td>2.138858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.930002</td>\n",
       "      <td>2.146644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.938609</td>\n",
       "      <td>3.069126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.034379</td>\n",
       "      <td>2.131292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.177832</td>\n",
       "      <td>-0.177990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.096339</td>\n",
       "      <td>2.145196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.033947</td>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.614247</td>\n",
       "      <td>0.578882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.939009</td>\n",
       "      <td>1.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.273336</td>\n",
       "      <td>0.184045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.180619</td>\n",
       "      <td>2.152843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.023611</td>\n",
       "      <td>2.130130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.966063</td>\n",
       "      <td>2.909044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.356697</td>\n",
       "      <td>2.404756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.054096</td>\n",
       "      <td>2.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.756707</td>\n",
       "      <td>3.670685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.457058</td>\n",
       "      <td>2.392812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.277029</td>\n",
       "      <td>2.403261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.261528</td>\n",
       "      <td>2.403139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.686868</td>\n",
       "      <td>1.702271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.978611</td>\n",
       "      <td>-1.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.162632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.405251</td>\n",
       "      <td>-1.439793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.486990</td>\n",
       "      <td>-0.472672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.184759</td>\n",
       "      <td>0.158220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.461133</td>\n",
       "      <td>1.444945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.606686</td>\n",
       "      <td>-0.630888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.290720</td>\n",
       "      <td>-0.307811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.137396</td>\n",
       "      <td>3.185393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.802254</td>\n",
       "      <td>2.712255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.673856</td>\n",
       "      <td>2.706410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.055939</td>\n",
       "      <td>2.059125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.089487</td>\n",
       "      <td>2.054994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.908004</td>\n",
       "      <td>3.904811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.738888</td>\n",
       "      <td>2.701189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.460176</td>\n",
       "      <td>2.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.788633</td>\n",
       "      <td>-1.814108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.565027</td>\n",
       "      <td>-0.572653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.458985</td>\n",
       "      <td>-0.450904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.318286</td>\n",
       "      <td>-0.341859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.564080</td>\n",
       "      <td>0.578379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.549626</td>\n",
       "      <td>-0.580085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.094556</td>\n",
       "      <td>2.066660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BI NUTSdual    pystan\n",
       "0      1.606676  1.621539\n",
       "1      1.354982  1.345123\n",
       "2      2.151212  2.140623\n",
       "3      3.352207  3.075581\n",
       "4      0.999321  0.997040\n",
       "5      2.919931  3.067604\n",
       "6      1.964355  2.138858\n",
       "7      1.930002  2.146644\n",
       "8      2.938609  3.069126\n",
       "9      2.034379  2.131292\n",
       "10    -0.177832 -0.177990\n",
       "11     2.096339  2.145196\n",
       "12     1.033947  0.999936\n",
       "13     0.614247  0.578882\n",
       "14     0.939009  1.009545\n",
       "15     0.273336  0.184045\n",
       "16     2.180619  2.152843\n",
       "17     2.023611  2.130130\n",
       "18     2.966063  2.909044\n",
       "19     2.356697  2.404756\n",
       "20     2.054096  2.015801\n",
       "21     3.756707  3.670685\n",
       "22     2.457058  2.392812\n",
       "23     2.277029  2.403261\n",
       "24     2.261528  2.403139\n",
       "25     1.686868  1.702271\n",
       "26    -0.978611 -1.001493\n",
       "27     0.155357  0.162632\n",
       "28    -1.405251 -1.439793\n",
       "29    -0.486990 -0.472672\n",
       "30     0.184759  0.158220\n",
       "31     1.461133  1.444945\n",
       "32    -0.606686 -0.630888\n",
       "33    -0.290720 -0.307811\n",
       "34     3.137396  3.185393\n",
       "35     2.802254  2.712255\n",
       "36     2.673856  2.706410\n",
       "37     2.055939  2.059125\n",
       "38     2.089487  2.054994\n",
       "39     3.908004  3.904811\n",
       "40     2.738888  2.701189\n",
       "41     2.460176  2.354839\n",
       "42    -1.788633 -1.814108\n",
       "43    -0.565027 -0.572653\n",
       "44    -0.458985 -0.450904\n",
       "45    -0.318286 -0.341859\n",
       "46     0.564080  0.578379\n",
       "47    -0.549626 -0.580085\n",
       "48     2.094556  2.066660\n",
       "49     0.015837  0.001912"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"BI NUTSdual\": jnp.concatenate([jnp.mean(posterior[0], axis = 1)[0], jnp.mean(posterior[1], axis = 1)[0], jnp.mean(posterior[2], axis = 1)[0][0]]),\n",
    "        \"pystan\": [1.621539,\n",
    "                    1.345123,\n",
    "                    2.140623,\n",
    "                    3.075581,\n",
    "                    0.997040,\n",
    "                    3.067604,\n",
    "                    2.138858,\n",
    "                    2.146644,\n",
    "                    3.069126,\n",
    "                    2.131292,\n",
    "                    -0.177990,\n",
    "                    2.145196,\n",
    "                    0.999936,\n",
    "                    0.578882,\n",
    "                    1.009545,\n",
    "                    0.184045,\n",
    "                    2.152843,\n",
    "                    2.130130,\n",
    "                    2.909044,\n",
    "                    2.404756,\n",
    "                    2.015801,\n",
    "                    3.670685,\n",
    "                    2.392812,\n",
    "                    2.403261,\n",
    "                    2.403139,\n",
    "                    1.702271,\n",
    "                    -1.001493,\n",
    "                    0.162632,\n",
    "                    -1.439793,\n",
    "                    -0.472672,\n",
    "                    0.158220,\n",
    "                    1.444945,\n",
    "                    -0.630888,\n",
    "                    -0.307811,\n",
    "                    3.185393,\n",
    "                    2.712255,\n",
    "                    2.706410,\n",
    "                    2.059125,\n",
    "                    2.054994,\n",
    "                    3.904811,\n",
    "                    2.701189,\n",
    "                    2.354839,\n",
    "                    -1.814108,\n",
    "                    -0.572653,\n",
    "                    -0.450904,\n",
    "                    -0.341859,\n",
    "                    0.578379,\n",
    "                    -0.580085,\n",
    "                    2.066660,\n",
    "                    0.001912]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, set_matplotlib_formats\n",
    "from matplotlib.patches import Ellipse, transforms\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(4)\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = dist.MultivariateNormal(Mu, Sigma).sample(seed, (N_cafes,))\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = dist.Normal(mu, sigma).sample(seed)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "c:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: shapes=[(200, 2), (200,)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\util.py:290\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m cached(config\u001b[38;5;241m.\u001b[39mtrace_context(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\util.py:283\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[1;34m(_, *args, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(max_size)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached\u001b[39m(_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\lax\\lax.py:155\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[1;34m(*shapes)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_shapes_cached\u001b[39m(\u001b[38;5;241m*\u001b[39mshapes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\lax\\lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[1;34m(*shapes)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(200, 2), (200,)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     mu \u001b[38;5;241m=\u001b[39m a_cafe_b_cafe[:, \u001b[38;5;241m0\u001b[39m][cafe_id] \u001b[38;5;241m+\u001b[39m a_cafe_b_cafe[:, \u001b[38;5;241m1\u001b[39m][cafe_id] \u001b[38;5;241m*\u001b[39m afternoon\n\u001b[0;32m     11\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m Independent(Normal(mu, sigma), reinterpreted_batch_ndims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m posterior, sample_stats \u001b[38;5;241m=\u001b[39m \u001b[43mNUTStrans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mNUTStrans\u001b[1;34m(model, obs, n_chains, init, target_log_prob_fn, num_results, num_burnin_steps, num_steps_between_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[0;32m     13\u001b[0m tensor \u001b[38;5;241m=\u001b[39m JointDistributionCoroutine(model)\n\u001b[0;32m     14\u001b[0m infos \u001b[38;5;241m=\u001b[39m get_distributions(model)\n\u001b[1;32m---> 15\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m _, bijectors \u001b[38;5;241m=\u001b[39m initialise(infos, init_params)\n\u001b[0;32m     18\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(init_params)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[1;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sample_n(sample_shape, seed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:956\u001b[0m, in \u001b[0;36mJointDistribution._call_sample_n\u001b[1;34m(self, sample_shape, seed, value, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 956\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\internal\\distribution_util.py:1350\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:693\u001b[0m, in \u001b[0;36mJointDistribution._sample_n\u001b[1;34m(self, sample_shape, seed, value)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;129m@distribution_util\u001b[39m\u001b[38;5;241m.\u001b[39mAppendDocstring(kwargs_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    685\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother dependent (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownstream\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) distribution-making functions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[1;32m--> 693\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m   might_have_batch_dims \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    696\u001b[0m       distribution_util\u001b[38;5;241m.\u001b[39mshape_may_be_nontrivial(sample_shape)\n\u001b[0;32m    697\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:361\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcallable_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\internal\\callable_util.py:55\u001b[0m, in \u001b[0;36mget_output_spec\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39meval_shape(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_tensor_spec\u001b[39m(t):\n\u001b[0;32m     58\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensorSpec):\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:362\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m callable_util\u001b[38;5;241m.\u001b[39mget_output_spec(\n\u001b[1;32m--> 362\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:1047\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[1;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m==\u001b[39m stop_index:\n\u001b[0;32m   1046\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m Rho \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m lkj((), \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      9\u001b[0m a_cafe_b_cafe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m multivariatenormaltril(N_cafes, loc \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstack([a, b], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), scale_tril \u001b[38;5;241m=\u001b[39m  Rho \u001b[38;5;241m*\u001b[39m sigma_cafe)\n\u001b[1;32m---> 10\u001b[0m mu \u001b[38;5;241m=\u001b[39m a_cafe_b_cafe[:, \u001b[38;5;241m0\u001b[39m][cafe_id] \u001b[38;5;241m+\u001b[39m \u001b[43ma_cafe_b_cafe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcafe_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mafternoon\u001b[49m\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m Independent(Normal(mu, sigma), reinterpreted_batch_ndims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:736\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 736\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:264\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    262\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[1;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\numpy\\ufuncs.py:99\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[1;32m---> 99\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m \u001b[43mpromote_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\numpy\\util.py:381\u001b[0m, in \u001b[0;36mpromote_args\u001b[1;34m(fun_name, *args)\u001b[0m\n\u001b[0;32m    379\u001b[0m _check_no_float0s(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    380\u001b[0m check_for_prngkeys(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpromote_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpromote_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\numpy\\util.py:250\u001b[0m, in \u001b[0;36mpromote_shapes\u001b[1;34m(fun_name, *args)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mnumpy_rank_promotion\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    249\u001b[0m   _rank_promotion_warning_or_error(fun_name, shapes)\n\u001b[1;32m--> 250\u001b[0m result_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [_broadcast_to(arg, (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (result_rank \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(shp)) \u001b[38;5;241m+\u001b[39m shp)\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m arg, shp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, shapes)]\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SSosa\\.pyenv\\pyenv-win\\versions\\3.10.9\\lib\\site-packages\\jax\\_src\\lax\\lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[1;34m(*shapes)\u001b[0m\n\u001b[0;32m    169\u001b[0m result_shape \u001b[38;5;241m=\u001b[39m _try_broadcast_shapes(shape_list)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(200, 2), (200,)]"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "cafe_id = jnp.array(d.cafe.values)\n",
    "def model():    \n",
    "    sigma = yield exponential(1,1)\n",
    "    a = yield normal(1, 5, 2)\n",
    "    b = yield normal(1, -1, 0.5)\n",
    "    sigma_cafe = yield exponential(2, 1)    \n",
    "    Rho = yield lkj((), 2, 2)\n",
    "    a_cafe_b_cafe = yield multivariatenormaltril(N_cafes, loc = jnp.stack([a, b], axis=1)[0], scale_tril =  Rho * sigma_cafe)\n",
    "    mu = a_cafe_b_cafe[:, 0][cafe_id] + a_cafe_b_cafe[:, 1][cafe_id] * afternoon\n",
    "    y = yield Independent(Normal(mu, sigma), reinterpreted_batch_ndims=[1])\n",
    "\n",
    "posterior, sample_stats = NUTStrans(model, obs = jnp.array(d.wait.astype('float32').values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2873298097592565"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sigma.mean()\n",
    "df.a.mean()\n",
    "df.b.mean()\n",
    "df['sigma_cafe.1'].mean()\n",
    "df['sigma_cafe.2'].mean()\n",
    "df['Rho.1.1'].mean()\n",
    "df['Rho.2.1'].mean()\n",
    "df['Rho.1.2'].mean()\n",
    "df['Rho.2.2'].mean()\n",
    "df['a_cafe.1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53117263]\n",
      "[3.14133]\n",
      "[-0.883886]\n",
      "[1.0519485 0.3173299]\n",
      "[[[ 1.          0.        ]\n",
      "  [-0.41266596  0.9050291 ]]]\n",
      "[[ 1.2774819  -0.03088792]\n",
      " [ 2.6031518  -0.647734  ]\n",
      " [ 2.572913   -0.37040803]\n",
      " [ 3.8227131  -0.98856807]\n",
      " [ 2.3991852  -0.7891954 ]\n",
      " [ 2.0080462  -0.50236875]\n",
      " [ 3.2757096  -0.87508285]\n",
      " [ 1.9705095  -0.40668753]\n",
      " [ 3.5029655  -1.110885  ]\n",
      " [ 2.7006576  -0.48040327]\n",
      " [ 5.4795637  -1.8634117 ]\n",
      " [ 3.0171678  -0.6829112 ]\n",
      " [ 3.6504285  -0.80163425]\n",
      " [ 4.10381    -1.3567264 ]\n",
      " [ 4.4678607  -1.3806102 ]\n",
      " [ 3.2447562  -1.2172555 ]\n",
      " [ 2.4375496  -1.0564926 ]\n",
      " [ 3.8227077  -1.2483317 ]\n",
      " [ 3.4980464  -1.0867492 ]\n",
      " [ 1.8433901  -0.3030343 ]]\n"
     ]
    }
   ],
   "source": [
    "print(jnp.mean(posterior[0], axis = 1)[0])#sigma\n",
    "print(jnp.mean(posterior[1], axis = 1)[0])#a\n",
    "print(jnp.mean(posterior[2], axis = 1)[0])#b\n",
    "print(jnp.mean(posterior[3], axis = 1)[0])#sigma_cafe\n",
    "print(jnp.mean(posterior[4], axis = 1))#Rho\n",
    "print(jnp.mean(posterior[5], axis = 1)[0])#a_cafe_b_cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 25.4s, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_yqkgg554/model_y5f2lzzr.stan', line 18, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:  25% (2500/10000)\n",
      "Sampling:  50% (5000/10000)\n",
      "Sampling:  75% (7500/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.000133 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.33 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 4.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_q6u14_fe/model_y5f2lzzr.stan', line 18, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 28.7846 seconds\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    vector[200] wait;\n",
    "    array[200] int afternoon;\n",
    "    array[200] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[20] b_cafe;\n",
    "    vector[20] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[200] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[20] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:20 ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:200 ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/stats/diagnostics.py:592: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp</th>\n",
       "      <th>pystan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>3.681804</td>\n",
       "      <td>3.677735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-1.038721</td>\n",
       "      <td>-1.043785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[0]</th>\n",
       "      <td>0.996543</td>\n",
       "      <td>1.004749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[1]</th>\n",
       "      <td>0.780823</td>\n",
       "      <td>0.635579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.502117</td>\n",
       "      <td>0.498614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[0, 0]</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[0, 1]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.635529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[1, 0]</th>\n",
       "      <td>0.020340</td>\n",
       "      <td>-0.635529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho[1, 1]</th>\n",
       "      <td>0.848365</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.058267</td>\n",
       "      <td>3.032632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-1.047070</td>\n",
       "      <td>-0.977173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>3.134787</td>\n",
       "      <td>3.107488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.613197</td>\n",
       "      <td>-0.578546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>5.317451</td>\n",
       "      <td>5.388742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-1.561063</td>\n",
       "      <td>-1.708907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>3.713464</td>\n",
       "      <td>3.716037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.103770</td>\n",
       "      <td>-1.104997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.621084</td>\n",
       "      <td>3.616285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-0.988168</td>\n",
       "      <td>-0.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>3.984966</td>\n",
       "      <td>3.998811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-1.405807</td>\n",
       "      <td>-1.416373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>2.987725</td>\n",
       "      <td>2.958500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.161351</td>\n",
       "      <td>-1.071907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.288649</td>\n",
       "      <td>3.273505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.675959</td>\n",
       "      <td>-1.580615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>4.059650</td>\n",
       "      <td>4.069937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-0.399303</td>\n",
       "      <td>-0.492811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>5.278705</td>\n",
       "      <td>5.353763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.354805</td>\n",
       "      <td>-1.523083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>5.336565</td>\n",
       "      <td>5.415836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-2.075883</td>\n",
       "      <td>-2.189090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>2.868150</td>\n",
       "      <td>2.826953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.832534</td>\n",
       "      <td>-0.747451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.224034</td>\n",
       "      <td>3.207041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-1.428114</td>\n",
       "      <td>-1.342380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>4.433628</td>\n",
       "      <td>4.468114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.578399</td>\n",
       "      <td>-1.624243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>3.664132</td>\n",
       "      <td>3.660069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-0.728567</td>\n",
       "      <td>-0.752927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>3.618428</td>\n",
       "      <td>3.617595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-0.790926</td>\n",
       "      <td>-0.808723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>2.635141</td>\n",
       "      <td>2.586418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>0.089425</td>\n",
       "      <td>0.119963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>1.699764</td>\n",
       "      <td>1.612554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>-0.147059</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>4.241937</td>\n",
       "      <td>4.260671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.002597</td>\n",
       "      <td>-1.066528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>3.166956</td>\n",
       "      <td>3.148119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-1.042370</td>\n",
       "      <td>-0.986801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tfp    pystan\n",
       "alpha[0]              3.681804  3.677735\n",
       "beta[0]              -1.038721 -1.043785\n",
       "sigma_cafe[0]         0.996543  1.004749\n",
       "sigma_cafe[1]         0.780823  0.635579\n",
       "sigma[0]              0.502117  0.498614\n",
       "rho[0, 0]             1.000000  1.000000\n",
       "rho[0, 1]             0.000000 -0.635529\n",
       "rho[1, 0]             0.020340 -0.635529\n",
       "rho[1, 1]             0.848365  1.000000\n",
       "a_cafe_b_cafe[0, 0]   3.058267  3.032632\n",
       "a_cafe_b_cafe[0, 1]  -1.047070 -0.977173\n",
       "a_cafe_b_cafe[1, 0]   3.134787  3.107488\n",
       "a_cafe_b_cafe[1, 1]  -0.613197 -0.578546\n",
       "a_cafe_b_cafe[2, 0]   5.317451  5.388742\n",
       "a_cafe_b_cafe[2, 1]  -1.561063 -1.708907\n",
       "a_cafe_b_cafe[3, 0]   3.713464  3.716037\n",
       "a_cafe_b_cafe[3, 1]  -1.103770 -1.104997\n",
       "a_cafe_b_cafe[4, 0]   3.621084  3.616285\n",
       "a_cafe_b_cafe[4, 1]  -0.988168 -0.984400\n",
       "a_cafe_b_cafe[5, 0]   3.984966  3.998811\n",
       "a_cafe_b_cafe[5, 1]  -1.405807 -1.416373\n",
       "a_cafe_b_cafe[6, 0]   2.987725  2.958500\n",
       "a_cafe_b_cafe[6, 1]  -1.161351 -1.071907\n",
       "a_cafe_b_cafe[7, 0]   3.288649  3.273505\n",
       "a_cafe_b_cafe[7, 1]  -1.675959 -1.580615\n",
       "a_cafe_b_cafe[8, 0]   4.059650  4.069937\n",
       "a_cafe_b_cafe[8, 1]  -0.399303 -0.492811\n",
       "a_cafe_b_cafe[9, 0]   5.278705  5.353763\n",
       "a_cafe_b_cafe[9, 1]  -1.354805 -1.523083\n",
       "a_cafe_b_cafe[10, 0]  5.336565  5.415836\n",
       "a_cafe_b_cafe[10, 1] -2.075883 -2.189090\n",
       "a_cafe_b_cafe[11, 0]  2.868150  2.826953\n",
       "a_cafe_b_cafe[11, 1] -0.832534 -0.747451\n",
       "a_cafe_b_cafe[12, 0]  3.224034  3.207041\n",
       "a_cafe_b_cafe[12, 1] -1.428114 -1.342380\n",
       "a_cafe_b_cafe[13, 0]  4.433628  4.468114\n",
       "a_cafe_b_cafe[13, 1] -1.578399 -1.624243\n",
       "a_cafe_b_cafe[14, 0]  3.664132  3.660069\n",
       "a_cafe_b_cafe[14, 1] -0.728567 -0.752927\n",
       "a_cafe_b_cafe[15, 0]  3.618428  3.617595\n",
       "a_cafe_b_cafe[15, 1] -0.790926 -0.808723\n",
       "a_cafe_b_cafe[16, 0]  2.635141  2.586418\n",
       "a_cafe_b_cafe[16, 1]  0.089425  0.119963\n",
       "a_cafe_b_cafe[17, 0]  1.699764  1.612554\n",
       "a_cafe_b_cafe[17, 1] -0.147059  0.009076\n",
       "a_cafe_b_cafe[18, 0]  4.241937  4.260671\n",
       "a_cafe_b_cafe[18, 1] -1.002597 -1.066528\n",
       "a_cafe_b_cafe[19, 0]  3.166956  3.148119\n",
       "a_cafe_b_cafe[19, 1] -1.042370 -0.986801"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": az.summary(trace,round_to='none')['mean'],\n",
    "        \"pystan\": [df['a'].mean(),df['b'].mean(),\n",
    "                   df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),   \n",
    "                   df['sigma'].mean(),                \n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),                   \n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")\n",
    "Y2 = jnp.array(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "#init_key = jnp.array(init_key)\n",
    "#means = Normal(0, 1).sample(NY, seed = init_key)\n",
    "#offset = Normal(0, 1).sample([NV,1], seed = init_key)\n",
    "#sigma = Exponential(1).sample([NY], seed = init_key)  \n",
    "#tmp = jnp.tile(means, [NV, 1]) # Correct\n",
    "#mu_l =  tmp + offset\n",
    "#mu_l\n",
    "#jnp.tile(sigma, [NV, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 13.7202 seconds\n"
     ]
    }
   ],
   "source": [
    "n_chains = 1\n",
    "def model():\n",
    "    means = yield normal(NY, 0, 1)\n",
    "    offset = yield normal([NV, 1], 0, 1)\n",
    "    sigma = yield exponential(NY, 1)  \n",
    "    tmp = jnp.tile(means, [NV, 1])\n",
    "    mu_l =  tmp + offset\n",
    "    y = yield Independent(Normal(mu_l, jnp.tile(sigma, [NV, 1]) ),  reinterpreted_batch_ndims=2)\n",
    "posterior, sample_stats = NUTStrans(model, obs = Y2, n_chains = n_chains, num_results = 1000, num_burnin_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33272076, 0.5066617 , 0.10083277, 0.72349854])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.4229656 , 0.59690624, 0.191077  , 0.8137438 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.reshape(posterior[0], (n_chains*1000, 4)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.04535762, 0.04535593, 0.04535816, 0.04535832], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.std(jnp.reshape(posterior[0], (n_chains*1000, 4)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.215217  , -0.62375594,  0.72093496,  0.32128815,  0.88970604,\n",
       "       -0.2219603 , -0.49029272, -0.39627718])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.1249738 , -0.71400034,  0.6306909 ,  0.23104739,  0.7994598 ,\n",
       "       -0.3122051 , -0.58053434, -0.4865218 ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.reshape(posterior[1], (n_chains*1000, 8)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.04535718, 0.04535824, 0.04535807, 0.04535695, 0.04535654,\n",
       "       0.04535753, 0.04535542, 0.04535763], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.std(jnp.reshape(posterior[1], (n_chains*1000, 8)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 14.0s, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/2000)\n",
      "Sampling:   5% (100/2000)\n",
      "Sampling:  10% (200/2000)\n",
      "Sampling:  15% (300/2000)\n",
      "Sampling:  20% (400/2000)\n",
      "Sampling:  25% (500/2000)\n",
      "Sampling:  30% (600/2000)\n",
      "Sampling:  35% (700/2000)\n",
      "Sampling:  40% (800/2000)\n",
      "Sampling:  45% (900/2000)\n",
      "Sampling: 100% (2000/2000)\n",
      "Sampling: 100% (2000/2000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 3.1e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/httpstan_iz2dztdy/model_5srngrtw.stan', line 23, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 17.1906 seconds\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "import numpy as np\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "  int nv;                     // NUmber of Unique Villages\n",
    "  int NY;\n",
    "  matrix[nv, NY] Y;               // Predictors of Market integration\n",
    "\n",
    "}\n",
    "parameters {\n",
    "  vector[nv] offsets; // Market Integration offset.\n",
    "  vector[NY] means;  // Means for predictors of Market Integration\n",
    "  vector<lower = 0>[NY] sigmas; // Sigmas for Market Integration\n",
    "}\n",
    "model{\n",
    "  matrix[nv, NY] mu_l;\n",
    "  means ~ normal(0, 1);\n",
    "  offsets ~ normal(0, 1);\n",
    "  sigmas ~ exponential(1);\n",
    "  \n",
    "  for(k in 1:NY){\n",
    "    for( i in 1:nv ){\n",
    "      mu_l[i,k] = means[k] + offsets[i];\n",
    "    }\n",
    "    Y[,k] ~ normal( mu_l[,k] , sigmas[k]);\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "data = {\n",
    "    'nv' :NV,\n",
    "    'NY' : NY,\n",
    "    'Y' : Y2\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=1000, num_warmup = 1000)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial model with random factors\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfpLigth import*\n",
    "import pandas as pd\n",
    "d = pd.read_csv('jeff/small_dat.csv')\n",
    "d = d.iloc[0:500, :]\n",
    "d.shape\n",
    "cats = d.iloc[:,1:62]\n",
    "N = d.shape[0]\n",
    "K = d.K.unique()[0]-1\n",
    "ni = d.ni.unique()[0]-1\n",
    "i_ID = jnp.array(d.i_ID.values)\n",
    "y = jnp.array(cats)\n",
    "\n",
    "\n",
    "#a = Normal(0, 1).sample(seed = init_key, sample_shape=K)\n",
    "#L_individual = LKJ(int(ni), int(ni)).sample(seed = init_key, sample_shape=())\n",
    "#Sigma_individual = Exponential(1).sample(seed = init_key, sample_shape=ni)\n",
    "#z_individual = Normal(0, 1).sample(seed = init_key, sample_shape=(ni, K))\n",
    "#b_individual = random_centered(Sigma_individual, L_individual, z_individual)\n",
    "#random_effect = b_individual[i_ID]\n",
    "#p = jnp.stack([a + random_effect])\n",
    "#y = DirichletMultinomial(N, softmax_fn(p)).sample(seed = init_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    a = yield normal(K, 0, 1)\n",
    "    L_individual = yield lkj((), ni, concentration = 1.5) \n",
    "    Sigma_individual = yield exponential(ni, 1)\n",
    "    z_individual = yield normal((ni, K), 0, 1)\n",
    "    rf = random_centered(Sigma_individual, L_individual, z_individual)[i_ID]\n",
    "    y = yield tfd.Independent(DirichletMultinomial (N, jnp.exp(a + rf)), reinterpreted_batch_ndims =  1)\n",
    "    \n",
    "tensor = JointDistributionCoroutineAutoBatched(model)\n",
    "init_params = tensor.sample(seed = init_key)\n",
    "tensor.log_prob(init_params)\n",
    "y = jnp.array(cats.values)\n",
    "#tensor.sample(seed = init_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 7.8645 seconds\n"
     ]
    }
   ],
   "source": [
    "posterior, sample_stats = NUTSdual(model, obs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.05615622, -0.6663588 ,  1.3982416 ,  0.62313735,  0.8350297 ,\n",
       "         1.0651187 , -0.7151321 ,  1.7792015 ,  0.8875723 , -1.3659457 ,\n",
       "         1.3132203 , -0.28332764, -0.62546504, -1.1582158 , -0.09721471,\n",
       "         0.7409373 ,  1.19223   ,  1.0297832 , -0.8839252 , -0.03948881,\n",
       "         1.0382149 , -0.8449937 , -0.4245596 , -0.49214274,  0.05853189,\n",
       "        -0.59798425, -1.0161266 ,  0.02900102, -0.6771232 , -0.63163674,\n",
       "         1.1186483 , -0.05101798, -0.86955243, -0.52079815,  0.23145588,\n",
       "         0.6927144 , -0.14934132,  0.06697238, -0.8134827 , -0.37827206,\n",
       "         0.05702852, -0.44461018,  0.8572168 ,  0.10744796, -0.36828473,\n",
       "        -0.6958005 , -0.06352754,  0.60554266, -0.92917377, -0.86278415,\n",
       "        -1.035126  ,  0.08371376, -0.10018361,  0.190146  ,  1.3295493 ,\n",
       "        -0.13258067,  0.60345596,  1.1266363 ,  0.23537996,  1.2127706 ,\n",
       "        -1.139107  ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.39305568e+00, 4.00237083e-01, 9.16378573e-02, 9.61950302e-01,\n",
       "        1.23204792e+00, 5.86139038e-02, 5.67673540e+00, 1.12955308e+00,\n",
       "        1.39652896e+00, 7.06040442e-01, 6.80083394e-01, 4.96822521e-02,\n",
       "        2.34810889e-01, 1.57803154e+00, 8.98694038e-01, 4.48252261e-01,\n",
       "        5.60243070e-01, 1.31814384e+00, 1.27323282e+00, 5.02183914e-01,\n",
       "        1.16391730e+00, 5.32268941e-01, 1.99821904e-01, 8.40371072e-01,\n",
       "        5.34804344e-01, 8.28324378e-01, 2.20273569e-01, 4.65340525e-01,\n",
       "        2.11460352e+00, 2.39558756e-01, 2.15173721e-01, 1.52623761e+00,\n",
       "        7.44600371e-02, 1.06354833e+00, 1.02381873e+00, 8.56124878e-01,\n",
       "        4.03137714e-01, 4.53552151e+00, 1.49732322e-01, 5.20960391e-01,\n",
       "        1.44391584e+00, 7.37378359e-01, 4.18330789e-01, 1.50932145e+00,\n",
       "        2.56037444e-01, 8.42307657e-02, 6.79948747e-01, 6.76697642e-02,\n",
       "        6.20886266e-01, 1.25371933e+00, 2.13660502e+00, 1.45660892e-01,\n",
       "        5.20948600e-03, 3.19303441e+00, 1.41794002e+00, 4.28807449e+00,\n",
       "        7.00193048e-01, 7.50313222e-01, 1.09112948e-01, 6.57162368e-01,\n",
       "        2.00137377e+00, 1.36129963e+00, 8.73416066e-01, 2.30703211e+00,\n",
       "        1.87436461e+00, 9.32609797e-01, 9.90902007e-01, 9.18763459e-01,\n",
       "        3.22543323e-01, 4.82659459e-01, 8.97863388e-01, 2.55676031e-01,\n",
       "        4.59441245e-01, 6.81911647e-01, 1.48731041e+00, 1.53939235e+00,\n",
       "        1.70396894e-01, 3.21135759e+00, 3.94004881e-01, 4.64242816e-01,\n",
       "        1.08022451e-01, 1.22850215e+00, 1.06806922e+00, 3.69260997e-01,\n",
       "        9.71607208e-01, 9.19239163e-01, 5.22754669e-01, 4.81553435e-01,\n",
       "        2.39773130e+00, 1.80654132e+00, 1.03257358e+00, 1.20243967e+00,\n",
       "        1.55485964e+00, 1.70483458e+00, 3.64543013e-02, 3.49967003e-01,\n",
       "        1.67760074e+00, 7.16804147e-01, 8.61451209e-01, 1.03050721e+00,\n",
       "        2.09644699e+00, 7.71911740e-01, 1.08946609e+00, 6.20375313e-02,\n",
       "        1.88971925e+00, 1.72338092e+00, 3.66082221e-01, 1.76280367e+00,\n",
       "        1.63644886e+00, 5.37831187e-01, 2.09306970e-01, 1.79213449e-01,\n",
       "        5.26920438e-01, 5.14558494e-01, 2.02021790e+00, 1.33286881e+00,\n",
       "        1.78939462e+00, 5.30331194e-01, 7.07484245e-01, 1.20269072e+00,\n",
       "        1.43305612e+00, 2.19038725e-01, 1.90202701e+00, 1.18180954e+00,\n",
       "        3.15664291e+00, 3.52972522e-02, 1.26905274e+00, 1.20853767e-01,\n",
       "        1.19533217e+00, 8.58804464e-01, 1.96929932e-01, 1.28207600e+00,\n",
       "        8.52940559e-01, 9.32480872e-01, 2.39005834e-01, 6.92055300e-02,\n",
       "        1.04018998e+00, 7.09534347e-01, 1.18820119e+00, 6.36141896e-01,\n",
       "        8.30823064e-01, 1.24931586e+00, 8.15641403e-01, 3.51474464e-01,\n",
       "        4.83187437e-02, 3.07617396e-01, 1.90744424e+00, 4.18928623e+00,\n",
       "        2.23898679e-01, 1.00479507e+00, 1.81203842e+00, 2.30749231e-02,\n",
       "        4.19143677e-01, 8.42748761e-01, 9.13206264e-02, 7.64119029e-01,\n",
       "        5.74245006e-02, 2.36732036e-01, 4.76063758e-01, 1.18585384e+00,\n",
       "        5.71269589e-03, 1.01349938e+00, 1.84074843e+00, 8.59545112e-01,\n",
       "        4.31468368e-01, 4.57208037e-01, 6.81886971e-01, 3.78456324e-01,\n",
       "        3.00244784e+00, 7.00401366e-01, 3.98731053e-01, 6.21704280e-01,\n",
       "        7.76228070e-01, 1.12544671e-01, 8.46903920e-01, 3.69382888e-01,\n",
       "        1.42359686e+00, 2.39335895e+00, 4.77267325e-01, 9.05149877e-02,\n",
       "        2.02080727e-01, 2.60388345e-01, 6.06457412e-01, 8.99610758e-01,\n",
       "        5.74381232e-01, 6.28923476e-01, 9.23755646e-01, 2.97450602e-01,\n",
       "        2.30223894e-01, 4.63534355e-01, 4.06005383e+00, 1.13211846e+00,\n",
       "        5.41286409e-01, 1.56976521e+00, 2.45317712e-01, 2.90908480e+00,\n",
       "        1.41602397e-01, 4.27233428e-02, 6.24828517e-01, 1.28547120e+00,\n",
       "        1.25637090e+00, 1.39252711e-02, 5.20790160e-01, 1.00091316e-01,\n",
       "        1.76074588e+00, 9.57833111e-01, 9.64633226e-01, 1.77057457e+00,\n",
       "        1.81938720e+00, 1.13749528e+00, 6.86784446e-01, 9.72197413e-01,\n",
       "        9.44058418e-01, 5.28344661e-02, 6.95900321e-01, 9.42330658e-01,\n",
       "        1.06101978e+00, 5.30459523e-01, 2.25312066e+00, 2.08276176e+00,\n",
       "        1.09121418e+00, 5.63487053e-01, 3.71093929e-01, 7.19130516e-01,\n",
       "        1.14468420e+00, 1.77376568e+00, 2.89172387e+00, 1.08109720e-01,\n",
       "        3.31926048e-01, 1.55037448e-01, 1.61972523e+00, 7.44949803e-02,\n",
       "        8.48898649e-01, 3.29133928e-01, 5.70056081e-01, 1.10480309e+00,\n",
       "        1.19396389e+00, 3.43733765e-02, 6.71622038e-01, 6.55422211e-02,\n",
       "        2.11405039e+00, 4.80755046e-02, 3.46504539e-01, 3.14490247e+00,\n",
       "        2.99108124e+00, 3.42339754e+00, 5.61786853e-02, 3.24070764e+00,\n",
       "        9.28404570e-01, 7.09155276e-02, 3.90204430e-01, 1.55069911e+00,\n",
       "        4.47355300e-01, 1.16783857e-01, 3.66326004e-01, 5.79109251e-01,\n",
       "        9.40452397e-01, 2.57550406e+00, 1.24015260e+00, 3.36838096e-01,\n",
       "        2.98173159e-01, 9.93341357e-02, 2.52893424e+00, 1.38430250e+00,\n",
       "        3.99840057e-01, 1.64067358e-01, 4.92573045e-02, 7.93023705e-01,\n",
       "        7.19614327e-01, 6.17216229e-01, 2.53319693e+00, 3.09292614e-01,\n",
       "        8.92360628e-01, 6.78706229e-01, 1.86720699e-01, 6.97701156e-01,\n",
       "        9.56079245e-01, 2.61198592e+00, 3.78601098e+00, 1.21502686e+00,\n",
       "        1.53909373e+00, 8.27039838e-01, 6.85946226e-01, 1.86782432e+00,\n",
       "        3.84220123e-01, 2.65481263e-01, 9.29033399e-01, 3.32954109e-01,\n",
       "        1.22202110e+00, 5.59242785e-01, 1.05781436e-01, 4.02484000e-01,\n",
       "        3.38718116e-01, 5.00017226e-01, 1.90306112e-01, 2.08682805e-01,\n",
       "        1.46614516e+00, 3.93665016e-01, 1.94499409e+00, 2.25266314e+00,\n",
       "        3.00390291e+00, 6.69875741e-01, 2.83935815e-01, 3.23674023e-01,\n",
       "        1.35473385e-01, 6.16096139e-01, 8.14195693e-01, 7.95604646e-01,\n",
       "        3.98160458e-01, 1.42552257e+00, 2.92626411e-01, 1.83558427e-02,\n",
       "        6.42436922e-01, 2.26175141e+00, 4.25618142e-01, 5.76775610e-01,\n",
       "        7.34907269e-01, 3.23184609e+00, 1.39913321e-01, 4.60579425e-01,\n",
       "        1.26087785e+00, 6.59429491e-01, 1.08177459e+00, 3.56799543e-01,\n",
       "        8.28201294e-01, 1.05477178e+00, 4.81755793e-01, 2.52200402e-02,\n",
       "        2.46755838e+00, 1.13607168e-01, 5.27163982e-01, 2.10987747e-01,\n",
       "        1.28459764e+00, 1.57018691e-01, 1.88232386e+00, 1.41001058e+00,\n",
       "        8.77423108e-01, 5.11012137e-01, 1.42502323e-01, 3.06394607e-01,\n",
       "        1.83502913e-01, 2.79791260e+00, 1.52085155e-01, 3.18431202e-03,\n",
       "        7.72885680e-01, 1.06187621e-02, 2.01663780e+00, 3.27437937e-01,\n",
       "        1.60584831e+00, 1.07545829e+00, 1.70927048e+00, 1.38648558e+00,\n",
       "        1.42705369e+00, 7.79287100e-01, 5.63881576e-01, 1.46457955e-01,\n",
       "        9.33773875e-01, 1.55499208e+00, 7.68961668e-01, 2.06680730e-01,\n",
       "        3.13316807e-02, 2.33243990e+00, 1.82291663e+00, 5.30271173e-01,\n",
       "        1.00829355e-01, 7.75401056e-01, 9.07002315e-02, 7.62177527e-01,\n",
       "        6.28844380e-01, 1.44175351e+00, 5.66238258e-03, 2.76950806e-01,\n",
       "        2.27598023e+00, 5.57843268e-01, 1.55414313e-01, 1.18940735e+00,\n",
       "        1.99445975e+00, 6.35097563e-01, 1.52445054e+00, 1.53682339e+00,\n",
       "        7.60891616e-01, 3.44374716e-01, 2.51826078e-01, 1.90529823e+00,\n",
       "        1.63220584e+00, 1.01011467e+00, 7.69811988e-01, 5.11708796e-01,\n",
       "        7.80561447e-01, 5.98218441e-01, 2.97206116e+00, 1.72629571e+00,\n",
       "        1.25325788e-02, 1.03249633e+00, 5.58736444e-01, 4.88280773e-01,\n",
       "        7.39589751e-01, 3.98670703e-01, 2.92439795e+00, 8.90847266e-01,\n",
       "        1.41322327e+00, 5.36606729e-01, 1.72734845e+00, 1.09466732e+00]],      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior[2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n",
      "(404, 404)\n",
      "(404,)\n",
      "(404, 61)\n",
      "(500, 61)\n",
      "(61,)\n",
      "(404, 404)\n",
      "(404,)\n",
      "(404, 61)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "for a in init_params:\n",
    "    print(a.shape)\n",
    "\n",
    "init_params2 = []\n",
    "init_params2.append(jnp.array(jnp.ones_like(init_params[0])))\n",
    "init_params2.append(jnp.array(jnp.eye(ni)))\n",
    "init_params2.append(jnp.array(jnp.ones_like(init_params[2])))\n",
    "init_params2.append(jnp.array(jnp.ones_like(init_params[3])))\n",
    "\n",
    "for a in init_params2:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tfp.bijectors.Identity 'identity' batch_shape=[] forward_min_event_ndims=0 inverse_min_event_ndims=0 dtype_x=? dtype_y=?>,\n",
       " <tfp.bijectors.CorrelationCholesky 'correlation_cholesky' batch_shape=[] forward_min_event_ndims=1 inverse_min_event_ndims=2 dtype_x=? dtype_y=?>,\n",
       " <tfp.bijectors.Exp 'exp' batch_shape=[] forward_min_event_ndims=0 inverse_min_event_ndims=0 dtype_x=? dtype_y=?>,\n",
       " <tfp.bijectors.Identity 'identity' batch_shape=[] forward_min_event_ndims=0 inverse_min_event_ndims=0 dtype_x=? dtype_y=?>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "bijectors = []\n",
    "bijectors.append(tfp.bijectors.Identity())\n",
    "bijectors.append(tfp.bijectors.CorrelationCholesky(ni))\n",
    "bijectors.append(tfp.bijectors.Exp())\n",
    "bijectors.append(tfp.bijectors.Identity())\n",
    "bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_tril(x):\n",
    "    n = x.shape[0]\n",
    "    return x[jnp.tril_indices(n)]\n",
    "\n",
    "dist = tfp.distributions.CholeskyLKJ(dimension=50, concentration= 1000)\n",
    "bijector = dist.experimental_default_event_space_bijector()\n",
    "s = dist.sample(seed = init_key)\n",
    "bijector.forward(pack_tril(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DualAveragingStepSizeAdaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_fn(_, pkr):\n",
    "    return (\n",
    "        pkr.inner_results.target_log_prob,\n",
    "        pkr.inner_results.leapfrogs_taken,\n",
    "        pkr.inner_results.has_divergence,\n",
    "        pkr.inner_results.energy,\n",
    "        pkr.inner_results.log_accept_ratio\n",
    "    )\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (y,))\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    inner_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob,\n",
    "        step_size= 1e-3\n",
    "    )\n",
    "    #hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "    #    inner_kernel,\n",
    "    #    target_accept_prob=.8,\n",
    "    #    num_adaptation_steps=int(0.8*500),\n",
    "    #    step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "    #        step_size=new_step_size\n",
    "    #    ),\n",
    "    #    step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "    #    log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,\n",
    "    #)\n",
    "    kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "            inner_kernel=inner_kernel,\n",
    "            bijector=bijectors\n",
    "        )\n",
    "    #hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "    #    inner_kernel,\n",
    "    #    target_accept_prob=.8,\n",
    "    #    num_adaptation_steps=int(0.8*500),\n",
    "    #    step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "    #        step_size=new_step_size\n",
    "    #    ),\n",
    "    #    step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "    #    log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,\n",
    "    #)\n",
    "    return tfp.mcmc.sample_chain(num_results = 500,\n",
    "                                 num_steps_between_results = 0,\n",
    "                                 current_state= init_params2,\n",
    "                                 kernel=kernel,\n",
    "                                 trace_fn=trace_fn,\n",
    "                                 num_burnin_steps=500,\n",
    "                                 parallel_iterations = 0,\n",
    "                                 seed=key)\n",
    "\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 1)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import time as tm\n",
    "import arviz as az\n",
    "import tensorflow as tf\n",
    "\n",
    "def trace_fn(_, pkr):\n",
    "    return (\n",
    "        pkr.target_log_prob,\n",
    "        pkr.leapfrogs_taken,\n",
    "        pkr.has_divergence,\n",
    "        pkr.energy,\n",
    "        pkr.log_accept_ratio\n",
    "    )\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (y,))\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    inner_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob,\n",
    "        step_size= 1e-3\n",
    "    )\n",
    "    kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "            inner_kernel=inner_kernel,\n",
    "            bijector=bijectors\n",
    "        )\n",
    "    hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "        kernel,\n",
    "        target_accept_prob=.8,\n",
    "        num_adaptation_steps=int(0.8*500),\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "              inner_results=pkr.inner_results._replace(step_size=new_step_size)\n",
    "          ),\n",
    "        step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,\n",
    "    )\n",
    "    return tfp.mcmc.sample_chain(500,\n",
    "        current_state= init_params2,\n",
    "        kernel=hmc,\n",
    "        trace_fn=trace_fn,\n",
    "        num_burnin_steps=500,\n",
    "        parallel_iterations = 10,\n",
    "        seed=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 1)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'distribution': 'normal'},\n",
       " 'L_individual': {'distribution': 'lkj'},\n",
       " 'Sigma_individual': {'distribution': 'exponential'},\n",
       " 'z_individual': {'distribution': 'normal'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distributions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mposterior\u001b[49m[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "jnp.mean(posterior[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.00011063e+00,  1.52363613e-01, -8.19926485e-02,\n",
       "         1.30560052e+00,  1.69159555e+00,  1.07562788e-01,\n",
       "         5.61449814e+00,  7.25113809e-01,  1.38531935e+00,\n",
       "         7.02273369e-01,  8.18800211e-01,  1.67456195e-01,\n",
       "         1.40602008e-01,  2.05478144e+00,  1.09147692e+00,\n",
       "         3.67792130e-01,  1.08147003e-01,  1.47573376e+00,\n",
       "         1.19409811e+00,  7.80298471e-01,  7.04531312e-01,\n",
       "         8.04857433e-01, -1.89564675e-02,  8.73912454e-01,\n",
       "         8.11408460e-01,  7.46483505e-01,  3.87466133e-01,\n",
       "         2.71474361e-01,  1.97974360e+00,  7.81769119e-03,\n",
       "        -2.70633269e-02,  1.76259911e+00,  2.34762058e-01,\n",
       "         1.29235864e+00,  1.05781448e+00,  9.74333525e-01,\n",
       "         1.79821968e-01,  4.79944563e+00,  4.40142214e-01,\n",
       "         3.85596037e-01,  1.76535356e+00,  6.98000252e-01,\n",
       "         6.21330917e-01,  1.93039691e+00,  8.25591013e-02,\n",
       "         1.17477439e-01,  7.71247864e-01,  1.39756957e-02,\n",
       "         4.82601136e-01,  4.87981230e-01,  2.13329816e+00,\n",
       "        -8.66590440e-02, -4.62611355e-02,  2.74643588e+00,\n",
       "         1.55734551e+00,  4.45019150e+00,  2.93812156e-01,\n",
       "         1.18459797e+00,  2.86396593e-01,  1.04916513e-01,\n",
       "         2.82301283e+00,  1.36191738e+00,  8.65207195e-01,\n",
       "         2.65292454e+00,  1.81592929e+00,  1.29018128e-02,\n",
       "         1.31935656e+00,  7.65937209e-01,  5.79058707e-01,\n",
       "         3.42853785e-01,  6.88882232e-01, -2.06889600e-01,\n",
       "         3.11831743e-01,  4.64900523e-01,  1.66376626e+00,\n",
       "         1.91726017e+00, -2.97606140e-01,  2.97101068e+00,\n",
       "         1.62931889e-01,  2.76069164e-01,  1.52634069e-01,\n",
       "         1.79530525e+00,  3.48292637e+00,  3.65578383e-01,\n",
       "         8.78959000e-01,  1.09887147e+00,  7.47079968e-01,\n",
       "         3.47651273e-01,  2.05929017e+00,  1.91147101e+00,\n",
       "         1.01795661e+00,  8.59111965e-01,  2.38097525e+00,\n",
       "         3.09456825e+00,  3.15505445e-01,  4.95176375e-01,\n",
       "         1.41536093e+00,  7.28506863e-01,  8.11068058e-01,\n",
       "         1.12492633e+00,  2.31597471e+00,  4.85489756e-01,\n",
       "         9.83789146e-01, -2.70481277e-02,  2.24516129e+00,\n",
       "         2.57193375e+00,  1.81236371e-01,  1.93529034e+00,\n",
       "         1.82007527e+00,  1.34791777e-01,  3.00252944e-01,\n",
       "         3.03651780e-01,  4.99903649e-01,  5.45288980e-01,\n",
       "         2.43640208e+00,  1.30598509e+00,  1.73499990e+00,\n",
       "         6.30528212e-01,  5.32030225e-01,  7.19696462e-01,\n",
       "         1.78401375e+00,  5.46380520e-01,  1.85859752e+00,\n",
       "         1.44905448e+00,  3.05738449e+00,  2.27660924e-01,\n",
       "         1.84049547e+00, -1.02064662e-01,  1.31371248e+00,\n",
       "         1.08744252e+00,  2.63951540e-01,  1.18144155e+00,\n",
       "         5.84581316e-01,  1.38593388e+00,  4.57226694e-01,\n",
       "         3.31724547e-02,  8.19636643e-01,  6.70264781e-01,\n",
       "         8.03190231e-01,  5.51693499e-01,  1.11006379e+00,\n",
       "         1.26442301e+00,  7.77282774e-01,  3.86602491e-01,\n",
       "        -1.61940128e-01,  1.64865553e-01,  1.74086988e+00,\n",
       "         4.04447556e+00,  5.53605407e-02,  8.48399222e-01,\n",
       "         1.54447806e+00, -4.51164633e-01,  3.60718042e-01,\n",
       "         1.14008403e+00,  3.45933557e-01,  5.98839760e-01,\n",
       "        -9.13165510e-02,  1.55364051e-01,  3.35817754e-01,\n",
       "         1.37384987e+00,  2.13047713e-01,  1.21436214e+00,\n",
       "         2.76720810e+00,  6.89217329e-01,  2.77340680e-01,\n",
       "        -1.13634206e-02,  5.39868414e-01,  3.15435439e-01,\n",
       "         3.48763990e+00,  1.04646552e+00,  8.67709100e-01,\n",
       "         2.15698034e-01,  5.05777240e-01, -4.77306284e-02,\n",
       "         8.08692515e-01,  2.39186078e-01,  1.44495738e+00,\n",
       "         2.31234121e+00,  5.05027056e-01,  1.72673404e-01,\n",
       "         5.12554944e-01,  7.42170438e-02,  3.30845714e-01,\n",
       "         6.24673605e-01,  4.08148885e-01,  6.91868544e-01,\n",
       "         9.63368773e-01,  2.09945142e-01,  1.29809543e-01,\n",
       "         4.61880833e-01,  4.37108517e+00,  1.17105329e+00,\n",
       "         7.17421591e-01,  1.89079833e+00,  3.64192098e-01,\n",
       "         3.36541605e+00, -5.19909374e-02, -2.04431355e-01,\n",
       "         6.55389309e-01,  1.84704351e+00,  3.21097404e-01,\n",
       "        -3.67126465e-02,  4.54816490e-01, -2.69497242e-02,\n",
       "         1.52453244e+00,  4.77184832e-01,  1.31252182e+00,\n",
       "         1.52293169e+00,  2.61695528e+00,  1.45244467e+00,\n",
       "         7.14327812e-01,  1.08988118e+00,  7.89151788e-01,\n",
       "        -2.95257807e-01,  1.04579568e+00,  1.24564326e+00,\n",
       "         7.89216697e-01,  2.73962706e-01,  1.70029414e+00,\n",
       "         1.92770863e+00,  6.77106321e-01,  3.67815584e-01,\n",
       "         1.06314629e-01,  9.58579481e-01,  1.46572065e+00,\n",
       "         2.03382325e+00,  3.20294404e+00, -3.02607119e-01,\n",
       "         4.58318144e-01, -1.69193968e-01,  1.14857781e+00,\n",
       "        -1.20720416e-01,  5.81914186e-01,  3.18557054e-01,\n",
       "         5.09618163e-01,  1.00031650e+00,  1.27389872e+00,\n",
       "        -1.76999971e-01,  1.19868588e+00, -7.59942085e-02,\n",
       "         2.50072694e+00,  1.53291592e-04,  5.47542572e-01,\n",
       "         2.92207503e+00,  2.90852022e+00,  3.70450425e+00,\n",
       "         1.22533282e-02,  3.61546206e+00,  1.09131706e+00,\n",
       "        -1.08176365e-01,  2.31861040e-01,  1.79252493e+00,\n",
       "         6.01725936e-01, -3.73060912e-01,  6.95920050e-01,\n",
       "         3.61375153e-01,  1.24440992e+00,  2.75441575e+00,\n",
       "         1.23682594e+00,  3.45475614e-01,  6.07280135e-02,\n",
       "         1.10419594e-01,  2.81764579e+00,  1.48524237e+00,\n",
       "         1.08497933e-01, -2.74036806e-02, -1.78914160e-01,\n",
       "         6.39475107e-01,  2.97694176e-01,  3.47986579e-01,\n",
       "         2.39259267e+00, -3.61951767e-03,  8.52226973e-01,\n",
       "         5.16763747e-01, -9.17025805e-02,  8.81695986e-01,\n",
       "         1.34371591e+00,  2.78804135e+00,  3.83157849e+00,\n",
       "         8.37278843e-01,  1.57223427e+00,  8.08427155e-01,\n",
       "         5.81225276e-01,  2.39059782e+00,  5.10621130e-01,\n",
       "         1.33607671e-01,  7.40751028e-01,  4.38836068e-01,\n",
       "         5.43378949e-01,  5.85421443e-01,  4.89837438e-01,\n",
       "         1.73586197e-02,  2.57405281e-01,  5.01068652e-01,\n",
       "         2.47812256e-01, -9.28822998e-03,  1.63435566e+00,\n",
       "         5.07049024e-01,  1.65232432e+00,  2.10572958e+00,\n",
       "         3.25365782e+00,  1.19655716e+00,  2.41037328e-02,\n",
       "         1.01336967e-02,  4.29612875e-01,  3.68240744e-01,\n",
       "         8.40838909e-01,  7.00821459e-01,  3.48587811e-01,\n",
       "         4.12717199e+00,  1.66625768e-01, -6.12409711e-02,\n",
       "         3.46792758e-01,  2.17970610e+00,  1.55925274e-01,\n",
       "         7.47651219e-01,  1.13710380e+00,  3.03170800e+00,\n",
       "         5.39831631e-02,  6.40197992e-01,  9.51360822e-01,\n",
       "         4.95555371e-01,  6.92281663e-01,  6.89658463e-01,\n",
       "         9.91732895e-01,  1.20548165e+00,  7.07845390e-01,\n",
       "         7.98055902e-02,  2.01270032e+00, -3.68090898e-01,\n",
       "         1.78702861e-01,  1.64311647e-01,  1.11837435e+00,\n",
       "         9.97360870e-02,  1.90568388e+00,  1.42811728e+00,\n",
       "         4.43105429e-01,  3.77855718e-01,  1.80292904e-01,\n",
       "        -5.25900628e-03, -9.91890952e-02,  3.00731015e+00,\n",
       "         2.65690804e-01, -1.67632848e-01,  9.77729917e-01,\n",
       "         6.43254593e-02,  2.36468029e+00,  8.14338699e-02,\n",
       "         1.61639643e+00,  9.10662174e-01,  1.32031524e+00,\n",
       "         1.65400302e+00,  1.61312973e+00,  9.62255001e-01,\n",
       "         5.29228628e-01, -6.86924309e-02,  9.23011541e-01,\n",
       "         1.70784366e+00,  5.10611117e-01,  2.95521438e-01,\n",
       "         2.78931826e-01,  2.42586398e+00,  1.36990178e+00,\n",
       "         3.85085464e-01,  3.15421224e-01,  9.11320627e-01,\n",
       "        -2.73646206e-01,  4.28651392e-01,  5.02963364e-01,\n",
       "         1.59733939e+00, -5.57289049e-02,  5.82559891e-02,\n",
       "         2.32655263e+00,  6.06282055e-01,  1.14265397e-01,\n",
       "         1.27429652e+00,  2.07791376e+00,  3.06163400e-01,\n",
       "         1.68849790e+00,  1.01697171e+00,  7.11153746e-01,\n",
       "        -5.32659851e-02, -3.00917402e-02,  2.18461585e+00,\n",
       "         1.33550155e+00,  1.04296982e+00,  5.00572979e-01,\n",
       "         1.08076525e+00,  6.03593051e-01,  6.91650435e-02,\n",
       "         2.63003802e+00,  1.41420567e+00, -6.29072264e-02,\n",
       "         1.10806692e+00,  1.05568516e+00,  5.36263824e-01,\n",
       "         8.86076450e-01,  4.78498250e-01,  3.02960420e+00,\n",
       "         1.04311597e+00,  1.55277133e+00,  2.25848958e-01,\n",
       "         1.98795640e+00,  1.10697031e+00]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior[2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NoUTurnSampler alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 65.5614 seconds\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import time as tm\n",
    "import arviz as az\n",
    "import tensorflow as tf\n",
    "\n",
    "def trace_fn(_, pkr): \n",
    "    return (\n",
    "        pkr.target_log_prob,\n",
    "        pkr.leapfrogs_taken,\n",
    "        pkr.has_divergence,\n",
    "        pkr.energy,\n",
    "        pkr.log_accept_ratio\n",
    "    )\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (y,))\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(target_log_prob, 1e-3)\n",
    "    return tfp.mcmc.sample_chain(500,\n",
    "        current_state= list(init_params)[:-1],\n",
    "        kernel=kernel,\n",
    "        trace_fn=trace_fn,\n",
    "        num_burnin_steps=500,\n",
    "        num_steps_between_results=0,\n",
    "        parallel_iterations = 10,\n",
    "        seed=key)\n",
    "\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 1)\n",
    "posterior2, sample_stats2 =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.4034606 , -1.1346765 ,  3.1924434 ,  0.66932553,  0.29799238,\n",
       "         0.2610749 ,  1.1627609 ,  2.1540978 ,  0.755107  ,  0.34156126,\n",
       "        -1.9521594 ,  0.1922808 ,  0.4180533 ,  0.2577459 ,  0.85660046,\n",
       "        -0.20592761, -1.2806857 , -0.8093615 ,  0.22852236,  1.2358865 ,\n",
       "         0.20555732, -0.14507087,  0.40217265,  1.0788429 ,  0.16350324,\n",
       "        -0.32166687, -1.3233563 , -1.5742496 , -0.46665955, -1.6789967 ,\n",
       "        -0.40845045, -0.37225986,  0.83301395, -2.09396   ,  0.06795674,\n",
       "         0.8595675 , -0.26314002, -0.0997107 ,  0.30717713,  0.23148885,\n",
       "         0.58175015, -0.328513  ,  0.09458601, -0.86974055, -0.80295664,\n",
       "         0.31401294,  0.82015616, -1.4378055 ,  0.22307374, -1.1262819 ,\n",
       "         1.1855804 , -1.6594874 , -1.7892952 , -0.5960501 , -1.2052361 ,\n",
       "        -0.5336667 , -0.78277445,  0.54185206,  0.10923031,  0.24993883,\n",
       "        -1.7556491 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior2[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.0478522 ,  4.6168027 ,  0.806246  ,  0.55435085,  1.2124165 ,\n",
       "         0.8402238 ,  1.1997579 ,  0.98817277,  0.11052682,  0.2415265 ,\n",
       "         0.6984694 ,  1.5758113 ,  0.73051775,  0.90180707,  0.36751804,\n",
       "         1.8084208 ,  0.30072904,  1.7485197 ,  0.3310387 ,  3.2664084 ,\n",
       "         0.23499492,  1.7388225 ,  0.6527658 , -0.07837035,  0.34133258,\n",
       "         1.0495123 , -0.03347005,  0.22365609, -0.06160263,  0.02182482,\n",
       "         0.24581675,  0.2452248 ,  0.11328835, -0.00920524,  0.09503133,\n",
       "         0.4557928 ,  0.889498  ,  0.17996153,  1.4649534 ,  0.5534055 ,\n",
       "         0.34939644,  0.6987182 ,  0.07868992,  0.15423095,  0.34984213,\n",
       "         0.98378724,  1.4895471 ,  2.5004003 , -0.15299293,  1.1412724 ,\n",
       "         0.6278556 ,  4.218789  ,  0.06748012,  1.3979177 , -0.20704472,\n",
       "        -0.09186274,  0.27757788,  0.14808482,  4.34597   ,  0.6803724 ,\n",
       "         0.10426059,  0.27552757,  0.8812772 , -0.07327913,  0.29115772,\n",
       "         1.0235922 ,  1.5615855 ,  0.7755718 ,  0.14002296,  0.5935415 ,\n",
       "         1.0455781 ,  1.3754947 ,  0.74648476,  0.35607088,  0.05979594,\n",
       "        -0.03304157,  0.41025674,  0.67524576,  0.7746872 ,  0.76172006,\n",
       "         2.8357797 ,  1.3449075 ,  3.5658138 ,  0.90540314, -0.25127852,\n",
       "         2.6075714 ,  0.39419112,  0.9956985 ,  1.8229009 , -0.05598654,\n",
       "         0.4227555 , -0.15961345,  0.83883005,  1.103437  ,  0.89552593,\n",
       "         0.5515734 ,  2.4101896 ,  1.1804795 ,  0.76015276,  2.717074  ,\n",
       "         0.6837003 ,  3.580047  ,  0.88328916,  0.8516436 ,  0.95858157,\n",
       "         0.43662184,  0.5880488 ,  1.8629318 ,  1.0261188 ,  2.3641691 ,\n",
       "        -0.03890435,  1.6222223 ,  0.8967392 ,  1.2222679 ,  0.2744373 ,\n",
       "         0.8940262 ,  0.25947753,  0.93102163,  0.41385385,  0.01100837,\n",
       "         1.8639603 ,  3.0132625 ,  0.9283081 ,  0.05189595,  0.36394966,\n",
       "         1.0310949 , -0.17809053,  0.67600536,  0.29480842,  1.1294276 ,\n",
       "         1.4646497 ,  0.7983046 ,  1.6253309 ,  1.6689537 ,  3.378945  ,\n",
       "         0.7536391 ,  1.104159  ,  1.5012751 ,  0.9235762 ,  0.4695828 ,\n",
       "         1.3489484 ,  0.15436529,  1.0165697 , -0.06669938,  0.36417824,\n",
       "         0.38154367,  0.31256348, -0.09354031,  0.33668855,  0.73173773,\n",
       "        -0.14644165,  0.75786525, -0.08382038, -0.11473814, -0.36472383,\n",
       "         0.09400935,  1.0874072 ,  0.07123581,  1.7152008 ,  0.8753311 ,\n",
       "         0.30247608,  0.9361954 ,  0.8456723 ,  1.7121243 ,  3.5248165 ,\n",
       "         0.22329283, -0.10407532,  3.054299  ,  0.33028543,  2.384915  ,\n",
       "         0.45415762,  0.3382575 ,  1.655599  ,  0.721357  ,  0.3260242 ,\n",
       "         2.0087793 ,  0.4812682 ,  0.7730312 ,  0.26064345,  0.56914186,\n",
       "         1.3451542 ,  0.41708043,  1.5922469 , -0.2533481 , -0.12272815,\n",
       "         0.8552768 ,  0.7857298 ,  0.778051  , -0.25900373,  0.83973426,\n",
       "         2.8663938 ,  0.03955528,  2.8024914 ,  2.904956  ,  0.9842403 ,\n",
       "         0.46369088,  1.9622737 , -0.05293177,  0.4084151 , -0.14409284,\n",
       "         3.498964  ,  0.68551713,  2.7835524 ,  0.433315  ,  1.311589  ,\n",
       "         2.2647595 ,  1.444726  ,  0.7964218 ,  2.7304673 ,  0.5718453 ,\n",
       "         2.0686996 ,  0.6704159 ,  0.26335132,  0.6994492 ,  0.9907574 ,\n",
       "         0.31224772, -0.09074466,  0.97558767,  2.2589889 ,  1.4714888 ,\n",
       "         0.78585076,  1.3217437 ,  0.17361948,  2.0540423 ,  2.0694401 ,\n",
       "        -0.2748575 ,  1.3172107 , -0.24187607,  2.4366481 ,  0.39183274,\n",
       "         1.602468  ,  0.28284025,  0.80731183,  0.6835212 ,  0.7686502 ,\n",
       "         1.1393187 , -0.09037422,  0.6330765 ,  0.48002845,  0.68692034,\n",
       "         0.7331164 , -0.2507682 , -0.17012967,  0.8051198 ,  0.0274995 ,\n",
       "         0.5736766 ,  2.3437507 ,  0.70046294,  1.397053  ,  1.385097  ,\n",
       "         0.07082977, -0.12777765,  2.0305321 ,  0.9369836 ,  0.35357442,\n",
       "         0.9924404 ,  0.18528101,  0.17490806,  0.7090673 ,  0.50704914,\n",
       "         0.45638886,  1.5297271 , -0.12762666,  0.17773382,  0.9996716 ,\n",
       "         0.11672356,  0.9537453 ,  1.4544063 ,  0.0702305 ,  0.89387006,\n",
       "         2.0986345 ,  0.10299508,  2.1454363 ,  3.2499654 ,  0.9887215 ,\n",
       "         1.0687621 ,  0.27647522,  0.02018124,  2.1061726 ,  2.628175  ,\n",
       "         0.4646292 ,  1.0876511 ,  1.5383177 ,  0.3117372 ,  0.01980251,\n",
       "         0.42580009,  0.6445044 ,  3.0831013 ,  2.4847202 ,  0.23652622,\n",
       "         0.84855276,  0.9909876 ,  0.41353422,  1.5294669 ,  0.3605685 ,\n",
       "         0.25909638,  0.9813277 ,  0.06871748,  1.3619033 ,  1.2247864 ,\n",
       "         0.3325079 ,  0.00470063,  0.64800954,  1.0775975 , -0.27135742,\n",
       "         0.7565775 ,  0.33977896,  0.96298265, -0.01403107,  0.56797904,\n",
       "         1.5583267 ,  2.1164727 ,  0.2637795 ,  2.1909149 ,  0.30125847,\n",
       "         0.90085006,  1.8772565 ,  1.2769537 ,  0.05459809,  0.50138104,\n",
       "         0.15120597,  0.8817873 ,  0.0572528 ,  0.48516452,  2.13419   ,\n",
       "         0.31952015,  0.12125696,  0.0690634 ,  1.7098976 ,  0.13375099,\n",
       "         1.3020096 ,  0.46676847,  2.882701  ,  3.8249102 ,  0.37814522,\n",
       "         1.5731612 ,  1.1399256 ,  1.2921844 ,  1.2808567 ,  0.68726975,\n",
       "         0.38733223,  0.05203629,  1.0189786 ,  0.5667604 ,  2.9408834 ,\n",
       "         0.42009193,  1.227514  ,  1.9868697 , -0.16240074,  1.056389  ,\n",
       "         1.5137262 ,  0.64129853,  0.10348205,  0.13929605,  1.0643659 ,\n",
       "         0.48310453,  2.1540558 ,  0.59474564,  1.1234934 ,  0.6335578 ,\n",
       "         0.442079  ,  1.5873911 ,  0.47553083, -0.04841311,  0.66896087,\n",
       "         0.7029726 , -0.00675381,  3.7148657 ,  0.15498261,  0.23446418,\n",
       "         0.5403538 ,  0.4696929 , -0.1109065 ,  0.4738259 ,  0.17186755,\n",
       "         0.86908376,  0.30470705,  0.43277264,  0.10804185,  1.1844529 ,\n",
       "         1.7875715 ,  1.2195565 ,  1.5067183 ,  0.74883825,  0.8115828 ,\n",
       "         3.851524  ,  0.07896645,  0.35022438,  0.70054007,  0.15080653,\n",
       "        -0.07733624,  0.2132418 ,  0.90404326,  2.3410392 ,  1.2417352 ,\n",
       "         0.25679985,  0.4115453 ,  0.6924263 ,  0.6819361 , -0.05570461,\n",
       "         0.6214799 ,  0.9923679 ,  1.7473413 ,  0.13916229]],      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior2[2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:339: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
      "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 22.8215 seconds\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import time as tm\n",
    "import arviz as az\n",
    "import tensorflow as tf\n",
    "\n",
    "def trace_fn(_, pkr): \n",
    "    return (\n",
    "        pkr.accepted_results.target_log_prob,\n",
    "        pkr.accepted_results.grads_target_log_prob,\n",
    "        pkr.accepted_results.step_size,\n",
    "        pkr.accepted_results.num_leapfrog_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (y,))\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, 1e-1, 10)\n",
    "    return tfp.mcmc.sample_chain(500,\n",
    "        current_state= init_params2,\n",
    "        kernel=kernel,\n",
    "        num_burnin_steps=500,\n",
    "        num_steps_between_results=0,\n",
    "        parallel_iterations = 10,\n",
    "        seed=key)\n",
    "\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 1)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.mean(posterior[0][0], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfp_trace_to_arviz(posterior, \n",
    "                       sample_stats,\n",
    "                       var_names=None, \n",
    "                       sample_stats_name=['target_log_prob','log_accept_ratio','has_divergence','energy']):\n",
    "    sample_stats = {k:jnp.transpose(v) for k, v in zip(sample_stats_name, sample_stats)}\n",
    "    trace = {}\n",
    "    for name, samp in zip(var_names, posterior):\n",
    "        if len(samp.shape) == 2:\n",
    "            transposed_shape = [1, 0]\n",
    "        elif len(samp.shape) == 3:\n",
    "            transposed_shape = [1, 0, 2]\n",
    "        else:\n",
    "            transposed_shape = [1, 0, 2, 3]\n",
    "        trace[name] = jnp.transpose(samp, transposed_shape)\n",
    "    trace = az.from_dict(posterior=trace, sample_stats=sample_stats)\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.17075604,  1.8285818 ,  6.3930597 ,  2.7856152 ,  3.873021  ,\n",
       "        1.3441055 ,  4.9141088 ,  4.975928  ,  1.3707489 ,  0.9074946 ,\n",
       "        1.065346  , -0.57267505,  0.15803   ,  0.76278585,  0.43486223,\n",
       "       -0.37818164,  0.63879645,  0.31040657,  0.5697799 ,  1.9183769 ,\n",
       "        0.35863957,  0.58145314,  0.7731921 ,  1.4149554 ,  0.5291521 ,\n",
       "        0.49656555,  0.10120066, -0.41637665,  0.12319879,  0.29882768,\n",
       "        0.51487076,  0.6279278 , -0.6436342 ,  0.55903953,  0.70796525,\n",
       "        0.8988394 ,  0.2713415 ,  0.39486876,  0.5402932 ,  1.2942464 ,\n",
       "        0.61471254,  1.1930902 ,  0.12997414,  0.05739949,  0.15165846,\n",
       "        0.42393422,  1.2716974 ,  1.1720806 ,  0.5304543 ,  0.16477822,\n",
       "       -0.1437211 , -0.41688234,  0.13445722,  0.43528157,  0.4540864 ,\n",
       "       -0.27339825,  0.9640692 ,  0.97138035,  0.32671636, -0.26243827,\n",
       "        0.290654  ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior[0][0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'distribution': 'normal'},\n",
       " 'L_individual': {'distribution': 'lkj'},\n",
       " 'Sigma_individual': {'distribution': 'exponential'},\n",
       " 'z_individual': {'distribution': 'normal'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distributions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jnp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(posterior[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jnp' is not defined"
     ]
    }
   ],
   "source": [
    "jnp.mean(posterior[2][0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.02244424,  0.02372372,  0.01254549, ..., -0.00806769,\n",
       "         0.04312034,  0.02906288],\n",
       "       [-0.01077929, -0.02681718,  0.14075312, ..., -0.00851562,\n",
       "        -0.01562825, -0.04346808],\n",
       "       [-0.00653557,  0.0392372 ,  0.61479545, ..., -0.00072711,\n",
       "        -0.00114275,  0.04940834],\n",
       "       ...,\n",
       "       [-0.00932836, -0.03513107,  0.27523237, ...,  0.00347041,\n",
       "         0.00279914, -0.03963635],\n",
       "       [ 0.01323285, -0.01217053,  0.02402683, ..., -0.00835181,\n",
       "         0.04521772, -0.02022482],\n",
       "       [-0.01873912, -0.01516065,  0.01899397, ...,  0.00296601,\n",
       "         0.01532093, -0.03747469]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(posterior[3][0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n",
      "arviz - WARNING - Shape validation failed: input_shape: (500, 1), minimum_shape: (chains=1, draws=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>1.880</td>\n",
       "      <td>0.036</td>\n",
       "      <td>1.824</td>\n",
       "      <td>1.953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>6.302</td>\n",
       "      <td>0.036</td>\n",
       "      <td>6.228</td>\n",
       "      <td>6.363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>3.580</td>\n",
       "      <td>0.041</td>\n",
       "      <td>3.529</td>\n",
       "      <td>3.646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>4.079</td>\n",
       "      <td>0.035</td>\n",
       "      <td>4.016</td>\n",
       "      <td>4.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_individual[403, 56]</th>\n",
       "      <td>1.436</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.390</td>\n",
       "      <td>1.476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_individual[403, 57]</th>\n",
       "      <td>1.069</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_individual[403, 58]</th>\n",
       "      <td>0.276</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_individual[403, 59]</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_individual[403, 60]</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188325 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  \\\n",
       "a[0]                   0.271  0.058   0.188    0.353        NaN      NaN   \n",
       "a[1]                   1.880  0.036   1.824    1.953        NaN      NaN   \n",
       "a[2]                   6.302  0.036   6.228    6.363        NaN      NaN   \n",
       "a[3]                   3.580  0.041   3.529    3.646        NaN      NaN   \n",
       "a[4]                   4.079  0.035   4.016    4.139        NaN      NaN   \n",
       "...                      ...    ...     ...      ...        ...      ...   \n",
       "z_individual[403, 56]  1.436  0.028   1.390    1.476        NaN      NaN   \n",
       "z_individual[403, 57]  1.069  0.021   1.041    1.112        NaN      NaN   \n",
       "z_individual[403, 58]  0.276  0.072   0.177    0.384        NaN      NaN   \n",
       "z_individual[403, 59]  0.632  0.049   0.535    0.690        NaN      NaN   \n",
       "z_individual[403, 60]  0.015  0.035  -0.035    0.074        NaN      NaN   \n",
       "\n",
       "                       ess_bulk  ess_tail  r_hat  \n",
       "a[0]                        NaN       NaN    NaN  \n",
       "a[1]                        NaN       NaN    NaN  \n",
       "a[2]                        NaN       NaN    NaN  \n",
       "a[3]                        NaN       NaN    NaN  \n",
       "a[4]                        NaN       NaN    NaN  \n",
       "...                         ...       ...    ...  \n",
       "z_individual[403, 56]       NaN       NaN    NaN  \n",
       "z_individual[403, 57]       NaN       NaN    NaN  \n",
       "z_individual[403, 58]       NaN       NaN    NaN  \n",
       "z_individual[403, 59]       NaN       NaN    NaN  \n",
       "z_individual[403, 60]       NaN       NaN    NaN  \n",
       "\n",
       "[188325 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = tfp_trace_to_arviz(posterior = posterior, sample_stats = sample_stats, var_names = ['a', 'L_individual', 'Sigma_individual', 'z_individual', 'b_individual'])\n",
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data frame to dict for pystan\n",
    "tmp = d\n",
    "tmp.N = N\n",
    "df_with_y = tmp[[col for col in tmp.columns if col.startswith('y.')]]\n",
    "df_without_y = tmp[[col for col in tmp.columns if not col.startswith('y.')]]\n",
    "tmp2 = {}\n",
    "for col in df_without_y:\n",
    "    tmp2[str(col)]= df_without_y[col].values\n",
    "tmp2['y'] = df_with_y.values\n",
    "tmp2['N'] = N\n",
    "tmp2['K'] = 62\n",
    "tmp2['ni'] = len(jnp.unique(tmp2['i_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "import numpy as np\n",
    "try:\n",
    "  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "except:\n",
    "  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "    int<lower=0>  N;             // number of observations\n",
    "    int<lower=0>  K;             // number of occupations\n",
    "    int ni;                     // NUmber of Unique Individauls\n",
    "    array[N, K] int y;           // array of observed occupation indicators\n",
    "    array[N]int<lower=0>  i_ID;     // village indicator for each individual\n",
    "}\n",
    "parameters {\n",
    "    vector[K] a;                    // intercept for each occupation\n",
    "    matrix[ni, K]  z_individual;    // raw random effect for household \n",
    "    cholesky_factor_corr[ni] L_individual; // Cholesky factor for \n",
    "    vector<lower=0>[ni] Sigma_individual;\n",
    "\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[K, ni] b_individual;\n",
    "    b_individual = (diag_pre_multiply(Sigma_individual, L_individual) * z_individual)';\n",
    "}\n",
    "model{\n",
    "    array[N] vector[K] p;\n",
    "    matrix[K, N] random_effects;\n",
    "    to_vector(a) ~ normal(0, 1);\n",
    "    L_individual ~   lkj_corr_cholesky(2);\n",
    "    Sigma_individual ~ exponential(1);\n",
    "\n",
    "    to_vector(z_individual) ~ normal(0, 1);\n",
    "\n",
    "\n",
    "    // Likelihood for\n",
    "    for (k in 1:K) {\n",
    "        for (i in 1:N) {\n",
    "          random_effects[k, i] = b_individual[k, i_ID[i]];\n",
    "          p[i,k] =  a[k] + random_effects[k, i];\n",
    "      }\n",
    "    }\n",
    "\n",
    "    for (i in 1:(N)) {\n",
    "        y[i,] ~ dirichlet_multinomial(softmax(p[i,]));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = tmp2\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500, init = [{'L_individual': np.zeros((ni+1, ni+1))}])\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Number of households\n",
    "N = 25\n",
    "vector = list(range(N))\n",
    "# Generate all possible dyads\n",
    "dyads =  list(itertools.combinations(vector, 2))\n",
    "N_dyads = len(dyads)\n",
    "# Simulate \"friendships\" in which ties are shared\n",
    "f = np.random.binomial(1, 0.1, N_dyads)\n",
    "# Base rate of ties\n",
    "alpha = -3.0\n",
    "\n",
    "# Matrix of ties\n",
    "y = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if i != j:\n",
    "            ids = np.sort([i, j])\n",
    "            the_dyad = dyads.index(tuple(ids))\n",
    "            p_tie = f[the_dyad] + (1 - f[the_dyad]) * (1 / (1 + np.exp(-alpha)))\n",
    "            y[i, j] = np.random.binomial(1, p_tie)\n",
    "# now simulate gifts\n",
    "giftsAB = np.zeros(N_dyads)\n",
    "giftsBA = np.zeros(N_dyads)\n",
    "lambda_ = np.log([0.5, 2])  # rates of giving for y=0,y=1\n",
    "\n",
    "for i in range(N_dyads):\n",
    "    A = dyads[i][0]\n",
    "    B = dyads[i][1]\n",
    "    giftsAB[i] = np.random.poisson(np.exp(lambda_[int(y[A, B])]))\n",
    "    giftsBA[i] = np.random.poisson(np.exp(lambda_[int(y[B, A])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generated_functions import*\n",
    "links = np.ravel(y)\n",
    "links = jnp.array(links)\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "\n",
    "@jit\n",
    "def jax_LinearOperatorDiag(s, cov):    \n",
    "    def multiply_with_s(a):\n",
    "        return jnp.multiply(a, s)\n",
    "    vectorized_multiply = vmap(multiply_with_s)\n",
    "    return jnp.transpose(vectorized_multiply(cov))\n",
    "\n",
    "\n",
    "def model():\n",
    "    alpha = yield normal(1, 0, 1)\n",
    "    sigma = yield exponential(1, 1)\n",
    "    rho = yield lkj((), 2, 2)\n",
    "    T = yield multivariatenormaltril(N_dyads, jnp.concatenate([sigma,sigma]), jax_LinearOperatorDiag(sigma, rho))\n",
    "    rateAB = alpha + T[:,0]\n",
    "    gAB = yield Independent(Poisson(log_rate = rateAB))\n",
    "    rateBA = alpha + T[:,0]\n",
    "    gBA = yield Independent(Poisson(log_rate = rateBA))\n",
    "    \n",
    "tensor = JointDistributionCoroutineAutoBatched(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.sample(seed = init_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KosterLeckie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count  32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import jax\n",
    "Ncores = os.cpu_count()    \n",
    "xla_flags = os.getenv(\"XLA_FLAGS\", \"\")\n",
    "xla_flags = re.sub(r\"--xla_force_host_platform_device_count=\\S+\", \"\", xla_flags).split()\n",
    "os.environ[\"XLA_FLAGS\"] = \" \".join([\"--xla_force_host_platform_device_count={}\".format(Ncores)] + xla_flags)\n",
    "print('jax.local_device_count ',jax.local_device_count(backend=None))\n",
    "\n",
    "\n",
    "import pyreadr\n",
    "result = pyreadr.read_r('data/KosterLeckie.rda')\n",
    "d = result['kl_dyads']\n",
    "data = {\n",
    "    'N':  int(d.shape[0]),\n",
    "    'N_households' : int(d['hidB'].max()),\n",
    "    'did' : d['did'].values,\n",
    "    'hidA' : d['hidA'].values,\n",
    "    'hidB' : d['hidB'].values,\n",
    "    'giftsAB' : d['giftsAB'].values,\n",
    "    'giftsBA' : d['giftsBA'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_57ywd5k3/model_54hivnd7.stan', line 31, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/10000)\n",
      "Sampling:   0% (2/10000)\n",
      "Sampling:   0% (3/10000)\n",
      "Sampling:   0% (4/10000)\n",
      "Sampling:   1% (103/10000)\n",
      "Sampling:   2% (202/10000)\n",
      "Sampling:   3% (301/10000)\n",
      "Sampling:   4% (401/10000)\n",
      "Sampling:   5% (500/10000)\n",
      "Sampling:   6% (600/10000)\n",
      "Sampling:   7% (700/10000)\n",
      "Sampling:   8% (800/10000)\n",
      "Sampling:  10% (1000/10000)\n",
      "Sampling:  11% (1100/10000)\n",
      "Sampling:  12% (1200/10000)\n",
      "Sampling:  14% (1400/10000)\n",
      "Sampling:  36% (3600/10000)\n",
      "Sampling:  58% (5800/10000)\n",
      "Sampling:  79% (7900/10000)\n",
      "Sampling: 100% (10000/10000)\n",
      "Sampling: 100% (10000/10000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.000126 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.26 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.000127 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.27 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.000115 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.15 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.000119 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 1.19 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 28, column 4 to column 37)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_i1wnqqex/model_54hivnd7.stan', line 31, column 4 to column 27)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 34.4269 seconds\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "#try:\n",
    "#  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "#except:\n",
    "#  pass\n",
    "#\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    int N_households;\n",
    "    int N;\n",
    "    array[300] int giftsAB;\n",
    "    array[300] int giftsBA;\n",
    "    array[300] int did;\n",
    "    array[300] int hidA;\n",
    "    array[300] int hidB;\n",
    "}\n",
    "parameters{\n",
    "    real a;\n",
    "    array[N_households] vector[2] gr;\n",
    "    corr_matrix[2] Rho_gr;\n",
    "    vector<lower=0>[2] sigma_gr;\n",
    "    matrix[2,N] z;\n",
    "    cholesky_factor_corr[2] L_Rho_d;\n",
    "    real<lower=0> sigma_d;\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[N,2] d;\n",
    "    d = (diag_pre_multiply(rep_vector(sigma_d, 2), L_Rho_d) * z)';\n",
    "}\n",
    "model{\n",
    "    vector[300] lambdaAB;\n",
    "    vector[300] lambdaBA;\n",
    "    sigma_d ~ exponential( 1 );\n",
    "    L_Rho_d ~ lkj_corr_cholesky( 8 );\n",
    "    to_vector( z ) ~ normal( 0 , 1 );\n",
    "    sigma_gr ~ exponential( 1 );\n",
    "    Rho_gr ~ lkj_corr( 4 );\n",
    "    gr ~ multi_normal( rep_vector(0,2) , quad_form_diag(Rho_gr , sigma_gr) );\n",
    "    a ~ normal( 0 , 1 );\n",
    "    for ( i in 1:300 ) {\n",
    "        lambdaBA[i] = a + gr[hidB[i], 1] + gr[hidA[i], 2] + d[did[i], 2];\n",
    "        lambdaBA[i] = exp(lambdaBA[i]);\n",
    "    }\n",
    "    for ( i in 1:300 ) {\n",
    "        lambdaAB[i] = a + gr[hidA[i], 1] + gr[hidB[i], 2] + d[did[i], 1];\n",
    "        lambdaAB[i] = exp(lambdaAB[i]);\n",
    "    }\n",
    "    giftsBA ~ poisson( lambdaBA );\n",
    "    giftsAB ~ poisson( lambdaAB );\n",
    "}\n",
    "\n",
    "generated quantities{\n",
    "    matrix[2,2] Rho_d;\n",
    "    Rho_d = multiply_lower_tri_self_transpose(L_Rho_d);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=4, num_samples=2000, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N =   jnp.array(int(d.shape[0]))\n",
    "N_households =  jnp.array(int(d['hidB'].max()))\n",
    "did = jnp.array(d['did'].values)\n",
    "hidA =  jnp.array(d['hidA'].values)\n",
    "hidB =  jnp.array(d['hidB'].values)\n",
    "giftsAB =  jnp.array(d['giftsAB'].values)\n",
    "giftsBA =  jnp.array(d['giftsBA'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 4,  5],\n",
       "       [12, 14],\n",
       "       [24, 27]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "@jit\n",
    "def diag_pre_multiply(v, m):\n",
    "    diag_matrix = jnp.diag(v)\n",
    "    return jnp.matmul(diag_matrix, m)\n",
    "\n",
    "# Define a matrix and a vector\n",
    "v = jnp.array([1, 2, 3])\n",
    "m = jnp.array([[4, 5], [6, 7], [8, 9]])\n",
    "\n",
    "# Apply the diag_pre_multiply function\n",
    "result = diag_pre_multiply(v, m)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    alpha = yield normal(1, 0, 1)\n",
    "\n",
    "    ## gr matrix of varying effects\n",
    "    sigma_gr = yield exponential(1, 1)\n",
    "    Rho_gr = yield lkj((), 2, 2)\n",
    "    gr = yield multivariatenormaltril(N_households, jnp.concatenate([jnp.array([0], dtype='float32'),jnp.array([0], dtype='float32')]), jax_LinearOperatorDiag(sigma_gr, Rho_gr))\n",
    "\n",
    "    ## dyad effects\n",
    "    sigma_d = yield exponential(1,1)\n",
    "    L_Rho_d = yield lkj((), 2, 2)\n",
    "    d = yield multivariatenormaltril(N, jnp.concatenate([sigma_d,sigma_d]), jax_LinearOperatorDiag(sigma_d, L_Rho_d))\n",
    "    \n",
    "    rateAB = alpha + gr[:,0][hidA] + gr[:,1][hidB] + d[:,0][did]\n",
    "    rateBA = alpha + gr[:,0][hidB] + gr[:,1][hidA] + d[:,1][did]\n",
    "\n",
    "    gAB = yield Independent(Poisson(log_rate = rateAB))\n",
    "    gBA = yield Independent(Poisson(log_rate = rateBA))\n",
    "\n",
    "tensor = JointDistributionCoroutineAutoBatched(model)\n",
    "#tmp = tensor.sample(seed = jnp.array(init_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$Sigma_i = exponential(1)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import display, Latex, Math\n",
    "\n",
    "greek_symbols = {\n",
    "    'alpha': '\\\\alpha',\n",
    "    'beta': '\\\\beta',\n",
    "    'gamma': '\\\\gamma',\n",
    "    'delta': '\\\\delta',\n",
    "    'epsilon': '\\\\epsilon',\n",
    "    'zeta': '\\\\zeta',\n",
    "    'eta': '\\\\eta',\n",
    "    'theta': '\\\\theta',\n",
    "    'iota': '\\\\iota',\n",
    "    'kappa': '\\\\kappa',\n",
    "    'lambda': '\\\\lambda',\n",
    "    'mu': '\\\\mu',\n",
    "    'nu': '\\\\nu',\n",
    "    'xi': '\\\\xi',\n",
    "    'omicron': 'o',  # No direct LaTeX symbol for omicron, using \"o\"\n",
    "    'pi': '\\\\pi',\n",
    "    'rho': '\\\\rho',\n",
    "    'sigma': '\\\\sigma',\n",
    "    'tau': '\\\\tau',\n",
    "    'upsilon': '\\\\upsilon',\n",
    "    'phi': '\\\\phi',\n",
    "    'chi': '\\\\chi',\n",
    "    'psi': '\\\\psi',\n",
    "    'omega': '\\\\omega'\n",
    "}\n",
    "\n",
    "def convert_to_greek(var_name):\n",
    "    # Convert variable name to lowercase for case-insensitive matching\n",
    "    var_name_lower = var_name.lower()\n",
    "    # Check if the variable name has a corresponding Greek symbol\n",
    "    if var_name_lower in greek_symbols:\n",
    "        return greek_symbols[var_name_lower]\n",
    "    else:\n",
    "        return var_name\n",
    "\n",
    "def extract_latex(command):\n",
    "    # Define a regular expression pattern to match the desired parts of the command\n",
    "    pattern = r\"(\\w+)\\s*=\\s*(\\w+)\\([^,]+,\\s*[^,]+,\\s*(.*)\\)\"\n",
    "    match = re.match(pattern, command)\n",
    "    \n",
    "    if match:\n",
    "        var_name = match.group(1)\n",
    "        func_name = match.group(2)\n",
    "        params = match.group(3)\n",
    "        # Convert var_name to Greek symbol if applicable\n",
    "        var_name_latex = convert_to_greek(var_name)\n",
    "        # Construct the desired LaTeX text\n",
    "        latex_text = f\"{var_name_latex} = {func_name}({params})\"\n",
    "        return latex_text\n",
    "    else:\n",
    "        return None\n",
    "# Example usage\n",
    "command = \"Sigma_i = exponential('Sigma_individual', [ni], 1)\"\n",
    "latex_text = extract_latex(command)\n",
    "display(Latex(f'''${latex_text}$'''))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import time as tm\n",
    "import arviz as az\n",
    "@partial(jit, static_argnums=1)\n",
    "def init_params(tensor, remove):\n",
    "    init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "    init = list(tensor.sample(seed=jnp.array(init_key, dtype=jnp.uint32)))\n",
    "    init.pop(remove)\n",
    "    return init\n",
    "\n",
    "#init_params = init_params(tensor, 6)\n",
    "\n",
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init = list(tensor.sample(seed=jnp.array(init_key, dtype=jnp.uint32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "(2, 2)\n",
      "(25, 2)\n",
      "(1,)\n",
      "(2, 2)\n",
      "(25, 2)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "for a in init:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "(2, 2)\n",
      "(25, 2)\n",
      "(1,)\n",
      "(2, 2)\n",
      "(25, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "init_params2 = []\n",
    "init_params2.append(jnp.array(tf.ones_like(init[0])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init[1])))\n",
    "init_params2.append(jnp.array(tf.eye(2)))\n",
    "init_params2.append(jnp.array(tf.ones_like(init[3])))\n",
    "init_params2.append(jnp.array(tf.ones_like(init[4])))\n",
    "init_params2.append(jnp.array(tf.eye(2)))\n",
    "init_params2.append(jnp.array(tf.ones_like(init[6])))\n",
    "for a in init_params2:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HonnorMode took: 2.6391 seconds\n"
     ]
    }
   ],
   "source": [
    "def trace_fn(_, pkr): \n",
    "    return (\n",
    "        pkr.target_log_prob,\n",
    "        pkr.log_accept_ratio,\n",
    "        pkr.has_divergence,\n",
    "        pkr.energy\n",
    "    )\n",
    "\n",
    "def target_log_prob(*params):\n",
    "  return tensor.log_prob(params + (giftsAB,) + (giftsBA,) )\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(target_log_prob, 1e-3)\n",
    "    return tfp.mcmc.sample_chain(2000,\n",
    "        current_state= init_params2,\n",
    "        kernel=kernel,\n",
    "        trace_fn=trace_fn,\n",
    "        num_burnin_steps=500,\n",
    "        parallel_iterations = 10,\n",
    "        seed=key)\n",
    "\n",
    "\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 4)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (2000) than draws (4). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p = dict(zip(tensor._flat_resolve_names(), posterior))\n",
    "def tfp_trace_to_arviz(posterior, \n",
    "                       sample_stats,\n",
    "                       var_names=None, \n",
    "                       sample_stats_name=['target_log_prob','log_accept_ratio','has_divergence','energy']):\n",
    "    sample_stats = {k:jnp.transpose(v) for k, v in zip(sample_stats_name, sample_stats)}\n",
    "    trace = {}\n",
    "    for name, samp in zip(var_names, posterior):\n",
    "        if len(samp.shape) == 2:\n",
    "            transposed_shape = [1, 0]\n",
    "        elif len(samp.shape) == 3:\n",
    "            transposed_shape = [1, 0, 2]\n",
    "        else:\n",
    "            transposed_shape = [1, 0, 2, 3]\n",
    "        trace[name] = tf.transpose(samp, transposed_shape)\n",
    "    trace = az.from_dict(posterior=trace, sample_stats=sample_stats)\n",
    "    return trace\n",
    "\n",
    "\n",
    "\n",
    "trace = tfp_trace_to_arviz(posterior = posterior, sample_stats = sample_stats, var_names = ['alpha', 'sigma_gr', 'Rho_gr', 'gr', 'sigma_d', 'L_Rho_d', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-1.551</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-2.392</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_gr[0]</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho_gr[0, 0]</th>\n",
       "      <td>2.013</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.686</td>\n",
       "      <td>3.514</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho_gr[0, 1]</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-1.468</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho_gr[1, 0]</th>\n",
       "      <td>0.038</td>\n",
       "      <td>1.940</td>\n",
       "      <td>-2.870</td>\n",
       "      <td>3.876</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d[22, 1]</th>\n",
       "      <td>1.806</td>\n",
       "      <td>0.337</td>\n",
       "      <td>1.135</td>\n",
       "      <td>2.394</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d[23, 0]</th>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-1.440</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d[23, 1]</th>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-1.686</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d[24, 0]</th>\n",
       "      <td>1.644</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.179</td>\n",
       "      <td>2.231</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d[24, 1]</th>\n",
       "      <td>2.016</td>\n",
       "      <td>0.284</td>\n",
       "      <td>1.532</td>\n",
       "      <td>2.617</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>31225.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]     -1.551  0.439  -2.392   -0.733      0.002    0.002   31225.0   \n",
       "sigma_gr[0]   0.460  0.228   0.172    0.941      0.001    0.001   31225.0   \n",
       "Rho_gr[0, 0]  2.013  0.823   0.686    3.514      0.005    0.003   31225.0   \n",
       "Rho_gr[0, 1] -0.613  0.398  -1.468   -0.052      0.002    0.002   31225.0   \n",
       "Rho_gr[1, 0]  0.038  1.940  -2.870    3.876      0.011    0.008   31225.0   \n",
       "...             ...    ...     ...      ...        ...      ...       ...   \n",
       "d[22, 1]      1.806  0.337   1.135    2.394      0.002    0.001   31225.0   \n",
       "d[23, 0]     -0.197  0.690  -1.440    0.934      0.004    0.003   31225.0   \n",
       "d[23, 1]     -0.303  0.770  -1.686    0.979      0.004    0.003   31225.0   \n",
       "d[24, 0]      1.644  0.280   1.179    2.231      0.002    0.001   31225.0   \n",
       "d[24, 1]      2.016  0.284   1.532    2.617      0.002    0.001   31225.0   \n",
       "\n",
       "              ess_tail  r_hat  \n",
       "alpha[0]       31225.0   1.15  \n",
       "sigma_gr[0]    31225.0   1.06  \n",
       "Rho_gr[0, 0]   31225.0   1.06  \n",
       "Rho_gr[0, 1]   31225.0   1.07  \n",
       "Rho_gr[1, 0]   31225.0   0.92  \n",
       "...                ...    ...  \n",
       "d[22, 1]       31225.0   1.07  \n",
       "d[23, 0]       31225.0   0.89  \n",
       "d[23, 1]       31225.0   1.01  \n",
       "d[24, 0]       31225.0   0.98  \n",
       "d[24, 1]       31225.0   0.99  \n",
       "\n",
       "[111 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha[0]',\n",
       " 'sigma_gr[0]',\n",
       " 'Rho_gr[0, 0]',\n",
       " 'Rho_gr[0, 1]',\n",
       " 'Rho_gr[1, 0]',\n",
       " 'Rho_gr[1, 1]',\n",
       " 'gr[0, 0]',\n",
       " 'gr[0, 1]',\n",
       " 'gr[1, 0]',\n",
       " 'gr[1, 1]',\n",
       " 'gr[2, 0]',\n",
       " 'gr[2, 1]',\n",
       " 'gr[3, 0]',\n",
       " 'gr[3, 1]',\n",
       " 'gr[4, 0]',\n",
       " 'gr[4, 1]',\n",
       " 'gr[5, 0]',\n",
       " 'gr[5, 1]',\n",
       " 'gr[6, 0]',\n",
       " 'gr[6, 1]',\n",
       " 'gr[7, 0]',\n",
       " 'gr[7, 1]',\n",
       " 'gr[8, 0]',\n",
       " 'gr[8, 1]',\n",
       " 'gr[9, 0]',\n",
       " 'gr[9, 1]',\n",
       " 'gr[10, 0]',\n",
       " 'gr[10, 1]',\n",
       " 'gr[11, 0]',\n",
       " 'gr[11, 1]',\n",
       " 'gr[12, 0]',\n",
       " 'gr[12, 1]',\n",
       " 'gr[13, 0]',\n",
       " 'gr[13, 1]',\n",
       " 'gr[14, 0]',\n",
       " 'gr[14, 1]',\n",
       " 'gr[15, 0]',\n",
       " 'gr[15, 1]',\n",
       " 'gr[16, 0]',\n",
       " 'gr[16, 1]',\n",
       " 'gr[17, 0]',\n",
       " 'gr[17, 1]',\n",
       " 'gr[18, 0]',\n",
       " 'gr[18, 1]',\n",
       " 'gr[19, 0]',\n",
       " 'gr[19, 1]',\n",
       " 'gr[20, 0]',\n",
       " 'gr[20, 1]',\n",
       " 'gr[21, 0]',\n",
       " 'gr[21, 1]',\n",
       " 'gr[22, 0]',\n",
       " 'gr[22, 1]',\n",
       " 'gr[23, 0]',\n",
       " 'gr[23, 1]',\n",
       " 'gr[24, 0]',\n",
       " 'gr[24, 1]',\n",
       " 'sigma_d[0]',\n",
       " 'L_Rho_d[0, 0]',\n",
       " 'L_Rho_d[0, 1]',\n",
       " 'L_Rho_d[1, 0]',\n",
       " 'L_Rho_d[1, 1]',\n",
       " 'd[0, 0]',\n",
       " 'd[0, 1]',\n",
       " 'd[1, 0]',\n",
       " 'd[1, 1]',\n",
       " 'd[2, 0]',\n",
       " 'd[2, 1]',\n",
       " 'd[3, 0]',\n",
       " 'd[3, 1]',\n",
       " 'd[4, 0]',\n",
       " 'd[4, 1]',\n",
       " 'd[5, 0]',\n",
       " 'd[5, 1]',\n",
       " 'd[6, 0]',\n",
       " 'd[6, 1]',\n",
       " 'd[7, 0]',\n",
       " 'd[7, 1]',\n",
       " 'd[8, 0]',\n",
       " 'd[8, 1]',\n",
       " 'd[9, 0]',\n",
       " 'd[9, 1]',\n",
       " 'd[10, 0]',\n",
       " 'd[10, 1]',\n",
       " 'd[11, 0]',\n",
       " 'd[11, 1]',\n",
       " 'd[12, 0]',\n",
       " 'd[12, 1]',\n",
       " 'd[13, 0]',\n",
       " 'd[13, 1]',\n",
       " 'd[14, 0]',\n",
       " 'd[14, 1]',\n",
       " 'd[15, 0]',\n",
       " 'd[15, 1]',\n",
       " 'd[16, 0]',\n",
       " 'd[16, 1]',\n",
       " 'd[17, 0]',\n",
       " 'd[17, 1]',\n",
       " 'd[18, 0]',\n",
       " 'd[18, 1]',\n",
       " 'd[19, 0]',\n",
       " 'd[19, 1]',\n",
       " 'd[20, 0]',\n",
       " 'd[20, 1]',\n",
       " 'd[21, 0]',\n",
       " 'd[21, 1]',\n",
       " 'd[22, 0]',\n",
       " 'd[22, 1]',\n",
       " 'd[23, 0]',\n",
       " 'd[23, 1]',\n",
       " 'd[24, 0]',\n",
       " 'd[24, 1]']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(az.summary(trace,round_to='none')['mean'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>parameters</th>\n",
       "      <th>lp__</th>\n",
       "      <th>accept_stat__</th>\n",
       "      <th>stepsize__</th>\n",
       "      <th>treedepth__</th>\n",
       "      <th>n_leapfrog__</th>\n",
       "      <th>divergent__</th>\n",
       "      <th>energy__</th>\n",
       "      <th>a</th>\n",
       "      <th>gr.1.1</th>\n",
       "      <th>gr.2.1</th>\n",
       "      <th>gr.3.1</th>\n",
       "      <th>gr.4.1</th>\n",
       "      <th>gr.5.1</th>\n",
       "      <th>gr.6.1</th>\n",
       "      <th>gr.7.1</th>\n",
       "      <th>gr.8.1</th>\n",
       "      <th>gr.9.1</th>\n",
       "      <th>gr.10.1</th>\n",
       "      <th>gr.11.1</th>\n",
       "      <th>gr.12.1</th>\n",
       "      <th>gr.13.1</th>\n",
       "      <th>gr.14.1</th>\n",
       "      <th>gr.15.1</th>\n",
       "      <th>gr.16.1</th>\n",
       "      <th>gr.17.1</th>\n",
       "      <th>gr.18.1</th>\n",
       "      <th>gr.19.1</th>\n",
       "      <th>gr.20.1</th>\n",
       "      <th>gr.21.1</th>\n",
       "      <th>gr.22.1</th>\n",
       "      <th>gr.23.1</th>\n",
       "      <th>gr.24.1</th>\n",
       "      <th>gr.25.1</th>\n",
       "      <th>gr.1.2</th>\n",
       "      <th>gr.2.2</th>\n",
       "      <th>gr.3.2</th>\n",
       "      <th>gr.4.2</th>\n",
       "      <th>gr.5.2</th>\n",
       "      <th>gr.6.2</th>\n",
       "      <th>gr.7.2</th>\n",
       "      <th>gr.8.2</th>\n",
       "      <th>gr.9.2</th>\n",
       "      <th>gr.10.2</th>\n",
       "      <th>gr.11.2</th>\n",
       "      <th>gr.12.2</th>\n",
       "      <th>gr.13.2</th>\n",
       "      <th>gr.14.2</th>\n",
       "      <th>gr.15.2</th>\n",
       "      <th>gr.16.2</th>\n",
       "      <th>gr.17.2</th>\n",
       "      <th>gr.18.2</th>\n",
       "      <th>gr.19.2</th>\n",
       "      <th>gr.20.2</th>\n",
       "      <th>gr.21.2</th>\n",
       "      <th>gr.22.2</th>\n",
       "      <th>gr.23.2</th>\n",
       "      <th>gr.24.2</th>\n",
       "      <th>gr.25.2</th>\n",
       "      <th>Rho_gr.1.1</th>\n",
       "      <th>Rho_gr.2.1</th>\n",
       "      <th>Rho_gr.1.2</th>\n",
       "      <th>Rho_gr.2.2</th>\n",
       "      <th>sigma_gr.1</th>\n",
       "      <th>sigma_gr.2</th>\n",
       "      <th>z.1.1</th>\n",
       "      <th>z.2.1</th>\n",
       "      <th>z.1.2</th>\n",
       "      <th>z.2.2</th>\n",
       "      <th>z.1.3</th>\n",
       "      <th>z.2.3</th>\n",
       "      <th>z.1.4</th>\n",
       "      <th>z.2.4</th>\n",
       "      <th>z.1.5</th>\n",
       "      <th>z.2.5</th>\n",
       "      <th>z.1.6</th>\n",
       "      <th>z.2.6</th>\n",
       "      <th>z.1.7</th>\n",
       "      <th>z.2.7</th>\n",
       "      <th>z.1.8</th>\n",
       "      <th>z.2.8</th>\n",
       "      <th>z.1.9</th>\n",
       "      <th>z.2.9</th>\n",
       "      <th>z.1.10</th>\n",
       "      <th>z.2.10</th>\n",
       "      <th>z.1.11</th>\n",
       "      <th>z.2.11</th>\n",
       "      <th>z.1.12</th>\n",
       "      <th>z.2.12</th>\n",
       "      <th>z.1.13</th>\n",
       "      <th>z.2.13</th>\n",
       "      <th>z.1.14</th>\n",
       "      <th>z.2.14</th>\n",
       "      <th>z.1.15</th>\n",
       "      <th>z.2.15</th>\n",
       "      <th>z.1.16</th>\n",
       "      <th>z.2.16</th>\n",
       "      <th>z.1.17</th>\n",
       "      <th>z.2.17</th>\n",
       "      <th>z.1.18</th>\n",
       "      <th>z.2.18</th>\n",
       "      <th>z.1.19</th>\n",
       "      <th>z.2.19</th>\n",
       "      <th>z.1.20</th>\n",
       "      <th>z.2.20</th>\n",
       "      <th>z.1.21</th>\n",
       "      <th>z.2.21</th>\n",
       "      <th>z.1.22</th>\n",
       "      <th>z.2.22</th>\n",
       "      <th>z.1.23</th>\n",
       "      <th>z.2.23</th>\n",
       "      <th>z.1.24</th>\n",
       "      <th>z.2.24</th>\n",
       "      <th>z.1.25</th>\n",
       "      <th>z.2.25</th>\n",
       "      <th>z.1.26</th>\n",
       "      <th>z.2.26</th>\n",
       "      <th>z.1.27</th>\n",
       "      <th>z.2.27</th>\n",
       "      <th>z.1.28</th>\n",
       "      <th>z.2.28</th>\n",
       "      <th>z.1.29</th>\n",
       "      <th>z.2.29</th>\n",
       "      <th>z.1.30</th>\n",
       "      <th>z.2.30</th>\n",
       "      <th>z.1.31</th>\n",
       "      <th>z.2.31</th>\n",
       "      <th>z.1.32</th>\n",
       "      <th>z.2.32</th>\n",
       "      <th>z.1.33</th>\n",
       "      <th>z.2.33</th>\n",
       "      <th>z.1.34</th>\n",
       "      <th>z.2.34</th>\n",
       "      <th>z.1.35</th>\n",
       "      <th>z.2.35</th>\n",
       "      <th>z.1.36</th>\n",
       "      <th>z.2.36</th>\n",
       "      <th>z.1.37</th>\n",
       "      <th>z.2.37</th>\n",
       "      <th>z.1.38</th>\n",
       "      <th>z.2.38</th>\n",
       "      <th>z.1.39</th>\n",
       "      <th>z.2.39</th>\n",
       "      <th>z.1.40</th>\n",
       "      <th>z.2.40</th>\n",
       "      <th>z.1.41</th>\n",
       "      <th>z.2.41</th>\n",
       "      <th>z.1.42</th>\n",
       "      <th>z.2.42</th>\n",
       "      <th>z.1.43</th>\n",
       "      <th>z.2.43</th>\n",
       "      <th>z.1.44</th>\n",
       "      <th>z.2.44</th>\n",
       "      <th>z.1.45</th>\n",
       "      <th>z.2.45</th>\n",
       "      <th>z.1.46</th>\n",
       "      <th>z.2.46</th>\n",
       "      <th>z.1.47</th>\n",
       "      <th>z.2.47</th>\n",
       "      <th>z.1.48</th>\n",
       "      <th>z.2.48</th>\n",
       "      <th>z.1.49</th>\n",
       "      <th>z.2.49</th>\n",
       "      <th>z.1.50</th>\n",
       "      <th>z.2.50</th>\n",
       "      <th>z.1.51</th>\n",
       "      <th>z.2.51</th>\n",
       "      <th>z.1.52</th>\n",
       "      <th>z.2.52</th>\n",
       "      <th>z.1.53</th>\n",
       "      <th>z.2.53</th>\n",
       "      <th>z.1.54</th>\n",
       "      <th>z.2.54</th>\n",
       "      <th>z.1.55</th>\n",
       "      <th>z.2.55</th>\n",
       "      <th>z.1.56</th>\n",
       "      <th>z.2.56</th>\n",
       "      <th>z.1.57</th>\n",
       "      <th>z.2.57</th>\n",
       "      <th>z.1.58</th>\n",
       "      <th>z.2.58</th>\n",
       "      <th>z.1.59</th>\n",
       "      <th>z.2.59</th>\n",
       "      <th>z.1.60</th>\n",
       "      <th>z.2.60</th>\n",
       "      <th>z.1.61</th>\n",
       "      <th>z.2.61</th>\n",
       "      <th>z.1.62</th>\n",
       "      <th>z.2.62</th>\n",
       "      <th>z.1.63</th>\n",
       "      <th>z.2.63</th>\n",
       "      <th>z.1.64</th>\n",
       "      <th>z.2.64</th>\n",
       "      <th>z.1.65</th>\n",
       "      <th>z.2.65</th>\n",
       "      <th>z.1.66</th>\n",
       "      <th>z.2.66</th>\n",
       "      <th>z.1.67</th>\n",
       "      <th>z.2.67</th>\n",
       "      <th>z.1.68</th>\n",
       "      <th>z.2.68</th>\n",
       "      <th>z.1.69</th>\n",
       "      <th>z.2.69</th>\n",
       "      <th>z.1.70</th>\n",
       "      <th>z.2.70</th>\n",
       "      <th>z.1.71</th>\n",
       "      <th>z.2.71</th>\n",
       "      <th>z.1.72</th>\n",
       "      <th>z.2.72</th>\n",
       "      <th>z.1.73</th>\n",
       "      <th>z.2.73</th>\n",
       "      <th>z.1.74</th>\n",
       "      <th>z.2.74</th>\n",
       "      <th>z.1.75</th>\n",
       "      <th>z.2.75</th>\n",
       "      <th>z.1.76</th>\n",
       "      <th>z.2.76</th>\n",
       "      <th>z.1.77</th>\n",
       "      <th>z.2.77</th>\n",
       "      <th>z.1.78</th>\n",
       "      <th>z.2.78</th>\n",
       "      <th>z.1.79</th>\n",
       "      <th>z.2.79</th>\n",
       "      <th>z.1.80</th>\n",
       "      <th>z.2.80</th>\n",
       "      <th>z.1.81</th>\n",
       "      <th>z.2.81</th>\n",
       "      <th>z.1.82</th>\n",
       "      <th>z.2.82</th>\n",
       "      <th>z.1.83</th>\n",
       "      <th>z.2.83</th>\n",
       "      <th>z.1.84</th>\n",
       "      <th>z.2.84</th>\n",
       "      <th>z.1.85</th>\n",
       "      <th>z.2.85</th>\n",
       "      <th>z.1.86</th>\n",
       "      <th>z.2.86</th>\n",
       "      <th>z.1.87</th>\n",
       "      <th>z.2.87</th>\n",
       "      <th>z.1.88</th>\n",
       "      <th>z.2.88</th>\n",
       "      <th>z.1.89</th>\n",
       "      <th>z.2.89</th>\n",
       "      <th>z.1.90</th>\n",
       "      <th>z.2.90</th>\n",
       "      <th>z.1.91</th>\n",
       "      <th>z.2.91</th>\n",
       "      <th>z.1.92</th>\n",
       "      <th>z.2.92</th>\n",
       "      <th>z.1.93</th>\n",
       "      <th>z.2.93</th>\n",
       "      <th>z.1.94</th>\n",
       "      <th>z.2.94</th>\n",
       "      <th>z.1.95</th>\n",
       "      <th>z.2.95</th>\n",
       "      <th>z.1.96</th>\n",
       "      <th>z.2.96</th>\n",
       "      <th>z.1.97</th>\n",
       "      <th>z.2.97</th>\n",
       "      <th>z.1.98</th>\n",
       "      <th>z.2.98</th>\n",
       "      <th>z.1.99</th>\n",
       "      <th>z.2.99</th>\n",
       "      <th>z.1.100</th>\n",
       "      <th>z.2.100</th>\n",
       "      <th>z.1.101</th>\n",
       "      <th>z.2.101</th>\n",
       "      <th>z.1.102</th>\n",
       "      <th>z.2.102</th>\n",
       "      <th>z.1.103</th>\n",
       "      <th>z.2.103</th>\n",
       "      <th>z.1.104</th>\n",
       "      <th>z.2.104</th>\n",
       "      <th>z.1.105</th>\n",
       "      <th>z.2.105</th>\n",
       "      <th>z.1.106</th>\n",
       "      <th>z.2.106</th>\n",
       "      <th>z.1.107</th>\n",
       "      <th>z.2.107</th>\n",
       "      <th>z.1.108</th>\n",
       "      <th>z.2.108</th>\n",
       "      <th>z.1.109</th>\n",
       "      <th>z.2.109</th>\n",
       "      <th>z.1.110</th>\n",
       "      <th>z.2.110</th>\n",
       "      <th>z.1.111</th>\n",
       "      <th>z.2.111</th>\n",
       "      <th>z.1.112</th>\n",
       "      <th>z.2.112</th>\n",
       "      <th>z.1.113</th>\n",
       "      <th>z.2.113</th>\n",
       "      <th>z.1.114</th>\n",
       "      <th>z.2.114</th>\n",
       "      <th>z.1.115</th>\n",
       "      <th>z.2.115</th>\n",
       "      <th>z.1.116</th>\n",
       "      <th>z.2.116</th>\n",
       "      <th>z.1.117</th>\n",
       "      <th>z.2.117</th>\n",
       "      <th>z.1.118</th>\n",
       "      <th>z.2.118</th>\n",
       "      <th>z.1.119</th>\n",
       "      <th>z.2.119</th>\n",
       "      <th>z.1.120</th>\n",
       "      <th>z.2.120</th>\n",
       "      <th>z.1.121</th>\n",
       "      <th>z.2.121</th>\n",
       "      <th>z.1.122</th>\n",
       "      <th>z.2.122</th>\n",
       "      <th>z.1.123</th>\n",
       "      <th>z.2.123</th>\n",
       "      <th>z.1.124</th>\n",
       "      <th>z.2.124</th>\n",
       "      <th>z.1.125</th>\n",
       "      <th>z.2.125</th>\n",
       "      <th>z.1.126</th>\n",
       "      <th>z.2.126</th>\n",
       "      <th>z.1.127</th>\n",
       "      <th>z.2.127</th>\n",
       "      <th>z.1.128</th>\n",
       "      <th>z.2.128</th>\n",
       "      <th>z.1.129</th>\n",
       "      <th>z.2.129</th>\n",
       "      <th>z.1.130</th>\n",
       "      <th>z.2.130</th>\n",
       "      <th>z.1.131</th>\n",
       "      <th>z.2.131</th>\n",
       "      <th>z.1.132</th>\n",
       "      <th>z.2.132</th>\n",
       "      <th>z.1.133</th>\n",
       "      <th>z.2.133</th>\n",
       "      <th>z.1.134</th>\n",
       "      <th>z.2.134</th>\n",
       "      <th>z.1.135</th>\n",
       "      <th>z.2.135</th>\n",
       "      <th>z.1.136</th>\n",
       "      <th>z.2.136</th>\n",
       "      <th>z.1.137</th>\n",
       "      <th>z.2.137</th>\n",
       "      <th>z.1.138</th>\n",
       "      <th>z.2.138</th>\n",
       "      <th>z.1.139</th>\n",
       "      <th>z.2.139</th>\n",
       "      <th>z.1.140</th>\n",
       "      <th>z.2.140</th>\n",
       "      <th>z.1.141</th>\n",
       "      <th>z.2.141</th>\n",
       "      <th>z.1.142</th>\n",
       "      <th>z.2.142</th>\n",
       "      <th>z.1.143</th>\n",
       "      <th>z.2.143</th>\n",
       "      <th>z.1.144</th>\n",
       "      <th>z.2.144</th>\n",
       "      <th>z.1.145</th>\n",
       "      <th>z.2.145</th>\n",
       "      <th>z.1.146</th>\n",
       "      <th>z.2.146</th>\n",
       "      <th>z.1.147</th>\n",
       "      <th>z.2.147</th>\n",
       "      <th>z.1.148</th>\n",
       "      <th>z.2.148</th>\n",
       "      <th>z.1.149</th>\n",
       "      <th>z.2.149</th>\n",
       "      <th>z.1.150</th>\n",
       "      <th>z.2.150</th>\n",
       "      <th>z.1.151</th>\n",
       "      <th>z.2.151</th>\n",
       "      <th>z.1.152</th>\n",
       "      <th>z.2.152</th>\n",
       "      <th>z.1.153</th>\n",
       "      <th>z.2.153</th>\n",
       "      <th>z.1.154</th>\n",
       "      <th>z.2.154</th>\n",
       "      <th>z.1.155</th>\n",
       "      <th>z.2.155</th>\n",
       "      <th>z.1.156</th>\n",
       "      <th>z.2.156</th>\n",
       "      <th>z.1.157</th>\n",
       "      <th>z.2.157</th>\n",
       "      <th>z.1.158</th>\n",
       "      <th>z.2.158</th>\n",
       "      <th>z.1.159</th>\n",
       "      <th>z.2.159</th>\n",
       "      <th>z.1.160</th>\n",
       "      <th>z.2.160</th>\n",
       "      <th>z.1.161</th>\n",
       "      <th>z.2.161</th>\n",
       "      <th>z.1.162</th>\n",
       "      <th>z.2.162</th>\n",
       "      <th>z.1.163</th>\n",
       "      <th>z.2.163</th>\n",
       "      <th>z.1.164</th>\n",
       "      <th>z.2.164</th>\n",
       "      <th>z.1.165</th>\n",
       "      <th>z.2.165</th>\n",
       "      <th>z.1.166</th>\n",
       "      <th>z.2.166</th>\n",
       "      <th>z.1.167</th>\n",
       "      <th>z.2.167</th>\n",
       "      <th>z.1.168</th>\n",
       "      <th>z.2.168</th>\n",
       "      <th>z.1.169</th>\n",
       "      <th>z.2.169</th>\n",
       "      <th>z.1.170</th>\n",
       "      <th>z.2.170</th>\n",
       "      <th>z.1.171</th>\n",
       "      <th>z.2.171</th>\n",
       "      <th>z.1.172</th>\n",
       "      <th>z.2.172</th>\n",
       "      <th>z.1.173</th>\n",
       "      <th>z.2.173</th>\n",
       "      <th>z.1.174</th>\n",
       "      <th>z.2.174</th>\n",
       "      <th>z.1.175</th>\n",
       "      <th>z.2.175</th>\n",
       "      <th>z.1.176</th>\n",
       "      <th>z.2.176</th>\n",
       "      <th>z.1.177</th>\n",
       "      <th>z.2.177</th>\n",
       "      <th>z.1.178</th>\n",
       "      <th>z.2.178</th>\n",
       "      <th>z.1.179</th>\n",
       "      <th>z.2.179</th>\n",
       "      <th>z.1.180</th>\n",
       "      <th>z.2.180</th>\n",
       "      <th>z.1.181</th>\n",
       "      <th>z.2.181</th>\n",
       "      <th>z.1.182</th>\n",
       "      <th>z.2.182</th>\n",
       "      <th>z.1.183</th>\n",
       "      <th>z.2.183</th>\n",
       "      <th>z.1.184</th>\n",
       "      <th>z.2.184</th>\n",
       "      <th>z.1.185</th>\n",
       "      <th>z.2.185</th>\n",
       "      <th>z.1.186</th>\n",
       "      <th>z.2.186</th>\n",
       "      <th>z.1.187</th>\n",
       "      <th>z.2.187</th>\n",
       "      <th>z.1.188</th>\n",
       "      <th>z.2.188</th>\n",
       "      <th>z.1.189</th>\n",
       "      <th>z.2.189</th>\n",
       "      <th>z.1.190</th>\n",
       "      <th>z.2.190</th>\n",
       "      <th>z.1.191</th>\n",
       "      <th>z.2.191</th>\n",
       "      <th>z.1.192</th>\n",
       "      <th>z.2.192</th>\n",
       "      <th>z.1.193</th>\n",
       "      <th>z.2.193</th>\n",
       "      <th>z.1.194</th>\n",
       "      <th>z.2.194</th>\n",
       "      <th>z.1.195</th>\n",
       "      <th>z.2.195</th>\n",
       "      <th>z.1.196</th>\n",
       "      <th>z.2.196</th>\n",
       "      <th>z.1.197</th>\n",
       "      <th>z.2.197</th>\n",
       "      <th>z.1.198</th>\n",
       "      <th>z.2.198</th>\n",
       "      <th>z.1.199</th>\n",
       "      <th>z.2.199</th>\n",
       "      <th>z.1.200</th>\n",
       "      <th>z.2.200</th>\n",
       "      <th>z.1.201</th>\n",
       "      <th>z.2.201</th>\n",
       "      <th>z.1.202</th>\n",
       "      <th>z.2.202</th>\n",
       "      <th>z.1.203</th>\n",
       "      <th>z.2.203</th>\n",
       "      <th>z.1.204</th>\n",
       "      <th>z.2.204</th>\n",
       "      <th>z.1.205</th>\n",
       "      <th>z.2.205</th>\n",
       "      <th>z.1.206</th>\n",
       "      <th>z.2.206</th>\n",
       "      <th>z.1.207</th>\n",
       "      <th>z.2.207</th>\n",
       "      <th>z.1.208</th>\n",
       "      <th>z.2.208</th>\n",
       "      <th>z.1.209</th>\n",
       "      <th>z.2.209</th>\n",
       "      <th>z.1.210</th>\n",
       "      <th>z.2.210</th>\n",
       "      <th>z.1.211</th>\n",
       "      <th>z.2.211</th>\n",
       "      <th>z.1.212</th>\n",
       "      <th>z.2.212</th>\n",
       "      <th>z.1.213</th>\n",
       "      <th>z.2.213</th>\n",
       "      <th>z.1.214</th>\n",
       "      <th>z.2.214</th>\n",
       "      <th>z.1.215</th>\n",
       "      <th>z.2.215</th>\n",
       "      <th>z.1.216</th>\n",
       "      <th>z.2.216</th>\n",
       "      <th>z.1.217</th>\n",
       "      <th>z.2.217</th>\n",
       "      <th>z.1.218</th>\n",
       "      <th>z.2.218</th>\n",
       "      <th>z.1.219</th>\n",
       "      <th>z.2.219</th>\n",
       "      <th>z.1.220</th>\n",
       "      <th>z.2.220</th>\n",
       "      <th>z.1.221</th>\n",
       "      <th>z.2.221</th>\n",
       "      <th>z.1.222</th>\n",
       "      <th>z.2.222</th>\n",
       "      <th>z.1.223</th>\n",
       "      <th>z.2.223</th>\n",
       "      <th>z.1.224</th>\n",
       "      <th>z.2.224</th>\n",
       "      <th>z.1.225</th>\n",
       "      <th>z.2.225</th>\n",
       "      <th>z.1.226</th>\n",
       "      <th>z.2.226</th>\n",
       "      <th>z.1.227</th>\n",
       "      <th>z.2.227</th>\n",
       "      <th>z.1.228</th>\n",
       "      <th>z.2.228</th>\n",
       "      <th>z.1.229</th>\n",
       "      <th>z.2.229</th>\n",
       "      <th>z.1.230</th>\n",
       "      <th>z.2.230</th>\n",
       "      <th>z.1.231</th>\n",
       "      <th>z.2.231</th>\n",
       "      <th>z.1.232</th>\n",
       "      <th>z.2.232</th>\n",
       "      <th>z.1.233</th>\n",
       "      <th>z.2.233</th>\n",
       "      <th>z.1.234</th>\n",
       "      <th>z.2.234</th>\n",
       "      <th>z.1.235</th>\n",
       "      <th>z.2.235</th>\n",
       "      <th>z.1.236</th>\n",
       "      <th>z.2.236</th>\n",
       "      <th>z.1.237</th>\n",
       "      <th>z.2.237</th>\n",
       "      <th>z.1.238</th>\n",
       "      <th>z.2.238</th>\n",
       "      <th>z.1.239</th>\n",
       "      <th>z.2.239</th>\n",
       "      <th>z.1.240</th>\n",
       "      <th>z.2.240</th>\n",
       "      <th>z.1.241</th>\n",
       "      <th>z.2.241</th>\n",
       "      <th>z.1.242</th>\n",
       "      <th>z.2.242</th>\n",
       "      <th>z.1.243</th>\n",
       "      <th>z.2.243</th>\n",
       "      <th>z.1.244</th>\n",
       "      <th>z.2.244</th>\n",
       "      <th>z.1.245</th>\n",
       "      <th>z.2.245</th>\n",
       "      <th>z.1.246</th>\n",
       "      <th>z.2.246</th>\n",
       "      <th>z.1.247</th>\n",
       "      <th>z.2.247</th>\n",
       "      <th>z.1.248</th>\n",
       "      <th>z.2.248</th>\n",
       "      <th>z.1.249</th>\n",
       "      <th>z.2.249</th>\n",
       "      <th>z.1.250</th>\n",
       "      <th>z.2.250</th>\n",
       "      <th>z.1.251</th>\n",
       "      <th>z.2.251</th>\n",
       "      <th>z.1.252</th>\n",
       "      <th>z.2.252</th>\n",
       "      <th>z.1.253</th>\n",
       "      <th>z.2.253</th>\n",
       "      <th>z.1.254</th>\n",
       "      <th>z.2.254</th>\n",
       "      <th>z.1.255</th>\n",
       "      <th>z.2.255</th>\n",
       "      <th>z.1.256</th>\n",
       "      <th>z.2.256</th>\n",
       "      <th>z.1.257</th>\n",
       "      <th>z.2.257</th>\n",
       "      <th>z.1.258</th>\n",
       "      <th>z.2.258</th>\n",
       "      <th>z.1.259</th>\n",
       "      <th>z.2.259</th>\n",
       "      <th>z.1.260</th>\n",
       "      <th>z.2.260</th>\n",
       "      <th>z.1.261</th>\n",
       "      <th>z.2.261</th>\n",
       "      <th>z.1.262</th>\n",
       "      <th>z.2.262</th>\n",
       "      <th>z.1.263</th>\n",
       "      <th>z.2.263</th>\n",
       "      <th>z.1.264</th>\n",
       "      <th>z.2.264</th>\n",
       "      <th>z.1.265</th>\n",
       "      <th>z.2.265</th>\n",
       "      <th>z.1.266</th>\n",
       "      <th>z.2.266</th>\n",
       "      <th>z.1.267</th>\n",
       "      <th>z.2.267</th>\n",
       "      <th>z.1.268</th>\n",
       "      <th>z.2.268</th>\n",
       "      <th>z.1.269</th>\n",
       "      <th>z.2.269</th>\n",
       "      <th>z.1.270</th>\n",
       "      <th>z.2.270</th>\n",
       "      <th>z.1.271</th>\n",
       "      <th>z.2.271</th>\n",
       "      <th>z.1.272</th>\n",
       "      <th>z.2.272</th>\n",
       "      <th>z.1.273</th>\n",
       "      <th>z.2.273</th>\n",
       "      <th>z.1.274</th>\n",
       "      <th>z.2.274</th>\n",
       "      <th>z.1.275</th>\n",
       "      <th>z.2.275</th>\n",
       "      <th>z.1.276</th>\n",
       "      <th>z.2.276</th>\n",
       "      <th>z.1.277</th>\n",
       "      <th>z.2.277</th>\n",
       "      <th>z.1.278</th>\n",
       "      <th>z.2.278</th>\n",
       "      <th>z.1.279</th>\n",
       "      <th>z.2.279</th>\n",
       "      <th>z.1.280</th>\n",
       "      <th>z.2.280</th>\n",
       "      <th>z.1.281</th>\n",
       "      <th>z.2.281</th>\n",
       "      <th>z.1.282</th>\n",
       "      <th>z.2.282</th>\n",
       "      <th>z.1.283</th>\n",
       "      <th>z.2.283</th>\n",
       "      <th>z.1.284</th>\n",
       "      <th>z.2.284</th>\n",
       "      <th>z.1.285</th>\n",
       "      <th>z.2.285</th>\n",
       "      <th>z.1.286</th>\n",
       "      <th>z.2.286</th>\n",
       "      <th>z.1.287</th>\n",
       "      <th>z.2.287</th>\n",
       "      <th>z.1.288</th>\n",
       "      <th>z.2.288</th>\n",
       "      <th>z.1.289</th>\n",
       "      <th>z.2.289</th>\n",
       "      <th>z.1.290</th>\n",
       "      <th>z.2.290</th>\n",
       "      <th>z.1.291</th>\n",
       "      <th>z.2.291</th>\n",
       "      <th>z.1.292</th>\n",
       "      <th>z.2.292</th>\n",
       "      <th>z.1.293</th>\n",
       "      <th>z.2.293</th>\n",
       "      <th>z.1.294</th>\n",
       "      <th>z.2.294</th>\n",
       "      <th>z.1.295</th>\n",
       "      <th>z.2.295</th>\n",
       "      <th>z.1.296</th>\n",
       "      <th>z.2.296</th>\n",
       "      <th>z.1.297</th>\n",
       "      <th>z.2.297</th>\n",
       "      <th>z.1.298</th>\n",
       "      <th>z.2.298</th>\n",
       "      <th>z.1.299</th>\n",
       "      <th>z.2.299</th>\n",
       "      <th>z.1.300</th>\n",
       "      <th>z.2.300</th>\n",
       "      <th>L_Rho_d.1.1</th>\n",
       "      <th>L_Rho_d.2.1</th>\n",
       "      <th>L_Rho_d.1.2</th>\n",
       "      <th>L_Rho_d.2.2</th>\n",
       "      <th>sigma_d</th>\n",
       "      <th>d.1.1</th>\n",
       "      <th>d.2.1</th>\n",
       "      <th>d.3.1</th>\n",
       "      <th>d.4.1</th>\n",
       "      <th>d.5.1</th>\n",
       "      <th>d.6.1</th>\n",
       "      <th>d.7.1</th>\n",
       "      <th>d.8.1</th>\n",
       "      <th>d.9.1</th>\n",
       "      <th>d.10.1</th>\n",
       "      <th>d.11.1</th>\n",
       "      <th>d.12.1</th>\n",
       "      <th>d.13.1</th>\n",
       "      <th>d.14.1</th>\n",
       "      <th>d.15.1</th>\n",
       "      <th>d.16.1</th>\n",
       "      <th>d.17.1</th>\n",
       "      <th>d.18.1</th>\n",
       "      <th>d.19.1</th>\n",
       "      <th>d.20.1</th>\n",
       "      <th>d.21.1</th>\n",
       "      <th>d.22.1</th>\n",
       "      <th>d.23.1</th>\n",
       "      <th>d.24.1</th>\n",
       "      <th>d.25.1</th>\n",
       "      <th>d.26.1</th>\n",
       "      <th>d.27.1</th>\n",
       "      <th>d.28.1</th>\n",
       "      <th>d.29.1</th>\n",
       "      <th>d.30.1</th>\n",
       "      <th>d.31.1</th>\n",
       "      <th>d.32.1</th>\n",
       "      <th>d.33.1</th>\n",
       "      <th>d.34.1</th>\n",
       "      <th>d.35.1</th>\n",
       "      <th>d.36.1</th>\n",
       "      <th>d.37.1</th>\n",
       "      <th>d.38.1</th>\n",
       "      <th>d.39.1</th>\n",
       "      <th>d.40.1</th>\n",
       "      <th>d.41.1</th>\n",
       "      <th>d.42.1</th>\n",
       "      <th>d.43.1</th>\n",
       "      <th>d.44.1</th>\n",
       "      <th>d.45.1</th>\n",
       "      <th>d.46.1</th>\n",
       "      <th>d.47.1</th>\n",
       "      <th>d.48.1</th>\n",
       "      <th>d.49.1</th>\n",
       "      <th>d.50.1</th>\n",
       "      <th>d.51.1</th>\n",
       "      <th>d.52.1</th>\n",
       "      <th>d.53.1</th>\n",
       "      <th>d.54.1</th>\n",
       "      <th>d.55.1</th>\n",
       "      <th>d.56.1</th>\n",
       "      <th>d.57.1</th>\n",
       "      <th>d.58.1</th>\n",
       "      <th>d.59.1</th>\n",
       "      <th>d.60.1</th>\n",
       "      <th>d.61.1</th>\n",
       "      <th>d.62.1</th>\n",
       "      <th>d.63.1</th>\n",
       "      <th>d.64.1</th>\n",
       "      <th>d.65.1</th>\n",
       "      <th>d.66.1</th>\n",
       "      <th>d.67.1</th>\n",
       "      <th>d.68.1</th>\n",
       "      <th>d.69.1</th>\n",
       "      <th>d.70.1</th>\n",
       "      <th>d.71.1</th>\n",
       "      <th>d.72.1</th>\n",
       "      <th>d.73.1</th>\n",
       "      <th>d.74.1</th>\n",
       "      <th>d.75.1</th>\n",
       "      <th>d.76.1</th>\n",
       "      <th>d.77.1</th>\n",
       "      <th>d.78.1</th>\n",
       "      <th>d.79.1</th>\n",
       "      <th>d.80.1</th>\n",
       "      <th>d.81.1</th>\n",
       "      <th>d.82.1</th>\n",
       "      <th>d.83.1</th>\n",
       "      <th>d.84.1</th>\n",
       "      <th>d.85.1</th>\n",
       "      <th>d.86.1</th>\n",
       "      <th>d.87.1</th>\n",
       "      <th>d.88.1</th>\n",
       "      <th>d.89.1</th>\n",
       "      <th>d.90.1</th>\n",
       "      <th>d.91.1</th>\n",
       "      <th>d.92.1</th>\n",
       "      <th>d.93.1</th>\n",
       "      <th>d.94.1</th>\n",
       "      <th>d.95.1</th>\n",
       "      <th>d.96.1</th>\n",
       "      <th>d.97.1</th>\n",
       "      <th>d.98.1</th>\n",
       "      <th>d.99.1</th>\n",
       "      <th>d.100.1</th>\n",
       "      <th>d.101.1</th>\n",
       "      <th>d.102.1</th>\n",
       "      <th>d.103.1</th>\n",
       "      <th>d.104.1</th>\n",
       "      <th>d.105.1</th>\n",
       "      <th>d.106.1</th>\n",
       "      <th>d.107.1</th>\n",
       "      <th>d.108.1</th>\n",
       "      <th>d.109.1</th>\n",
       "      <th>d.110.1</th>\n",
       "      <th>d.111.1</th>\n",
       "      <th>d.112.1</th>\n",
       "      <th>d.113.1</th>\n",
       "      <th>d.114.1</th>\n",
       "      <th>d.115.1</th>\n",
       "      <th>d.116.1</th>\n",
       "      <th>d.117.1</th>\n",
       "      <th>d.118.1</th>\n",
       "      <th>d.119.1</th>\n",
       "      <th>d.120.1</th>\n",
       "      <th>d.121.1</th>\n",
       "      <th>d.122.1</th>\n",
       "      <th>d.123.1</th>\n",
       "      <th>d.124.1</th>\n",
       "      <th>d.125.1</th>\n",
       "      <th>d.126.1</th>\n",
       "      <th>d.127.1</th>\n",
       "      <th>d.128.1</th>\n",
       "      <th>d.129.1</th>\n",
       "      <th>d.130.1</th>\n",
       "      <th>d.131.1</th>\n",
       "      <th>d.132.1</th>\n",
       "      <th>d.133.1</th>\n",
       "      <th>d.134.1</th>\n",
       "      <th>d.135.1</th>\n",
       "      <th>d.136.1</th>\n",
       "      <th>d.137.1</th>\n",
       "      <th>d.138.1</th>\n",
       "      <th>d.139.1</th>\n",
       "      <th>d.140.1</th>\n",
       "      <th>d.141.1</th>\n",
       "      <th>d.142.1</th>\n",
       "      <th>d.143.1</th>\n",
       "      <th>d.144.1</th>\n",
       "      <th>d.145.1</th>\n",
       "      <th>d.146.1</th>\n",
       "      <th>d.147.1</th>\n",
       "      <th>d.148.1</th>\n",
       "      <th>d.149.1</th>\n",
       "      <th>d.150.1</th>\n",
       "      <th>d.151.1</th>\n",
       "      <th>d.152.1</th>\n",
       "      <th>d.153.1</th>\n",
       "      <th>d.154.1</th>\n",
       "      <th>d.155.1</th>\n",
       "      <th>d.156.1</th>\n",
       "      <th>d.157.1</th>\n",
       "      <th>d.158.1</th>\n",
       "      <th>d.159.1</th>\n",
       "      <th>d.160.1</th>\n",
       "      <th>d.161.1</th>\n",
       "      <th>d.162.1</th>\n",
       "      <th>d.163.1</th>\n",
       "      <th>d.164.1</th>\n",
       "      <th>d.165.1</th>\n",
       "      <th>d.166.1</th>\n",
       "      <th>d.167.1</th>\n",
       "      <th>d.168.1</th>\n",
       "      <th>d.169.1</th>\n",
       "      <th>d.170.1</th>\n",
       "      <th>d.171.1</th>\n",
       "      <th>d.172.1</th>\n",
       "      <th>d.173.1</th>\n",
       "      <th>d.174.1</th>\n",
       "      <th>d.175.1</th>\n",
       "      <th>d.176.1</th>\n",
       "      <th>d.177.1</th>\n",
       "      <th>d.178.1</th>\n",
       "      <th>d.179.1</th>\n",
       "      <th>d.180.1</th>\n",
       "      <th>d.181.1</th>\n",
       "      <th>d.182.1</th>\n",
       "      <th>d.183.1</th>\n",
       "      <th>d.184.1</th>\n",
       "      <th>d.185.1</th>\n",
       "      <th>d.186.1</th>\n",
       "      <th>d.187.1</th>\n",
       "      <th>d.188.1</th>\n",
       "      <th>d.189.1</th>\n",
       "      <th>d.190.1</th>\n",
       "      <th>d.191.1</th>\n",
       "      <th>d.192.1</th>\n",
       "      <th>d.193.1</th>\n",
       "      <th>d.194.1</th>\n",
       "      <th>d.195.1</th>\n",
       "      <th>d.196.1</th>\n",
       "      <th>d.197.1</th>\n",
       "      <th>d.198.1</th>\n",
       "      <th>d.199.1</th>\n",
       "      <th>d.200.1</th>\n",
       "      <th>d.201.1</th>\n",
       "      <th>d.202.1</th>\n",
       "      <th>d.203.1</th>\n",
       "      <th>d.204.1</th>\n",
       "      <th>d.205.1</th>\n",
       "      <th>d.206.1</th>\n",
       "      <th>d.207.1</th>\n",
       "      <th>d.208.1</th>\n",
       "      <th>d.209.1</th>\n",
       "      <th>d.210.1</th>\n",
       "      <th>d.211.1</th>\n",
       "      <th>d.212.1</th>\n",
       "      <th>d.213.1</th>\n",
       "      <th>d.214.1</th>\n",
       "      <th>d.215.1</th>\n",
       "      <th>d.216.1</th>\n",
       "      <th>d.217.1</th>\n",
       "      <th>d.218.1</th>\n",
       "      <th>d.219.1</th>\n",
       "      <th>d.220.1</th>\n",
       "      <th>d.221.1</th>\n",
       "      <th>d.222.1</th>\n",
       "      <th>d.223.1</th>\n",
       "      <th>d.224.1</th>\n",
       "      <th>d.225.1</th>\n",
       "      <th>d.226.1</th>\n",
       "      <th>d.227.1</th>\n",
       "      <th>d.228.1</th>\n",
       "      <th>d.229.1</th>\n",
       "      <th>d.230.1</th>\n",
       "      <th>d.231.1</th>\n",
       "      <th>d.232.1</th>\n",
       "      <th>d.233.1</th>\n",
       "      <th>d.234.1</th>\n",
       "      <th>d.235.1</th>\n",
       "      <th>d.236.1</th>\n",
       "      <th>d.237.1</th>\n",
       "      <th>d.238.1</th>\n",
       "      <th>d.239.1</th>\n",
       "      <th>d.240.1</th>\n",
       "      <th>d.241.1</th>\n",
       "      <th>d.242.1</th>\n",
       "      <th>d.243.1</th>\n",
       "      <th>d.244.1</th>\n",
       "      <th>d.245.1</th>\n",
       "      <th>d.246.1</th>\n",
       "      <th>d.247.1</th>\n",
       "      <th>d.248.1</th>\n",
       "      <th>d.249.1</th>\n",
       "      <th>d.250.1</th>\n",
       "      <th>d.251.1</th>\n",
       "      <th>d.252.1</th>\n",
       "      <th>d.253.1</th>\n",
       "      <th>d.254.1</th>\n",
       "      <th>d.255.1</th>\n",
       "      <th>d.256.1</th>\n",
       "      <th>d.257.1</th>\n",
       "      <th>d.258.1</th>\n",
       "      <th>d.259.1</th>\n",
       "      <th>d.260.1</th>\n",
       "      <th>d.261.1</th>\n",
       "      <th>d.262.1</th>\n",
       "      <th>d.263.1</th>\n",
       "      <th>d.264.1</th>\n",
       "      <th>d.265.1</th>\n",
       "      <th>d.266.1</th>\n",
       "      <th>d.267.1</th>\n",
       "      <th>d.268.1</th>\n",
       "      <th>d.269.1</th>\n",
       "      <th>d.270.1</th>\n",
       "      <th>d.271.1</th>\n",
       "      <th>d.272.1</th>\n",
       "      <th>d.273.1</th>\n",
       "      <th>d.274.1</th>\n",
       "      <th>d.275.1</th>\n",
       "      <th>d.276.1</th>\n",
       "      <th>d.277.1</th>\n",
       "      <th>d.278.1</th>\n",
       "      <th>d.279.1</th>\n",
       "      <th>d.280.1</th>\n",
       "      <th>d.281.1</th>\n",
       "      <th>d.282.1</th>\n",
       "      <th>d.283.1</th>\n",
       "      <th>d.284.1</th>\n",
       "      <th>d.285.1</th>\n",
       "      <th>d.286.1</th>\n",
       "      <th>d.287.1</th>\n",
       "      <th>d.288.1</th>\n",
       "      <th>d.289.1</th>\n",
       "      <th>d.290.1</th>\n",
       "      <th>d.291.1</th>\n",
       "      <th>d.292.1</th>\n",
       "      <th>d.293.1</th>\n",
       "      <th>d.294.1</th>\n",
       "      <th>d.295.1</th>\n",
       "      <th>d.296.1</th>\n",
       "      <th>d.297.1</th>\n",
       "      <th>d.298.1</th>\n",
       "      <th>d.299.1</th>\n",
       "      <th>d.300.1</th>\n",
       "      <th>d.1.2</th>\n",
       "      <th>d.2.2</th>\n",
       "      <th>d.3.2</th>\n",
       "      <th>d.4.2</th>\n",
       "      <th>d.5.2</th>\n",
       "      <th>d.6.2</th>\n",
       "      <th>d.7.2</th>\n",
       "      <th>d.8.2</th>\n",
       "      <th>d.9.2</th>\n",
       "      <th>d.10.2</th>\n",
       "      <th>d.11.2</th>\n",
       "      <th>d.12.2</th>\n",
       "      <th>d.13.2</th>\n",
       "      <th>d.14.2</th>\n",
       "      <th>d.15.2</th>\n",
       "      <th>d.16.2</th>\n",
       "      <th>d.17.2</th>\n",
       "      <th>d.18.2</th>\n",
       "      <th>d.19.2</th>\n",
       "      <th>d.20.2</th>\n",
       "      <th>d.21.2</th>\n",
       "      <th>d.22.2</th>\n",
       "      <th>d.23.2</th>\n",
       "      <th>d.24.2</th>\n",
       "      <th>d.25.2</th>\n",
       "      <th>d.26.2</th>\n",
       "      <th>d.27.2</th>\n",
       "      <th>d.28.2</th>\n",
       "      <th>d.29.2</th>\n",
       "      <th>d.30.2</th>\n",
       "      <th>d.31.2</th>\n",
       "      <th>d.32.2</th>\n",
       "      <th>d.33.2</th>\n",
       "      <th>d.34.2</th>\n",
       "      <th>d.35.2</th>\n",
       "      <th>d.36.2</th>\n",
       "      <th>d.37.2</th>\n",
       "      <th>d.38.2</th>\n",
       "      <th>d.39.2</th>\n",
       "      <th>d.40.2</th>\n",
       "      <th>d.41.2</th>\n",
       "      <th>d.42.2</th>\n",
       "      <th>d.43.2</th>\n",
       "      <th>d.44.2</th>\n",
       "      <th>d.45.2</th>\n",
       "      <th>d.46.2</th>\n",
       "      <th>d.47.2</th>\n",
       "      <th>d.48.2</th>\n",
       "      <th>d.49.2</th>\n",
       "      <th>d.50.2</th>\n",
       "      <th>d.51.2</th>\n",
       "      <th>d.52.2</th>\n",
       "      <th>d.53.2</th>\n",
       "      <th>d.54.2</th>\n",
       "      <th>d.55.2</th>\n",
       "      <th>d.56.2</th>\n",
       "      <th>d.57.2</th>\n",
       "      <th>d.58.2</th>\n",
       "      <th>d.59.2</th>\n",
       "      <th>d.60.2</th>\n",
       "      <th>d.61.2</th>\n",
       "      <th>d.62.2</th>\n",
       "      <th>d.63.2</th>\n",
       "      <th>d.64.2</th>\n",
       "      <th>d.65.2</th>\n",
       "      <th>d.66.2</th>\n",
       "      <th>d.67.2</th>\n",
       "      <th>d.68.2</th>\n",
       "      <th>d.69.2</th>\n",
       "      <th>d.70.2</th>\n",
       "      <th>d.71.2</th>\n",
       "      <th>d.72.2</th>\n",
       "      <th>d.73.2</th>\n",
       "      <th>d.74.2</th>\n",
       "      <th>d.75.2</th>\n",
       "      <th>d.76.2</th>\n",
       "      <th>d.77.2</th>\n",
       "      <th>d.78.2</th>\n",
       "      <th>d.79.2</th>\n",
       "      <th>d.80.2</th>\n",
       "      <th>d.81.2</th>\n",
       "      <th>d.82.2</th>\n",
       "      <th>d.83.2</th>\n",
       "      <th>d.84.2</th>\n",
       "      <th>d.85.2</th>\n",
       "      <th>d.86.2</th>\n",
       "      <th>d.87.2</th>\n",
       "      <th>d.88.2</th>\n",
       "      <th>d.89.2</th>\n",
       "      <th>d.90.2</th>\n",
       "      <th>d.91.2</th>\n",
       "      <th>d.92.2</th>\n",
       "      <th>d.93.2</th>\n",
       "      <th>d.94.2</th>\n",
       "      <th>d.95.2</th>\n",
       "      <th>d.96.2</th>\n",
       "      <th>d.97.2</th>\n",
       "      <th>d.98.2</th>\n",
       "      <th>d.99.2</th>\n",
       "      <th>d.100.2</th>\n",
       "      <th>d.101.2</th>\n",
       "      <th>d.102.2</th>\n",
       "      <th>d.103.2</th>\n",
       "      <th>d.104.2</th>\n",
       "      <th>d.105.2</th>\n",
       "      <th>d.106.2</th>\n",
       "      <th>d.107.2</th>\n",
       "      <th>d.108.2</th>\n",
       "      <th>d.109.2</th>\n",
       "      <th>d.110.2</th>\n",
       "      <th>d.111.2</th>\n",
       "      <th>d.112.2</th>\n",
       "      <th>d.113.2</th>\n",
       "      <th>d.114.2</th>\n",
       "      <th>d.115.2</th>\n",
       "      <th>d.116.2</th>\n",
       "      <th>d.117.2</th>\n",
       "      <th>d.118.2</th>\n",
       "      <th>d.119.2</th>\n",
       "      <th>d.120.2</th>\n",
       "      <th>d.121.2</th>\n",
       "      <th>d.122.2</th>\n",
       "      <th>d.123.2</th>\n",
       "      <th>d.124.2</th>\n",
       "      <th>d.125.2</th>\n",
       "      <th>d.126.2</th>\n",
       "      <th>d.127.2</th>\n",
       "      <th>d.128.2</th>\n",
       "      <th>d.129.2</th>\n",
       "      <th>d.130.2</th>\n",
       "      <th>d.131.2</th>\n",
       "      <th>d.132.2</th>\n",
       "      <th>d.133.2</th>\n",
       "      <th>d.134.2</th>\n",
       "      <th>d.135.2</th>\n",
       "      <th>d.136.2</th>\n",
       "      <th>d.137.2</th>\n",
       "      <th>d.138.2</th>\n",
       "      <th>d.139.2</th>\n",
       "      <th>d.140.2</th>\n",
       "      <th>d.141.2</th>\n",
       "      <th>d.142.2</th>\n",
       "      <th>d.143.2</th>\n",
       "      <th>d.144.2</th>\n",
       "      <th>d.145.2</th>\n",
       "      <th>d.146.2</th>\n",
       "      <th>d.147.2</th>\n",
       "      <th>d.148.2</th>\n",
       "      <th>d.149.2</th>\n",
       "      <th>d.150.2</th>\n",
       "      <th>d.151.2</th>\n",
       "      <th>d.152.2</th>\n",
       "      <th>d.153.2</th>\n",
       "      <th>d.154.2</th>\n",
       "      <th>d.155.2</th>\n",
       "      <th>d.156.2</th>\n",
       "      <th>d.157.2</th>\n",
       "      <th>d.158.2</th>\n",
       "      <th>d.159.2</th>\n",
       "      <th>d.160.2</th>\n",
       "      <th>d.161.2</th>\n",
       "      <th>d.162.2</th>\n",
       "      <th>d.163.2</th>\n",
       "      <th>d.164.2</th>\n",
       "      <th>d.165.2</th>\n",
       "      <th>d.166.2</th>\n",
       "      <th>d.167.2</th>\n",
       "      <th>d.168.2</th>\n",
       "      <th>d.169.2</th>\n",
       "      <th>d.170.2</th>\n",
       "      <th>d.171.2</th>\n",
       "      <th>d.172.2</th>\n",
       "      <th>d.173.2</th>\n",
       "      <th>d.174.2</th>\n",
       "      <th>d.175.2</th>\n",
       "      <th>d.176.2</th>\n",
       "      <th>d.177.2</th>\n",
       "      <th>d.178.2</th>\n",
       "      <th>d.179.2</th>\n",
       "      <th>d.180.2</th>\n",
       "      <th>d.181.2</th>\n",
       "      <th>d.182.2</th>\n",
       "      <th>d.183.2</th>\n",
       "      <th>d.184.2</th>\n",
       "      <th>d.185.2</th>\n",
       "      <th>d.186.2</th>\n",
       "      <th>d.187.2</th>\n",
       "      <th>d.188.2</th>\n",
       "      <th>d.189.2</th>\n",
       "      <th>d.190.2</th>\n",
       "      <th>d.191.2</th>\n",
       "      <th>d.192.2</th>\n",
       "      <th>d.193.2</th>\n",
       "      <th>d.194.2</th>\n",
       "      <th>d.195.2</th>\n",
       "      <th>d.196.2</th>\n",
       "      <th>d.197.2</th>\n",
       "      <th>d.198.2</th>\n",
       "      <th>d.199.2</th>\n",
       "      <th>d.200.2</th>\n",
       "      <th>d.201.2</th>\n",
       "      <th>d.202.2</th>\n",
       "      <th>d.203.2</th>\n",
       "      <th>d.204.2</th>\n",
       "      <th>d.205.2</th>\n",
       "      <th>d.206.2</th>\n",
       "      <th>d.207.2</th>\n",
       "      <th>d.208.2</th>\n",
       "      <th>d.209.2</th>\n",
       "      <th>d.210.2</th>\n",
       "      <th>d.211.2</th>\n",
       "      <th>d.212.2</th>\n",
       "      <th>d.213.2</th>\n",
       "      <th>d.214.2</th>\n",
       "      <th>d.215.2</th>\n",
       "      <th>d.216.2</th>\n",
       "      <th>d.217.2</th>\n",
       "      <th>d.218.2</th>\n",
       "      <th>d.219.2</th>\n",
       "      <th>d.220.2</th>\n",
       "      <th>d.221.2</th>\n",
       "      <th>d.222.2</th>\n",
       "      <th>d.223.2</th>\n",
       "      <th>d.224.2</th>\n",
       "      <th>d.225.2</th>\n",
       "      <th>d.226.2</th>\n",
       "      <th>d.227.2</th>\n",
       "      <th>d.228.2</th>\n",
       "      <th>d.229.2</th>\n",
       "      <th>d.230.2</th>\n",
       "      <th>d.231.2</th>\n",
       "      <th>d.232.2</th>\n",
       "      <th>d.233.2</th>\n",
       "      <th>d.234.2</th>\n",
       "      <th>d.235.2</th>\n",
       "      <th>d.236.2</th>\n",
       "      <th>d.237.2</th>\n",
       "      <th>d.238.2</th>\n",
       "      <th>d.239.2</th>\n",
       "      <th>d.240.2</th>\n",
       "      <th>d.241.2</th>\n",
       "      <th>d.242.2</th>\n",
       "      <th>d.243.2</th>\n",
       "      <th>d.244.2</th>\n",
       "      <th>d.245.2</th>\n",
       "      <th>d.246.2</th>\n",
       "      <th>d.247.2</th>\n",
       "      <th>d.248.2</th>\n",
       "      <th>d.249.2</th>\n",
       "      <th>d.250.2</th>\n",
       "      <th>d.251.2</th>\n",
       "      <th>d.252.2</th>\n",
       "      <th>d.253.2</th>\n",
       "      <th>d.254.2</th>\n",
       "      <th>d.255.2</th>\n",
       "      <th>d.256.2</th>\n",
       "      <th>d.257.2</th>\n",
       "      <th>d.258.2</th>\n",
       "      <th>d.259.2</th>\n",
       "      <th>d.260.2</th>\n",
       "      <th>d.261.2</th>\n",
       "      <th>d.262.2</th>\n",
       "      <th>d.263.2</th>\n",
       "      <th>d.264.2</th>\n",
       "      <th>d.265.2</th>\n",
       "      <th>d.266.2</th>\n",
       "      <th>d.267.2</th>\n",
       "      <th>d.268.2</th>\n",
       "      <th>d.269.2</th>\n",
       "      <th>d.270.2</th>\n",
       "      <th>d.271.2</th>\n",
       "      <th>d.272.2</th>\n",
       "      <th>d.273.2</th>\n",
       "      <th>d.274.2</th>\n",
       "      <th>d.275.2</th>\n",
       "      <th>d.276.2</th>\n",
       "      <th>d.277.2</th>\n",
       "      <th>d.278.2</th>\n",
       "      <th>d.279.2</th>\n",
       "      <th>d.280.2</th>\n",
       "      <th>d.281.2</th>\n",
       "      <th>d.282.2</th>\n",
       "      <th>d.283.2</th>\n",
       "      <th>d.284.2</th>\n",
       "      <th>d.285.2</th>\n",
       "      <th>d.286.2</th>\n",
       "      <th>d.287.2</th>\n",
       "      <th>d.288.2</th>\n",
       "      <th>d.289.2</th>\n",
       "      <th>d.290.2</th>\n",
       "      <th>d.291.2</th>\n",
       "      <th>d.292.2</th>\n",
       "      <th>d.293.2</th>\n",
       "      <th>d.294.2</th>\n",
       "      <th>d.295.2</th>\n",
       "      <th>d.296.2</th>\n",
       "      <th>d.297.2</th>\n",
       "      <th>d.298.2</th>\n",
       "      <th>d.299.2</th>\n",
       "      <th>d.300.2</th>\n",
       "      <th>Rho_d.1.1</th>\n",
       "      <th>Rho_d.2.1</th>\n",
       "      <th>Rho_d.1.2</th>\n",
       "      <th>Rho_d.2.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draws</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4048.459180</td>\n",
       "      <td>0.975809</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3743.302273</td>\n",
       "      <td>0.433051</td>\n",
       "      <td>-0.220741</td>\n",
       "      <td>0.401745</td>\n",
       "      <td>1.242820</td>\n",
       "      <td>-0.622549</td>\n",
       "      <td>-0.318421</td>\n",
       "      <td>-0.709739</td>\n",
       "      <td>-0.088533</td>\n",
       "      <td>-0.765039</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>1.300275</td>\n",
       "      <td>-1.044434</td>\n",
       "      <td>-0.673696</td>\n",
       "      <td>1.260101</td>\n",
       "      <td>0.461959</td>\n",
       "      <td>-0.942580</td>\n",
       "      <td>-0.132762</td>\n",
       "      <td>0.614654</td>\n",
       "      <td>-0.270887</td>\n",
       "      <td>-0.156980</td>\n",
       "      <td>1.502897</td>\n",
       "      <td>1.702542</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>1.225790</td>\n",
       "      <td>-0.047847</td>\n",
       "      <td>-1.211805</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>-0.021407</td>\n",
       "      <td>0.021177</td>\n",
       "      <td>0.141976</td>\n",
       "      <td>0.319627</td>\n",
       "      <td>0.483374</td>\n",
       "      <td>0.071446</td>\n",
       "      <td>0.286244</td>\n",
       "      <td>-0.116576</td>\n",
       "      <td>-0.272807</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>0.198853</td>\n",
       "      <td>0.395958</td>\n",
       "      <td>0.173881</td>\n",
       "      <td>0.126640</td>\n",
       "      <td>-0.078914</td>\n",
       "      <td>-0.393609</td>\n",
       "      <td>-0.330482</td>\n",
       "      <td>0.374049</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>-0.194554</td>\n",
       "      <td>-0.588709</td>\n",
       "      <td>0.062139</td>\n",
       "      <td>0.103976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.305117</td>\n",
       "      <td>-0.305117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758852</td>\n",
       "      <td>0.257449</td>\n",
       "      <td>-0.407745</td>\n",
       "      <td>-0.229848</td>\n",
       "      <td>0.745506</td>\n",
       "      <td>1.532677</td>\n",
       "      <td>0.263228</td>\n",
       "      <td>-0.105839</td>\n",
       "      <td>-0.319586</td>\n",
       "      <td>0.401045</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>-0.321751</td>\n",
       "      <td>0.238768</td>\n",
       "      <td>0.472407</td>\n",
       "      <td>0.877066</td>\n",
       "      <td>0.612783</td>\n",
       "      <td>-1.050062</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>2.260091</td>\n",
       "      <td>1.262163</td>\n",
       "      <td>-0.480780</td>\n",
       "      <td>0.704697</td>\n",
       "      <td>0.497196</td>\n",
       "      <td>-1.933527</td>\n",
       "      <td>-1.193025</td>\n",
       "      <td>0.778337</td>\n",
       "      <td>0.324471</td>\n",
       "      <td>1.366866</td>\n",
       "      <td>0.961185</td>\n",
       "      <td>0.306431</td>\n",
       "      <td>-0.124357</td>\n",
       "      <td>-0.490751</td>\n",
       "      <td>-1.485669</td>\n",
       "      <td>-0.191628</td>\n",
       "      <td>-1.674750</td>\n",
       "      <td>0.754830</td>\n",
       "      <td>-0.312898</td>\n",
       "      <td>-0.349709</td>\n",
       "      <td>-1.749415</td>\n",
       "      <td>-2.414545</td>\n",
       "      <td>-0.749000</td>\n",
       "      <td>1.034366</td>\n",
       "      <td>-1.185957</td>\n",
       "      <td>-0.086775</td>\n",
       "      <td>-0.293986</td>\n",
       "      <td>1.944776</td>\n",
       "      <td>-1.060016</td>\n",
       "      <td>0.405065</td>\n",
       "      <td>1.941936</td>\n",
       "      <td>-0.417049</td>\n",
       "      <td>0.067733</td>\n",
       "      <td>-1.119269</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.731391</td>\n",
       "      <td>-2.030987</td>\n",
       "      <td>-0.047180</td>\n",
       "      <td>-0.067319</td>\n",
       "      <td>-0.633767</td>\n",
       "      <td>-2.100427</td>\n",
       "      <td>0.748536</td>\n",
       "      <td>2.290921</td>\n",
       "      <td>0.322586</td>\n",
       "      <td>1.001075</td>\n",
       "      <td>-1.643911</td>\n",
       "      <td>-0.791191</td>\n",
       "      <td>-0.555883</td>\n",
       "      <td>-0.996328</td>\n",
       "      <td>0.249450</td>\n",
       "      <td>-1.043384</td>\n",
       "      <td>-2.008439</td>\n",
       "      <td>-0.369917</td>\n",
       "      <td>-0.256396</td>\n",
       "      <td>-1.620561</td>\n",
       "      <td>-1.049313</td>\n",
       "      <td>0.383279</td>\n",
       "      <td>0.104765</td>\n",
       "      <td>0.260491</td>\n",
       "      <td>0.260654</td>\n",
       "      <td>2.223554</td>\n",
       "      <td>-0.389354</td>\n",
       "      <td>-1.086489</td>\n",
       "      <td>-0.466568</td>\n",
       "      <td>1.303266</td>\n",
       "      <td>-0.343015</td>\n",
       "      <td>-0.388987</td>\n",
       "      <td>0.287837</td>\n",
       "      <td>-1.464585</td>\n",
       "      <td>-1.734827</td>\n",
       "      <td>1.674691</td>\n",
       "      <td>1.022999</td>\n",
       "      <td>0.555116</td>\n",
       "      <td>-0.201714</td>\n",
       "      <td>0.416743</td>\n",
       "      <td>1.014936</td>\n",
       "      <td>-0.721373</td>\n",
       "      <td>-1.217924</td>\n",
       "      <td>0.298772</td>\n",
       "      <td>-0.104211</td>\n",
       "      <td>0.874799</td>\n",
       "      <td>-0.092232</td>\n",
       "      <td>1.548656</td>\n",
       "      <td>0.165177</td>\n",
       "      <td>0.120429</td>\n",
       "      <td>-0.790525</td>\n",
       "      <td>-0.212109</td>\n",
       "      <td>0.105493</td>\n",
       "      <td>-2.423640</td>\n",
       "      <td>1.280650</td>\n",
       "      <td>-0.020982</td>\n",
       "      <td>-0.089133</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>0.284171</td>\n",
       "      <td>-0.103780</td>\n",
       "      <td>-0.857248</td>\n",
       "      <td>-0.086808</td>\n",
       "      <td>0.031664</td>\n",
       "      <td>0.421852</td>\n",
       "      <td>-0.720321</td>\n",
       "      <td>1.080155</td>\n",
       "      <td>1.266750</td>\n",
       "      <td>-0.164728</td>\n",
       "      <td>-1.038069</td>\n",
       "      <td>0.507673</td>\n",
       "      <td>0.098148</td>\n",
       "      <td>-1.619776</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>-1.033245</td>\n",
       "      <td>-1.687531</td>\n",
       "      <td>-1.086015</td>\n",
       "      <td>-0.236832</td>\n",
       "      <td>-0.598458</td>\n",
       "      <td>-1.058645</td>\n",
       "      <td>-0.777863</td>\n",
       "      <td>-0.096043</td>\n",
       "      <td>1.031097</td>\n",
       "      <td>1.108616</td>\n",
       "      <td>-0.846200</td>\n",
       "      <td>-1.242557</td>\n",
       "      <td>-0.107453</td>\n",
       "      <td>1.103464</td>\n",
       "      <td>0.596517</td>\n",
       "      <td>1.019058</td>\n",
       "      <td>2.489772</td>\n",
       "      <td>-0.638243</td>\n",
       "      <td>-1.290517</td>\n",
       "      <td>0.731291</td>\n",
       "      <td>-1.020852</td>\n",
       "      <td>-1.599648</td>\n",
       "      <td>-1.804380</td>\n",
       "      <td>1.193622</td>\n",
       "      <td>-0.136760</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.351336</td>\n",
       "      <td>-0.287122</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>-1.046923</td>\n",
       "      <td>-0.842048</td>\n",
       "      <td>2.763843</td>\n",
       "      <td>0.734349</td>\n",
       "      <td>0.087597</td>\n",
       "      <td>1.456988</td>\n",
       "      <td>0.159415</td>\n",
       "      <td>2.185086</td>\n",
       "      <td>0.705207</td>\n",
       "      <td>0.288196</td>\n",
       "      <td>-1.496956</td>\n",
       "      <td>-0.526712</td>\n",
       "      <td>1.017949</td>\n",
       "      <td>-0.349215</td>\n",
       "      <td>1.599696</td>\n",
       "      <td>-1.281741</td>\n",
       "      <td>-1.474860</td>\n",
       "      <td>-0.614036</td>\n",
       "      <td>-0.381978</td>\n",
       "      <td>-0.206835</td>\n",
       "      <td>-0.721385</td>\n",
       "      <td>0.489974</td>\n",
       "      <td>0.460484</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>1.007295</td>\n",
       "      <td>1.960641</td>\n",
       "      <td>1.302999</td>\n",
       "      <td>-0.169176</td>\n",
       "      <td>0.692012</td>\n",
       "      <td>-1.269539</td>\n",
       "      <td>-1.065533</td>\n",
       "      <td>-0.796902</td>\n",
       "      <td>1.692118</td>\n",
       "      <td>1.425208</td>\n",
       "      <td>-1.222763</td>\n",
       "      <td>0.138387</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>1.035881</td>\n",
       "      <td>0.585491</td>\n",
       "      <td>-0.428275</td>\n",
       "      <td>2.392275</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>-1.074735</td>\n",
       "      <td>0.471482</td>\n",
       "      <td>0.667781</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>0.589836</td>\n",
       "      <td>-0.918103</td>\n",
       "      <td>0.095939</td>\n",
       "      <td>-1.118690</td>\n",
       "      <td>-0.035443</td>\n",
       "      <td>0.446277</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>0.225159</td>\n",
       "      <td>-0.967839</td>\n",
       "      <td>-0.342213</td>\n",
       "      <td>-0.499825</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.836272</td>\n",
       "      <td>-0.697026</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>0.830182</td>\n",
       "      <td>-2.256811</td>\n",
       "      <td>-0.288981</td>\n",
       "      <td>-1.866656</td>\n",
       "      <td>-1.704418</td>\n",
       "      <td>-0.500388</td>\n",
       "      <td>-1.182197</td>\n",
       "      <td>-2.068117</td>\n",
       "      <td>0.359677</td>\n",
       "      <td>0.892811</td>\n",
       "      <td>0.276389</td>\n",
       "      <td>1.055525</td>\n",
       "      <td>-1.644336</td>\n",
       "      <td>0.232529</td>\n",
       "      <td>0.134439</td>\n",
       "      <td>-0.110337</td>\n",
       "      <td>1.155801</td>\n",
       "      <td>1.614495</td>\n",
       "      <td>-0.501635</td>\n",
       "      <td>1.622383</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>1.382536</td>\n",
       "      <td>0.203832</td>\n",
       "      <td>0.494538</td>\n",
       "      <td>-1.860905</td>\n",
       "      <td>-0.553706</td>\n",
       "      <td>-0.171643</td>\n",
       "      <td>0.550548</td>\n",
       "      <td>-1.272862</td>\n",
       "      <td>-0.756821</td>\n",
       "      <td>-0.478944</td>\n",
       "      <td>-0.362341</td>\n",
       "      <td>-0.668495</td>\n",
       "      <td>0.242355</td>\n",
       "      <td>1.059903</td>\n",
       "      <td>1.033359</td>\n",
       "      <td>-0.323507</td>\n",
       "      <td>-1.081084</td>\n",
       "      <td>1.019081</td>\n",
       "      <td>-0.851183</td>\n",
       "      <td>0.137213</td>\n",
       "      <td>-0.013310</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.637840</td>\n",
       "      <td>-0.987354</td>\n",
       "      <td>1.277181</td>\n",
       "      <td>-0.030232</td>\n",
       "      <td>-1.991862</td>\n",
       "      <td>-0.854215</td>\n",
       "      <td>1.014998</td>\n",
       "      <td>0.657532</td>\n",
       "      <td>-0.611398</td>\n",
       "      <td>-0.467277</td>\n",
       "      <td>-0.842790</td>\n",
       "      <td>0.178724</td>\n",
       "      <td>1.877258</td>\n",
       "      <td>0.878334</td>\n",
       "      <td>0.230417</td>\n",
       "      <td>-0.142293</td>\n",
       "      <td>-0.296493</td>\n",
       "      <td>-0.530164</td>\n",
       "      <td>-0.232112</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-1.124009</td>\n",
       "      <td>-0.069369</td>\n",
       "      <td>-0.222869</td>\n",
       "      <td>0.205650</td>\n",
       "      <td>0.569872</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.378692</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.097842</td>\n",
       "      <td>1.157225</td>\n",
       "      <td>0.186577</td>\n",
       "      <td>0.512074</td>\n",
       "      <td>1.608333</td>\n",
       "      <td>0.149923</td>\n",
       "      <td>0.951102</td>\n",
       "      <td>-1.609562</td>\n",
       "      <td>0.192476</td>\n",
       "      <td>0.577872</td>\n",
       "      <td>-0.532397</td>\n",
       "      <td>0.347975</td>\n",
       "      <td>-0.710726</td>\n",
       "      <td>-0.587099</td>\n",
       "      <td>-0.182126</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>-0.273606</td>\n",
       "      <td>-0.442736</td>\n",
       "      <td>0.124064</td>\n",
       "      <td>1.007144</td>\n",
       "      <td>1.004323</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>-0.719621</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.649594</td>\n",
       "      <td>1.639052</td>\n",
       "      <td>0.218945</td>\n",
       "      <td>0.921334</td>\n",
       "      <td>-1.496541</td>\n",
       "      <td>0.940202</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>-0.387609</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>-1.545164</td>\n",
       "      <td>-1.111940</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>-2.177462</td>\n",
       "      <td>-0.457252</td>\n",
       "      <td>-1.048763</td>\n",
       "      <td>-0.849832</td>\n",
       "      <td>-1.993255</td>\n",
       "      <td>-1.256607</td>\n",
       "      <td>-0.394906</td>\n",
       "      <td>-1.735839</td>\n",
       "      <td>-0.351334</td>\n",
       "      <td>-0.269150</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>-0.382552</td>\n",
       "      <td>0.858676</td>\n",
       "      <td>0.394325</td>\n",
       "      <td>1.014967</td>\n",
       "      <td>-0.150683</td>\n",
       "      <td>0.870288</td>\n",
       "      <td>0.560541</td>\n",
       "      <td>0.858278</td>\n",
       "      <td>1.134295</td>\n",
       "      <td>0.260536</td>\n",
       "      <td>1.691566</td>\n",
       "      <td>0.469394</td>\n",
       "      <td>0.185033</td>\n",
       "      <td>-0.063194</td>\n",
       "      <td>-0.266999</td>\n",
       "      <td>-1.294115</td>\n",
       "      <td>-0.193082</td>\n",
       "      <td>2.953827</td>\n",
       "      <td>-0.380779</td>\n",
       "      <td>-0.717379</td>\n",
       "      <td>-0.981844</td>\n",
       "      <td>0.371068</td>\n",
       "      <td>1.282060</td>\n",
       "      <td>0.865336</td>\n",
       "      <td>-3.044838</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.678863</td>\n",
       "      <td>-0.394857</td>\n",
       "      <td>0.962960</td>\n",
       "      <td>0.691870</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.670726</td>\n",
       "      <td>0.252591</td>\n",
       "      <td>0.342732</td>\n",
       "      <td>-0.480275</td>\n",
       "      <td>-0.963289</td>\n",
       "      <td>-0.705400</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>-0.593233</td>\n",
       "      <td>-0.981008</td>\n",
       "      <td>0.378491</td>\n",
       "      <td>-0.175633</td>\n",
       "      <td>-0.270884</td>\n",
       "      <td>1.676750</td>\n",
       "      <td>-0.079560</td>\n",
       "      <td>-0.289013</td>\n",
       "      <td>-1.249484</td>\n",
       "      <td>0.244958</td>\n",
       "      <td>1.730934</td>\n",
       "      <td>1.530976</td>\n",
       "      <td>3.259456</td>\n",
       "      <td>-0.090013</td>\n",
       "      <td>1.640392</td>\n",
       "      <td>0.769577</td>\n",
       "      <td>1.001403</td>\n",
       "      <td>-0.524934</td>\n",
       "      <td>-0.332415</td>\n",
       "      <td>-0.135464</td>\n",
       "      <td>-1.127972</td>\n",
       "      <td>2.307152</td>\n",
       "      <td>-0.267959</td>\n",
       "      <td>-0.661513</td>\n",
       "      <td>-0.912385</td>\n",
       "      <td>-0.907534</td>\n",
       "      <td>-0.255144</td>\n",
       "      <td>-1.676469</td>\n",
       "      <td>-1.135161</td>\n",
       "      <td>0.796501</td>\n",
       "      <td>-1.397150</td>\n",
       "      <td>0.750070</td>\n",
       "      <td>-1.901946</td>\n",
       "      <td>-0.161131</td>\n",
       "      <td>-0.070010</td>\n",
       "      <td>0.771634</td>\n",
       "      <td>0.721395</td>\n",
       "      <td>-0.687563</td>\n",
       "      <td>0.625212</td>\n",
       "      <td>-0.331866</td>\n",
       "      <td>1.471524</td>\n",
       "      <td>1.067197</td>\n",
       "      <td>0.379751</td>\n",
       "      <td>-0.160306</td>\n",
       "      <td>-0.047961</td>\n",
       "      <td>-0.137530</td>\n",
       "      <td>-0.012484</td>\n",
       "      <td>0.348187</td>\n",
       "      <td>-1.012746</td>\n",
       "      <td>-1.528896</td>\n",
       "      <td>-1.991741</td>\n",
       "      <td>-0.057893</td>\n",
       "      <td>0.251506</td>\n",
       "      <td>1.056235</td>\n",
       "      <td>-1.503587</td>\n",
       "      <td>0.939415</td>\n",
       "      <td>-0.279350</td>\n",
       "      <td>-0.333166</td>\n",
       "      <td>-0.624511</td>\n",
       "      <td>0.825865</td>\n",
       "      <td>-0.870484</td>\n",
       "      <td>2.048743</td>\n",
       "      <td>-1.759479</td>\n",
       "      <td>0.364668</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>-1.123401</td>\n",
       "      <td>1.649176</td>\n",
       "      <td>0.764155</td>\n",
       "      <td>-0.862793</td>\n",
       "      <td>-0.442504</td>\n",
       "      <td>0.175428</td>\n",
       "      <td>-0.887106</td>\n",
       "      <td>-1.410454</td>\n",
       "      <td>-0.269047</td>\n",
       "      <td>-2.524708</td>\n",
       "      <td>-1.321545</td>\n",
       "      <td>-0.326580</td>\n",
       "      <td>0.745544</td>\n",
       "      <td>0.466806</td>\n",
       "      <td>-0.109665</td>\n",
       "      <td>-0.571703</td>\n",
       "      <td>-1.814963</td>\n",
       "      <td>-1.455457</td>\n",
       "      <td>0.395886</td>\n",
       "      <td>-1.247855</td>\n",
       "      <td>-1.368274</td>\n",
       "      <td>-0.090387</td>\n",
       "      <td>-0.547681</td>\n",
       "      <td>0.563610</td>\n",
       "      <td>0.085771</td>\n",
       "      <td>0.145211</td>\n",
       "      <td>0.989378</td>\n",
       "      <td>-0.444949</td>\n",
       "      <td>1.129208</td>\n",
       "      <td>0.085336</td>\n",
       "      <td>0.373794</td>\n",
       "      <td>-1.108464</td>\n",
       "      <td>0.683629</td>\n",
       "      <td>-0.615402</td>\n",
       "      <td>0.244323</td>\n",
       "      <td>0.408857</td>\n",
       "      <td>-0.108795</td>\n",
       "      <td>-0.243651</td>\n",
       "      <td>0.462552</td>\n",
       "      <td>-0.533178</td>\n",
       "      <td>-2.039531</td>\n",
       "      <td>-0.713953</td>\n",
       "      <td>1.175128</td>\n",
       "      <td>-0.762853</td>\n",
       "      <td>-1.074885</td>\n",
       "      <td>-1.638510</td>\n",
       "      <td>-0.322943</td>\n",
       "      <td>2.306729</td>\n",
       "      <td>1.017136</td>\n",
       "      <td>-0.460609</td>\n",
       "      <td>1.093187</td>\n",
       "      <td>-1.070493</td>\n",
       "      <td>1.089439</td>\n",
       "      <td>-0.084093</td>\n",
       "      <td>1.913826</td>\n",
       "      <td>0.348161</td>\n",
       "      <td>0.237829</td>\n",
       "      <td>1.075346</td>\n",
       "      <td>0.625004</td>\n",
       "      <td>1.178419</td>\n",
       "      <td>-0.916089</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>-1.027177</td>\n",
       "      <td>0.562374</td>\n",
       "      <td>0.784724</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>0.840861</td>\n",
       "      <td>0.391231</td>\n",
       "      <td>-0.550165</td>\n",
       "      <td>0.681499</td>\n",
       "      <td>1.176131</td>\n",
       "      <td>1.432658</td>\n",
       "      <td>0.147938</td>\n",
       "      <td>-0.299009</td>\n",
       "      <td>0.179229</td>\n",
       "      <td>0.158094</td>\n",
       "      <td>2.042774</td>\n",
       "      <td>-0.646161</td>\n",
       "      <td>2.643519</td>\n",
       "      <td>0.441437</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>-0.424986</td>\n",
       "      <td>-0.060793</td>\n",
       "      <td>0.421211</td>\n",
       "      <td>-1.303775</td>\n",
       "      <td>0.058181</td>\n",
       "      <td>1.618167</td>\n",
       "      <td>1.012304</td>\n",
       "      <td>1.954381</td>\n",
       "      <td>-0.201758</td>\n",
       "      <td>1.133942</td>\n",
       "      <td>-0.857608</td>\n",
       "      <td>2.361891</td>\n",
       "      <td>1.373045</td>\n",
       "      <td>0.498801</td>\n",
       "      <td>-0.401383</td>\n",
       "      <td>-1.235380</td>\n",
       "      <td>0.428421</td>\n",
       "      <td>1.323584</td>\n",
       "      <td>0.405822</td>\n",
       "      <td>0.942658</td>\n",
       "      <td>-0.138024</td>\n",
       "      <td>0.268988</td>\n",
       "      <td>-1.314127</td>\n",
       "      <td>0.826033</td>\n",
       "      <td>2.160101</td>\n",
       "      <td>0.209759</td>\n",
       "      <td>-1.542430</td>\n",
       "      <td>-1.264669</td>\n",
       "      <td>0.093430</td>\n",
       "      <td>0.147259</td>\n",
       "      <td>0.924504</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>-0.384478</td>\n",
       "      <td>-0.264944</td>\n",
       "      <td>0.059454</td>\n",
       "      <td>1.899268</td>\n",
       "      <td>0.800016</td>\n",
       "      <td>0.643279</td>\n",
       "      <td>1.854994</td>\n",
       "      <td>0.560486</td>\n",
       "      <td>-0.808894</td>\n",
       "      <td>0.453711</td>\n",
       "      <td>-0.421325</td>\n",
       "      <td>0.466425</td>\n",
       "      <td>0.716427</td>\n",
       "      <td>0.733540</td>\n",
       "      <td>0.279733</td>\n",
       "      <td>-0.807705</td>\n",
       "      <td>-1.196004</td>\n",
       "      <td>0.116112</td>\n",
       "      <td>-0.097709</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>0.224051</td>\n",
       "      <td>-2.115554</td>\n",
       "      <td>-1.622363</td>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.774984</td>\n",
       "      <td>0.393429</td>\n",
       "      <td>0.072614</td>\n",
       "      <td>-1.813051</td>\n",
       "      <td>-1.882276</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>0.084141</td>\n",
       "      <td>0.159880</td>\n",
       "      <td>-0.748036</td>\n",
       "      <td>-0.764569</td>\n",
       "      <td>-1.022217</td>\n",
       "      <td>-0.460769</td>\n",
       "      <td>-0.640573</td>\n",
       "      <td>-0.477693</td>\n",
       "      <td>-0.387916</td>\n",
       "      <td>0.388673</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>0.084240</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>-0.862092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501076</td>\n",
       "      <td>1.174641</td>\n",
       "      <td>-0.478953</td>\n",
       "      <td>0.875701</td>\n",
       "      <td>0.309198</td>\n",
       "      <td>-0.375399</td>\n",
       "      <td>0.997592</td>\n",
       "      <td>0.280467</td>\n",
       "      <td>1.030238</td>\n",
       "      <td>-1.233445</td>\n",
       "      <td>2.654795</td>\n",
       "      <td>-0.564744</td>\n",
       "      <td>0.584026</td>\n",
       "      <td>-1.401375</td>\n",
       "      <td>0.381137</td>\n",
       "      <td>1.129046</td>\n",
       "      <td>-0.146075</td>\n",
       "      <td>-1.745127</td>\n",
       "      <td>-1.967229</td>\n",
       "      <td>-0.367542</td>\n",
       "      <td>-2.054934</td>\n",
       "      <td>-0.879806</td>\n",
       "      <td>-1.393074</td>\n",
       "      <td>-0.345328</td>\n",
       "      <td>-1.245138</td>\n",
       "      <td>2.281077</td>\n",
       "      <td>0.079562</td>\n",
       "      <td>0.063589</td>\n",
       "      <td>-2.385680</td>\n",
       "      <td>-0.079076</td>\n",
       "      <td>-2.467246</td>\n",
       "      <td>2.691009</td>\n",
       "      <td>1.175903</td>\n",
       "      <td>-0.929365</td>\n",
       "      <td>-1.170327</td>\n",
       "      <td>-1.225601</td>\n",
       "      <td>-0.434519</td>\n",
       "      <td>-1.903577</td>\n",
       "      <td>0.450214</td>\n",
       "      <td>0.305983</td>\n",
       "      <td>2.611876</td>\n",
       "      <td>-1.276234</td>\n",
       "      <td>1.530870</td>\n",
       "      <td>-0.456919</td>\n",
       "      <td>-1.720361</td>\n",
       "      <td>1.967160</td>\n",
       "      <td>0.652061</td>\n",
       "      <td>0.489523</td>\n",
       "      <td>-0.847354</td>\n",
       "      <td>0.350949</td>\n",
       "      <td>1.027575</td>\n",
       "      <td>1.819114</td>\n",
       "      <td>0.141461</td>\n",
       "      <td>-0.249152</td>\n",
       "      <td>-2.846906</td>\n",
       "      <td>-0.024646</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>-0.121904</td>\n",
       "      <td>-0.101969</td>\n",
       "      <td>0.495524</td>\n",
       "      <td>1.268794</td>\n",
       "      <td>-0.193496</td>\n",
       "      <td>0.596334</td>\n",
       "      <td>-1.902655</td>\n",
       "      <td>-1.213691</td>\n",
       "      <td>-1.275677</td>\n",
       "      <td>-0.702973</td>\n",
       "      <td>-0.913710</td>\n",
       "      <td>1.211168</td>\n",
       "      <td>-0.993981</td>\n",
       "      <td>-0.126219</td>\n",
       "      <td>0.700694</td>\n",
       "      <td>2.924587</td>\n",
       "      <td>-1.515894</td>\n",
       "      <td>-1.199134</td>\n",
       "      <td>-2.119498</td>\n",
       "      <td>-0.160644</td>\n",
       "      <td>0.412693</td>\n",
       "      <td>0.907245</td>\n",
       "      <td>-0.989104</td>\n",
       "      <td>0.862596</td>\n",
       "      <td>1.711437</td>\n",
       "      <td>2.566690</td>\n",
       "      <td>0.338527</td>\n",
       "      <td>-0.618698</td>\n",
       "      <td>-0.410202</td>\n",
       "      <td>-1.505585</td>\n",
       "      <td>-0.721272</td>\n",
       "      <td>-0.242957</td>\n",
       "      <td>0.575543</td>\n",
       "      <td>0.059661</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>2.303049</td>\n",
       "      <td>-0.198721</td>\n",
       "      <td>-1.491252</td>\n",
       "      <td>-0.936074</td>\n",
       "      <td>1.674106</td>\n",
       "      <td>0.162555</td>\n",
       "      <td>1.216787</td>\n",
       "      <td>-0.503069</td>\n",
       "      <td>0.067878</td>\n",
       "      <td>0.553822</td>\n",
       "      <td>0.540015</td>\n",
       "      <td>-1.078441</td>\n",
       "      <td>-1.314059</td>\n",
       "      <td>0.524216</td>\n",
       "      <td>-0.032583</td>\n",
       "      <td>-1.136863</td>\n",
       "      <td>-0.587115</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>-0.818755</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>-0.339449</td>\n",
       "      <td>-2.002079</td>\n",
       "      <td>-1.388657</td>\n",
       "      <td>0.422492</td>\n",
       "      <td>0.324657</td>\n",
       "      <td>-1.931504</td>\n",
       "      <td>0.157918</td>\n",
       "      <td>1.357651</td>\n",
       "      <td>-0.589241</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.239429</td>\n",
       "      <td>-2.185894</td>\n",
       "      <td>-0.201618</td>\n",
       "      <td>-1.495156</td>\n",
       "      <td>-0.562587</td>\n",
       "      <td>-0.785242</td>\n",
       "      <td>1.245005</td>\n",
       "      <td>-0.380004</td>\n",
       "      <td>1.197054</td>\n",
       "      <td>0.161175</td>\n",
       "      <td>0.458448</td>\n",
       "      <td>-1.159786</td>\n",
       "      <td>-0.035512</td>\n",
       "      <td>-1.003396</td>\n",
       "      <td>0.772364</td>\n",
       "      <td>-0.548882</td>\n",
       "      <td>0.209936</td>\n",
       "      <td>1.031726</td>\n",
       "      <td>-0.167143</td>\n",
       "      <td>-0.622752</td>\n",
       "      <td>-0.909620</td>\n",
       "      <td>-0.081484</td>\n",
       "      <td>0.241565</td>\n",
       "      <td>-0.215075</td>\n",
       "      <td>-1.296413</td>\n",
       "      <td>1.359324</td>\n",
       "      <td>0.601503</td>\n",
       "      <td>0.176105</td>\n",
       "      <td>-1.890656</td>\n",
       "      <td>0.678792</td>\n",
       "      <td>0.408745</td>\n",
       "      <td>-0.689631</td>\n",
       "      <td>1.010307</td>\n",
       "      <td>-0.321389</td>\n",
       "      <td>0.145731</td>\n",
       "      <td>1.179719</td>\n",
       "      <td>-0.845296</td>\n",
       "      <td>0.763039</td>\n",
       "      <td>0.257182</td>\n",
       "      <td>-1.757898</td>\n",
       "      <td>0.660822</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>-1.306130</td>\n",
       "      <td>-2.557735</td>\n",
       "      <td>-1.231920</td>\n",
       "      <td>-2.341358</td>\n",
       "      <td>-0.463872</td>\n",
       "      <td>-0.412691</td>\n",
       "      <td>1.074902</td>\n",
       "      <td>1.008635</td>\n",
       "      <td>1.192221</td>\n",
       "      <td>1.022275</td>\n",
       "      <td>1.008169</td>\n",
       "      <td>0.306036</td>\n",
       "      <td>0.551369</td>\n",
       "      <td>-0.074231</td>\n",
       "      <td>-1.520120</td>\n",
       "      <td>3.469684</td>\n",
       "      <td>-0.842662</td>\n",
       "      <td>0.435872</td>\n",
       "      <td>1.016459</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>-0.463815</td>\n",
       "      <td>0.812699</td>\n",
       "      <td>0.787862</td>\n",
       "      <td>0.402586</td>\n",
       "      <td>-1.131518</td>\n",
       "      <td>-0.013257</td>\n",
       "      <td>-0.696836</td>\n",
       "      <td>0.444591</td>\n",
       "      <td>-0.318191</td>\n",
       "      <td>-0.093454</td>\n",
       "      <td>-1.467694</td>\n",
       "      <td>2.033226</td>\n",
       "      <td>3.828689</td>\n",
       "      <td>1.926871</td>\n",
       "      <td>1.176288</td>\n",
       "      <td>-0.390468</td>\n",
       "      <td>-1.324961</td>\n",
       "      <td>-0.314756</td>\n",
       "      <td>-1.071725</td>\n",
       "      <td>-0.299702</td>\n",
       "      <td>-1.333406</td>\n",
       "      <td>-1.641149</td>\n",
       "      <td>-2.234103</td>\n",
       "      <td>-0.082236</td>\n",
       "      <td>0.847379</td>\n",
       "      <td>0.734399</td>\n",
       "      <td>1.728512</td>\n",
       "      <td>0.446070</td>\n",
       "      <td>-0.056337</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>-1.189612</td>\n",
       "      <td>-2.339580</td>\n",
       "      <td>0.295429</td>\n",
       "      <td>-1.766174</td>\n",
       "      <td>-0.328136</td>\n",
       "      <td>-0.733575</td>\n",
       "      <td>-1.022506</td>\n",
       "      <td>-2.066756</td>\n",
       "      <td>0.769696</td>\n",
       "      <td>1.937188</td>\n",
       "      <td>-1.013471</td>\n",
       "      <td>0.206065</td>\n",
       "      <td>-1.656777</td>\n",
       "      <td>-2.965625</td>\n",
       "      <td>-0.383614</td>\n",
       "      <td>0.548329</td>\n",
       "      <td>-0.671545</td>\n",
       "      <td>-1.709639</td>\n",
       "      <td>-1.465781</td>\n",
       "      <td>-0.106172</td>\n",
       "      <td>0.662039</td>\n",
       "      <td>0.170571</td>\n",
       "      <td>-0.522655</td>\n",
       "      <td>0.100239</td>\n",
       "      <td>-1.302047</td>\n",
       "      <td>-0.722876</td>\n",
       "      <td>0.480261</td>\n",
       "      <td>-0.286202</td>\n",
       "      <td>-0.626293</td>\n",
       "      <td>-0.838638</td>\n",
       "      <td>-0.896078</td>\n",
       "      <td>-1.924661</td>\n",
       "      <td>2.709577</td>\n",
       "      <td>-0.541050</td>\n",
       "      <td>-1.257444</td>\n",
       "      <td>-0.098779</td>\n",
       "      <td>0.408964</td>\n",
       "      <td>1.263144</td>\n",
       "      <td>1.384219</td>\n",
       "      <td>-0.143112</td>\n",
       "      <td>0.660587</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>0.459556</td>\n",
       "      <td>0.800517</td>\n",
       "      <td>1.682858</td>\n",
       "      <td>-0.351228</td>\n",
       "      <td>0.185703</td>\n",
       "      <td>-0.759007</td>\n",
       "      <td>0.518530</td>\n",
       "      <td>-0.499206</td>\n",
       "      <td>0.494772</td>\n",
       "      <td>0.068342</td>\n",
       "      <td>1.189093</td>\n",
       "      <td>-0.236993</td>\n",
       "      <td>-1.007381</td>\n",
       "      <td>1.612834</td>\n",
       "      <td>-0.471481</td>\n",
       "      <td>0.503241</td>\n",
       "      <td>0.476695</td>\n",
       "      <td>-0.162129</td>\n",
       "      <td>-1.543627</td>\n",
       "      <td>2.537342</td>\n",
       "      <td>-1.811801</td>\n",
       "      <td>0.109747</td>\n",
       "      <td>1.085960</td>\n",
       "      <td>-0.451623</td>\n",
       "      <td>0.069837</td>\n",
       "      <td>0.939732</td>\n",
       "      <td>2.178951</td>\n",
       "      <td>-0.950160</td>\n",
       "      <td>-0.494906</td>\n",
       "      <td>0.841544</td>\n",
       "      <td>0.328586</td>\n",
       "      <td>-1.404875</td>\n",
       "      <td>-0.114773</td>\n",
       "      <td>0.263179</td>\n",
       "      <td>-1.905694</td>\n",
       "      <td>0.910328</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>-2.210998</td>\n",
       "      <td>0.098835</td>\n",
       "      <td>-0.878673</td>\n",
       "      <td>-1.200737</td>\n",
       "      <td>-0.752444</td>\n",
       "      <td>-0.455662</td>\n",
       "      <td>-0.434457</td>\n",
       "      <td>0.179727</td>\n",
       "      <td>-0.549773</td>\n",
       "      <td>1.659944</td>\n",
       "      <td>0.205286</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>0.673942</td>\n",
       "      <td>0.520768</td>\n",
       "      <td>1.252245</td>\n",
       "      <td>-1.068320</td>\n",
       "      <td>3.040357</td>\n",
       "      <td>-0.073958</td>\n",
       "      <td>-0.632624</td>\n",
       "      <td>-0.754639</td>\n",
       "      <td>1.134353</td>\n",
       "      <td>1.157441</td>\n",
       "      <td>-0.415262</td>\n",
       "      <td>-1.623028</td>\n",
       "      <td>-1.258167</td>\n",
       "      <td>-0.523906</td>\n",
       "      <td>-3.199509</td>\n",
       "      <td>-0.152576</td>\n",
       "      <td>-1.256645</td>\n",
       "      <td>0.845815</td>\n",
       "      <td>-0.839132</td>\n",
       "      <td>1.728583</td>\n",
       "      <td>-0.589931</td>\n",
       "      <td>0.485515</td>\n",
       "      <td>-2.092345</td>\n",
       "      <td>-0.441458</td>\n",
       "      <td>-1.694587</td>\n",
       "      <td>2.518677</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>-1.131460</td>\n",
       "      <td>-0.865983</td>\n",
       "      <td>-2.242773</td>\n",
       "      <td>-0.526945</td>\n",
       "      <td>-2.264971</td>\n",
       "      <td>0.451280</td>\n",
       "      <td>0.418215</td>\n",
       "      <td>2.031159</td>\n",
       "      <td>-1.379071</td>\n",
       "      <td>1.122927</td>\n",
       "      <td>-0.226003</td>\n",
       "      <td>-2.509897</td>\n",
       "      <td>2.304508</td>\n",
       "      <td>0.445570</td>\n",
       "      <td>1.021010</td>\n",
       "      <td>-1.450153</td>\n",
       "      <td>0.242376</td>\n",
       "      <td>0.834981</td>\n",
       "      <td>1.671488</td>\n",
       "      <td>-0.342870</td>\n",
       "      <td>-0.153526</td>\n",
       "      <td>-1.709953</td>\n",
       "      <td>-0.073791</td>\n",
       "      <td>0.194541</td>\n",
       "      <td>-0.610058</td>\n",
       "      <td>-0.069607</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>1.843607</td>\n",
       "      <td>-0.778443</td>\n",
       "      <td>0.573837</td>\n",
       "      <td>-1.452957</td>\n",
       "      <td>-2.043586</td>\n",
       "      <td>-1.243371</td>\n",
       "      <td>-1.231457</td>\n",
       "      <td>-0.847257</td>\n",
       "      <td>1.700662</td>\n",
       "      <td>-1.591544</td>\n",
       "      <td>0.540250</td>\n",
       "      <td>1.206184</td>\n",
       "      <td>2.155288</td>\n",
       "      <td>-0.881434</td>\n",
       "      <td>-1.979262</td>\n",
       "      <td>-1.131675</td>\n",
       "      <td>-0.059214</td>\n",
       "      <td>0.188151</td>\n",
       "      <td>0.168931</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.798052</td>\n",
       "      <td>1.574913</td>\n",
       "      <td>2.636296</td>\n",
       "      <td>-0.588122</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.586565</td>\n",
       "      <td>-2.171017</td>\n",
       "      <td>-0.849017</td>\n",
       "      <td>-0.634851</td>\n",
       "      <td>0.769110</td>\n",
       "      <td>0.364261</td>\n",
       "      <td>0.615412</td>\n",
       "      <td>2.759990</td>\n",
       "      <td>0.235333</td>\n",
       "      <td>-1.917690</td>\n",
       "      <td>0.185871</td>\n",
       "      <td>0.729079</td>\n",
       "      <td>0.624729</td>\n",
       "      <td>1.397623</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>-0.573830</td>\n",
       "      <td>0.872325</td>\n",
       "      <td>0.814499</td>\n",
       "      <td>-0.876818</td>\n",
       "      <td>-1.158053</td>\n",
       "      <td>0.901152</td>\n",
       "      <td>0.104327</td>\n",
       "      <td>-1.185266</td>\n",
       "      <td>0.028245</td>\n",
       "      <td>0.501512</td>\n",
       "      <td>-0.826979</td>\n",
       "      <td>-0.484411</td>\n",
       "      <td>-1.392443</td>\n",
       "      <td>-2.027127</td>\n",
       "      <td>-2.419008</td>\n",
       "      <td>0.891120</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>-1.534668</td>\n",
       "      <td>0.071720</td>\n",
       "      <td>2.125181</td>\n",
       "      <td>0.444977</td>\n",
       "      <td>0.829271</td>\n",
       "      <td>0.498280</td>\n",
       "      <td>-2.217583</td>\n",
       "      <td>0.149562</td>\n",
       "      <td>-1.739366</td>\n",
       "      <td>-0.700133</td>\n",
       "      <td>-0.536904</td>\n",
       "      <td>1.685650</td>\n",
       "      <td>-0.965166</td>\n",
       "      <td>0.534942</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>0.772165</td>\n",
       "      <td>-0.251955</td>\n",
       "      <td>-1.203110</td>\n",
       "      <td>-0.270931</td>\n",
       "      <td>0.308548</td>\n",
       "      <td>-0.971057</td>\n",
       "      <td>1.286603</td>\n",
       "      <td>1.028479</td>\n",
       "      <td>-0.319157</td>\n",
       "      <td>-0.675549</td>\n",
       "      <td>-1.448762</td>\n",
       "      <td>-0.201693</td>\n",
       "      <td>0.544469</td>\n",
       "      <td>-0.409019</td>\n",
       "      <td>-0.475749</td>\n",
       "      <td>1.286180</td>\n",
       "      <td>1.467181</td>\n",
       "      <td>0.712206</td>\n",
       "      <td>-1.522892</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>-0.064592</td>\n",
       "      <td>-0.704005</td>\n",
       "      <td>1.158432</td>\n",
       "      <td>-0.538718</td>\n",
       "      <td>0.718904</td>\n",
       "      <td>1.542056</td>\n",
       "      <td>-0.282974</td>\n",
       "      <td>1.625056</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>-0.967903</td>\n",
       "      <td>0.343737</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>-0.888741</td>\n",
       "      <td>-1.083211</td>\n",
       "      <td>-2.482604</td>\n",
       "      <td>-1.566305</td>\n",
       "      <td>-2.765838</td>\n",
       "      <td>-1.423123</td>\n",
       "      <td>-0.515561</td>\n",
       "      <td>0.705060</td>\n",
       "      <td>1.104969</td>\n",
       "      <td>0.943062</td>\n",
       "      <td>1.214606</td>\n",
       "      <td>1.540100</td>\n",
       "      <td>1.260473</td>\n",
       "      <td>0.586064</td>\n",
       "      <td>-0.221391</td>\n",
       "      <td>-1.429163</td>\n",
       "      <td>2.778557</td>\n",
       "      <td>-1.307140</td>\n",
       "      <td>1.131804</td>\n",
       "      <td>-0.912495</td>\n",
       "      <td>0.407278</td>\n",
       "      <td>0.165395</td>\n",
       "      <td>0.711644</td>\n",
       "      <td>0.830489</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>-1.394407</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>-1.180450</td>\n",
       "      <td>0.281375</td>\n",
       "      <td>0.711544</td>\n",
       "      <td>-0.250984</td>\n",
       "      <td>-1.125969</td>\n",
       "      <td>2.660668</td>\n",
       "      <td>3.260381</td>\n",
       "      <td>2.120481</td>\n",
       "      <td>0.708997</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>0.211326</td>\n",
       "      <td>-0.661747</td>\n",
       "      <td>-1.461634</td>\n",
       "      <td>-1.246105</td>\n",
       "      <td>-0.685126</td>\n",
       "      <td>-0.978777</td>\n",
       "      <td>-2.028239</td>\n",
       "      <td>0.383003</td>\n",
       "      <td>0.328637</td>\n",
       "      <td>0.440221</td>\n",
       "      <td>2.123995</td>\n",
       "      <td>0.291677</td>\n",
       "      <td>-0.129702</td>\n",
       "      <td>0.192246</td>\n",
       "      <td>-1.929378</td>\n",
       "      <td>-2.058755</td>\n",
       "      <td>0.877348</td>\n",
       "      <td>-0.975529</td>\n",
       "      <td>-0.480067</td>\n",
       "      <td>-0.148748</td>\n",
       "      <td>0.320977</td>\n",
       "      <td>-1.573940</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>2.126219</td>\n",
       "      <td>-1.137512</td>\n",
       "      <td>-0.343807</td>\n",
       "      <td>-1.592137</td>\n",
       "      <td>-3.344302</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.409979</td>\n",
       "      <td>-1.649416</td>\n",
       "      <td>-1.246516</td>\n",
       "      <td>-2.073836</td>\n",
       "      <td>-0.414237</td>\n",
       "      <td>0.623414</td>\n",
       "      <td>0.729944</td>\n",
       "      <td>0.212326</td>\n",
       "      <td>0.306756</td>\n",
       "      <td>-0.724423</td>\n",
       "      <td>-0.481775</td>\n",
       "      <td>0.351584</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>-1.742430</td>\n",
       "      <td>-0.034099</td>\n",
       "      <td>-1.408129</td>\n",
       "      <td>-1.855687</td>\n",
       "      <td>2.943547</td>\n",
       "      <td>0.175205</td>\n",
       "      <td>-0.446971</td>\n",
       "      <td>1.040963</td>\n",
       "      <td>0.493902</td>\n",
       "      <td>1.460997</td>\n",
       "      <td>0.658713</td>\n",
       "      <td>-0.728429</td>\n",
       "      <td>1.033550</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>0.073883</td>\n",
       "      <td>1.385021</td>\n",
       "      <td>1.543426</td>\n",
       "      <td>-0.198463</td>\n",
       "      <td>1.363052</td>\n",
       "      <td>0.899085</td>\n",
       "      <td>0.787222</td>\n",
       "      <td>-0.467796</td>\n",
       "      <td>-0.339204</td>\n",
       "      <td>1.011570</td>\n",
       "      <td>2.179362</td>\n",
       "      <td>0.462325</td>\n",
       "      <td>0.518380</td>\n",
       "      <td>1.689338</td>\n",
       "      <td>-1.135146</td>\n",
       "      <td>1.214546</td>\n",
       "      <td>0.967366</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>-0.849670</td>\n",
       "      <td>2.319285</td>\n",
       "      <td>-2.312302</td>\n",
       "      <td>0.181650</td>\n",
       "      <td>0.979730</td>\n",
       "      <td>-0.546778</td>\n",
       "      <td>1.178315</td>\n",
       "      <td>1.191871</td>\n",
       "      <td>2.215565</td>\n",
       "      <td>-0.555225</td>\n",
       "      <td>-0.153763</td>\n",
       "      <td>1.160025</td>\n",
       "      <td>-0.191043</td>\n",
       "      <td>-1.147442</td>\n",
       "      <td>-0.135083</td>\n",
       "      <td>-1.017425</td>\n",
       "      <td>-1.585886</td>\n",
       "      <td>1.019367</td>\n",
       "      <td>-0.993318</td>\n",
       "      <td>-1.865278</td>\n",
       "      <td>0.179635</td>\n",
       "      <td>-1.210420</td>\n",
       "      <td>-1.310323</td>\n",
       "      <td>-0.932329</td>\n",
       "      <td>-0.165565</td>\n",
       "      <td>-0.326398</td>\n",
       "      <td>-0.351877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000.317830</td>\n",
       "      <td>0.853466</td>\n",
       "      <td>0.085521</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3626.271650</td>\n",
       "      <td>0.592820</td>\n",
       "      <td>-0.759868</td>\n",
       "      <td>0.140981</td>\n",
       "      <td>0.977731</td>\n",
       "      <td>-0.559760</td>\n",
       "      <td>-0.823520</td>\n",
       "      <td>-1.452902</td>\n",
       "      <td>-0.343682</td>\n",
       "      <td>-0.786345</td>\n",
       "      <td>0.119280</td>\n",
       "      <td>1.383189</td>\n",
       "      <td>-1.215400</td>\n",
       "      <td>-1.280178</td>\n",
       "      <td>0.185032</td>\n",
       "      <td>-0.036604</td>\n",
       "      <td>-1.153484</td>\n",
       "      <td>-0.256516</td>\n",
       "      <td>0.254112</td>\n",
       "      <td>-0.826525</td>\n",
       "      <td>-0.234021</td>\n",
       "      <td>0.741035</td>\n",
       "      <td>1.305643</td>\n",
       "      <td>0.157998</td>\n",
       "      <td>0.745974</td>\n",
       "      <td>-0.456016</td>\n",
       "      <td>-1.180467</td>\n",
       "      <td>-0.060042</td>\n",
       "      <td>0.092258</td>\n",
       "      <td>-0.087628</td>\n",
       "      <td>0.817547</td>\n",
       "      <td>0.608606</td>\n",
       "      <td>0.750173</td>\n",
       "      <td>0.639276</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>-0.054557</td>\n",
       "      <td>-0.260005</td>\n",
       "      <td>0.560006</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>-0.536984</td>\n",
       "      <td>0.321488</td>\n",
       "      <td>0.377634</td>\n",
       "      <td>0.580639</td>\n",
       "      <td>0.503633</td>\n",
       "      <td>-0.318153</td>\n",
       "      <td>0.055859</td>\n",
       "      <td>-0.505933</td>\n",
       "      <td>-0.159597</td>\n",
       "      <td>-0.175171</td>\n",
       "      <td>-0.609359</td>\n",
       "      <td>0.140080</td>\n",
       "      <td>0.317619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.563858</td>\n",
       "      <td>-0.563858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713273</td>\n",
       "      <td>0.413273</td>\n",
       "      <td>0.032451</td>\n",
       "      <td>-0.199629</td>\n",
       "      <td>1.423530</td>\n",
       "      <td>1.070036</td>\n",
       "      <td>0.665557</td>\n",
       "      <td>2.117824</td>\n",
       "      <td>-0.247921</td>\n",
       "      <td>1.360856</td>\n",
       "      <td>0.850230</td>\n",
       "      <td>0.235428</td>\n",
       "      <td>0.151449</td>\n",
       "      <td>-1.552373</td>\n",
       "      <td>-0.157621</td>\n",
       "      <td>-0.794261</td>\n",
       "      <td>-1.139913</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>2.379607</td>\n",
       "      <td>0.706867</td>\n",
       "      <td>-1.333687</td>\n",
       "      <td>0.367995</td>\n",
       "      <td>-1.055634</td>\n",
       "      <td>1.657169</td>\n",
       "      <td>0.477517</td>\n",
       "      <td>1.660216</td>\n",
       "      <td>0.579685</td>\n",
       "      <td>2.477001</td>\n",
       "      <td>-0.038977</td>\n",
       "      <td>-0.938574</td>\n",
       "      <td>-0.560492</td>\n",
       "      <td>1.132672</td>\n",
       "      <td>-0.489051</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>-1.533959</td>\n",
       "      <td>-0.532571</td>\n",
       "      <td>-0.364614</td>\n",
       "      <td>-0.585120</td>\n",
       "      <td>-1.702427</td>\n",
       "      <td>-1.012436</td>\n",
       "      <td>0.139679</td>\n",
       "      <td>0.816663</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.422700</td>\n",
       "      <td>0.417432</td>\n",
       "      <td>0.469441</td>\n",
       "      <td>-0.863028</td>\n",
       "      <td>-0.733371</td>\n",
       "      <td>2.660222</td>\n",
       "      <td>-1.784547</td>\n",
       "      <td>-1.293091</td>\n",
       "      <td>-0.114571</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.611696</td>\n",
       "      <td>-0.388008</td>\n",
       "      <td>0.923100</td>\n",
       "      <td>-0.939498</td>\n",
       "      <td>-0.669807</td>\n",
       "      <td>-0.730806</td>\n",
       "      <td>0.084760</td>\n",
       "      <td>2.046776</td>\n",
       "      <td>0.233848</td>\n",
       "      <td>0.191640</td>\n",
       "      <td>0.596165</td>\n",
       "      <td>-1.253260</td>\n",
       "      <td>0.662783</td>\n",
       "      <td>-0.238446</td>\n",
       "      <td>-1.237495</td>\n",
       "      <td>0.138887</td>\n",
       "      <td>0.866105</td>\n",
       "      <td>-0.432057</td>\n",
       "      <td>-0.722960</td>\n",
       "      <td>-0.295695</td>\n",
       "      <td>0.290195</td>\n",
       "      <td>-0.232082</td>\n",
       "      <td>-1.071746</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>-0.253616</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>-0.348175</td>\n",
       "      <td>-0.811127</td>\n",
       "      <td>0.179085</td>\n",
       "      <td>1.069834</td>\n",
       "      <td>1.124860</td>\n",
       "      <td>-0.217365</td>\n",
       "      <td>1.577169</td>\n",
       "      <td>-1.348581</td>\n",
       "      <td>0.528206</td>\n",
       "      <td>1.936467</td>\n",
       "      <td>0.672239</td>\n",
       "      <td>-0.357275</td>\n",
       "      <td>-0.639551</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>-1.160964</td>\n",
       "      <td>-1.732336</td>\n",
       "      <td>-1.516764</td>\n",
       "      <td>0.228672</td>\n",
       "      <td>-0.901420</td>\n",
       "      <td>0.879513</td>\n",
       "      <td>0.800832</td>\n",
       "      <td>1.280497</td>\n",
       "      <td>0.731519</td>\n",
       "      <td>-0.988749</td>\n",
       "      <td>-0.519766</td>\n",
       "      <td>-1.378319</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>-1.271321</td>\n",
       "      <td>-1.503426</td>\n",
       "      <td>-0.912829</td>\n",
       "      <td>1.426416</td>\n",
       "      <td>-0.124897</td>\n",
       "      <td>2.014694</td>\n",
       "      <td>0.797348</td>\n",
       "      <td>1.282970</td>\n",
       "      <td>0.509578</td>\n",
       "      <td>-1.286556</td>\n",
       "      <td>0.177890</td>\n",
       "      <td>-0.181982</td>\n",
       "      <td>1.106896</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>-0.212558</td>\n",
       "      <td>-0.327489</td>\n",
       "      <td>0.252539</td>\n",
       "      <td>0.124555</td>\n",
       "      <td>-2.684077</td>\n",
       "      <td>-0.588774</td>\n",
       "      <td>-1.431945</td>\n",
       "      <td>-1.706941</td>\n",
       "      <td>0.214785</td>\n",
       "      <td>-1.122459</td>\n",
       "      <td>-1.651631</td>\n",
       "      <td>0.796036</td>\n",
       "      <td>-0.033439</td>\n",
       "      <td>1.122536</td>\n",
       "      <td>1.515252</td>\n",
       "      <td>1.085802</td>\n",
       "      <td>-1.545437</td>\n",
       "      <td>-1.633067</td>\n",
       "      <td>0.178389</td>\n",
       "      <td>-1.996615</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>1.989090</td>\n",
       "      <td>1.694810</td>\n",
       "      <td>-0.356188</td>\n",
       "      <td>-0.531155</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-1.483828</td>\n",
       "      <td>0.960308</td>\n",
       "      <td>-1.950884</td>\n",
       "      <td>-0.435862</td>\n",
       "      <td>-0.897392</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.208612</td>\n",
       "      <td>0.441890</td>\n",
       "      <td>0.104347</td>\n",
       "      <td>1.172613</td>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.728767</td>\n",
       "      <td>-0.250864</td>\n",
       "      <td>-0.072925</td>\n",
       "      <td>0.287911</td>\n",
       "      <td>1.155447</td>\n",
       "      <td>1.223913</td>\n",
       "      <td>1.288444</td>\n",
       "      <td>-0.140799</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.162507</td>\n",
       "      <td>0.452874</td>\n",
       "      <td>-0.379135</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>-1.024412</td>\n",
       "      <td>0.177973</td>\n",
       "      <td>-0.827499</td>\n",
       "      <td>-1.371405</td>\n",
       "      <td>-0.746969</td>\n",
       "      <td>-1.846273</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>-1.620297</td>\n",
       "      <td>-0.533657</td>\n",
       "      <td>-0.147648</td>\n",
       "      <td>-0.977057</td>\n",
       "      <td>0.112389</td>\n",
       "      <td>1.874142</td>\n",
       "      <td>3.086769</td>\n",
       "      <td>-0.722104</td>\n",
       "      <td>1.083863</td>\n",
       "      <td>-1.877257</td>\n",
       "      <td>-0.504853</td>\n",
       "      <td>0.102076</td>\n",
       "      <td>0.209604</td>\n",
       "      <td>-0.733907</td>\n",
       "      <td>2.130679</td>\n",
       "      <td>-0.072846</td>\n",
       "      <td>-0.527030</td>\n",
       "      <td>0.537864</td>\n",
       "      <td>0.932215</td>\n",
       "      <td>1.183489</td>\n",
       "      <td>0.264282</td>\n",
       "      <td>-1.094703</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>1.200935</td>\n",
       "      <td>-1.387576</td>\n",
       "      <td>0.920645</td>\n",
       "      <td>0.175354</td>\n",
       "      <td>-0.556458</td>\n",
       "      <td>0.377342</td>\n",
       "      <td>-0.806093</td>\n",
       "      <td>-0.037180</td>\n",
       "      <td>-0.731136</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>-1.885443</td>\n",
       "      <td>-1.746999</td>\n",
       "      <td>0.135861</td>\n",
       "      <td>-0.536543</td>\n",
       "      <td>0.737920</td>\n",
       "      <td>0.596928</td>\n",
       "      <td>-0.231204</td>\n",
       "      <td>-0.809170</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>0.751349</td>\n",
       "      <td>-1.082185</td>\n",
       "      <td>-1.514102</td>\n",
       "      <td>-0.989855</td>\n",
       "      <td>-1.118389</td>\n",
       "      <td>1.429890</td>\n",
       "      <td>-1.699497</td>\n",
       "      <td>-0.366827</td>\n",
       "      <td>0.103048</td>\n",
       "      <td>0.923215</td>\n",
       "      <td>1.367391</td>\n",
       "      <td>0.431371</td>\n",
       "      <td>-0.763896</td>\n",
       "      <td>-0.199512</td>\n",
       "      <td>0.495769</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.849340</td>\n",
       "      <td>2.129651</td>\n",
       "      <td>-0.136289</td>\n",
       "      <td>1.075759</td>\n",
       "      <td>-1.116050</td>\n",
       "      <td>0.821959</td>\n",
       "      <td>-0.128255</td>\n",
       "      <td>-0.388867</td>\n",
       "      <td>-2.332194</td>\n",
       "      <td>1.602850</td>\n",
       "      <td>-1.585078</td>\n",
       "      <td>-1.120535</td>\n",
       "      <td>-2.620574</td>\n",
       "      <td>-1.040520</td>\n",
       "      <td>-1.117670</td>\n",
       "      <td>0.980866</td>\n",
       "      <td>0.266947</td>\n",
       "      <td>-1.701556</td>\n",
       "      <td>2.342002</td>\n",
       "      <td>-0.957553</td>\n",
       "      <td>-1.200572</td>\n",
       "      <td>0.653476</td>\n",
       "      <td>1.232093</td>\n",
       "      <td>-2.295682</td>\n",
       "      <td>-0.617676</td>\n",
       "      <td>0.237318</td>\n",
       "      <td>0.369793</td>\n",
       "      <td>0.524519</td>\n",
       "      <td>-0.791921</td>\n",
       "      <td>0.777930</td>\n",
       "      <td>0.071869</td>\n",
       "      <td>-0.421980</td>\n",
       "      <td>-0.726124</td>\n",
       "      <td>0.638399</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.708897</td>\n",
       "      <td>-1.551183</td>\n",
       "      <td>0.830761</td>\n",
       "      <td>2.386426</td>\n",
       "      <td>1.201632</td>\n",
       "      <td>-1.241883</td>\n",
       "      <td>-0.133010</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>-1.376960</td>\n",
       "      <td>0.755083</td>\n",
       "      <td>-1.546680</td>\n",
       "      <td>-0.727240</td>\n",
       "      <td>-0.130014</td>\n",
       "      <td>1.828757</td>\n",
       "      <td>-0.260097</td>\n",
       "      <td>1.021324</td>\n",
       "      <td>-0.080298</td>\n",
       "      <td>-0.975998</td>\n",
       "      <td>0.236623</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.225526</td>\n",
       "      <td>-0.226727</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>-0.439470</td>\n",
       "      <td>0.852087</td>\n",
       "      <td>0.990138</td>\n",
       "      <td>-1.897289</td>\n",
       "      <td>0.424397</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>-0.710408</td>\n",
       "      <td>0.212363</td>\n",
       "      <td>1.406536</td>\n",
       "      <td>-0.304735</td>\n",
       "      <td>-0.480709</td>\n",
       "      <td>0.565026</td>\n",
       "      <td>1.369861</td>\n",
       "      <td>-0.536017</td>\n",
       "      <td>1.121768</td>\n",
       "      <td>-0.252996</td>\n",
       "      <td>0.500366</td>\n",
       "      <td>0.678141</td>\n",
       "      <td>1.155191</td>\n",
       "      <td>-0.836983</td>\n",
       "      <td>0.458582</td>\n",
       "      <td>0.735660</td>\n",
       "      <td>0.596172</td>\n",
       "      <td>0.260916</td>\n",
       "      <td>-0.063499</td>\n",
       "      <td>-0.445095</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>1.206005</td>\n",
       "      <td>-1.268302</td>\n",
       "      <td>0.818413</td>\n",
       "      <td>-0.551326</td>\n",
       "      <td>-0.106251</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>-0.017240</td>\n",
       "      <td>0.395501</td>\n",
       "      <td>-1.491857</td>\n",
       "      <td>-1.531709</td>\n",
       "      <td>-2.105942</td>\n",
       "      <td>-0.336488</td>\n",
       "      <td>-0.265552</td>\n",
       "      <td>0.081830</td>\n",
       "      <td>-1.147754</td>\n",
       "      <td>0.341580</td>\n",
       "      <td>-0.137328</td>\n",
       "      <td>-0.177554</td>\n",
       "      <td>0.630829</td>\n",
       "      <td>-1.480606</td>\n",
       "      <td>0.832355</td>\n",
       "      <td>-0.051371</td>\n",
       "      <td>1.072925</td>\n",
       "      <td>-0.038436</td>\n",
       "      <td>0.911512</td>\n",
       "      <td>-0.100041</td>\n",
       "      <td>1.443372</td>\n",
       "      <td>-0.558760</td>\n",
       "      <td>1.337643</td>\n",
       "      <td>1.023709</td>\n",
       "      <td>0.405004</td>\n",
       "      <td>0.381058</td>\n",
       "      <td>-0.529059</td>\n",
       "      <td>0.838514</td>\n",
       "      <td>-0.115977</td>\n",
       "      <td>-0.852715</td>\n",
       "      <td>3.211665</td>\n",
       "      <td>-0.535774</td>\n",
       "      <td>-1.047202</td>\n",
       "      <td>-1.772947</td>\n",
       "      <td>0.296972</td>\n",
       "      <td>-1.131994</td>\n",
       "      <td>0.801422</td>\n",
       "      <td>0.040765</td>\n",
       "      <td>0.940442</td>\n",
       "      <td>1.667801</td>\n",
       "      <td>0.197949</td>\n",
       "      <td>1.160642</td>\n",
       "      <td>0.201224</td>\n",
       "      <td>-0.426407</td>\n",
       "      <td>0.285955</td>\n",
       "      <td>-0.168967</td>\n",
       "      <td>-0.408858</td>\n",
       "      <td>-1.174512</td>\n",
       "      <td>-1.160729</td>\n",
       "      <td>-1.221132</td>\n",
       "      <td>-0.095612</td>\n",
       "      <td>-0.160734</td>\n",
       "      <td>-0.138141</td>\n",
       "      <td>-1.878979</td>\n",
       "      <td>-0.668088</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>-0.003959</td>\n",
       "      <td>1.420048</td>\n",
       "      <td>-0.014935</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>-2.655963</td>\n",
       "      <td>-0.661855</td>\n",
       "      <td>1.365808</td>\n",
       "      <td>1.640728</td>\n",
       "      <td>2.973286</td>\n",
       "      <td>1.527735</td>\n",
       "      <td>2.599604</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.939341</td>\n",
       "      <td>-0.144960</td>\n",
       "      <td>-0.145220</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>-1.176126</td>\n",
       "      <td>-1.491962</td>\n",
       "      <td>0.796506</td>\n",
       "      <td>-2.444328</td>\n",
       "      <td>-0.328050</td>\n",
       "      <td>1.343301</td>\n",
       "      <td>-1.271974</td>\n",
       "      <td>-1.586865</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>-0.615715</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>-1.821769</td>\n",
       "      <td>1.759781</td>\n",
       "      <td>1.069821</td>\n",
       "      <td>-0.667240</td>\n",
       "      <td>-0.077468</td>\n",
       "      <td>2.264576</td>\n",
       "      <td>-0.939363</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>2.799483</td>\n",
       "      <td>1.179418</td>\n",
       "      <td>-0.579041</td>\n",
       "      <td>-0.495169</td>\n",
       "      <td>0.368723</td>\n",
       "      <td>0.132089</td>\n",
       "      <td>-0.300547</td>\n",
       "      <td>-0.965856</td>\n",
       "      <td>-1.881721</td>\n",
       "      <td>1.189040</td>\n",
       "      <td>-0.172974</td>\n",
       "      <td>-1.605619</td>\n",
       "      <td>-1.249434</td>\n",
       "      <td>-1.197815</td>\n",
       "      <td>0.235497</td>\n",
       "      <td>0.605939</td>\n",
       "      <td>0.311934</td>\n",
       "      <td>-1.221290</td>\n",
       "      <td>-1.005650</td>\n",
       "      <td>0.467686</td>\n",
       "      <td>-0.448532</td>\n",
       "      <td>-1.094489</td>\n",
       "      <td>0.179539</td>\n",
       "      <td>-0.233023</td>\n",
       "      <td>-1.444420</td>\n",
       "      <td>0.471709</td>\n",
       "      <td>2.469363</td>\n",
       "      <td>0.832983</td>\n",
       "      <td>0.581295</td>\n",
       "      <td>1.141798</td>\n",
       "      <td>0.773065</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>-2.293732</td>\n",
       "      <td>-0.080565</td>\n",
       "      <td>-1.703107</td>\n",
       "      <td>-0.565061</td>\n",
       "      <td>-0.097318</td>\n",
       "      <td>0.214134</td>\n",
       "      <td>1.646032</td>\n",
       "      <td>-0.393141</td>\n",
       "      <td>-0.778745</td>\n",
       "      <td>-1.511284</td>\n",
       "      <td>-2.513872</td>\n",
       "      <td>-0.379097</td>\n",
       "      <td>-0.138979</td>\n",
       "      <td>-0.681795</td>\n",
       "      <td>-0.718249</td>\n",
       "      <td>0.812110</td>\n",
       "      <td>0.863742</td>\n",
       "      <td>-1.033062</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>1.877719</td>\n",
       "      <td>-0.732319</td>\n",
       "      <td>-1.096513</td>\n",
       "      <td>0.924446</td>\n",
       "      <td>-0.178373</td>\n",
       "      <td>0.336057</td>\n",
       "      <td>-0.162994</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>1.388979</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.356189</td>\n",
       "      <td>0.217826</td>\n",
       "      <td>-0.309193</td>\n",
       "      <td>0.303724</td>\n",
       "      <td>-0.264035</td>\n",
       "      <td>0.276895</td>\n",
       "      <td>0.897497</td>\n",
       "      <td>0.544454</td>\n",
       "      <td>-1.878713</td>\n",
       "      <td>-2.843090</td>\n",
       "      <td>0.195806</td>\n",
       "      <td>2.322523</td>\n",
       "      <td>0.452795</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.600361</td>\n",
       "      <td>-0.647861</td>\n",
       "      <td>-0.531207</td>\n",
       "      <td>-0.280747</td>\n",
       "      <td>-1.104201</td>\n",
       "      <td>0.806677</td>\n",
       "      <td>-0.793322</td>\n",
       "      <td>0.871006</td>\n",
       "      <td>0.898156</td>\n",
       "      <td>1.433423</td>\n",
       "      <td>-0.872420</td>\n",
       "      <td>-0.232187</td>\n",
       "      <td>-0.083297</td>\n",
       "      <td>0.093483</td>\n",
       "      <td>-0.039666</td>\n",
       "      <td>-0.349354</td>\n",
       "      <td>0.560424</td>\n",
       "      <td>-0.952093</td>\n",
       "      <td>-1.138840</td>\n",
       "      <td>-0.172878</td>\n",
       "      <td>0.281017</td>\n",
       "      <td>0.504794</td>\n",
       "      <td>-0.093700</td>\n",
       "      <td>-0.015784</td>\n",
       "      <td>0.578468</td>\n",
       "      <td>1.049017</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>-0.988660</td>\n",
       "      <td>0.843067</td>\n",
       "      <td>-0.051253</td>\n",
       "      <td>1.755931</td>\n",
       "      <td>-0.622006</td>\n",
       "      <td>0.980958</td>\n",
       "      <td>-0.465890</td>\n",
       "      <td>0.543176</td>\n",
       "      <td>0.660120</td>\n",
       "      <td>-0.283653</td>\n",
       "      <td>0.531581</td>\n",
       "      <td>1.397366</td>\n",
       "      <td>-0.176482</td>\n",
       "      <td>1.610705</td>\n",
       "      <td>0.088528</td>\n",
       "      <td>-0.175157</td>\n",
       "      <td>1.334912</td>\n",
       "      <td>-0.239708</td>\n",
       "      <td>-0.586957</td>\n",
       "      <td>-0.198358</td>\n",
       "      <td>1.129805</td>\n",
       "      <td>-0.245695</td>\n",
       "      <td>-0.535657</td>\n",
       "      <td>1.013168</td>\n",
       "      <td>0.875010</td>\n",
       "      <td>-1.254255</td>\n",
       "      <td>-0.836622</td>\n",
       "      <td>-1.663900</td>\n",
       "      <td>2.822336</td>\n",
       "      <td>-0.639772</td>\n",
       "      <td>-0.086349</td>\n",
       "      <td>0.876283</td>\n",
       "      <td>-1.914034</td>\n",
       "      <td>0.271241</td>\n",
       "      <td>0.291514</td>\n",
       "      <td>0.654012</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>0.317220</td>\n",
       "      <td>0.989637</td>\n",
       "      <td>0.841708</td>\n",
       "      <td>-0.070195</td>\n",
       "      <td>1.747652</td>\n",
       "      <td>0.163938</td>\n",
       "      <td>-0.191805</td>\n",
       "      <td>0.662206</td>\n",
       "      <td>-1.128978</td>\n",
       "      <td>0.599339</td>\n",
       "      <td>1.037551</td>\n",
       "      <td>0.716601</td>\n",
       "      <td>0.549227</td>\n",
       "      <td>0.545540</td>\n",
       "      <td>-0.212931</td>\n",
       "      <td>-0.485441</td>\n",
       "      <td>0.374575</td>\n",
       "      <td>1.179519</td>\n",
       "      <td>0.734138</td>\n",
       "      <td>1.328872</td>\n",
       "      <td>-1.108271</td>\n",
       "      <td>0.820515</td>\n",
       "      <td>0.874072</td>\n",
       "      <td>0.677977</td>\n",
       "      <td>0.088330</td>\n",
       "      <td>0.028556</td>\n",
       "      <td>-1.018966</td>\n",
       "      <td>-0.846479</td>\n",
       "      <td>-0.256766</td>\n",
       "      <td>-1.759974</td>\n",
       "      <td>-1.034167</td>\n",
       "      <td>0.206706</td>\n",
       "      <td>-0.663623</td>\n",
       "      <td>-0.122557</td>\n",
       "      <td>-0.983829</td>\n",
       "      <td>0.207802</td>\n",
       "      <td>-0.575686</td>\n",
       "      <td>-1.349441</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>-1.117551</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>-0.093888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421847</td>\n",
       "      <td>1.114294</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>1.586232</td>\n",
       "      <td>0.741627</td>\n",
       "      <td>-0.276257</td>\n",
       "      <td>0.947406</td>\n",
       "      <td>0.168759</td>\n",
       "      <td>-0.175637</td>\n",
       "      <td>-1.270199</td>\n",
       "      <td>2.651583</td>\n",
       "      <td>-1.486119</td>\n",
       "      <td>-1.176287</td>\n",
       "      <td>0.532095</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>-0.043432</td>\n",
       "      <td>-0.624553</td>\n",
       "      <td>-0.544947</td>\n",
       "      <td>-1.709282</td>\n",
       "      <td>-0.406287</td>\n",
       "      <td>-1.897005</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>-0.039408</td>\n",
       "      <td>0.465143</td>\n",
       "      <td>-0.961667</td>\n",
       "      <td>2.964271</td>\n",
       "      <td>-1.440884</td>\n",
       "      <td>-0.365272</td>\n",
       "      <td>-0.432355</td>\n",
       "      <td>-1.046878</td>\n",
       "      <td>-0.814333</td>\n",
       "      <td>2.280711</td>\n",
       "      <td>0.213543</td>\n",
       "      <td>-1.396501</td>\n",
       "      <td>-0.265699</td>\n",
       "      <td>0.154761</td>\n",
       "      <td>-0.481439</td>\n",
       "      <td>-0.329492</td>\n",
       "      <td>-0.258608</td>\n",
       "      <td>0.218621</td>\n",
       "      <td>1.822336</td>\n",
       "      <td>-0.903834</td>\n",
       "      <td>1.192110</td>\n",
       "      <td>-0.242208</td>\n",
       "      <td>-1.502716</td>\n",
       "      <td>2.157794</td>\n",
       "      <td>-0.398110</td>\n",
       "      <td>1.113703</td>\n",
       "      <td>-1.930332</td>\n",
       "      <td>0.254808</td>\n",
       "      <td>0.980036</td>\n",
       "      <td>1.426851</td>\n",
       "      <td>-1.101757</td>\n",
       "      <td>-1.535853</td>\n",
       "      <td>-1.416625</td>\n",
       "      <td>-1.017160</td>\n",
       "      <td>-0.139172</td>\n",
       "      <td>0.888480</td>\n",
       "      <td>0.567819</td>\n",
       "      <td>0.198222</td>\n",
       "      <td>1.233408</td>\n",
       "      <td>-0.236852</td>\n",
       "      <td>0.281403</td>\n",
       "      <td>-2.990852</td>\n",
       "      <td>-1.595608</td>\n",
       "      <td>0.239334</td>\n",
       "      <td>-1.840403</td>\n",
       "      <td>-0.037261</td>\n",
       "      <td>1.688437</td>\n",
       "      <td>-1.722072</td>\n",
       "      <td>0.198778</td>\n",
       "      <td>0.154268</td>\n",
       "      <td>1.888517</td>\n",
       "      <td>-0.591863</td>\n",
       "      <td>-1.653421</td>\n",
       "      <td>-2.173859</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>0.232455</td>\n",
       "      <td>0.116273</td>\n",
       "      <td>-0.129550</td>\n",
       "      <td>-0.279536</td>\n",
       "      <td>0.320817</td>\n",
       "      <td>1.363799</td>\n",
       "      <td>-0.156892</td>\n",
       "      <td>-0.181080</td>\n",
       "      <td>-0.422468</td>\n",
       "      <td>-1.141496</td>\n",
       "      <td>-0.922077</td>\n",
       "      <td>-0.832344</td>\n",
       "      <td>0.749481</td>\n",
       "      <td>-0.594651</td>\n",
       "      <td>-1.088730</td>\n",
       "      <td>2.088345</td>\n",
       "      <td>-0.804637</td>\n",
       "      <td>-2.091817</td>\n",
       "      <td>0.113743</td>\n",
       "      <td>-0.817788</td>\n",
       "      <td>-0.081172</td>\n",
       "      <td>0.599339</td>\n",
       "      <td>1.318755</td>\n",
       "      <td>-1.219822</td>\n",
       "      <td>1.338196</td>\n",
       "      <td>1.025870</td>\n",
       "      <td>-0.620058</td>\n",
       "      <td>-0.898224</td>\n",
       "      <td>-0.814701</td>\n",
       "      <td>0.905694</td>\n",
       "      <td>-1.946671</td>\n",
       "      <td>-0.597867</td>\n",
       "      <td>0.665153</td>\n",
       "      <td>-0.901654</td>\n",
       "      <td>0.837224</td>\n",
       "      <td>-1.687155</td>\n",
       "      <td>-1.246215</td>\n",
       "      <td>-1.893740</td>\n",
       "      <td>0.114825</td>\n",
       "      <td>1.523676</td>\n",
       "      <td>-0.851205</td>\n",
       "      <td>0.552432</td>\n",
       "      <td>0.946415</td>\n",
       "      <td>-0.151866</td>\n",
       "      <td>-1.243608</td>\n",
       "      <td>-0.142913</td>\n",
       "      <td>-2.598751</td>\n",
       "      <td>-1.766244</td>\n",
       "      <td>-2.920091</td>\n",
       "      <td>-1.245414</td>\n",
       "      <td>0.297457</td>\n",
       "      <td>2.609680</td>\n",
       "      <td>-1.337790</td>\n",
       "      <td>1.372915</td>\n",
       "      <td>-0.688273</td>\n",
       "      <td>0.412058</td>\n",
       "      <td>-0.882433</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>-0.809116</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.789920</td>\n",
       "      <td>0.925712</td>\n",
       "      <td>1.338971</td>\n",
       "      <td>-0.148212</td>\n",
       "      <td>-1.534339</td>\n",
       "      <td>-1.723457</td>\n",
       "      <td>-0.144874</td>\n",
       "      <td>-0.289824</td>\n",
       "      <td>-0.089475</td>\n",
       "      <td>0.263668</td>\n",
       "      <td>0.251302</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>0.949476</td>\n",
       "      <td>-2.114139</td>\n",
       "      <td>-0.093563</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>-0.339564</td>\n",
       "      <td>0.629605</td>\n",
       "      <td>-0.597281</td>\n",
       "      <td>-0.281912</td>\n",
       "      <td>0.755649</td>\n",
       "      <td>-0.932646</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.290737</td>\n",
       "      <td>-0.495966</td>\n",
       "      <td>1.343845</td>\n",
       "      <td>0.911953</td>\n",
       "      <td>-0.118395</td>\n",
       "      <td>-0.019211</td>\n",
       "      <td>-1.662367</td>\n",
       "      <td>-2.346640</td>\n",
       "      <td>-0.295903</td>\n",
       "      <td>-1.278936</td>\n",
       "      <td>-0.153024</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>0.927489</td>\n",
       "      <td>1.195554</td>\n",
       "      <td>1.015693</td>\n",
       "      <td>1.608341</td>\n",
       "      <td>1.490528</td>\n",
       "      <td>0.451293</td>\n",
       "      <td>-0.589528</td>\n",
       "      <td>-0.129233</td>\n",
       "      <td>3.578741</td>\n",
       "      <td>-1.166891</td>\n",
       "      <td>0.330915</td>\n",
       "      <td>0.893020</td>\n",
       "      <td>1.047929</td>\n",
       "      <td>0.220574</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.318638</td>\n",
       "      <td>-0.455588</td>\n",
       "      <td>-1.293394</td>\n",
       "      <td>-0.106540</td>\n",
       "      <td>-0.153930</td>\n",
       "      <td>-0.744447</td>\n",
       "      <td>-0.004412</td>\n",
       "      <td>-0.016642</td>\n",
       "      <td>-2.959525</td>\n",
       "      <td>1.521912</td>\n",
       "      <td>3.313116</td>\n",
       "      <td>2.896724</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>-0.161528</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>-1.662484</td>\n",
       "      <td>-2.723701</td>\n",
       "      <td>1.496833</td>\n",
       "      <td>-1.768235</td>\n",
       "      <td>-0.686088</td>\n",
       "      <td>-2.029987</td>\n",
       "      <td>1.192096</td>\n",
       "      <td>-0.086323</td>\n",
       "      <td>-1.046727</td>\n",
       "      <td>3.119448</td>\n",
       "      <td>-0.645222</td>\n",
       "      <td>0.410866</td>\n",
       "      <td>-0.334898</td>\n",
       "      <td>-2.096791</td>\n",
       "      <td>-0.192744</td>\n",
       "      <td>-1.392237</td>\n",
       "      <td>0.262413</td>\n",
       "      <td>0.347586</td>\n",
       "      <td>-1.120590</td>\n",
       "      <td>-0.499797</td>\n",
       "      <td>0.200059</td>\n",
       "      <td>-1.609509</td>\n",
       "      <td>2.751597</td>\n",
       "      <td>0.647734</td>\n",
       "      <td>0.861422</td>\n",
       "      <td>-2.555892</td>\n",
       "      <td>-1.897763</td>\n",
       "      <td>-0.108441</td>\n",
       "      <td>1.834164</td>\n",
       "      <td>-0.867751</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>-0.154864</td>\n",
       "      <td>-0.800341</td>\n",
       "      <td>0.962462</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.816019</td>\n",
       "      <td>1.030105</td>\n",
       "      <td>0.374466</td>\n",
       "      <td>0.292530</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.242722</td>\n",
       "      <td>0.338438</td>\n",
       "      <td>0.308543</td>\n",
       "      <td>0.606682</td>\n",
       "      <td>-3.168040</td>\n",
       "      <td>2.587975</td>\n",
       "      <td>0.341334</td>\n",
       "      <td>-0.721908</td>\n",
       "      <td>-0.312835</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>1.597255</td>\n",
       "      <td>-0.258725</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>-0.389283</td>\n",
       "      <td>-1.060911</td>\n",
       "      <td>-0.192637</td>\n",
       "      <td>0.562489</td>\n",
       "      <td>-0.017588</td>\n",
       "      <td>1.168913</td>\n",
       "      <td>-1.101658</td>\n",
       "      <td>-0.057111</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.519139</td>\n",
       "      <td>0.735568</td>\n",
       "      <td>0.592338</td>\n",
       "      <td>-0.196653</td>\n",
       "      <td>0.098647</td>\n",
       "      <td>1.487484</td>\n",
       "      <td>-0.654043</td>\n",
       "      <td>1.258935</td>\n",
       "      <td>-0.596879</td>\n",
       "      <td>0.975019</td>\n",
       "      <td>-0.932243</td>\n",
       "      <td>3.144913</td>\n",
       "      <td>-0.096218</td>\n",
       "      <td>-2.132798</td>\n",
       "      <td>0.324833</td>\n",
       "      <td>-0.214510</td>\n",
       "      <td>0.353476</td>\n",
       "      <td>0.937910</td>\n",
       "      <td>1.947399</td>\n",
       "      <td>-0.213727</td>\n",
       "      <td>-1.258014</td>\n",
       "      <td>1.156138</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>-0.237267</td>\n",
       "      <td>0.417387</td>\n",
       "      <td>0.818045</td>\n",
       "      <td>-1.234940</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.098426</td>\n",
       "      <td>-1.135428</td>\n",
       "      <td>-0.286113</td>\n",
       "      <td>-1.152367</td>\n",
       "      <td>-0.739472</td>\n",
       "      <td>-1.096275</td>\n",
       "      <td>-0.641484</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>1.941167</td>\n",
       "      <td>1.667916</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.969648</td>\n",
       "      <td>-0.576702</td>\n",
       "      <td>-0.532595</td>\n",
       "      <td>-1.163938</td>\n",
       "      <td>2.736374</td>\n",
       "      <td>-1.174436</td>\n",
       "      <td>-0.287530</td>\n",
       "      <td>1.262836</td>\n",
       "      <td>1.749995</td>\n",
       "      <td>-0.480566</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.337356</td>\n",
       "      <td>-1.800091</td>\n",
       "      <td>-0.643410</td>\n",
       "      <td>-2.195859</td>\n",
       "      <td>0.524999</td>\n",
       "      <td>-0.234425</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>-1.216641</td>\n",
       "      <td>1.848761</td>\n",
       "      <td>-1.360257</td>\n",
       "      <td>-0.618715</td>\n",
       "      <td>0.041912</td>\n",
       "      <td>-1.264020</td>\n",
       "      <td>-0.698487</td>\n",
       "      <td>2.177768</td>\n",
       "      <td>0.473847</td>\n",
       "      <td>-0.954612</td>\n",
       "      <td>-0.822599</td>\n",
       "      <td>0.547439</td>\n",
       "      <td>-0.776341</td>\n",
       "      <td>-0.162330</td>\n",
       "      <td>-0.738258</td>\n",
       "      <td>0.079002</td>\n",
       "      <td>1.488589</td>\n",
       "      <td>-0.735296</td>\n",
       "      <td>1.609600</td>\n",
       "      <td>0.521764</td>\n",
       "      <td>-1.114174</td>\n",
       "      <td>2.272394</td>\n",
       "      <td>-0.661581</td>\n",
       "      <td>0.464034</td>\n",
       "      <td>-2.463141</td>\n",
       "      <td>-0.192697</td>\n",
       "      <td>1.265006</td>\n",
       "      <td>1.637538</td>\n",
       "      <td>-1.243249</td>\n",
       "      <td>-1.388345</td>\n",
       "      <td>-1.991110</td>\n",
       "      <td>-0.251722</td>\n",
       "      <td>0.820847</td>\n",
       "      <td>1.408630</td>\n",
       "      <td>-0.089937</td>\n",
       "      <td>0.094179</td>\n",
       "      <td>1.309253</td>\n",
       "      <td>-0.368686</td>\n",
       "      <td>0.313688</td>\n",
       "      <td>-2.988467</td>\n",
       "      <td>-2.249053</td>\n",
       "      <td>-0.310629</td>\n",
       "      <td>-1.294447</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>2.041244</td>\n",
       "      <td>-2.328988</td>\n",
       "      <td>-0.758306</td>\n",
       "      <td>1.074864</td>\n",
       "      <td>1.544826</td>\n",
       "      <td>-0.536788</td>\n",
       "      <td>-1.047699</td>\n",
       "      <td>-2.175849</td>\n",
       "      <td>-0.841033</td>\n",
       "      <td>0.418474</td>\n",
       "      <td>0.656621</td>\n",
       "      <td>0.225106</td>\n",
       "      <td>-0.287726</td>\n",
       "      <td>0.834005</td>\n",
       "      <td>1.842159</td>\n",
       "      <td>-0.317446</td>\n",
       "      <td>0.048699</td>\n",
       "      <td>0.054294</td>\n",
       "      <td>-0.951299</td>\n",
       "      <td>-1.480662</td>\n",
       "      <td>-1.622520</td>\n",
       "      <td>-0.082109</td>\n",
       "      <td>-0.608555</td>\n",
       "      <td>-0.934286</td>\n",
       "      <td>3.344405</td>\n",
       "      <td>-0.220055</td>\n",
       "      <td>-2.133894</td>\n",
       "      <td>0.201654</td>\n",
       "      <td>0.260088</td>\n",
       "      <td>-0.321333</td>\n",
       "      <td>0.981599</td>\n",
       "      <td>1.319900</td>\n",
       "      <td>-0.904057</td>\n",
       "      <td>0.561052</td>\n",
       "      <td>1.012550</td>\n",
       "      <td>-0.384813</td>\n",
       "      <td>-0.831868</td>\n",
       "      <td>-0.616652</td>\n",
       "      <td>-0.065111</td>\n",
       "      <td>-1.701120</td>\n",
       "      <td>-0.195199</td>\n",
       "      <td>0.494392</td>\n",
       "      <td>-0.821257</td>\n",
       "      <td>0.250390</td>\n",
       "      <td>-1.994981</td>\n",
       "      <td>-0.457766</td>\n",
       "      <td>-1.889423</td>\n",
       "      <td>0.538076</td>\n",
       "      <td>1.584238</td>\n",
       "      <td>-0.865543</td>\n",
       "      <td>0.486495</td>\n",
       "      <td>1.859150</td>\n",
       "      <td>0.367981</td>\n",
       "      <td>-0.741168</td>\n",
       "      <td>-0.312366</td>\n",
       "      <td>-1.602764</td>\n",
       "      <td>-2.128115</td>\n",
       "      <td>-3.136659</td>\n",
       "      <td>-0.668109</td>\n",
       "      <td>-0.530141</td>\n",
       "      <td>1.916003</td>\n",
       "      <td>-0.905756</td>\n",
       "      <td>0.165666</td>\n",
       "      <td>-0.512481</td>\n",
       "      <td>0.620156</td>\n",
       "      <td>-0.434398</td>\n",
       "      <td>-0.125748</td>\n",
       "      <td>-0.433512</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>1.961079</td>\n",
       "      <td>0.630240</td>\n",
       "      <td>0.236783</td>\n",
       "      <td>-1.036200</td>\n",
       "      <td>-1.904449</td>\n",
       "      <td>0.728275</td>\n",
       "      <td>0.217311</td>\n",
       "      <td>-0.539903</td>\n",
       "      <td>0.254554</td>\n",
       "      <td>0.121272</td>\n",
       "      <td>-0.196726</td>\n",
       "      <td>1.326284</td>\n",
       "      <td>-1.717327</td>\n",
       "      <td>-0.418766</td>\n",
       "      <td>0.875707</td>\n",
       "      <td>-0.533835</td>\n",
       "      <td>1.214761</td>\n",
       "      <td>-0.014235</td>\n",
       "      <td>-0.020398</td>\n",
       "      <td>1.228133</td>\n",
       "      <td>-0.630038</td>\n",
       "      <td>1.023471</td>\n",
       "      <td>0.233753</td>\n",
       "      <td>-0.446556</td>\n",
       "      <td>0.622241</td>\n",
       "      <td>0.567681</td>\n",
       "      <td>0.247804</td>\n",
       "      <td>0.168492</td>\n",
       "      <td>-2.227211</td>\n",
       "      <td>-2.285791</td>\n",
       "      <td>-0.229820</td>\n",
       "      <td>-0.999006</td>\n",
       "      <td>-0.222203</td>\n",
       "      <td>-0.058653</td>\n",
       "      <td>0.816776</td>\n",
       "      <td>1.065903</td>\n",
       "      <td>0.873870</td>\n",
       "      <td>1.195579</td>\n",
       "      <td>1.832619</td>\n",
       "      <td>0.588293</td>\n",
       "      <td>-0.140352</td>\n",
       "      <td>-0.518000</td>\n",
       "      <td>2.992880</td>\n",
       "      <td>-1.891376</td>\n",
       "      <td>-0.232077</td>\n",
       "      <td>0.828834</td>\n",
       "      <td>1.734091</td>\n",
       "      <td>0.745560</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.209474</td>\n",
       "      <td>-0.965160</td>\n",
       "      <td>-1.746685</td>\n",
       "      <td>-0.172151</td>\n",
       "      <td>-1.022799</td>\n",
       "      <td>-0.375388</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>-2.994416</td>\n",
       "      <td>2.151111</td>\n",
       "      <td>3.722023</td>\n",
       "      <td>2.912947</td>\n",
       "      <td>0.819212</td>\n",
       "      <td>-0.214714</td>\n",
       "      <td>-0.548075</td>\n",
       "      <td>-1.132913</td>\n",
       "      <td>-2.623694</td>\n",
       "      <td>0.759224</td>\n",
       "      <td>-1.479217</td>\n",
       "      <td>-0.268732</td>\n",
       "      <td>-1.013318</td>\n",
       "      <td>0.767190</td>\n",
       "      <td>0.986224</td>\n",
       "      <td>-0.908374</td>\n",
       "      <td>3.382700</td>\n",
       "      <td>-0.817762</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>-0.757652</td>\n",
       "      <td>-1.342170</td>\n",
       "      <td>-0.929494</td>\n",
       "      <td>-1.825342</td>\n",
       "      <td>0.522749</td>\n",
       "      <td>-0.258936</td>\n",
       "      <td>-0.796161</td>\n",
       "      <td>-0.967626</td>\n",
       "      <td>0.071852</td>\n",
       "      <td>-1.237557</td>\n",
       "      <td>2.886336</td>\n",
       "      <td>1.123994</td>\n",
       "      <td>0.986919</td>\n",
       "      <td>-2.355214</td>\n",
       "      <td>-1.986252</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>1.478176</td>\n",
       "      <td>-1.497158</td>\n",
       "      <td>-2.717949</td>\n",
       "      <td>-0.460896</td>\n",
       "      <td>-0.343902</td>\n",
       "      <td>0.387031</td>\n",
       "      <td>0.874117</td>\n",
       "      <td>-1.255285</td>\n",
       "      <td>0.850116</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>0.918133</td>\n",
       "      <td>0.174630</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.182737</td>\n",
       "      <td>0.701624</td>\n",
       "      <td>-0.333052</td>\n",
       "      <td>-2.780317</td>\n",
       "      <td>2.559273</td>\n",
       "      <td>0.591683</td>\n",
       "      <td>-0.904230</td>\n",
       "      <td>-0.802679</td>\n",
       "      <td>0.442071</td>\n",
       "      <td>1.302161</td>\n",
       "      <td>1.038088</td>\n",
       "      <td>-0.273732</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>-0.089517</td>\n",
       "      <td>-1.497218</td>\n",
       "      <td>-0.042562</td>\n",
       "      <td>0.465946</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>1.349233</td>\n",
       "      <td>-0.602544</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>-0.167299</td>\n",
       "      <td>-0.215360</td>\n",
       "      <td>0.533581</td>\n",
       "      <td>1.193901</td>\n",
       "      <td>0.578831</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>1.235976</td>\n",
       "      <td>-0.686240</td>\n",
       "      <td>1.025943</td>\n",
       "      <td>-0.064920</td>\n",
       "      <td>0.294441</td>\n",
       "      <td>-1.627370</td>\n",
       "      <td>2.550657</td>\n",
       "      <td>0.324669</td>\n",
       "      <td>-1.806238</td>\n",
       "      <td>0.601941</td>\n",
       "      <td>-0.881103</td>\n",
       "      <td>0.785675</td>\n",
       "      <td>0.817376</td>\n",
       "      <td>1.842704</td>\n",
       "      <td>0.117498</td>\n",
       "      <td>-0.858874</td>\n",
       "      <td>1.385079</td>\n",
       "      <td>0.811318</td>\n",
       "      <td>-0.443309</td>\n",
       "      <td>0.932877</td>\n",
       "      <td>1.366346</td>\n",
       "      <td>-0.733987</td>\n",
       "      <td>1.201761</td>\n",
       "      <td>0.102663</td>\n",
       "      <td>-1.427353</td>\n",
       "      <td>-1.086705</td>\n",
       "      <td>-0.947648</td>\n",
       "      <td>-0.728064</td>\n",
       "      <td>-0.896277</td>\n",
       "      <td>-1.215933</td>\n",
       "      <td>-0.464430</td>\n",
       "      <td>-0.010734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4076.728618</td>\n",
       "      <td>0.815608</td>\n",
       "      <td>0.081578</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3750.717653</td>\n",
       "      <td>0.519060</td>\n",
       "      <td>-0.544211</td>\n",
       "      <td>0.410085</td>\n",
       "      <td>1.383205</td>\n",
       "      <td>-1.102180</td>\n",
       "      <td>-0.126573</td>\n",
       "      <td>-0.751257</td>\n",
       "      <td>-1.166125</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.467768</td>\n",
       "      <td>1.666830</td>\n",
       "      <td>-0.402227</td>\n",
       "      <td>-0.409941</td>\n",
       "      <td>1.243718</td>\n",
       "      <td>0.583777</td>\n",
       "      <td>-0.660820</td>\n",
       "      <td>0.226999</td>\n",
       "      <td>0.937196</td>\n",
       "      <td>-0.390602</td>\n",
       "      <td>0.486926</td>\n",
       "      <td>0.871450</td>\n",
       "      <td>1.317343</td>\n",
       "      <td>0.116498</td>\n",
       "      <td>1.026098</td>\n",
       "      <td>0.033741</td>\n",
       "      <td>-0.756651</td>\n",
       "      <td>-0.117320</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>-0.544048</td>\n",
       "      <td>0.195070</td>\n",
       "      <td>0.134134</td>\n",
       "      <td>0.672954</td>\n",
       "      <td>-0.198248</td>\n",
       "      <td>0.494765</td>\n",
       "      <td>-0.445202</td>\n",
       "      <td>-0.353934</td>\n",
       "      <td>0.404414</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>-0.231080</td>\n",
       "      <td>0.257195</td>\n",
       "      <td>0.531735</td>\n",
       "      <td>0.309292</td>\n",
       "      <td>0.141346</td>\n",
       "      <td>-0.898221</td>\n",
       "      <td>0.067316</td>\n",
       "      <td>-0.528505</td>\n",
       "      <td>-0.603799</td>\n",
       "      <td>-0.475617</td>\n",
       "      <td>-1.119679</td>\n",
       "      <td>-0.193074</td>\n",
       "      <td>0.153844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.622202</td>\n",
       "      <td>-0.622202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883341</td>\n",
       "      <td>0.552263</td>\n",
       "      <td>-0.477849</td>\n",
       "      <td>0.248305</td>\n",
       "      <td>0.945412</td>\n",
       "      <td>1.217739</td>\n",
       "      <td>1.079517</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.913664</td>\n",
       "      <td>-1.214741</td>\n",
       "      <td>0.792083</td>\n",
       "      <td>-0.568536</td>\n",
       "      <td>0.728442</td>\n",
       "      <td>1.461994</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>-0.452482</td>\n",
       "      <td>-0.854899</td>\n",
       "      <td>-0.568953</td>\n",
       "      <td>2.345650</td>\n",
       "      <td>0.274084</td>\n",
       "      <td>-0.509614</td>\n",
       "      <td>-0.198938</td>\n",
       "      <td>-0.182595</td>\n",
       "      <td>0.661121</td>\n",
       "      <td>-1.408162</td>\n",
       "      <td>1.182050</td>\n",
       "      <td>1.022638</td>\n",
       "      <td>0.993028</td>\n",
       "      <td>1.155076</td>\n",
       "      <td>-0.288149</td>\n",
       "      <td>-0.279598</td>\n",
       "      <td>-0.380838</td>\n",
       "      <td>-1.489876</td>\n",
       "      <td>0.518357</td>\n",
       "      <td>-1.492988</td>\n",
       "      <td>-1.439540</td>\n",
       "      <td>-1.773317</td>\n",
       "      <td>0.509189</td>\n",
       "      <td>-1.309460</td>\n",
       "      <td>0.185584</td>\n",
       "      <td>-0.647301</td>\n",
       "      <td>1.131877</td>\n",
       "      <td>-4.384728</td>\n",
       "      <td>-0.927009</td>\n",
       "      <td>0.834160</td>\n",
       "      <td>-0.216239</td>\n",
       "      <td>-2.132970</td>\n",
       "      <td>-0.397237</td>\n",
       "      <td>1.955279</td>\n",
       "      <td>-2.537978</td>\n",
       "      <td>-0.122483</td>\n",
       "      <td>-0.915963</td>\n",
       "      <td>0.574112</td>\n",
       "      <td>-0.423051</td>\n",
       "      <td>-0.842613</td>\n",
       "      <td>2.131898</td>\n",
       "      <td>-0.482536</td>\n",
       "      <td>-1.419383</td>\n",
       "      <td>-0.291420</td>\n",
       "      <td>0.448921</td>\n",
       "      <td>1.977976</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>1.081682</td>\n",
       "      <td>-0.441748</td>\n",
       "      <td>-1.254173</td>\n",
       "      <td>-0.032522</td>\n",
       "      <td>-1.525957</td>\n",
       "      <td>-0.253144</td>\n",
       "      <td>-1.715876</td>\n",
       "      <td>0.712936</td>\n",
       "      <td>-1.152601</td>\n",
       "      <td>-0.387493</td>\n",
       "      <td>-1.318359</td>\n",
       "      <td>-1.048490</td>\n",
       "      <td>-1.008816</td>\n",
       "      <td>-1.249758</td>\n",
       "      <td>0.546879</td>\n",
       "      <td>-1.786857</td>\n",
       "      <td>1.714262</td>\n",
       "      <td>-1.377044</td>\n",
       "      <td>0.292190</td>\n",
       "      <td>0.383550</td>\n",
       "      <td>0.441229</td>\n",
       "      <td>1.070662</td>\n",
       "      <td>0.488727</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>-0.689693</td>\n",
       "      <td>0.235307</td>\n",
       "      <td>1.823351</td>\n",
       "      <td>1.046317</td>\n",
       "      <td>0.631064</td>\n",
       "      <td>-1.175797</td>\n",
       "      <td>0.607319</td>\n",
       "      <td>-0.098467</td>\n",
       "      <td>-1.383710</td>\n",
       "      <td>0.089452</td>\n",
       "      <td>0.552594</td>\n",
       "      <td>-2.522122</td>\n",
       "      <td>1.119062</td>\n",
       "      <td>1.653892</td>\n",
       "      <td>1.147259</td>\n",
       "      <td>0.678807</td>\n",
       "      <td>0.028873</td>\n",
       "      <td>0.749810</td>\n",
       "      <td>-1.528499</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>-2.580648</td>\n",
       "      <td>-0.576350</td>\n",
       "      <td>0.146343</td>\n",
       "      <td>-0.897146</td>\n",
       "      <td>0.618766</td>\n",
       "      <td>-0.074857</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>-0.486478</td>\n",
       "      <td>-0.442482</td>\n",
       "      <td>0.240351</td>\n",
       "      <td>-0.303637</td>\n",
       "      <td>-0.516523</td>\n",
       "      <td>0.470631</td>\n",
       "      <td>-1.410381</td>\n",
       "      <td>-0.799205</td>\n",
       "      <td>-0.739280</td>\n",
       "      <td>0.377443</td>\n",
       "      <td>0.504710</td>\n",
       "      <td>-0.958683</td>\n",
       "      <td>0.483551</td>\n",
       "      <td>-0.918463</td>\n",
       "      <td>-1.592223</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>-1.613022</td>\n",
       "      <td>-0.762804</td>\n",
       "      <td>-0.203612</td>\n",
       "      <td>-0.543591</td>\n",
       "      <td>0.898989</td>\n",
       "      <td>1.550943</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>-1.467820</td>\n",
       "      <td>-0.963223</td>\n",
       "      <td>0.155268</td>\n",
       "      <td>-0.213300</td>\n",
       "      <td>0.363040</td>\n",
       "      <td>-1.096934</td>\n",
       "      <td>2.086288</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0.166183</td>\n",
       "      <td>0.490820</td>\n",
       "      <td>-1.333572</td>\n",
       "      <td>-1.263228</td>\n",
       "      <td>-0.441280</td>\n",
       "      <td>-0.211867</td>\n",
       "      <td>0.267667</td>\n",
       "      <td>-0.066594</td>\n",
       "      <td>0.723358</td>\n",
       "      <td>-2.710476</td>\n",
       "      <td>-0.501903</td>\n",
       "      <td>1.364723</td>\n",
       "      <td>0.760223</td>\n",
       "      <td>-0.762381</td>\n",
       "      <td>-0.339300</td>\n",
       "      <td>1.528382</td>\n",
       "      <td>0.950937</td>\n",
       "      <td>-2.103084</td>\n",
       "      <td>1.306236</td>\n",
       "      <td>0.298729</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>-0.662007</td>\n",
       "      <td>0.293944</td>\n",
       "      <td>-0.952797</td>\n",
       "      <td>-0.427309</td>\n",
       "      <td>-0.426850</td>\n",
       "      <td>-1.199208</td>\n",
       "      <td>0.862368</td>\n",
       "      <td>-0.220573</td>\n",
       "      <td>0.764875</td>\n",
       "      <td>-0.416196</td>\n",
       "      <td>-0.435559</td>\n",
       "      <td>0.745336</td>\n",
       "      <td>0.045365</td>\n",
       "      <td>-0.913414</td>\n",
       "      <td>-0.409874</td>\n",
       "      <td>1.017311</td>\n",
       "      <td>-0.312572</td>\n",
       "      <td>1.354477</td>\n",
       "      <td>2.131161</td>\n",
       "      <td>0.746993</td>\n",
       "      <td>0.072755</td>\n",
       "      <td>-0.834732</td>\n",
       "      <td>1.085008</td>\n",
       "      <td>-0.372841</td>\n",
       "      <td>0.222031</td>\n",
       "      <td>0.395946</td>\n",
       "      <td>-0.315272</td>\n",
       "      <td>0.111767</td>\n",
       "      <td>-0.288567</td>\n",
       "      <td>0.821708</td>\n",
       "      <td>0.439607</td>\n",
       "      <td>0.733257</td>\n",
       "      <td>-0.327657</td>\n",
       "      <td>-0.680554</td>\n",
       "      <td>-1.080868</td>\n",
       "      <td>0.472120</td>\n",
       "      <td>-0.870400</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.717764</td>\n",
       "      <td>-0.667639</td>\n",
       "      <td>-1.314597</td>\n",
       "      <td>-0.708519</td>\n",
       "      <td>-0.491111</td>\n",
       "      <td>0.091919</td>\n",
       "      <td>0.228649</td>\n",
       "      <td>-0.994099</td>\n",
       "      <td>-1.353445</td>\n",
       "      <td>0.549188</td>\n",
       "      <td>0.038436</td>\n",
       "      <td>0.550655</td>\n",
       "      <td>-0.133454</td>\n",
       "      <td>1.145093</td>\n",
       "      <td>-1.297613</td>\n",
       "      <td>-1.069393</td>\n",
       "      <td>0.197911</td>\n",
       "      <td>-1.203810</td>\n",
       "      <td>0.091049</td>\n",
       "      <td>0.617568</td>\n",
       "      <td>-1.891563</td>\n",
       "      <td>-0.032179</td>\n",
       "      <td>-0.483659</td>\n",
       "      <td>-1.667509</td>\n",
       "      <td>-0.153547</td>\n",
       "      <td>1.634203</td>\n",
       "      <td>0.282840</td>\n",
       "      <td>0.440186</td>\n",
       "      <td>-0.709753</td>\n",
       "      <td>-1.184122</td>\n",
       "      <td>-0.251957</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>1.634089</td>\n",
       "      <td>-0.630729</td>\n",
       "      <td>-0.057776</td>\n",
       "      <td>-1.006898</td>\n",
       "      <td>-0.941499</td>\n",
       "      <td>0.649928</td>\n",
       "      <td>-0.101452</td>\n",
       "      <td>-0.185905</td>\n",
       "      <td>-0.844065</td>\n",
       "      <td>-0.196751</td>\n",
       "      <td>-0.915483</td>\n",
       "      <td>0.236645</td>\n",
       "      <td>-0.903566</td>\n",
       "      <td>-1.181377</td>\n",
       "      <td>0.255018</td>\n",
       "      <td>-2.457474</td>\n",
       "      <td>0.248068</td>\n",
       "      <td>-1.168868</td>\n",
       "      <td>1.711816</td>\n",
       "      <td>-0.068314</td>\n",
       "      <td>-1.326105</td>\n",
       "      <td>-0.217509</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>-0.289936</td>\n",
       "      <td>-0.375619</td>\n",
       "      <td>1.650580</td>\n",
       "      <td>0.027187</td>\n",
       "      <td>1.721621</td>\n",
       "      <td>-0.904158</td>\n",
       "      <td>1.119111</td>\n",
       "      <td>1.034891</td>\n",
       "      <td>-0.410894</td>\n",
       "      <td>0.187660</td>\n",
       "      <td>1.380473</td>\n",
       "      <td>0.926150</td>\n",
       "      <td>-1.120997</td>\n",
       "      <td>-0.004882</td>\n",
       "      <td>-0.583486</td>\n",
       "      <td>1.389918</td>\n",
       "      <td>0.032643</td>\n",
       "      <td>1.810088</td>\n",
       "      <td>-1.274165</td>\n",
       "      <td>-0.186252</td>\n",
       "      <td>0.132843</td>\n",
       "      <td>0.087116</td>\n",
       "      <td>0.167818</td>\n",
       "      <td>-1.145285</td>\n",
       "      <td>-0.135244</td>\n",
       "      <td>0.384378</td>\n",
       "      <td>0.173818</td>\n",
       "      <td>0.939236</td>\n",
       "      <td>0.301775</td>\n",
       "      <td>-1.194826</td>\n",
       "      <td>1.534230</td>\n",
       "      <td>0.875701</td>\n",
       "      <td>-1.121229</td>\n",
       "      <td>2.033307</td>\n",
       "      <td>-0.479138</td>\n",
       "      <td>-0.008581</td>\n",
       "      <td>0.919947</td>\n",
       "      <td>0.249215</td>\n",
       "      <td>0.045518</td>\n",
       "      <td>-0.378709</td>\n",
       "      <td>-0.686520</td>\n",
       "      <td>-0.706487</td>\n",
       "      <td>-1.368280</td>\n",
       "      <td>-0.113121</td>\n",
       "      <td>-0.896983</td>\n",
       "      <td>0.330392</td>\n",
       "      <td>-2.663619</td>\n",
       "      <td>0.415593</td>\n",
       "      <td>0.190554</td>\n",
       "      <td>-0.288286</td>\n",
       "      <td>-1.571392</td>\n",
       "      <td>-1.305867</td>\n",
       "      <td>-0.492824</td>\n",
       "      <td>-0.314600</td>\n",
       "      <td>1.416678</td>\n",
       "      <td>-1.327251</td>\n",
       "      <td>0.378493</td>\n",
       "      <td>0.950476</td>\n",
       "      <td>-0.694245</td>\n",
       "      <td>-0.226502</td>\n",
       "      <td>0.805719</td>\n",
       "      <td>-0.283369</td>\n",
       "      <td>-0.422526</td>\n",
       "      <td>1.093486</td>\n",
       "      <td>-1.254696</td>\n",
       "      <td>-0.103765</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>0.061417</td>\n",
       "      <td>-0.073706</td>\n",
       "      <td>-0.667549</td>\n",
       "      <td>-0.008747</td>\n",
       "      <td>-1.198921</td>\n",
       "      <td>-0.742022</td>\n",
       "      <td>-2.152284</td>\n",
       "      <td>0.078743</td>\n",
       "      <td>-1.251353</td>\n",
       "      <td>0.924700</td>\n",
       "      <td>-0.422887</td>\n",
       "      <td>-0.465372</td>\n",
       "      <td>-0.813787</td>\n",
       "      <td>0.222424</td>\n",
       "      <td>0.350794</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.767841</td>\n",
       "      <td>0.900905</td>\n",
       "      <td>0.179267</td>\n",
       "      <td>0.881224</td>\n",
       "      <td>-0.613312</td>\n",
       "      <td>0.438182</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>1.241677</td>\n",
       "      <td>1.032885</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>1.674452</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>-0.109069</td>\n",
       "      <td>2.863246</td>\n",
       "      <td>0.413239</td>\n",
       "      <td>-1.854232</td>\n",
       "      <td>0.515844</td>\n",
       "      <td>0.020855</td>\n",
       "      <td>1.053780</td>\n",
       "      <td>0.476365</td>\n",
       "      <td>-0.588165</td>\n",
       "      <td>0.708927</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.230843</td>\n",
       "      <td>0.904100</td>\n",
       "      <td>-0.214649</td>\n",
       "      <td>-1.945305</td>\n",
       "      <td>0.374889</td>\n",
       "      <td>-0.119012</td>\n",
       "      <td>-0.351334</td>\n",
       "      <td>0.112966</td>\n",
       "      <td>-0.461936</td>\n",
       "      <td>-1.267577</td>\n",
       "      <td>-0.985031</td>\n",
       "      <td>1.076021</td>\n",
       "      <td>-1.269692</td>\n",
       "      <td>-1.859964</td>\n",
       "      <td>0.202662</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.975067</td>\n",
       "      <td>-0.509898</td>\n",
       "      <td>0.267249</td>\n",
       "      <td>-2.003884</td>\n",
       "      <td>-0.711713</td>\n",
       "      <td>1.482148</td>\n",
       "      <td>0.659332</td>\n",
       "      <td>2.320429</td>\n",
       "      <td>1.372529</td>\n",
       "      <td>1.803248</td>\n",
       "      <td>0.844227</td>\n",
       "      <td>0.430172</td>\n",
       "      <td>0.067439</td>\n",
       "      <td>-1.123553</td>\n",
       "      <td>0.286673</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.015220</td>\n",
       "      <td>-0.373115</td>\n",
       "      <td>-1.703799</td>\n",
       "      <td>-1.475855</td>\n",
       "      <td>1.163295</td>\n",
       "      <td>-0.661072</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>-0.996595</td>\n",
       "      <td>0.218159</td>\n",
       "      <td>-0.325123</td>\n",
       "      <td>-0.241869</td>\n",
       "      <td>-1.260406</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>-0.332912</td>\n",
       "      <td>1.164616</td>\n",
       "      <td>0.113986</td>\n",
       "      <td>0.288987</td>\n",
       "      <td>-0.237401</td>\n",
       "      <td>-1.677699</td>\n",
       "      <td>1.346649</td>\n",
       "      <td>1.564966</td>\n",
       "      <td>-1.041032</td>\n",
       "      <td>-0.658147</td>\n",
       "      <td>-0.479500</td>\n",
       "      <td>0.834507</td>\n",
       "      <td>-0.067109</td>\n",
       "      <td>-0.240953</td>\n",
       "      <td>-0.398746</td>\n",
       "      <td>-0.892674</td>\n",
       "      <td>-0.882704</td>\n",
       "      <td>-0.308510</td>\n",
       "      <td>-0.262881</td>\n",
       "      <td>-0.153623</td>\n",
       "      <td>0.077194</td>\n",
       "      <td>-1.559162</td>\n",
       "      <td>0.348832</td>\n",
       "      <td>-0.432021</td>\n",
       "      <td>-1.041795</td>\n",
       "      <td>-0.403227</td>\n",
       "      <td>-0.050247</td>\n",
       "      <td>-0.460290</td>\n",
       "      <td>-1.069693</td>\n",
       "      <td>0.877592</td>\n",
       "      <td>-0.381193</td>\n",
       "      <td>-0.368850</td>\n",
       "      <td>1.505813</td>\n",
       "      <td>1.592643</td>\n",
       "      <td>-0.843110</td>\n",
       "      <td>1.703313</td>\n",
       "      <td>-0.042113</td>\n",
       "      <td>-1.165736</td>\n",
       "      <td>-1.601744</td>\n",
       "      <td>-1.666208</td>\n",
       "      <td>-2.960863</td>\n",
       "      <td>-0.516680</td>\n",
       "      <td>-0.300672</td>\n",
       "      <td>-0.568188</td>\n",
       "      <td>0.983079</td>\n",
       "      <td>-0.690330</td>\n",
       "      <td>-0.434836</td>\n",
       "      <td>-0.608055</td>\n",
       "      <td>-0.424472</td>\n",
       "      <td>-2.100685</td>\n",
       "      <td>0.020218</td>\n",
       "      <td>-0.934597</td>\n",
       "      <td>-0.960235</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.051111</td>\n",
       "      <td>0.378809</td>\n",
       "      <td>0.234517</td>\n",
       "      <td>-0.389450</td>\n",
       "      <td>-1.099462</td>\n",
       "      <td>1.406926</td>\n",
       "      <td>0.206169</td>\n",
       "      <td>-0.179828</td>\n",
       "      <td>-0.648036</td>\n",
       "      <td>1.410921</td>\n",
       "      <td>-0.404205</td>\n",
       "      <td>0.916267</td>\n",
       "      <td>0.091081</td>\n",
       "      <td>1.091886</td>\n",
       "      <td>0.810037</td>\n",
       "      <td>-0.812652</td>\n",
       "      <td>-1.053037</td>\n",
       "      <td>0.297415</td>\n",
       "      <td>0.052266</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>-0.620484</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-2.799254</td>\n",
       "      <td>1.284142</td>\n",
       "      <td>1.772670</td>\n",
       "      <td>0.980446</td>\n",
       "      <td>-0.958395</td>\n",
       "      <td>1.383803</td>\n",
       "      <td>-0.607795</td>\n",
       "      <td>0.697924</td>\n",
       "      <td>-1.020350</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.950967</td>\n",
       "      <td>0.479462</td>\n",
       "      <td>0.776310</td>\n",
       "      <td>-0.130608</td>\n",
       "      <td>-0.704579</td>\n",
       "      <td>0.762597</td>\n",
       "      <td>-0.776734</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>-0.386332</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.256450</td>\n",
       "      <td>-1.307405</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>-0.428751</td>\n",
       "      <td>0.590734</td>\n",
       "      <td>-0.151886</td>\n",
       "      <td>0.412937</td>\n",
       "      <td>-0.167005</td>\n",
       "      <td>1.051520</td>\n",
       "      <td>0.750296</td>\n",
       "      <td>-0.009801</td>\n",
       "      <td>0.379676</td>\n",
       "      <td>-0.423180</td>\n",
       "      <td>1.066256</td>\n",
       "      <td>-0.685271</td>\n",
       "      <td>-0.347575</td>\n",
       "      <td>-0.279267</td>\n",
       "      <td>-1.335536</td>\n",
       "      <td>0.609899</td>\n",
       "      <td>-0.495841</td>\n",
       "      <td>0.593815</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>0.946898</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>-0.016392</td>\n",
       "      <td>0.302775</td>\n",
       "      <td>0.934820</td>\n",
       "      <td>1.870012</td>\n",
       "      <td>-0.329719</td>\n",
       "      <td>0.300999</td>\n",
       "      <td>0.334733</td>\n",
       "      <td>1.278774</td>\n",
       "      <td>-1.068891</td>\n",
       "      <td>-1.265800</td>\n",
       "      <td>0.880380</td>\n",
       "      <td>-1.677525</td>\n",
       "      <td>1.093640</td>\n",
       "      <td>-0.385379</td>\n",
       "      <td>2.538488</td>\n",
       "      <td>0.784056</td>\n",
       "      <td>-0.267945</td>\n",
       "      <td>-0.182904</td>\n",
       "      <td>-0.511911</td>\n",
       "      <td>-0.147752</td>\n",
       "      <td>0.734731</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>-1.557591</td>\n",
       "      <td>1.533074</td>\n",
       "      <td>-0.068991</td>\n",
       "      <td>2.890663</td>\n",
       "      <td>0.745933</td>\n",
       "      <td>0.097765</td>\n",
       "      <td>1.422909</td>\n",
       "      <td>0.609237</td>\n",
       "      <td>-0.187450</td>\n",
       "      <td>0.350478</td>\n",
       "      <td>-0.193836</td>\n",
       "      <td>0.466069</td>\n",
       "      <td>-0.311532</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>1.274218</td>\n",
       "      <td>-1.105257</td>\n",
       "      <td>-0.226131</td>\n",
       "      <td>-1.284584</td>\n",
       "      <td>1.455893</td>\n",
       "      <td>-1.024499</td>\n",
       "      <td>1.037440</td>\n",
       "      <td>-0.814616</td>\n",
       "      <td>-0.682827</td>\n",
       "      <td>-0.291145</td>\n",
       "      <td>1.492311</td>\n",
       "      <td>-0.383265</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>-0.817560</td>\n",
       "      <td>-1.787894</td>\n",
       "      <td>-0.421822</td>\n",
       "      <td>0.190112</td>\n",
       "      <td>0.600203</td>\n",
       "      <td>-0.674290</td>\n",
       "      <td>-1.531854</td>\n",
       "      <td>-0.870796</td>\n",
       "      <td>-0.198345</td>\n",
       "      <td>-0.324021</td>\n",
       "      <td>-0.943876</td>\n",
       "      <td>-0.085068</td>\n",
       "      <td>0.724013</td>\n",
       "      <td>0.115212</td>\n",
       "      <td>-0.850596</td>\n",
       "      <td>-0.075968</td>\n",
       "      <td>0.834294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448993</td>\n",
       "      <td>1.156236</td>\n",
       "      <td>-0.552507</td>\n",
       "      <td>1.093119</td>\n",
       "      <td>1.248176</td>\n",
       "      <td>1.056411</td>\n",
       "      <td>0.915834</td>\n",
       "      <td>0.842251</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>-0.988465</td>\n",
       "      <td>2.712124</td>\n",
       "      <td>-0.589233</td>\n",
       "      <td>-0.211123</td>\n",
       "      <td>-1.628166</td>\n",
       "      <td>1.182411</td>\n",
       "      <td>1.335540</td>\n",
       "      <td>-0.323282</td>\n",
       "      <td>-1.722648</td>\n",
       "      <td>-1.726245</td>\n",
       "      <td>-2.050372</td>\n",
       "      <td>-1.514044</td>\n",
       "      <td>-0.748433</td>\n",
       "      <td>-5.069778</td>\n",
       "      <td>0.964486</td>\n",
       "      <td>-2.466216</td>\n",
       "      <td>2.260763</td>\n",
       "      <td>-0.141619</td>\n",
       "      <td>0.663809</td>\n",
       "      <td>-0.974260</td>\n",
       "      <td>-0.557925</td>\n",
       "      <td>-0.336950</td>\n",
       "      <td>2.287006</td>\n",
       "      <td>1.250679</td>\n",
       "      <td>-1.450120</td>\n",
       "      <td>-1.764366</td>\n",
       "      <td>-1.983956</td>\n",
       "      <td>-1.332678</td>\n",
       "      <td>-1.524334</td>\n",
       "      <td>-1.166429</td>\n",
       "      <td>0.632321</td>\n",
       "      <td>1.982091</td>\n",
       "      <td>0.337840</td>\n",
       "      <td>0.510165</td>\n",
       "      <td>0.565084</td>\n",
       "      <td>-0.797448</td>\n",
       "      <td>2.108223</td>\n",
       "      <td>0.729659</td>\n",
       "      <td>0.702204</td>\n",
       "      <td>-1.599895</td>\n",
       "      <td>0.638929</td>\n",
       "      <td>1.293899</td>\n",
       "      <td>1.326501</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>-1.767305</td>\n",
       "      <td>-2.983836</td>\n",
       "      <td>0.169207</td>\n",
       "      <td>0.715439</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>-0.511613</td>\n",
       "      <td>-0.351076</td>\n",
       "      <td>0.544161</td>\n",
       "      <td>-0.924069</td>\n",
       "      <td>0.436413</td>\n",
       "      <td>-1.108464</td>\n",
       "      <td>-1.061959</td>\n",
       "      <td>0.074151</td>\n",
       "      <td>-0.881981</td>\n",
       "      <td>-0.628520</td>\n",
       "      <td>1.793255</td>\n",
       "      <td>-1.697145</td>\n",
       "      <td>0.179526</td>\n",
       "      <td>0.419759</td>\n",
       "      <td>2.412240</td>\n",
       "      <td>0.192147</td>\n",
       "      <td>-1.541924</td>\n",
       "      <td>-0.510223</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.836373</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>-0.392311</td>\n",
       "      <td>1.099507</td>\n",
       "      <td>1.510316</td>\n",
       "      <td>0.179438</td>\n",
       "      <td>0.339868</td>\n",
       "      <td>-0.494070</td>\n",
       "      <td>-1.386567</td>\n",
       "      <td>-0.255034</td>\n",
       "      <td>-0.481221</td>\n",
       "      <td>0.861784</td>\n",
       "      <td>-1.056121</td>\n",
       "      <td>1.176251</td>\n",
       "      <td>1.566095</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>-0.965147</td>\n",
       "      <td>-0.431092</td>\n",
       "      <td>0.457807</td>\n",
       "      <td>0.129229</td>\n",
       "      <td>0.950087</td>\n",
       "      <td>0.847818</td>\n",
       "      <td>-0.786880</td>\n",
       "      <td>0.545882</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>-0.829904</td>\n",
       "      <td>-1.519984</td>\n",
       "      <td>-0.567840</td>\n",
       "      <td>0.264372</td>\n",
       "      <td>-1.564901</td>\n",
       "      <td>0.044441</td>\n",
       "      <td>-0.154304</td>\n",
       "      <td>-1.500347</td>\n",
       "      <td>0.228832</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>-2.187093</td>\n",
       "      <td>-0.559223</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.327030</td>\n",
       "      <td>-0.820642</td>\n",
       "      <td>-0.291321</td>\n",
       "      <td>1.889391</td>\n",
       "      <td>-0.066803</td>\n",
       "      <td>-1.088594</td>\n",
       "      <td>-0.117302</td>\n",
       "      <td>-0.975938</td>\n",
       "      <td>-1.058514</td>\n",
       "      <td>-1.044736</td>\n",
       "      <td>0.294860</td>\n",
       "      <td>0.286825</td>\n",
       "      <td>1.979262</td>\n",
       "      <td>-1.533290</td>\n",
       "      <td>0.059103</td>\n",
       "      <td>-0.434304</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>-1.045420</td>\n",
       "      <td>1.196577</td>\n",
       "      <td>0.216979</td>\n",
       "      <td>1.070848</td>\n",
       "      <td>-0.005644</td>\n",
       "      <td>1.607073</td>\n",
       "      <td>2.092888</td>\n",
       "      <td>-0.215351</td>\n",
       "      <td>0.100726</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>0.444431</td>\n",
       "      <td>1.085978</td>\n",
       "      <td>-1.381500</td>\n",
       "      <td>1.012517</td>\n",
       "      <td>2.350982</td>\n",
       "      <td>-0.009922</td>\n",
       "      <td>0.288151</td>\n",
       "      <td>-0.437877</td>\n",
       "      <td>-0.816865</td>\n",
       "      <td>-0.130795</td>\n",
       "      <td>0.382010</td>\n",
       "      <td>0.480523</td>\n",
       "      <td>-0.333326</td>\n",
       "      <td>-1.509889</td>\n",
       "      <td>-0.363752</td>\n",
       "      <td>-1.534615</td>\n",
       "      <td>1.098974</td>\n",
       "      <td>-0.261890</td>\n",
       "      <td>-0.327641</td>\n",
       "      <td>1.264328</td>\n",
       "      <td>-0.119976</td>\n",
       "      <td>0.071012</td>\n",
       "      <td>-0.771844</td>\n",
       "      <td>-1.386235</td>\n",
       "      <td>-2.488547</td>\n",
       "      <td>-1.446859</td>\n",
       "      <td>-0.488957</td>\n",
       "      <td>-0.940930</td>\n",
       "      <td>0.405601</td>\n",
       "      <td>1.051519</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>1.018902</td>\n",
       "      <td>0.506642</td>\n",
       "      <td>1.435671</td>\n",
       "      <td>0.316009</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>3.310587</td>\n",
       "      <td>-2.143929</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.550791</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>0.266909</td>\n",
       "      <td>-0.248185</td>\n",
       "      <td>0.433461</td>\n",
       "      <td>-0.406225</td>\n",
       "      <td>-0.534107</td>\n",
       "      <td>-1.138927</td>\n",
       "      <td>-1.468063</td>\n",
       "      <td>0.234325</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>-0.589562</td>\n",
       "      <td>-2.316962</td>\n",
       "      <td>1.713713</td>\n",
       "      <td>2.682963</td>\n",
       "      <td>2.084980</td>\n",
       "      <td>0.497381</td>\n",
       "      <td>-1.299091</td>\n",
       "      <td>-0.105574</td>\n",
       "      <td>-0.431409</td>\n",
       "      <td>-1.706436</td>\n",
       "      <td>-0.764355</td>\n",
       "      <td>-1.152298</td>\n",
       "      <td>-0.375918</td>\n",
       "      <td>-1.457326</td>\n",
       "      <td>-0.384925</td>\n",
       "      <td>0.131795</td>\n",
       "      <td>-0.274492</td>\n",
       "      <td>1.557043</td>\n",
       "      <td>-1.203678</td>\n",
       "      <td>-0.554415</td>\n",
       "      <td>-0.077594</td>\n",
       "      <td>-0.461044</td>\n",
       "      <td>-1.020614</td>\n",
       "      <td>-0.303952</td>\n",
       "      <td>0.089255</td>\n",
       "      <td>0.403331</td>\n",
       "      <td>-1.204560</td>\n",
       "      <td>-0.058098</td>\n",
       "      <td>-1.236817</td>\n",
       "      <td>-0.440749</td>\n",
       "      <td>1.741074</td>\n",
       "      <td>-0.974834</td>\n",
       "      <td>-0.048693</td>\n",
       "      <td>-1.851994</td>\n",
       "      <td>-3.423455</td>\n",
       "      <td>-0.347648</td>\n",
       "      <td>1.136671</td>\n",
       "      <td>-0.502773</td>\n",
       "      <td>-0.490789</td>\n",
       "      <td>0.023376</td>\n",
       "      <td>-1.110258</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>0.271157</td>\n",
       "      <td>-1.271237</td>\n",
       "      <td>0.238380</td>\n",
       "      <td>-0.749283</td>\n",
       "      <td>-0.467356</td>\n",
       "      <td>0.105311</td>\n",
       "      <td>0.936594</td>\n",
       "      <td>-1.217559</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>-0.717425</td>\n",
       "      <td>-3.236597</td>\n",
       "      <td>2.049624</td>\n",
       "      <td>-1.108130</td>\n",
       "      <td>-0.702754</td>\n",
       "      <td>-1.179765</td>\n",
       "      <td>0.265136</td>\n",
       "      <td>1.099541</td>\n",
       "      <td>0.897597</td>\n",
       "      <td>-0.814659</td>\n",
       "      <td>-0.898088</td>\n",
       "      <td>-0.446690</td>\n",
       "      <td>0.296517</td>\n",
       "      <td>0.148090</td>\n",
       "      <td>0.683028</td>\n",
       "      <td>0.477453</td>\n",
       "      <td>1.215805</td>\n",
       "      <td>-0.011332</td>\n",
       "      <td>-0.489295</td>\n",
       "      <td>-0.792334</td>\n",
       "      <td>-0.322898</td>\n",
       "      <td>0.705187</td>\n",
       "      <td>0.686590</td>\n",
       "      <td>1.094837</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>-0.381233</td>\n",
       "      <td>0.387030</td>\n",
       "      <td>-1.235889</td>\n",
       "      <td>1.017926</td>\n",
       "      <td>1.264505</td>\n",
       "      <td>2.935089</td>\n",
       "      <td>-0.309807</td>\n",
       "      <td>-0.591890</td>\n",
       "      <td>0.849522</td>\n",
       "      <td>-1.800942</td>\n",
       "      <td>-0.079769</td>\n",
       "      <td>0.862475</td>\n",
       "      <td>1.645217</td>\n",
       "      <td>-0.216736</td>\n",
       "      <td>-0.224120</td>\n",
       "      <td>-0.360205</td>\n",
       "      <td>1.473297</td>\n",
       "      <td>-0.261461</td>\n",
       "      <td>1.683355</td>\n",
       "      <td>1.199525</td>\n",
       "      <td>-0.789509</td>\n",
       "      <td>1.725463</td>\n",
       "      <td>0.929757</td>\n",
       "      <td>-2.067227</td>\n",
       "      <td>0.219814</td>\n",
       "      <td>-0.779638</td>\n",
       "      <td>-1.006846</td>\n",
       "      <td>-0.374644</td>\n",
       "      <td>-0.098359</td>\n",
       "      <td>0.133213</td>\n",
       "      <td>-0.087837</td>\n",
       "      <td>-0.364778</td>\n",
       "      <td>1.608919</td>\n",
       "      <td>1.525883</td>\n",
       "      <td>0.313317</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>1.511563</td>\n",
       "      <td>-0.225942</td>\n",
       "      <td>-1.178596</td>\n",
       "      <td>2.565667</td>\n",
       "      <td>-0.629778</td>\n",
       "      <td>0.154570</td>\n",
       "      <td>-0.841172</td>\n",
       "      <td>1.572048</td>\n",
       "      <td>1.043762</td>\n",
       "      <td>-0.486572</td>\n",
       "      <td>-1.270145</td>\n",
       "      <td>-2.289787</td>\n",
       "      <td>-1.567739</td>\n",
       "      <td>-1.256507</td>\n",
       "      <td>-0.081146</td>\n",
       "      <td>-5.011274</td>\n",
       "      <td>0.749544</td>\n",
       "      <td>-2.409873</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>-0.602056</td>\n",
       "      <td>0.373513</td>\n",
       "      <td>0.236222</td>\n",
       "      <td>-1.235387</td>\n",
       "      <td>-0.068023</td>\n",
       "      <td>2.051218</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>-1.312616</td>\n",
       "      <td>-1.707940</td>\n",
       "      <td>-1.402620</td>\n",
       "      <td>-1.391959</td>\n",
       "      <td>-1.906361</td>\n",
       "      <td>-1.691047</td>\n",
       "      <td>-0.362632</td>\n",
       "      <td>1.056187</td>\n",
       "      <td>0.500989</td>\n",
       "      <td>1.011676</td>\n",
       "      <td>0.513328</td>\n",
       "      <td>-0.590390</td>\n",
       "      <td>2.426959</td>\n",
       "      <td>0.041570</td>\n",
       "      <td>0.576326</td>\n",
       "      <td>-1.383124</td>\n",
       "      <td>-0.738434</td>\n",
       "      <td>2.014749</td>\n",
       "      <td>1.537673</td>\n",
       "      <td>0.419088</td>\n",
       "      <td>-1.528418</td>\n",
       "      <td>-2.965370</td>\n",
       "      <td>-0.314553</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>-0.234514</td>\n",
       "      <td>-0.332368</td>\n",
       "      <td>-0.581848</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-1.209480</td>\n",
       "      <td>0.651966</td>\n",
       "      <td>-0.739420</td>\n",
       "      <td>-1.775488</td>\n",
       "      <td>-0.771131</td>\n",
       "      <td>-0.893785</td>\n",
       "      <td>-0.094902</td>\n",
       "      <td>2.111888</td>\n",
       "      <td>-2.016509</td>\n",
       "      <td>0.049680</td>\n",
       "      <td>-0.194395</td>\n",
       "      <td>2.198106</td>\n",
       "      <td>0.426496</td>\n",
       "      <td>-2.033557</td>\n",
       "      <td>-0.565892</td>\n",
       "      <td>0.241965</td>\n",
       "      <td>-0.659793</td>\n",
       "      <td>0.189951</td>\n",
       "      <td>0.389631</td>\n",
       "      <td>0.442904</td>\n",
       "      <td>-0.109351</td>\n",
       "      <td>1.504604</td>\n",
       "      <td>-0.183342</td>\n",
       "      <td>-0.190953</td>\n",
       "      <td>-0.663065</td>\n",
       "      <td>-0.791255</td>\n",
       "      <td>0.169196</td>\n",
       "      <td>-0.656104</td>\n",
       "      <td>0.793585</td>\n",
       "      <td>-1.156464</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>2.505736</td>\n",
       "      <td>0.809516</td>\n",
       "      <td>-0.299119</td>\n",
       "      <td>-0.269930</td>\n",
       "      <td>0.245396</td>\n",
       "      <td>-0.034337</td>\n",
       "      <td>1.077155</td>\n",
       "      <td>0.587455</td>\n",
       "      <td>-1.264229</td>\n",
       "      <td>0.035904</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>-1.088148</td>\n",
       "      <td>-1.725981</td>\n",
       "      <td>-0.459666</td>\n",
       "      <td>-0.279853</td>\n",
       "      <td>-1.113187</td>\n",
       "      <td>0.325578</td>\n",
       "      <td>0.456590</td>\n",
       "      <td>-1.895779</td>\n",
       "      <td>-0.420479</td>\n",
       "      <td>0.414671</td>\n",
       "      <td>-1.970949</td>\n",
       "      <td>-1.365360</td>\n",
       "      <td>0.689748</td>\n",
       "      <td>0.520732</td>\n",
       "      <td>-1.348000</td>\n",
       "      <td>-0.218094</td>\n",
       "      <td>1.360800</td>\n",
       "      <td>-0.582414</td>\n",
       "      <td>-0.635292</td>\n",
       "      <td>-0.201325</td>\n",
       "      <td>-0.974176</td>\n",
       "      <td>-0.822967</td>\n",
       "      <td>-1.546810</td>\n",
       "      <td>-1.012310</td>\n",
       "      <td>-0.350520</td>\n",
       "      <td>1.733075</td>\n",
       "      <td>-1.482966</td>\n",
       "      <td>-0.097708</td>\n",
       "      <td>0.468820</td>\n",
       "      <td>0.921853</td>\n",
       "      <td>-0.353141</td>\n",
       "      <td>0.855872</td>\n",
       "      <td>0.910540</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>-0.307956</td>\n",
       "      <td>1.452923</td>\n",
       "      <td>1.208596</td>\n",
       "      <td>-0.123460</td>\n",
       "      <td>0.177124</td>\n",
       "      <td>-1.253447</td>\n",
       "      <td>0.487351</td>\n",
       "      <td>1.127023</td>\n",
       "      <td>-0.437936</td>\n",
       "      <td>0.322642</td>\n",
       "      <td>1.851944</td>\n",
       "      <td>0.468717</td>\n",
       "      <td>0.281103</td>\n",
       "      <td>-0.747660</td>\n",
       "      <td>-1.440229</td>\n",
       "      <td>-0.582532</td>\n",
       "      <td>-1.041456</td>\n",
       "      <td>0.528289</td>\n",
       "      <td>-1.113614</td>\n",
       "      <td>-1.604985</td>\n",
       "      <td>0.410432</td>\n",
       "      <td>-1.174740</td>\n",
       "      <td>0.621560</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>-0.512109</td>\n",
       "      <td>0.478356</td>\n",
       "      <td>-0.077871</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>-0.694211</td>\n",
       "      <td>-1.623864</td>\n",
       "      <td>-2.182725</td>\n",
       "      <td>-0.812769</td>\n",
       "      <td>-0.678495</td>\n",
       "      <td>-0.725284</td>\n",
       "      <td>0.318695</td>\n",
       "      <td>1.338188</td>\n",
       "      <td>1.023823</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>0.473331</td>\n",
       "      <td>1.819037</td>\n",
       "      <td>1.151643</td>\n",
       "      <td>0.635531</td>\n",
       "      <td>-0.035871</td>\n",
       "      <td>3.172655</td>\n",
       "      <td>-1.647880</td>\n",
       "      <td>0.568607</td>\n",
       "      <td>0.186810</td>\n",
       "      <td>0.742029</td>\n",
       "      <td>0.707849</td>\n",
       "      <td>-1.231651</td>\n",
       "      <td>0.325528</td>\n",
       "      <td>-0.304331</td>\n",
       "      <td>-1.135296</td>\n",
       "      <td>-0.459064</td>\n",
       "      <td>-2.277352</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>-0.383516</td>\n",
       "      <td>-0.388054</td>\n",
       "      <td>-2.439767</td>\n",
       "      <td>1.873550</td>\n",
       "      <td>3.109859</td>\n",
       "      <td>2.301276</td>\n",
       "      <td>0.479438</td>\n",
       "      <td>-1.011960</td>\n",
       "      <td>-0.102235</td>\n",
       "      <td>-1.269992</td>\n",
       "      <td>-0.920845</td>\n",
       "      <td>-0.635908</td>\n",
       "      <td>-0.916363</td>\n",
       "      <td>-0.461461</td>\n",
       "      <td>-1.384890</td>\n",
       "      <td>0.260657</td>\n",
       "      <td>0.267789</td>\n",
       "      <td>-1.116232</td>\n",
       "      <td>2.203712</td>\n",
       "      <td>-1.417201</td>\n",
       "      <td>-0.062162</td>\n",
       "      <td>-0.194422</td>\n",
       "      <td>-0.875384</td>\n",
       "      <td>-1.072115</td>\n",
       "      <td>-0.351344</td>\n",
       "      <td>-0.729674</td>\n",
       "      <td>0.136110</td>\n",
       "      <td>-1.285649</td>\n",
       "      <td>-0.290868</td>\n",
       "      <td>-0.649544</td>\n",
       "      <td>-0.585311</td>\n",
       "      <td>2.382519</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>-0.648691</td>\n",
       "      <td>-2.519820</td>\n",
       "      <td>-3.327208</td>\n",
       "      <td>-0.605606</td>\n",
       "      <td>0.657276</td>\n",
       "      <td>-0.764912</td>\n",
       "      <td>-1.529091</td>\n",
       "      <td>-0.464301</td>\n",
       "      <td>-0.987403</td>\n",
       "      <td>0.249460</td>\n",
       "      <td>0.040108</td>\n",
       "      <td>-0.405501</td>\n",
       "      <td>0.119645</td>\n",
       "      <td>0.062958</td>\n",
       "      <td>0.058074</td>\n",
       "      <td>0.660944</td>\n",
       "      <td>0.414998</td>\n",
       "      <td>-0.933531</td>\n",
       "      <td>0.273428</td>\n",
       "      <td>-0.654104</td>\n",
       "      <td>-2.225361</td>\n",
       "      <td>2.340402</td>\n",
       "      <td>-0.271763</td>\n",
       "      <td>-0.265614</td>\n",
       "      <td>-1.062281</td>\n",
       "      <td>0.570357</td>\n",
       "      <td>1.231388</td>\n",
       "      <td>0.734230</td>\n",
       "      <td>-0.332030</td>\n",
       "      <td>-0.768671</td>\n",
       "      <td>-0.340577</td>\n",
       "      <td>-0.413781</td>\n",
       "      <td>-0.090259</td>\n",
       "      <td>0.531459</td>\n",
       "      <td>0.339921</td>\n",
       "      <td>1.475874</td>\n",
       "      <td>0.186980</td>\n",
       "      <td>0.116336</td>\n",
       "      <td>-0.888419</td>\n",
       "      <td>-0.981854</td>\n",
       "      <td>0.372697</td>\n",
       "      <td>1.036668</td>\n",
       "      <td>0.989350</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>1.936599</td>\n",
       "      <td>-0.184384</td>\n",
       "      <td>1.009690</td>\n",
       "      <td>-1.761441</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.929813</td>\n",
       "      <td>3.029642</td>\n",
       "      <td>-0.371777</td>\n",
       "      <td>-0.605579</td>\n",
       "      <td>0.758918</td>\n",
       "      <td>-0.813322</td>\n",
       "      <td>1.429388</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>1.786340</td>\n",
       "      <td>-0.011713</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>-0.320574</td>\n",
       "      <td>0.742657</td>\n",
       "      <td>-0.900506</td>\n",
       "      <td>0.972276</td>\n",
       "      <td>0.648917</td>\n",
       "      <td>-0.856599</td>\n",
       "      <td>1.342793</td>\n",
       "      <td>0.406341</td>\n",
       "      <td>-2.066126</td>\n",
       "      <td>0.508002</td>\n",
       "      <td>-1.491883</td>\n",
       "      <td>-1.002621</td>\n",
       "      <td>-0.824764</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>-0.322550</td>\n",
       "      <td>0.354632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893535</td>\n",
       "      <td>0.893535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4055.168882</td>\n",
       "      <td>0.732131</td>\n",
       "      <td>0.077561</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3692.125460</td>\n",
       "      <td>0.409729</td>\n",
       "      <td>-0.084470</td>\n",
       "      <td>0.181364</td>\n",
       "      <td>1.487987</td>\n",
       "      <td>-0.563458</td>\n",
       "      <td>-0.471456</td>\n",
       "      <td>-0.975806</td>\n",
       "      <td>0.308908</td>\n",
       "      <td>-0.696337</td>\n",
       "      <td>0.665534</td>\n",
       "      <td>1.676413</td>\n",
       "      <td>-0.758495</td>\n",
       "      <td>-0.348640</td>\n",
       "      <td>1.417454</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>-0.765200</td>\n",
       "      <td>-0.167886</td>\n",
       "      <td>0.650347</td>\n",
       "      <td>-0.551643</td>\n",
       "      <td>0.179427</td>\n",
       "      <td>1.167825</td>\n",
       "      <td>1.619838</td>\n",
       "      <td>0.392076</td>\n",
       "      <td>1.468229</td>\n",
       "      <td>0.345566</td>\n",
       "      <td>-0.944737</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.104401</td>\n",
       "      <td>-0.059609</td>\n",
       "      <td>0.338477</td>\n",
       "      <td>0.160966</td>\n",
       "      <td>0.522734</td>\n",
       "      <td>0.363621</td>\n",
       "      <td>0.407103</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>-0.843825</td>\n",
       "      <td>-0.138331</td>\n",
       "      <td>-0.241210</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>-0.016069</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>-0.065427</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>-1.086291</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>-0.457107</td>\n",
       "      <td>-0.079732</td>\n",
       "      <td>-0.226263</td>\n",
       "      <td>-0.427232</td>\n",
       "      <td>-0.126720</td>\n",
       "      <td>0.298414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.355538</td>\n",
       "      <td>-0.355538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.851807</td>\n",
       "      <td>0.359705</td>\n",
       "      <td>-0.285118</td>\n",
       "      <td>0.405777</td>\n",
       "      <td>1.653049</td>\n",
       "      <td>-0.298667</td>\n",
       "      <td>0.922738</td>\n",
       "      <td>1.011133</td>\n",
       "      <td>1.011660</td>\n",
       "      <td>-0.312802</td>\n",
       "      <td>1.327599</td>\n",
       "      <td>-1.983745</td>\n",
       "      <td>-1.081870</td>\n",
       "      <td>0.274117</td>\n",
       "      <td>-1.235188</td>\n",
       "      <td>2.093716</td>\n",
       "      <td>-0.578111</td>\n",
       "      <td>-0.658953</td>\n",
       "      <td>2.120344</td>\n",
       "      <td>0.932049</td>\n",
       "      <td>-0.600898</td>\n",
       "      <td>-0.519813</td>\n",
       "      <td>-0.720554</td>\n",
       "      <td>-0.887870</td>\n",
       "      <td>-0.786204</td>\n",
       "      <td>0.636922</td>\n",
       "      <td>0.680370</td>\n",
       "      <td>1.383218</td>\n",
       "      <td>1.050668</td>\n",
       "      <td>-0.242659</td>\n",
       "      <td>0.080210</td>\n",
       "      <td>-0.591254</td>\n",
       "      <td>-0.428144</td>\n",
       "      <td>-0.065150</td>\n",
       "      <td>-0.447022</td>\n",
       "      <td>-1.344697</td>\n",
       "      <td>-1.711217</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.164807</td>\n",
       "      <td>-1.257286</td>\n",
       "      <td>0.249592</td>\n",
       "      <td>-0.298079</td>\n",
       "      <td>-1.821185</td>\n",
       "      <td>0.810949</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>1.094537</td>\n",
       "      <td>-0.923004</td>\n",
       "      <td>0.796656</td>\n",
       "      <td>1.556535</td>\n",
       "      <td>-0.153883</td>\n",
       "      <td>-1.064906</td>\n",
       "      <td>-0.271044</td>\n",
       "      <td>-0.102455</td>\n",
       "      <td>1.180990</td>\n",
       "      <td>-0.364190</td>\n",
       "      <td>1.027025</td>\n",
       "      <td>-0.663895</td>\n",
       "      <td>0.222891</td>\n",
       "      <td>-1.107675</td>\n",
       "      <td>0.206399</td>\n",
       "      <td>2.596629</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>-0.096853</td>\n",
       "      <td>-0.792260</td>\n",
       "      <td>-0.133292</td>\n",
       "      <td>-0.766049</td>\n",
       "      <td>-0.660631</td>\n",
       "      <td>-0.603100</td>\n",
       "      <td>-1.249820</td>\n",
       "      <td>2.113088</td>\n",
       "      <td>0.027775</td>\n",
       "      <td>-0.812743</td>\n",
       "      <td>-1.780777</td>\n",
       "      <td>0.123686</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.551475</td>\n",
       "      <td>0.620656</td>\n",
       "      <td>0.394846</td>\n",
       "      <td>1.868764</td>\n",
       "      <td>-0.535296</td>\n",
       "      <td>0.094466</td>\n",
       "      <td>-0.522489</td>\n",
       "      <td>1.012734</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>-0.376113</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.860865</td>\n",
       "      <td>-1.413640</td>\n",
       "      <td>1.999030</td>\n",
       "      <td>0.636520</td>\n",
       "      <td>-0.296653</td>\n",
       "      <td>-1.049413</td>\n",
       "      <td>1.272486</td>\n",
       "      <td>-0.956749</td>\n",
       "      <td>-0.294148</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>-0.047569</td>\n",
       "      <td>-0.692646</td>\n",
       "      <td>1.038218</td>\n",
       "      <td>-0.171632</td>\n",
       "      <td>1.331722</td>\n",
       "      <td>1.625692</td>\n",
       "      <td>-0.490659</td>\n",
       "      <td>-1.051846</td>\n",
       "      <td>-0.537964</td>\n",
       "      <td>0.427878</td>\n",
       "      <td>-1.316384</td>\n",
       "      <td>-1.110096</td>\n",
       "      <td>-1.342565</td>\n",
       "      <td>0.887751</td>\n",
       "      <td>0.583107</td>\n",
       "      <td>-1.729338</td>\n",
       "      <td>-0.311059</td>\n",
       "      <td>-0.109466</td>\n",
       "      <td>-0.058496</td>\n",
       "      <td>-1.637134</td>\n",
       "      <td>0.498233</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.741406</td>\n",
       "      <td>1.521551</td>\n",
       "      <td>0.077421</td>\n",
       "      <td>-0.852036</td>\n",
       "      <td>0.235890</td>\n",
       "      <td>0.329996</td>\n",
       "      <td>-1.627502</td>\n",
       "      <td>1.502486</td>\n",
       "      <td>-0.965720</td>\n",
       "      <td>-0.052865</td>\n",
       "      <td>-0.891102</td>\n",
       "      <td>-0.126900</td>\n",
       "      <td>-0.916214</td>\n",
       "      <td>-1.001230</td>\n",
       "      <td>-0.145483</td>\n",
       "      <td>0.900813</td>\n",
       "      <td>1.197273</td>\n",
       "      <td>0.848045</td>\n",
       "      <td>-0.868675</td>\n",
       "      <td>0.462872</td>\n",
       "      <td>-0.029981</td>\n",
       "      <td>-0.707439</td>\n",
       "      <td>0.578180</td>\n",
       "      <td>0.957454</td>\n",
       "      <td>2.371285</td>\n",
       "      <td>-0.160592</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-1.414939</td>\n",
       "      <td>-0.942772</td>\n",
       "      <td>-0.570482</td>\n",
       "      <td>-0.315899</td>\n",
       "      <td>-0.640316</td>\n",
       "      <td>0.882068</td>\n",
       "      <td>-1.232861</td>\n",
       "      <td>0.071896</td>\n",
       "      <td>-1.667103</td>\n",
       "      <td>-0.482745</td>\n",
       "      <td>1.074750</td>\n",
       "      <td>0.930528</td>\n",
       "      <td>-0.808302</td>\n",
       "      <td>0.731952</td>\n",
       "      <td>-0.413760</td>\n",
       "      <td>0.562538</td>\n",
       "      <td>-0.258239</td>\n",
       "      <td>1.860032</td>\n",
       "      <td>0.667257</td>\n",
       "      <td>0.269687</td>\n",
       "      <td>-1.911067</td>\n",
       "      <td>-1.225897</td>\n",
       "      <td>-0.876473</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>-1.880575</td>\n",
       "      <td>-0.780035</td>\n",
       "      <td>-0.327461</td>\n",
       "      <td>-0.477785</td>\n",
       "      <td>-0.734616</td>\n",
       "      <td>-0.243673</td>\n",
       "      <td>1.153620</td>\n",
       "      <td>0.207475</td>\n",
       "      <td>-0.506123</td>\n",
       "      <td>0.229015</td>\n",
       "      <td>-0.820618</td>\n",
       "      <td>-0.331310</td>\n",
       "      <td>-0.322671</td>\n",
       "      <td>2.243803</td>\n",
       "      <td>0.658727</td>\n",
       "      <td>-0.206132</td>\n",
       "      <td>-0.102983</td>\n",
       "      <td>0.560646</td>\n",
       "      <td>-1.797792</td>\n",
       "      <td>-0.131800</td>\n",
       "      <td>-0.296205</td>\n",
       "      <td>0.333294</td>\n",
       "      <td>0.163465</td>\n",
       "      <td>-0.093406</td>\n",
       "      <td>-0.122367</td>\n",
       "      <td>1.369165</td>\n",
       "      <td>-1.181823</td>\n",
       "      <td>1.446019</td>\n",
       "      <td>-1.034380</td>\n",
       "      <td>-0.066791</td>\n",
       "      <td>-0.110820</td>\n",
       "      <td>0.633619</td>\n",
       "      <td>0.970541</td>\n",
       "      <td>0.498484</td>\n",
       "      <td>1.599172</td>\n",
       "      <td>-0.010571</td>\n",
       "      <td>0.064114</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.406307</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.611187</td>\n",
       "      <td>0.313328</td>\n",
       "      <td>-0.799393</td>\n",
       "      <td>-0.450504</td>\n",
       "      <td>-1.760621</td>\n",
       "      <td>-0.701216</td>\n",
       "      <td>0.330177</td>\n",
       "      <td>-0.242090</td>\n",
       "      <td>0.826249</td>\n",
       "      <td>-1.136835</td>\n",
       "      <td>-0.748174</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>-0.051621</td>\n",
       "      <td>-1.020181</td>\n",
       "      <td>-1.111574</td>\n",
       "      <td>-2.537954</td>\n",
       "      <td>0.327959</td>\n",
       "      <td>-1.263636</td>\n",
       "      <td>0.107016</td>\n",
       "      <td>-0.072795</td>\n",
       "      <td>1.363701</td>\n",
       "      <td>1.113044</td>\n",
       "      <td>0.731276</td>\n",
       "      <td>-0.016962</td>\n",
       "      <td>0.118595</td>\n",
       "      <td>0.265416</td>\n",
       "      <td>-1.128841</td>\n",
       "      <td>2.127662</td>\n",
       "      <td>0.516819</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>1.693425</td>\n",
       "      <td>-0.385051</td>\n",
       "      <td>-1.316113</td>\n",
       "      <td>0.495767</td>\n",
       "      <td>-1.191193</td>\n",
       "      <td>0.666189</td>\n",
       "      <td>-0.851244</td>\n",
       "      <td>-0.233789</td>\n",
       "      <td>-1.333151</td>\n",
       "      <td>-1.459939</td>\n",
       "      <td>-0.452787</td>\n",
       "      <td>-1.314317</td>\n",
       "      <td>0.893076</td>\n",
       "      <td>-0.978523</td>\n",
       "      <td>-0.497490</td>\n",
       "      <td>1.183981</td>\n",
       "      <td>0.457466</td>\n",
       "      <td>-0.295013</td>\n",
       "      <td>-1.866267</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>-1.038555</td>\n",
       "      <td>-1.489938</td>\n",
       "      <td>-0.362210</td>\n",
       "      <td>0.331062</td>\n",
       "      <td>-0.601377</td>\n",
       "      <td>-1.671971</td>\n",
       "      <td>0.731664</td>\n",
       "      <td>-0.045461</td>\n",
       "      <td>-0.581446</td>\n",
       "      <td>-0.867031</td>\n",
       "      <td>0.406182</td>\n",
       "      <td>-0.719129</td>\n",
       "      <td>1.268360</td>\n",
       "      <td>-0.089959</td>\n",
       "      <td>0.539472</td>\n",
       "      <td>0.508317</td>\n",
       "      <td>0.806898</td>\n",
       "      <td>1.309377</td>\n",
       "      <td>0.133092</td>\n",
       "      <td>-0.114487</td>\n",
       "      <td>0.152128</td>\n",
       "      <td>0.232162</td>\n",
       "      <td>0.458293</td>\n",
       "      <td>-0.821656</td>\n",
       "      <td>-1.026838</td>\n",
       "      <td>-0.588132</td>\n",
       "      <td>1.372060</td>\n",
       "      <td>0.117968</td>\n",
       "      <td>0.556803</td>\n",
       "      <td>-1.846453</td>\n",
       "      <td>1.813139</td>\n",
       "      <td>-0.693386</td>\n",
       "      <td>1.427753</td>\n",
       "      <td>0.732330</td>\n",
       "      <td>-0.480106</td>\n",
       "      <td>-0.052404</td>\n",
       "      <td>-0.022492</td>\n",
       "      <td>0.768021</td>\n",
       "      <td>-1.069563</td>\n",
       "      <td>-0.919992</td>\n",
       "      <td>0.197537</td>\n",
       "      <td>1.183008</td>\n",
       "      <td>-1.382627</td>\n",
       "      <td>1.031120</td>\n",
       "      <td>-0.481680</td>\n",
       "      <td>-0.193260</td>\n",
       "      <td>-1.126306</td>\n",
       "      <td>0.913665</td>\n",
       "      <td>0.281344</td>\n",
       "      <td>-0.254246</td>\n",
       "      <td>-0.082714</td>\n",
       "      <td>-0.375480</td>\n",
       "      <td>0.780076</td>\n",
       "      <td>0.909704</td>\n",
       "      <td>-0.171177</td>\n",
       "      <td>-0.241654</td>\n",
       "      <td>1.137462</td>\n",
       "      <td>1.204758</td>\n",
       "      <td>-0.552063</td>\n",
       "      <td>-0.843273</td>\n",
       "      <td>1.324540</td>\n",
       "      <td>-1.601353</td>\n",
       "      <td>-0.277398</td>\n",
       "      <td>0.575406</td>\n",
       "      <td>-0.962586</td>\n",
       "      <td>-0.571055</td>\n",
       "      <td>1.081831</td>\n",
       "      <td>0.475545</td>\n",
       "      <td>-0.368258</td>\n",
       "      <td>-0.096840</td>\n",
       "      <td>-0.447416</td>\n",
       "      <td>-0.906761</td>\n",
       "      <td>-1.484180</td>\n",
       "      <td>-1.271660</td>\n",
       "      <td>-0.710865</td>\n",
       "      <td>-2.288414</td>\n",
       "      <td>-1.160996</td>\n",
       "      <td>-0.913291</td>\n",
       "      <td>1.090702</td>\n",
       "      <td>-0.525932</td>\n",
       "      <td>-1.032769</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>-0.390301</td>\n",
       "      <td>1.249191</td>\n",
       "      <td>0.257019</td>\n",
       "      <td>0.811666</td>\n",
       "      <td>0.644727</td>\n",
       "      <td>0.867438</td>\n",
       "      <td>0.819504</td>\n",
       "      <td>1.111360</td>\n",
       "      <td>-2.299784</td>\n",
       "      <td>0.118286</td>\n",
       "      <td>2.685036</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>0.915740</td>\n",
       "      <td>-0.675624</td>\n",
       "      <td>0.170311</td>\n",
       "      <td>-0.981117</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>3.046258</td>\n",
       "      <td>-0.302474</td>\n",
       "      <td>-0.836490</td>\n",
       "      <td>-1.389416</td>\n",
       "      <td>0.805599</td>\n",
       "      <td>-0.598141</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.172501</td>\n",
       "      <td>2.416750</td>\n",
       "      <td>0.050916</td>\n",
       "      <td>0.484942</td>\n",
       "      <td>0.360076</td>\n",
       "      <td>0.270846</td>\n",
       "      <td>0.342511</td>\n",
       "      <td>1.700868</td>\n",
       "      <td>-0.303349</td>\n",
       "      <td>2.201669</td>\n",
       "      <td>-0.432906</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>-0.972072</td>\n",
       "      <td>-1.116622</td>\n",
       "      <td>-1.152451</td>\n",
       "      <td>0.224959</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.412230</td>\n",
       "      <td>-0.463664</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.135820</td>\n",
       "      <td>0.236283</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>1.336694</td>\n",
       "      <td>2.203182</td>\n",
       "      <td>3.123642</td>\n",
       "      <td>1.267467</td>\n",
       "      <td>2.235961</td>\n",
       "      <td>1.064833</td>\n",
       "      <td>1.549990</td>\n",
       "      <td>1.306227</td>\n",
       "      <td>0.047364</td>\n",
       "      <td>-0.375184</td>\n",
       "      <td>1.108521</td>\n",
       "      <td>-0.786399</td>\n",
       "      <td>0.216688</td>\n",
       "      <td>-0.895912</td>\n",
       "      <td>-2.839768</td>\n",
       "      <td>-0.531010</td>\n",
       "      <td>-1.037511</td>\n",
       "      <td>1.212546</td>\n",
       "      <td>-0.241543</td>\n",
       "      <td>-0.413399</td>\n",
       "      <td>-0.252692</td>\n",
       "      <td>0.630187</td>\n",
       "      <td>-0.521892</td>\n",
       "      <td>-0.026792</td>\n",
       "      <td>-0.072190</td>\n",
       "      <td>0.876789</td>\n",
       "      <td>-0.331647</td>\n",
       "      <td>1.255788</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>-0.795172</td>\n",
       "      <td>0.996092</td>\n",
       "      <td>2.316779</td>\n",
       "      <td>0.949739</td>\n",
       "      <td>-1.029926</td>\n",
       "      <td>-0.569946</td>\n",
       "      <td>-0.359061</td>\n",
       "      <td>-0.392044</td>\n",
       "      <td>-0.313228</td>\n",
       "      <td>-2.214638</td>\n",
       "      <td>-1.485882</td>\n",
       "      <td>-0.107226</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>-1.727922</td>\n",
       "      <td>-1.023749</td>\n",
       "      <td>-0.709151</td>\n",
       "      <td>-0.155993</td>\n",
       "      <td>-0.194077</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.619831</td>\n",
       "      <td>-0.313530</td>\n",
       "      <td>-1.329584</td>\n",
       "      <td>0.687450</td>\n",
       "      <td>-0.553795</td>\n",
       "      <td>-0.656326</td>\n",
       "      <td>-0.473457</td>\n",
       "      <td>-1.098787</td>\n",
       "      <td>2.039641</td>\n",
       "      <td>1.327381</td>\n",
       "      <td>-0.582409</td>\n",
       "      <td>1.377688</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>-1.178746</td>\n",
       "      <td>-1.594711</td>\n",
       "      <td>-0.034631</td>\n",
       "      <td>-1.845421</td>\n",
       "      <td>-0.468800</td>\n",
       "      <td>-1.083567</td>\n",
       "      <td>0.643403</td>\n",
       "      <td>0.573586</td>\n",
       "      <td>-0.172829</td>\n",
       "      <td>-0.757809</td>\n",
       "      <td>-1.274483</td>\n",
       "      <td>-1.888483</td>\n",
       "      <td>-0.874226</td>\n",
       "      <td>-0.512385</td>\n",
       "      <td>-0.164714</td>\n",
       "      <td>-0.795544</td>\n",
       "      <td>-0.580163</td>\n",
       "      <td>-0.118204</td>\n",
       "      <td>0.471488</td>\n",
       "      <td>0.862001</td>\n",
       "      <td>0.872008</td>\n",
       "      <td>0.387048</td>\n",
       "      <td>-0.591753</td>\n",
       "      <td>1.250002</td>\n",
       "      <td>-0.675579</td>\n",
       "      <td>0.218131</td>\n",
       "      <td>-0.124039</td>\n",
       "      <td>-0.609615</td>\n",
       "      <td>0.247457</td>\n",
       "      <td>0.781949</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>-0.586910</td>\n",
       "      <td>1.141393</td>\n",
       "      <td>-1.233994</td>\n",
       "      <td>-1.351729</td>\n",
       "      <td>0.459993</td>\n",
       "      <td>-0.367312</td>\n",
       "      <td>-1.120764</td>\n",
       "      <td>1.358222</td>\n",
       "      <td>-2.305675</td>\n",
       "      <td>0.650903</td>\n",
       "      <td>2.832756</td>\n",
       "      <td>1.069020</td>\n",
       "      <td>-0.357712</td>\n",
       "      <td>0.553850</td>\n",
       "      <td>-0.793237</td>\n",
       "      <td>0.178772</td>\n",
       "      <td>0.386098</td>\n",
       "      <td>-1.071301</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>1.067161</td>\n",
       "      <td>0.810650</td>\n",
       "      <td>0.647335</td>\n",
       "      <td>0.676572</td>\n",
       "      <td>1.658786</td>\n",
       "      <td>-0.131825</td>\n",
       "      <td>-0.846245</td>\n",
       "      <td>-0.099016</td>\n",
       "      <td>-0.569132</td>\n",
       "      <td>0.168716</td>\n",
       "      <td>-0.161406</td>\n",
       "      <td>0.225184</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>1.227320</td>\n",
       "      <td>-0.014663</td>\n",
       "      <td>0.828610</td>\n",
       "      <td>0.198026</td>\n",
       "      <td>1.236628</td>\n",
       "      <td>-0.907020</td>\n",
       "      <td>0.818787</td>\n",
       "      <td>1.075956</td>\n",
       "      <td>0.535393</td>\n",
       "      <td>1.558724</td>\n",
       "      <td>0.719315</td>\n",
       "      <td>-0.451938</td>\n",
       "      <td>-0.970884</td>\n",
       "      <td>1.504297</td>\n",
       "      <td>-0.547936</td>\n",
       "      <td>-0.259178</td>\n",
       "      <td>0.787641</td>\n",
       "      <td>0.722499</td>\n",
       "      <td>1.073586</td>\n",
       "      <td>1.253372</td>\n",
       "      <td>1.265875</td>\n",
       "      <td>-0.696305</td>\n",
       "      <td>-0.363185</td>\n",
       "      <td>0.429031</td>\n",
       "      <td>1.117184</td>\n",
       "      <td>1.201860</td>\n",
       "      <td>-0.140075</td>\n",
       "      <td>-1.063485</td>\n",
       "      <td>0.170880</td>\n",
       "      <td>0.550350</td>\n",
       "      <td>-0.178869</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>-0.158383</td>\n",
       "      <td>0.316424</td>\n",
       "      <td>0.290799</td>\n",
       "      <td>-0.623618</td>\n",
       "      <td>2.598997</td>\n",
       "      <td>1.073300</td>\n",
       "      <td>0.630356</td>\n",
       "      <td>0.689101</td>\n",
       "      <td>-0.183603</td>\n",
       "      <td>-1.017696</td>\n",
       "      <td>1.019354</td>\n",
       "      <td>1.387370</td>\n",
       "      <td>-0.630696</td>\n",
       "      <td>-0.588749</td>\n",
       "      <td>0.495696</td>\n",
       "      <td>1.061598</td>\n",
       "      <td>1.526201</td>\n",
       "      <td>-1.052216</td>\n",
       "      <td>1.569018</td>\n",
       "      <td>-0.129039</td>\n",
       "      <td>-0.560663</td>\n",
       "      <td>-0.151458</td>\n",
       "      <td>0.392602</td>\n",
       "      <td>-1.219229</td>\n",
       "      <td>0.246292</td>\n",
       "      <td>-1.075527</td>\n",
       "      <td>0.637531</td>\n",
       "      <td>0.695340</td>\n",
       "      <td>0.643347</td>\n",
       "      <td>-0.232398</td>\n",
       "      <td>0.506610</td>\n",
       "      <td>0.323395</td>\n",
       "      <td>0.410212</td>\n",
       "      <td>0.508741</td>\n",
       "      <td>-1.738624</td>\n",
       "      <td>-0.066920</td>\n",
       "      <td>1.195792</td>\n",
       "      <td>-0.942897</td>\n",
       "      <td>0.280506</td>\n",
       "      <td>-1.369278</td>\n",
       "      <td>-2.476761</td>\n",
       "      <td>-0.089866</td>\n",
       "      <td>-0.258388</td>\n",
       "      <td>-1.021006</td>\n",
       "      <td>-0.985414</td>\n",
       "      <td>-0.908527</td>\n",
       "      <td>-2.107126</td>\n",
       "      <td>0.246224</td>\n",
       "      <td>-1.462594</td>\n",
       "      <td>0.743746</td>\n",
       "      <td>-1.582374</td>\n",
       "      <td>-0.581092</td>\n",
       "      <td>-0.275418</td>\n",
       "      <td>-0.199287</td>\n",
       "      <td>-0.565434</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510719</td>\n",
       "      <td>1.094353</td>\n",
       "      <td>-0.312019</td>\n",
       "      <td>1.809019</td>\n",
       "      <td>1.009801</td>\n",
       "      <td>1.107113</td>\n",
       "      <td>1.452863</td>\n",
       "      <td>-1.183948</td>\n",
       "      <td>-1.351732</td>\n",
       "      <td>-0.632658</td>\n",
       "      <td>2.320406</td>\n",
       "      <td>-0.657594</td>\n",
       "      <td>-0.788541</td>\n",
       "      <td>-0.860385</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>1.149802</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>-0.468541</td>\n",
       "      <td>-0.489200</td>\n",
       "      <td>-1.872676</td>\n",
       "      <td>0.180357</td>\n",
       "      <td>0.273141</td>\n",
       "      <td>-1.993020</td>\n",
       "      <td>0.049188</td>\n",
       "      <td>-1.010092</td>\n",
       "      <td>1.703399</td>\n",
       "      <td>-1.165383</td>\n",
       "      <td>-0.112122</td>\n",
       "      <td>-0.398553</td>\n",
       "      <td>-0.726536</td>\n",
       "      <td>-1.212188</td>\n",
       "      <td>2.841629</td>\n",
       "      <td>-0.105991</td>\n",
       "      <td>-0.145868</td>\n",
       "      <td>-0.722964</td>\n",
       "      <td>-1.367744</td>\n",
       "      <td>0.030395</td>\n",
       "      <td>-1.948798</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.679217</td>\n",
       "      <td>2.045087</td>\n",
       "      <td>0.103380</td>\n",
       "      <td>1.108289</td>\n",
       "      <td>-0.411600</td>\n",
       "      <td>-0.942090</td>\n",
       "      <td>2.187644</td>\n",
       "      <td>-0.324643</td>\n",
       "      <td>1.392549</td>\n",
       "      <td>-0.321902</td>\n",
       "      <td>-0.052057</td>\n",
       "      <td>1.136178</td>\n",
       "      <td>1.457374</td>\n",
       "      <td>-0.536954</td>\n",
       "      <td>-0.588722</td>\n",
       "      <td>-1.440589</td>\n",
       "      <td>-1.469241</td>\n",
       "      <td>0.638125</td>\n",
       "      <td>-0.340409</td>\n",
       "      <td>-0.064015</td>\n",
       "      <td>0.545242</td>\n",
       "      <td>0.811360</td>\n",
       "      <td>0.084726</td>\n",
       "      <td>0.258146</td>\n",
       "      <td>-1.781062</td>\n",
       "      <td>-1.056839</td>\n",
       "      <td>-0.975180</td>\n",
       "      <td>-1.002662</td>\n",
       "      <td>-0.159209</td>\n",
       "      <td>1.310240</td>\n",
       "      <td>-0.950637</td>\n",
       "      <td>-0.032809</td>\n",
       "      <td>0.632733</td>\n",
       "      <td>2.595023</td>\n",
       "      <td>-0.006785</td>\n",
       "      <td>-1.031726</td>\n",
       "      <td>-0.345705</td>\n",
       "      <td>0.965294</td>\n",
       "      <td>0.078679</td>\n",
       "      <td>-0.528294</td>\n",
       "      <td>1.018327</td>\n",
       "      <td>0.801014</td>\n",
       "      <td>0.615615</td>\n",
       "      <td>2.035532</td>\n",
       "      <td>0.295132</td>\n",
       "      <td>-1.341565</td>\n",
       "      <td>-0.121134</td>\n",
       "      <td>-0.853633</td>\n",
       "      <td>-0.522866</td>\n",
       "      <td>-0.266665</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>0.250623</td>\n",
       "      <td>-0.362570</td>\n",
       "      <td>2.455514</td>\n",
       "      <td>-0.225581</td>\n",
       "      <td>0.613545</td>\n",
       "      <td>-0.144236</td>\n",
       "      <td>0.364741</td>\n",
       "      <td>-0.102219</td>\n",
       "      <td>1.498351</td>\n",
       "      <td>1.582455</td>\n",
       "      <td>-0.073093</td>\n",
       "      <td>0.693403</td>\n",
       "      <td>0.545517</td>\n",
       "      <td>-0.011568</td>\n",
       "      <td>0.382596</td>\n",
       "      <td>0.024713</td>\n",
       "      <td>0.342891</td>\n",
       "      <td>-0.493010</td>\n",
       "      <td>-0.767378</td>\n",
       "      <td>-0.264932</td>\n",
       "      <td>-1.244099</td>\n",
       "      <td>0.659503</td>\n",
       "      <td>-1.116438</td>\n",
       "      <td>-2.777419</td>\n",
       "      <td>-1.382864</td>\n",
       "      <td>-0.079664</td>\n",
       "      <td>1.218063</td>\n",
       "      <td>-0.018562</td>\n",
       "      <td>0.290459</td>\n",
       "      <td>2.328414</td>\n",
       "      <td>-1.140065</td>\n",
       "      <td>-0.421382</td>\n",
       "      <td>0.542544</td>\n",
       "      <td>0.729046</td>\n",
       "      <td>-0.255848</td>\n",
       "      <td>-1.597689</td>\n",
       "      <td>-1.438327</td>\n",
       "      <td>-1.070850</td>\n",
       "      <td>1.295693</td>\n",
       "      <td>-0.322848</td>\n",
       "      <td>0.467980</td>\n",
       "      <td>-1.630519</td>\n",
       "      <td>0.362299</td>\n",
       "      <td>-1.829727</td>\n",
       "      <td>-0.049750</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.786981</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>0.556278</td>\n",
       "      <td>1.432921</td>\n",
       "      <td>-0.125289</td>\n",
       "      <td>0.254067</td>\n",
       "      <td>-0.899182</td>\n",
       "      <td>-0.643624</td>\n",
       "      <td>0.129099</td>\n",
       "      <td>-2.020672</td>\n",
       "      <td>-0.758809</td>\n",
       "      <td>0.801428</td>\n",
       "      <td>-0.057348</td>\n",
       "      <td>0.840487</td>\n",
       "      <td>-1.006796</td>\n",
       "      <td>1.294628</td>\n",
       "      <td>1.128410</td>\n",
       "      <td>-0.211495</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>-0.278235</td>\n",
       "      <td>-0.410908</td>\n",
       "      <td>0.995537</td>\n",
       "      <td>-0.264455</td>\n",
       "      <td>1.318431</td>\n",
       "      <td>-0.922838</td>\n",
       "      <td>-1.752446</td>\n",
       "      <td>0.629697</td>\n",
       "      <td>-0.624935</td>\n",
       "      <td>0.520414</td>\n",
       "      <td>-0.105977</td>\n",
       "      <td>-0.992316</td>\n",
       "      <td>-1.391645</td>\n",
       "      <td>-2.504333</td>\n",
       "      <td>-0.999463</td>\n",
       "      <td>-0.575555</td>\n",
       "      <td>0.558319</td>\n",
       "      <td>1.367056</td>\n",
       "      <td>0.888250</td>\n",
       "      <td>0.949284</td>\n",
       "      <td>1.216221</td>\n",
       "      <td>0.129446</td>\n",
       "      <td>0.245468</td>\n",
       "      <td>-0.739372</td>\n",
       "      <td>-1.073689</td>\n",
       "      <td>3.333682</td>\n",
       "      <td>-0.915415</td>\n",
       "      <td>0.881610</td>\n",
       "      <td>0.713859</td>\n",
       "      <td>0.188777</td>\n",
       "      <td>0.055720</td>\n",
       "      <td>0.394050</td>\n",
       "      <td>0.374828</td>\n",
       "      <td>-0.331970</td>\n",
       "      <td>-0.473752</td>\n",
       "      <td>-1.063790</td>\n",
       "      <td>-1.261188</td>\n",
       "      <td>0.072201</td>\n",
       "      <td>-0.507412</td>\n",
       "      <td>0.148635</td>\n",
       "      <td>-0.440169</td>\n",
       "      <td>1.462816</td>\n",
       "      <td>3.418368</td>\n",
       "      <td>2.446931</td>\n",
       "      <td>1.696236</td>\n",
       "      <td>0.051833</td>\n",
       "      <td>1.213113</td>\n",
       "      <td>0.237133</td>\n",
       "      <td>-3.107710</td>\n",
       "      <td>-1.135404</td>\n",
       "      <td>-0.264333</td>\n",
       "      <td>-0.276535</td>\n",
       "      <td>-0.571135</td>\n",
       "      <td>-0.079002</td>\n",
       "      <td>-0.362939</td>\n",
       "      <td>0.825123</td>\n",
       "      <td>1.090077</td>\n",
       "      <td>1.039350</td>\n",
       "      <td>-0.623722</td>\n",
       "      <td>-0.429034</td>\n",
       "      <td>-2.423597</td>\n",
       "      <td>-0.117343</td>\n",
       "      <td>-1.890957</td>\n",
       "      <td>-0.776062</td>\n",
       "      <td>-0.212388</td>\n",
       "      <td>-0.678314</td>\n",
       "      <td>-1.455035</td>\n",
       "      <td>-0.606048</td>\n",
       "      <td>-0.518129</td>\n",
       "      <td>2.232087</td>\n",
       "      <td>-0.637361</td>\n",
       "      <td>0.396228</td>\n",
       "      <td>-1.745177</td>\n",
       "      <td>-2.019543</td>\n",
       "      <td>-1.185806</td>\n",
       "      <td>0.627706</td>\n",
       "      <td>-0.829310</td>\n",
       "      <td>-2.066668</td>\n",
       "      <td>-0.560730</td>\n",
       "      <td>-0.870606</td>\n",
       "      <td>-0.129357</td>\n",
       "      <td>0.943334</td>\n",
       "      <td>0.423567</td>\n",
       "      <td>1.367944</td>\n",
       "      <td>0.238712</td>\n",
       "      <td>-0.667134</td>\n",
       "      <td>0.855728</td>\n",
       "      <td>-0.642287</td>\n",
       "      <td>-1.350425</td>\n",
       "      <td>0.503394</td>\n",
       "      <td>-1.226511</td>\n",
       "      <td>-2.523222</td>\n",
       "      <td>3.100036</td>\n",
       "      <td>-0.391463</td>\n",
       "      <td>-0.868081</td>\n",
       "      <td>0.422528</td>\n",
       "      <td>-0.091888</td>\n",
       "      <td>0.887138</td>\n",
       "      <td>0.740408</td>\n",
       "      <td>-0.144263</td>\n",
       "      <td>-0.108359</td>\n",
       "      <td>0.184635</td>\n",
       "      <td>0.246431</td>\n",
       "      <td>1.343121</td>\n",
       "      <td>0.906792</td>\n",
       "      <td>1.353308</td>\n",
       "      <td>0.896042</td>\n",
       "      <td>0.585909</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>-1.062490</td>\n",
       "      <td>-0.599636</td>\n",
       "      <td>0.861957</td>\n",
       "      <td>1.174883</td>\n",
       "      <td>1.385314</td>\n",
       "      <td>-0.397453</td>\n",
       "      <td>1.222594</td>\n",
       "      <td>-0.153292</td>\n",
       "      <td>0.187003</td>\n",
       "      <td>-0.195746</td>\n",
       "      <td>-0.173327</td>\n",
       "      <td>0.318237</td>\n",
       "      <td>2.844221</td>\n",
       "      <td>0.689832</td>\n",
       "      <td>-0.200927</td>\n",
       "      <td>1.115533</td>\n",
       "      <td>-0.690205</td>\n",
       "      <td>0.542467</td>\n",
       "      <td>1.670203</td>\n",
       "      <td>1.717060</td>\n",
       "      <td>-0.613563</td>\n",
       "      <td>0.429645</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.697685</td>\n",
       "      <td>0.704049</td>\n",
       "      <td>0.554411</td>\n",
       "      <td>0.448917</td>\n",
       "      <td>-1.902668</td>\n",
       "      <td>1.308618</td>\n",
       "      <td>0.306972</td>\n",
       "      <td>-2.710452</td>\n",
       "      <td>-0.282768</td>\n",
       "      <td>-1.078391</td>\n",
       "      <td>-2.305940</td>\n",
       "      <td>-1.600594</td>\n",
       "      <td>-1.731676</td>\n",
       "      <td>-0.301404</td>\n",
       "      <td>-0.618785</td>\n",
       "      <td>-0.041467</td>\n",
       "      <td>1.388373</td>\n",
       "      <td>1.433303</td>\n",
       "      <td>0.777011</td>\n",
       "      <td>0.140366</td>\n",
       "      <td>-0.864691</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>-0.912220</td>\n",
       "      <td>2.515892</td>\n",
       "      <td>-0.855892</td>\n",
       "      <td>-1.174183</td>\n",
       "      <td>-0.383733</td>\n",
       "      <td>1.413228</td>\n",
       "      <td>0.852916</td>\n",
       "      <td>-0.254989</td>\n",
       "      <td>-0.439240</td>\n",
       "      <td>-1.172149</td>\n",
       "      <td>-1.299892</td>\n",
       "      <td>-0.547645</td>\n",
       "      <td>0.068234</td>\n",
       "      <td>-1.260249</td>\n",
       "      <td>0.654034</td>\n",
       "      <td>-0.423167</td>\n",
       "      <td>1.378487</td>\n",
       "      <td>-1.153424</td>\n",
       "      <td>0.563668</td>\n",
       "      <td>0.231357</td>\n",
       "      <td>-0.500062</td>\n",
       "      <td>-0.926818</td>\n",
       "      <td>2.623153</td>\n",
       "      <td>-0.533925</td>\n",
       "      <td>-0.553560</td>\n",
       "      <td>-0.958643</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>-0.428116</td>\n",
       "      <td>-1.606346</td>\n",
       "      <td>-0.307749</td>\n",
       "      <td>0.804638</td>\n",
       "      <td>1.459078</td>\n",
       "      <td>-0.203143</td>\n",
       "      <td>1.378065</td>\n",
       "      <td>-0.354104</td>\n",
       "      <td>-1.600053</td>\n",
       "      <td>2.236578</td>\n",
       "      <td>-0.865636</td>\n",
       "      <td>0.662507</td>\n",
       "      <td>-0.137847</td>\n",
       "      <td>-0.431881</td>\n",
       "      <td>0.880899</td>\n",
       "      <td>2.161585</td>\n",
       "      <td>-1.049529</td>\n",
       "      <td>-0.267008</td>\n",
       "      <td>-1.858983</td>\n",
       "      <td>-0.767006</td>\n",
       "      <td>-0.417913</td>\n",
       "      <td>-0.353847</td>\n",
       "      <td>-0.970043</td>\n",
       "      <td>0.479652</td>\n",
       "      <td>1.547971</td>\n",
       "      <td>-0.403366</td>\n",
       "      <td>0.406378</td>\n",
       "      <td>-0.691514</td>\n",
       "      <td>-0.938161</td>\n",
       "      <td>-0.909334</td>\n",
       "      <td>-1.421630</td>\n",
       "      <td>0.366591</td>\n",
       "      <td>1.600454</td>\n",
       "      <td>-0.558606</td>\n",
       "      <td>-0.423601</td>\n",
       "      <td>1.079119</td>\n",
       "      <td>2.141309</td>\n",
       "      <td>-0.796653</td>\n",
       "      <td>-1.205870</td>\n",
       "      <td>-0.655096</td>\n",
       "      <td>0.140854</td>\n",
       "      <td>-0.864112</td>\n",
       "      <td>0.146486</td>\n",
       "      <td>0.423738</td>\n",
       "      <td>0.457416</td>\n",
       "      <td>0.384942</td>\n",
       "      <td>2.122979</td>\n",
       "      <td>-0.814370</td>\n",
       "      <td>-1.643274</td>\n",
       "      <td>-1.155211</td>\n",
       "      <td>-0.916929</td>\n",
       "      <td>-0.860115</td>\n",
       "      <td>0.415502</td>\n",
       "      <td>-0.087669</td>\n",
       "      <td>-0.243177</td>\n",
       "      <td>-0.492062</td>\n",
       "      <td>2.479289</td>\n",
       "      <td>-0.251501</td>\n",
       "      <td>-0.477305</td>\n",
       "      <td>-0.289557</td>\n",
       "      <td>0.404947</td>\n",
       "      <td>-0.156275</td>\n",
       "      <td>0.627674</td>\n",
       "      <td>0.782390</td>\n",
       "      <td>-0.124779</td>\n",
       "      <td>1.138594</td>\n",
       "      <td>1.362796</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.556024</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>-0.151986</td>\n",
       "      <td>-1.407888</td>\n",
       "      <td>-0.475213</td>\n",
       "      <td>0.234022</td>\n",
       "      <td>-1.487771</td>\n",
       "      <td>0.538155</td>\n",
       "      <td>-1.581122</td>\n",
       "      <td>-2.204580</td>\n",
       "      <td>-1.129102</td>\n",
       "      <td>0.693692</td>\n",
       "      <td>1.455942</td>\n",
       "      <td>0.050325</td>\n",
       "      <td>-0.381196</td>\n",
       "      <td>2.290702</td>\n",
       "      <td>-0.033701</td>\n",
       "      <td>-1.097867</td>\n",
       "      <td>-0.199315</td>\n",
       "      <td>0.151029</td>\n",
       "      <td>-0.965072</td>\n",
       "      <td>-1.626675</td>\n",
       "      <td>-0.737451</td>\n",
       "      <td>-1.198711</td>\n",
       "      <td>1.369650</td>\n",
       "      <td>-1.320638</td>\n",
       "      <td>-0.178111</td>\n",
       "      <td>-1.604276</td>\n",
       "      <td>-0.024628</td>\n",
       "      <td>-1.164171</td>\n",
       "      <td>-0.367747</td>\n",
       "      <td>-0.588743</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.216875</td>\n",
       "      <td>0.929240</td>\n",
       "      <td>1.306337</td>\n",
       "      <td>-0.022692</td>\n",
       "      <td>0.474577</td>\n",
       "      <td>-1.346977</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>0.422193</td>\n",
       "      <td>-0.723892</td>\n",
       "      <td>0.145597</td>\n",
       "      <td>0.420691</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>-0.755186</td>\n",
       "      <td>0.340293</td>\n",
       "      <td>0.700933</td>\n",
       "      <td>-0.811333</td>\n",
       "      <td>1.016883</td>\n",
       "      <td>-0.285441</td>\n",
       "      <td>0.082713</td>\n",
       "      <td>0.760238</td>\n",
       "      <td>0.408371</td>\n",
       "      <td>0.824966</td>\n",
       "      <td>-0.053113</td>\n",
       "      <td>-1.661701</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.067356</td>\n",
       "      <td>0.241603</td>\n",
       "      <td>-0.341178</td>\n",
       "      <td>-1.682661</td>\n",
       "      <td>-1.593771</td>\n",
       "      <td>-2.801984</td>\n",
       "      <td>-0.249685</td>\n",
       "      <td>-1.072054</td>\n",
       "      <td>0.261871</td>\n",
       "      <td>1.318973</td>\n",
       "      <td>1.124013</td>\n",
       "      <td>1.274171</td>\n",
       "      <td>-0.239723</td>\n",
       "      <td>1.611977</td>\n",
       "      <td>0.722854</td>\n",
       "      <td>-0.540485</td>\n",
       "      <td>-0.842954</td>\n",
       "      <td>2.697070</td>\n",
       "      <td>-1.563581</td>\n",
       "      <td>0.423657</td>\n",
       "      <td>1.159921</td>\n",
       "      <td>1.513039</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.490161</td>\n",
       "      <td>1.272885</td>\n",
       "      <td>0.945118</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>-1.538679</td>\n",
       "      <td>-0.958572</td>\n",
       "      <td>0.292473</td>\n",
       "      <td>-0.434004</td>\n",
       "      <td>0.259849</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>2.489027</td>\n",
       "      <td>3.647330</td>\n",
       "      <td>2.698886</td>\n",
       "      <td>2.188395</td>\n",
       "      <td>-0.165130</td>\n",
       "      <td>0.603447</td>\n",
       "      <td>-0.296857</td>\n",
       "      <td>-2.968631</td>\n",
       "      <td>-0.298460</td>\n",
       "      <td>-0.458311</td>\n",
       "      <td>0.114466</td>\n",
       "      <td>-0.506006</td>\n",
       "      <td>0.422122</td>\n",
       "      <td>0.389833</td>\n",
       "      <td>0.264970</td>\n",
       "      <td>2.232056</td>\n",
       "      <td>0.317945</td>\n",
       "      <td>-0.736926</td>\n",
       "      <td>-0.543927</td>\n",
       "      <td>-2.914152</td>\n",
       "      <td>0.086918</td>\n",
       "      <td>-2.197926</td>\n",
       "      <td>-0.754403</td>\n",
       "      <td>-0.265569</td>\n",
       "      <td>-0.758413</td>\n",
       "      <td>-0.866742</td>\n",
       "      <td>-0.887874</td>\n",
       "      <td>-1.059580</td>\n",
       "      <td>2.660915</td>\n",
       "      <td>0.222031</td>\n",
       "      <td>-0.318154</td>\n",
       "      <td>-1.519767</td>\n",
       "      <td>-1.998313</td>\n",
       "      <td>-0.659891</td>\n",
       "      <td>0.443073</td>\n",
       "      <td>-1.425315</td>\n",
       "      <td>-2.265424</td>\n",
       "      <td>-0.574146</td>\n",
       "      <td>-1.072758</td>\n",
       "      <td>0.152303</td>\n",
       "      <td>1.298401</td>\n",
       "      <td>0.033426</td>\n",
       "      <td>0.798501</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>-0.435261</td>\n",
       "      <td>0.994211</td>\n",
       "      <td>0.085728</td>\n",
       "      <td>-1.916516</td>\n",
       "      <td>0.227499</td>\n",
       "      <td>-0.295370</td>\n",
       "      <td>-1.805540</td>\n",
       "      <td>3.262731</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>-0.646414</td>\n",
       "      <td>-0.235491</td>\n",
       "      <td>0.517444</td>\n",
       "      <td>1.124515</td>\n",
       "      <td>1.563672</td>\n",
       "      <td>-0.597002</td>\n",
       "      <td>-0.411254</td>\n",
       "      <td>0.068529</td>\n",
       "      <td>0.490166</td>\n",
       "      <td>1.146550</td>\n",
       "      <td>0.890290</td>\n",
       "      <td>0.656563</td>\n",
       "      <td>1.371729</td>\n",
       "      <td>1.374916</td>\n",
       "      <td>0.424188</td>\n",
       "      <td>-0.072711</td>\n",
       "      <td>-0.660392</td>\n",
       "      <td>1.144875</td>\n",
       "      <td>1.710621</td>\n",
       "      <td>0.801851</td>\n",
       "      <td>-0.101921</td>\n",
       "      <td>1.722850</td>\n",
       "      <td>-0.726182</td>\n",
       "      <td>0.468370</td>\n",
       "      <td>-0.137550</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.074941</td>\n",
       "      <td>3.045187</td>\n",
       "      <td>0.978225</td>\n",
       "      <td>-0.741544</td>\n",
       "      <td>1.734488</td>\n",
       "      <td>-0.922457</td>\n",
       "      <td>1.059719</td>\n",
       "      <td>0.847862</td>\n",
       "      <td>1.404117</td>\n",
       "      <td>-0.612160</td>\n",
       "      <td>-0.312050</td>\n",
       "      <td>-0.369391</td>\n",
       "      <td>0.988463</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>0.657401</td>\n",
       "      <td>0.670294</td>\n",
       "      <td>-1.673217</td>\n",
       "      <td>0.598089</td>\n",
       "      <td>-0.501381</td>\n",
       "      <td>-2.380531</td>\n",
       "      <td>-0.813756</td>\n",
       "      <td>-1.434926</td>\n",
       "      <td>-1.844910</td>\n",
       "      <td>-0.960422</td>\n",
       "      <td>-1.813581</td>\n",
       "      <td>-0.370514</td>\n",
       "      <td>-0.517408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859748</td>\n",
       "      <td>0.859748</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4062.418611</td>\n",
       "      <td>0.873030</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3735.737037</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>-0.599347</td>\n",
       "      <td>0.291509</td>\n",
       "      <td>0.891327</td>\n",
       "      <td>-0.452046</td>\n",
       "      <td>-0.364742</td>\n",
       "      <td>-0.905138</td>\n",
       "      <td>-1.057678</td>\n",
       "      <td>-0.762324</td>\n",
       "      <td>0.469060</td>\n",
       "      <td>1.518425</td>\n",
       "      <td>-1.115048</td>\n",
       "      <td>-1.029767</td>\n",
       "      <td>0.995560</td>\n",
       "      <td>0.086230</td>\n",
       "      <td>-0.456640</td>\n",
       "      <td>-0.119099</td>\n",
       "      <td>0.335472</td>\n",
       "      <td>-0.463306</td>\n",
       "      <td>0.228852</td>\n",
       "      <td>0.896316</td>\n",
       "      <td>1.487407</td>\n",
       "      <td>0.361845</td>\n",
       "      <td>1.000504</td>\n",
       "      <td>-0.436321</td>\n",
       "      <td>-0.742161</td>\n",
       "      <td>0.066231</td>\n",
       "      <td>-0.362446</td>\n",
       "      <td>-0.307655</td>\n",
       "      <td>0.309673</td>\n",
       "      <td>0.346564</td>\n",
       "      <td>0.559064</td>\n",
       "      <td>0.265252</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>-0.304625</td>\n",
       "      <td>-0.391085</td>\n",
       "      <td>0.369321</td>\n",
       "      <td>-0.004250</td>\n",
       "      <td>-0.575777</td>\n",
       "      <td>-0.039055</td>\n",
       "      <td>0.440368</td>\n",
       "      <td>0.248530</td>\n",
       "      <td>0.191769</td>\n",
       "      <td>-0.528783</td>\n",
       "      <td>0.270046</td>\n",
       "      <td>-0.515687</td>\n",
       "      <td>-0.171994</td>\n",
       "      <td>-0.282391</td>\n",
       "      <td>-0.900829</td>\n",
       "      <td>-0.376512</td>\n",
       "      <td>0.126440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.605239</td>\n",
       "      <td>-0.605239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819467</td>\n",
       "      <td>0.330803</td>\n",
       "      <td>-1.036967</td>\n",
       "      <td>-0.339240</td>\n",
       "      <td>2.175442</td>\n",
       "      <td>0.289644</td>\n",
       "      <td>0.144783</td>\n",
       "      <td>1.308984</td>\n",
       "      <td>0.804418</td>\n",
       "      <td>-0.413863</td>\n",
       "      <td>1.164383</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>-0.043738</td>\n",
       "      <td>-0.734228</td>\n",
       "      <td>-1.982793</td>\n",
       "      <td>-0.415779</td>\n",
       "      <td>-0.895637</td>\n",
       "      <td>-0.907366</td>\n",
       "      <td>2.219420</td>\n",
       "      <td>0.995263</td>\n",
       "      <td>-0.642637</td>\n",
       "      <td>-1.654480</td>\n",
       "      <td>-3.077215</td>\n",
       "      <td>1.530508</td>\n",
       "      <td>0.164108</td>\n",
       "      <td>-0.895104</td>\n",
       "      <td>0.736261</td>\n",
       "      <td>0.850008</td>\n",
       "      <td>0.595061</td>\n",
       "      <td>-2.257333</td>\n",
       "      <td>-1.520728</td>\n",
       "      <td>0.275320</td>\n",
       "      <td>-0.572879</td>\n",
       "      <td>-0.528718</td>\n",
       "      <td>-0.796492</td>\n",
       "      <td>-1.740853</td>\n",
       "      <td>-0.968844</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>-1.791443</td>\n",
       "      <td>-0.617944</td>\n",
       "      <td>0.448155</td>\n",
       "      <td>-0.308155</td>\n",
       "      <td>-0.808820</td>\n",
       "      <td>-1.424160</td>\n",
       "      <td>0.870526</td>\n",
       "      <td>-0.094931</td>\n",
       "      <td>-1.583877</td>\n",
       "      <td>-0.613265</td>\n",
       "      <td>2.211515</td>\n",
       "      <td>-1.347715</td>\n",
       "      <td>-0.734069</td>\n",
       "      <td>1.284942</td>\n",
       "      <td>-0.714206</td>\n",
       "      <td>-0.846094</td>\n",
       "      <td>-0.273410</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>-0.268027</td>\n",
       "      <td>0.322494</td>\n",
       "      <td>0.212969</td>\n",
       "      <td>-0.038949</td>\n",
       "      <td>2.667067</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>-0.058786</td>\n",
       "      <td>0.685202</td>\n",
       "      <td>-1.647806</td>\n",
       "      <td>0.171919</td>\n",
       "      <td>-0.373607</td>\n",
       "      <td>-0.603068</td>\n",
       "      <td>-0.934357</td>\n",
       "      <td>1.361805</td>\n",
       "      <td>-0.734280</td>\n",
       "      <td>-0.204837</td>\n",
       "      <td>-0.417016</td>\n",
       "      <td>0.671381</td>\n",
       "      <td>-1.078292</td>\n",
       "      <td>-0.904728</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>-0.530033</td>\n",
       "      <td>2.021051</td>\n",
       "      <td>1.031225</td>\n",
       "      <td>0.403782</td>\n",
       "      <td>0.617619</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>1.377703</td>\n",
       "      <td>-0.907499</td>\n",
       "      <td>1.511212</td>\n",
       "      <td>-0.305179</td>\n",
       "      <td>0.703376</td>\n",
       "      <td>2.182323</td>\n",
       "      <td>0.572354</td>\n",
       "      <td>0.392887</td>\n",
       "      <td>0.493605</td>\n",
       "      <td>0.594619</td>\n",
       "      <td>-0.480529</td>\n",
       "      <td>-0.336430</td>\n",
       "      <td>0.637393</td>\n",
       "      <td>0.217214</td>\n",
       "      <td>-0.556516</td>\n",
       "      <td>0.761182</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.354182</td>\n",
       "      <td>1.245085</td>\n",
       "      <td>-0.404319</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>-0.558079</td>\n",
       "      <td>-0.700018</td>\n",
       "      <td>-1.477893</td>\n",
       "      <td>-0.294654</td>\n",
       "      <td>0.627229</td>\n",
       "      <td>0.642513</td>\n",
       "      <td>-0.162928</td>\n",
       "      <td>0.554091</td>\n",
       "      <td>-0.147193</td>\n",
       "      <td>0.376622</td>\n",
       "      <td>-1.478061</td>\n",
       "      <td>0.718518</td>\n",
       "      <td>0.356444</td>\n",
       "      <td>1.247978</td>\n",
       "      <td>0.685547</td>\n",
       "      <td>-0.321107</td>\n",
       "      <td>0.864315</td>\n",
       "      <td>0.366150</td>\n",
       "      <td>0.830132</td>\n",
       "      <td>-1.083764</td>\n",
       "      <td>-0.893724</td>\n",
       "      <td>-0.387184</td>\n",
       "      <td>0.546351</td>\n",
       "      <td>0.164963</td>\n",
       "      <td>-0.880032</td>\n",
       "      <td>-0.793657</td>\n",
       "      <td>-0.920289</td>\n",
       "      <td>-1.349705</td>\n",
       "      <td>0.629840</td>\n",
       "      <td>1.418349</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>-0.720336</td>\n",
       "      <td>0.626807</td>\n",
       "      <td>0.184249</td>\n",
       "      <td>-2.255575</td>\n",
       "      <td>0.586541</td>\n",
       "      <td>0.697202</td>\n",
       "      <td>2.135226</td>\n",
       "      <td>-0.391511</td>\n",
       "      <td>-0.198696</td>\n",
       "      <td>-0.484061</td>\n",
       "      <td>-0.751352</td>\n",
       "      <td>0.578739</td>\n",
       "      <td>0.083347</td>\n",
       "      <td>-1.743041</td>\n",
       "      <td>0.204799</td>\n",
       "      <td>-0.799315</td>\n",
       "      <td>-0.202736</td>\n",
       "      <td>-0.970448</td>\n",
       "      <td>-0.775741</td>\n",
       "      <td>1.823041</td>\n",
       "      <td>0.884970</td>\n",
       "      <td>-0.221103</td>\n",
       "      <td>-1.069471</td>\n",
       "      <td>1.481746</td>\n",
       "      <td>-0.965789</td>\n",
       "      <td>0.287672</td>\n",
       "      <td>1.315301</td>\n",
       "      <td>1.298957</td>\n",
       "      <td>-0.389352</td>\n",
       "      <td>-0.337766</td>\n",
       "      <td>-1.549889</td>\n",
       "      <td>-0.419583</td>\n",
       "      <td>-0.808692</td>\n",
       "      <td>-1.139919</td>\n",
       "      <td>-1.052158</td>\n",
       "      <td>0.228460</td>\n",
       "      <td>-0.897440</td>\n",
       "      <td>-0.936589</td>\n",
       "      <td>-1.261927</td>\n",
       "      <td>0.493772</td>\n",
       "      <td>-0.211824</td>\n",
       "      <td>0.666508</td>\n",
       "      <td>-0.973221</td>\n",
       "      <td>-2.352049</td>\n",
       "      <td>-0.472930</td>\n",
       "      <td>-2.088445</td>\n",
       "      <td>1.453805</td>\n",
       "      <td>1.905972</td>\n",
       "      <td>0.134254</td>\n",
       "      <td>0.927951</td>\n",
       "      <td>-2.152600</td>\n",
       "      <td>0.917679</td>\n",
       "      <td>-1.093427</td>\n",
       "      <td>-2.033931</td>\n",
       "      <td>-0.490332</td>\n",
       "      <td>0.982181</td>\n",
       "      <td>0.114844</td>\n",
       "      <td>0.479742</td>\n",
       "      <td>0.265104</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>1.337529</td>\n",
       "      <td>-0.557033</td>\n",
       "      <td>-0.405437</td>\n",
       "      <td>0.571190</td>\n",
       "      <td>0.682782</td>\n",
       "      <td>-0.358157</td>\n",
       "      <td>0.876576</td>\n",
       "      <td>-0.238264</td>\n",
       "      <td>0.204925</td>\n",
       "      <td>0.121197</td>\n",
       "      <td>-0.810561</td>\n",
       "      <td>-0.954611</td>\n",
       "      <td>-1.285289</td>\n",
       "      <td>-1.132923</td>\n",
       "      <td>0.274064</td>\n",
       "      <td>-0.817277</td>\n",
       "      <td>-0.257297</td>\n",
       "      <td>-1.342353</td>\n",
       "      <td>0.049238</td>\n",
       "      <td>-0.472411</td>\n",
       "      <td>0.185282</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>-0.506570</td>\n",
       "      <td>-0.061578</td>\n",
       "      <td>0.087854</td>\n",
       "      <td>0.915890</td>\n",
       "      <td>-0.697742</td>\n",
       "      <td>1.314842</td>\n",
       "      <td>-0.249932</td>\n",
       "      <td>-0.218442</td>\n",
       "      <td>-1.503723</td>\n",
       "      <td>0.939925</td>\n",
       "      <td>-0.006544</td>\n",
       "      <td>0.748876</td>\n",
       "      <td>1.356459</td>\n",
       "      <td>0.102613</td>\n",
       "      <td>-0.277292</td>\n",
       "      <td>-0.556315</td>\n",
       "      <td>-0.615303</td>\n",
       "      <td>0.520751</td>\n",
       "      <td>2.155388</td>\n",
       "      <td>0.074356</td>\n",
       "      <td>-0.029390</td>\n",
       "      <td>-0.541897</td>\n",
       "      <td>-0.792718</td>\n",
       "      <td>-0.938633</td>\n",
       "      <td>0.188063</td>\n",
       "      <td>0.571190</td>\n",
       "      <td>-0.577383</td>\n",
       "      <td>-0.138990</td>\n",
       "      <td>-1.250142</td>\n",
       "      <td>-0.044088</td>\n",
       "      <td>-0.990438</td>\n",
       "      <td>-1.072802</td>\n",
       "      <td>-1.818917</td>\n",
       "      <td>0.928800</td>\n",
       "      <td>-0.257523</td>\n",
       "      <td>-1.724678</td>\n",
       "      <td>2.525503</td>\n",
       "      <td>-0.689312</td>\n",
       "      <td>-0.716477</td>\n",
       "      <td>-0.149750</td>\n",
       "      <td>-0.008334</td>\n",
       "      <td>-0.102597</td>\n",
       "      <td>-1.726208</td>\n",
       "      <td>0.067183</td>\n",
       "      <td>-0.748452</td>\n",
       "      <td>0.484706</td>\n",
       "      <td>-0.325678</td>\n",
       "      <td>-0.578324</td>\n",
       "      <td>0.740673</td>\n",
       "      <td>2.387250</td>\n",
       "      <td>-0.227316</td>\n",
       "      <td>0.227056</td>\n",
       "      <td>0.988796</td>\n",
       "      <td>-0.347031</td>\n",
       "      <td>0.181107</td>\n",
       "      <td>-0.839675</td>\n",
       "      <td>1.557306</td>\n",
       "      <td>-0.508544</td>\n",
       "      <td>2.164569</td>\n",
       "      <td>-1.109170</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.482996</td>\n",
       "      <td>-0.868239</td>\n",
       "      <td>-0.539690</td>\n",
       "      <td>-0.880146</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-1.477497</td>\n",
       "      <td>0.919313</td>\n",
       "      <td>-0.060237</td>\n",
       "      <td>1.041878</td>\n",
       "      <td>-1.308110</td>\n",
       "      <td>-0.165086</td>\n",
       "      <td>-0.693327</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>1.530379</td>\n",
       "      <td>-0.401217</td>\n",
       "      <td>0.480855</td>\n",
       "      <td>-0.636019</td>\n",
       "      <td>1.248863</td>\n",
       "      <td>-0.172627</td>\n",
       "      <td>-0.346142</td>\n",
       "      <td>-1.785206</td>\n",
       "      <td>-0.848510</td>\n",
       "      <td>0.272208</td>\n",
       "      <td>0.042337</td>\n",
       "      <td>-0.209815</td>\n",
       "      <td>-0.217377</td>\n",
       "      <td>-1.132545</td>\n",
       "      <td>0.123129</td>\n",
       "      <td>1.309486</td>\n",
       "      <td>-0.047297</td>\n",
       "      <td>-0.884290</td>\n",
       "      <td>0.570448</td>\n",
       "      <td>-1.916283</td>\n",
       "      <td>0.867504</td>\n",
       "      <td>1.589157</td>\n",
       "      <td>-0.525725</td>\n",
       "      <td>-0.784453</td>\n",
       "      <td>0.086689</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>-0.240026</td>\n",
       "      <td>1.796550</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>-1.391895</td>\n",
       "      <td>1.191840</td>\n",
       "      <td>0.219449</td>\n",
       "      <td>-0.141133</td>\n",
       "      <td>0.739154</td>\n",
       "      <td>0.084006</td>\n",
       "      <td>0.423434</td>\n",
       "      <td>0.604698</td>\n",
       "      <td>1.118998</td>\n",
       "      <td>-1.363806</td>\n",
       "      <td>-0.531565</td>\n",
       "      <td>-1.508123</td>\n",
       "      <td>0.463599</td>\n",
       "      <td>-0.020091</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-1.262085</td>\n",
       "      <td>1.680026</td>\n",
       "      <td>-1.086741</td>\n",
       "      <td>0.209841</td>\n",
       "      <td>0.572442</td>\n",
       "      <td>-1.069968</td>\n",
       "      <td>1.074539</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>1.111427</td>\n",
       "      <td>0.553215</td>\n",
       "      <td>0.212641</td>\n",
       "      <td>-0.043222</td>\n",
       "      <td>1.003507</td>\n",
       "      <td>-0.834806</td>\n",
       "      <td>1.035909</td>\n",
       "      <td>1.222001</td>\n",
       "      <td>0.293826</td>\n",
       "      <td>1.439900</td>\n",
       "      <td>0.203877</td>\n",
       "      <td>0.853915</td>\n",
       "      <td>0.433642</td>\n",
       "      <td>-1.145680</td>\n",
       "      <td>3.196986</td>\n",
       "      <td>1.202695</td>\n",
       "      <td>-2.072165</td>\n",
       "      <td>0.904956</td>\n",
       "      <td>0.331675</td>\n",
       "      <td>-0.844193</td>\n",
       "      <td>0.473184</td>\n",
       "      <td>1.750913</td>\n",
       "      <td>0.661052</td>\n",
       "      <td>0.725755</td>\n",
       "      <td>0.424379</td>\n",
       "      <td>-1.115300</td>\n",
       "      <td>-0.138423</td>\n",
       "      <td>-0.002756</td>\n",
       "      <td>0.157621</td>\n",
       "      <td>0.374635</td>\n",
       "      <td>-0.402657</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>-1.306412</td>\n",
       "      <td>0.140663</td>\n",
       "      <td>-1.524950</td>\n",
       "      <td>-1.288148</td>\n",
       "      <td>-1.287174</td>\n",
       "      <td>-0.259746</td>\n",
       "      <td>-0.622368</td>\n",
       "      <td>0.939121</td>\n",
       "      <td>-0.485930</td>\n",
       "      <td>-3.007541</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.160314</td>\n",
       "      <td>-1.038253</td>\n",
       "      <td>0.272730</td>\n",
       "      <td>1.381904</td>\n",
       "      <td>1.358055</td>\n",
       "      <td>3.323599</td>\n",
       "      <td>1.351659</td>\n",
       "      <td>1.919174</td>\n",
       "      <td>1.239821</td>\n",
       "      <td>0.613619</td>\n",
       "      <td>0.943296</td>\n",
       "      <td>0.478014</td>\n",
       "      <td>-0.261993</td>\n",
       "      <td>1.681605</td>\n",
       "      <td>-1.424684</td>\n",
       "      <td>-0.912467</td>\n",
       "      <td>-0.396006</td>\n",
       "      <td>-0.177310</td>\n",
       "      <td>-0.492794</td>\n",
       "      <td>-1.582802</td>\n",
       "      <td>1.118340</td>\n",
       "      <td>-0.508731</td>\n",
       "      <td>-0.453288</td>\n",
       "      <td>-0.502404</td>\n",
       "      <td>-0.527122</td>\n",
       "      <td>-0.590293</td>\n",
       "      <td>-0.411418</td>\n",
       "      <td>0.442320</td>\n",
       "      <td>0.521634</td>\n",
       "      <td>-0.301809</td>\n",
       "      <td>1.740962</td>\n",
       "      <td>-1.051555</td>\n",
       "      <td>-0.518726</td>\n",
       "      <td>1.660539</td>\n",
       "      <td>0.936958</td>\n",
       "      <td>0.257436</td>\n",
       "      <td>-1.477411</td>\n",
       "      <td>-0.588826</td>\n",
       "      <td>-0.382202</td>\n",
       "      <td>-0.416234</td>\n",
       "      <td>1.008025</td>\n",
       "      <td>-1.375485</td>\n",
       "      <td>0.909629</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.089157</td>\n",
       "      <td>-1.853798</td>\n",
       "      <td>-1.038188</td>\n",
       "      <td>-0.164796</td>\n",
       "      <td>-1.139340</td>\n",
       "      <td>0.100946</td>\n",
       "      <td>-0.400948</td>\n",
       "      <td>-1.248121</td>\n",
       "      <td>-2.055430</td>\n",
       "      <td>0.231581</td>\n",
       "      <td>-0.771794</td>\n",
       "      <td>0.756095</td>\n",
       "      <td>-0.253487</td>\n",
       "      <td>-1.379638</td>\n",
       "      <td>0.581856</td>\n",
       "      <td>2.187511</td>\n",
       "      <td>1.895891</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.430093</td>\n",
       "      <td>0.302575</td>\n",
       "      <td>0.348330</td>\n",
       "      <td>-1.890432</td>\n",
       "      <td>-0.187185</td>\n",
       "      <td>-0.412855</td>\n",
       "      <td>0.690796</td>\n",
       "      <td>-1.680816</td>\n",
       "      <td>-1.467388</td>\n",
       "      <td>1.287025</td>\n",
       "      <td>0.983148</td>\n",
       "      <td>-1.228409</td>\n",
       "      <td>-0.416436</td>\n",
       "      <td>-1.513315</td>\n",
       "      <td>-1.700213</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>-1.682862</td>\n",
       "      <td>1.315415</td>\n",
       "      <td>0.459968</td>\n",
       "      <td>-0.860687</td>\n",
       "      <td>1.114685</td>\n",
       "      <td>-0.318541</td>\n",
       "      <td>-0.676480</td>\n",
       "      <td>-0.614642</td>\n",
       "      <td>1.028749</td>\n",
       "      <td>-0.129637</td>\n",
       "      <td>0.357023</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.290544</td>\n",
       "      <td>0.541237</td>\n",
       "      <td>-0.679540</td>\n",
       "      <td>2.052404</td>\n",
       "      <td>0.604984</td>\n",
       "      <td>-0.050366</td>\n",
       "      <td>-1.340168</td>\n",
       "      <td>1.629408</td>\n",
       "      <td>0.168874</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.182089</td>\n",
       "      <td>0.318462</td>\n",
       "      <td>-1.112054</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>1.999570</td>\n",
       "      <td>1.081604</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>1.078398</td>\n",
       "      <td>-0.179065</td>\n",
       "      <td>-0.468040</td>\n",
       "      <td>-0.259917</td>\n",
       "      <td>-2.818806</td>\n",
       "      <td>0.613847</td>\n",
       "      <td>0.220184</td>\n",
       "      <td>0.965255</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.179985</td>\n",
       "      <td>0.842887</td>\n",
       "      <td>-1.162737</td>\n",
       "      <td>-0.175657</td>\n",
       "      <td>-0.856963</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>-0.256250</td>\n",
       "      <td>0.294449</td>\n",
       "      <td>-0.046434</td>\n",
       "      <td>-0.112443</td>\n",
       "      <td>0.156580</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>-0.613286</td>\n",
       "      <td>0.424840</td>\n",
       "      <td>0.752702</td>\n",
       "      <td>-1.194433</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>1.994057</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.413713</td>\n",
       "      <td>0.292042</td>\n",
       "      <td>-0.335081</td>\n",
       "      <td>0.484873</td>\n",
       "      <td>-0.329836</td>\n",
       "      <td>1.119952</td>\n",
       "      <td>1.081773</td>\n",
       "      <td>-1.742862</td>\n",
       "      <td>1.042681</td>\n",
       "      <td>0.536760</td>\n",
       "      <td>0.906130</td>\n",
       "      <td>-0.273998</td>\n",
       "      <td>1.092537</td>\n",
       "      <td>-1.301619</td>\n",
       "      <td>0.908740</td>\n",
       "      <td>1.389195</td>\n",
       "      <td>-0.782242</td>\n",
       "      <td>0.122848</td>\n",
       "      <td>0.807822</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.739058</td>\n",
       "      <td>-1.579089</td>\n",
       "      <td>0.348236</td>\n",
       "      <td>-0.493016</td>\n",
       "      <td>0.575670</td>\n",
       "      <td>-2.703362</td>\n",
       "      <td>2.546202</td>\n",
       "      <td>0.504383</td>\n",
       "      <td>0.278097</td>\n",
       "      <td>-0.760029</td>\n",
       "      <td>-0.443575</td>\n",
       "      <td>-2.825268</td>\n",
       "      <td>1.357040</td>\n",
       "      <td>0.697337</td>\n",
       "      <td>-0.225871</td>\n",
       "      <td>-0.159475</td>\n",
       "      <td>0.183501</td>\n",
       "      <td>0.505265</td>\n",
       "      <td>1.094177</td>\n",
       "      <td>-1.112240</td>\n",
       "      <td>1.591243</td>\n",
       "      <td>-0.018674</td>\n",
       "      <td>-1.651850</td>\n",
       "      <td>-0.163068</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>-1.536314</td>\n",
       "      <td>-0.162778</td>\n",
       "      <td>0.502315</td>\n",
       "      <td>0.743246</td>\n",
       "      <td>0.422530</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.828291</td>\n",
       "      <td>0.249841</td>\n",
       "      <td>0.763714</td>\n",
       "      <td>1.350901</td>\n",
       "      <td>1.846830</td>\n",
       "      <td>-1.547625</td>\n",
       "      <td>-0.014038</td>\n",
       "      <td>0.967586</td>\n",
       "      <td>-0.060688</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>-0.959703</td>\n",
       "      <td>-1.833566</td>\n",
       "      <td>-0.045371</td>\n",
       "      <td>-0.208809</td>\n",
       "      <td>0.174372</td>\n",
       "      <td>-1.104280</td>\n",
       "      <td>-0.709082</td>\n",
       "      <td>-1.064152</td>\n",
       "      <td>1.055789</td>\n",
       "      <td>-0.500776</td>\n",
       "      <td>0.146946</td>\n",
       "      <td>-1.076277</td>\n",
       "      <td>-0.809873</td>\n",
       "      <td>-0.450995</td>\n",
       "      <td>-0.910374</td>\n",
       "      <td>-0.151399</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600848</td>\n",
       "      <td>1.043099</td>\n",
       "      <td>-1.081659</td>\n",
       "      <td>2.269201</td>\n",
       "      <td>0.151023</td>\n",
       "      <td>0.839087</td>\n",
       "      <td>1.214566</td>\n",
       "      <td>-0.045623</td>\n",
       "      <td>-2.068249</td>\n",
       "      <td>-0.934238</td>\n",
       "      <td>2.315075</td>\n",
       "      <td>-0.670333</td>\n",
       "      <td>-3.209839</td>\n",
       "      <td>0.171181</td>\n",
       "      <td>0.767993</td>\n",
       "      <td>0.620708</td>\n",
       "      <td>-1.586270</td>\n",
       "      <td>-0.597569</td>\n",
       "      <td>-0.830820</td>\n",
       "      <td>-1.010600</td>\n",
       "      <td>-1.868653</td>\n",
       "      <td>0.467470</td>\n",
       "      <td>-0.843680</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>-1.652141</td>\n",
       "      <td>2.306828</td>\n",
       "      <td>-0.765707</td>\n",
       "      <td>-0.744988</td>\n",
       "      <td>-0.285193</td>\n",
       "      <td>-0.279578</td>\n",
       "      <td>0.222148</td>\n",
       "      <td>2.782015</td>\n",
       "      <td>-0.061319</td>\n",
       "      <td>-1.718825</td>\n",
       "      <td>-0.389709</td>\n",
       "      <td>-0.974627</td>\n",
       "      <td>-0.765927</td>\n",
       "      <td>-0.434989</td>\n",
       "      <td>-1.124765</td>\n",
       "      <td>0.160699</td>\n",
       "      <td>2.108156</td>\n",
       "      <td>0.421185</td>\n",
       "      <td>0.036311</td>\n",
       "      <td>-0.946611</td>\n",
       "      <td>-0.318332</td>\n",
       "      <td>2.276379</td>\n",
       "      <td>0.409820</td>\n",
       "      <td>0.620247</td>\n",
       "      <td>-0.350930</td>\n",
       "      <td>0.226575</td>\n",
       "      <td>0.793988</td>\n",
       "      <td>1.412545</td>\n",
       "      <td>-0.421745</td>\n",
       "      <td>-1.278911</td>\n",
       "      <td>-0.730188</td>\n",
       "      <td>-0.307353</td>\n",
       "      <td>0.670205</td>\n",
       "      <td>0.577972</td>\n",
       "      <td>0.392854</td>\n",
       "      <td>0.749485</td>\n",
       "      <td>1.301764</td>\n",
       "      <td>-0.334947</td>\n",
       "      <td>0.381931</td>\n",
       "      <td>-1.130474</td>\n",
       "      <td>-0.403871</td>\n",
       "      <td>0.172073</td>\n",
       "      <td>-0.827863</td>\n",
       "      <td>-1.407875</td>\n",
       "      <td>1.479479</td>\n",
       "      <td>-0.751381</td>\n",
       "      <td>0.192190</td>\n",
       "      <td>0.611820</td>\n",
       "      <td>2.227252</td>\n",
       "      <td>-0.207259</td>\n",
       "      <td>-0.783734</td>\n",
       "      <td>0.086940</td>\n",
       "      <td>0.213626</td>\n",
       "      <td>-0.211474</td>\n",
       "      <td>-0.809175</td>\n",
       "      <td>0.923111</td>\n",
       "      <td>-1.115564</td>\n",
       "      <td>-1.007413</td>\n",
       "      <td>1.371989</td>\n",
       "      <td>-0.406133</td>\n",
       "      <td>-1.616687</td>\n",
       "      <td>-0.843546</td>\n",
       "      <td>-1.097504</td>\n",
       "      <td>-0.936119</td>\n",
       "      <td>-1.316315</td>\n",
       "      <td>-0.220954</td>\n",
       "      <td>-1.015166</td>\n",
       "      <td>-0.493313</td>\n",
       "      <td>1.516462</td>\n",
       "      <td>0.140041</td>\n",
       "      <td>-2.245375</td>\n",
       "      <td>-1.140552</td>\n",
       "      <td>-0.511464</td>\n",
       "      <td>0.119794</td>\n",
       "      <td>0.276529</td>\n",
       "      <td>1.395175</td>\n",
       "      <td>-0.422910</td>\n",
       "      <td>0.712210</td>\n",
       "      <td>0.914355</td>\n",
       "      <td>0.213758</td>\n",
       "      <td>-0.845495</td>\n",
       "      <td>-1.340684</td>\n",
       "      <td>0.285876</td>\n",
       "      <td>-0.268386</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>0.193268</td>\n",
       "      <td>-0.528402</td>\n",
       "      <td>0.091640</td>\n",
       "      <td>-0.727814</td>\n",
       "      <td>-0.260704</td>\n",
       "      <td>-1.568531</td>\n",
       "      <td>-0.006826</td>\n",
       "      <td>1.414921</td>\n",
       "      <td>-0.289243</td>\n",
       "      <td>-0.641822</td>\n",
       "      <td>2.248282</td>\n",
       "      <td>-0.030657</td>\n",
       "      <td>-0.826884</td>\n",
       "      <td>0.196169</td>\n",
       "      <td>-0.602268</td>\n",
       "      <td>-1.304021</td>\n",
       "      <td>-1.033125</td>\n",
       "      <td>-1.897310</td>\n",
       "      <td>-0.268622</td>\n",
       "      <td>2.634350</td>\n",
       "      <td>-0.747357</td>\n",
       "      <td>-0.008694</td>\n",
       "      <td>-1.800606</td>\n",
       "      <td>-0.780709</td>\n",
       "      <td>-0.339714</td>\n",
       "      <td>0.772595</td>\n",
       "      <td>-0.237113</td>\n",
       "      <td>1.031412</td>\n",
       "      <td>0.188912</td>\n",
       "      <td>1.624425</td>\n",
       "      <td>2.257859</td>\n",
       "      <td>0.065757</td>\n",
       "      <td>-0.905659</td>\n",
       "      <td>-0.918080</td>\n",
       "      <td>-1.541176</td>\n",
       "      <td>-0.062834</td>\n",
       "      <td>-1.364488</td>\n",
       "      <td>-0.723209</td>\n",
       "      <td>1.596336</td>\n",
       "      <td>0.501579</td>\n",
       "      <td>1.302688</td>\n",
       "      <td>-0.361060</td>\n",
       "      <td>-0.885080</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>-0.226745</td>\n",
       "      <td>0.128436</td>\n",
       "      <td>-0.049336</td>\n",
       "      <td>0.595034</td>\n",
       "      <td>0.904893</td>\n",
       "      <td>-0.548383</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>-0.250371</td>\n",
       "      <td>0.099825</td>\n",
       "      <td>1.243207</td>\n",
       "      <td>-0.147216</td>\n",
       "      <td>0.087626</td>\n",
       "      <td>0.630759</td>\n",
       "      <td>-1.422585</td>\n",
       "      <td>-1.573122</td>\n",
       "      <td>-0.020957</td>\n",
       "      <td>-1.316480</td>\n",
       "      <td>-1.133579</td>\n",
       "      <td>0.597113</td>\n",
       "      <td>1.120850</td>\n",
       "      <td>1.159328</td>\n",
       "      <td>0.221806</td>\n",
       "      <td>1.046757</td>\n",
       "      <td>1.080555</td>\n",
       "      <td>0.306489</td>\n",
       "      <td>0.212663</td>\n",
       "      <td>0.452331</td>\n",
       "      <td>3.334772</td>\n",
       "      <td>-2.161473</td>\n",
       "      <td>0.345970</td>\n",
       "      <td>0.493578</td>\n",
       "      <td>0.689542</td>\n",
       "      <td>0.442669</td>\n",
       "      <td>-0.144389</td>\n",
       "      <td>0.164414</td>\n",
       "      <td>-0.420011</td>\n",
       "      <td>-1.362716</td>\n",
       "      <td>-1.590674</td>\n",
       "      <td>-1.342650</td>\n",
       "      <td>-0.649191</td>\n",
       "      <td>-0.506873</td>\n",
       "      <td>0.032127</td>\n",
       "      <td>-1.083001</td>\n",
       "      <td>1.441462</td>\n",
       "      <td>3.466843</td>\n",
       "      <td>2.001889</td>\n",
       "      <td>0.640065</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>1.754080</td>\n",
       "      <td>-0.951793</td>\n",
       "      <td>-0.184952</td>\n",
       "      <td>-1.651019</td>\n",
       "      <td>-0.530657</td>\n",
       "      <td>-0.524057</td>\n",
       "      <td>-0.615734</td>\n",
       "      <td>0.461384</td>\n",
       "      <td>-0.314817</td>\n",
       "      <td>-1.096875</td>\n",
       "      <td>1.732107</td>\n",
       "      <td>0.268532</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>-0.434174</td>\n",
       "      <td>-1.434767</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-1.933695</td>\n",
       "      <td>-0.171898</td>\n",
       "      <td>0.105296</td>\n",
       "      <td>-1.301914</td>\n",
       "      <td>0.241562</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>-1.439099</td>\n",
       "      <td>2.281790</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.315615</td>\n",
       "      <td>-1.971908</td>\n",
       "      <td>-0.430648</td>\n",
       "      <td>-1.753258</td>\n",
       "      <td>1.342495</td>\n",
       "      <td>-1.281352</td>\n",
       "      <td>-1.578537</td>\n",
       "      <td>0.186740</td>\n",
       "      <td>-1.755392</td>\n",
       "      <td>0.479792</td>\n",
       "      <td>1.162727</td>\n",
       "      <td>-0.705636</td>\n",
       "      <td>1.073087</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.303066</td>\n",
       "      <td>-0.708828</td>\n",
       "      <td>0.631059</td>\n",
       "      <td>-1.397928</td>\n",
       "      <td>0.176152</td>\n",
       "      <td>0.189937</td>\n",
       "      <td>-1.159983</td>\n",
       "      <td>2.085750</td>\n",
       "      <td>-0.489042</td>\n",
       "      <td>-0.186783</td>\n",
       "      <td>-0.271120</td>\n",
       "      <td>0.640304</td>\n",
       "      <td>1.006856</td>\n",
       "      <td>0.187742</td>\n",
       "      <td>-1.212850</td>\n",
       "      <td>-0.893897</td>\n",
       "      <td>-0.267294</td>\n",
       "      <td>-0.048435</td>\n",
       "      <td>0.163329</td>\n",
       "      <td>-0.639718</td>\n",
       "      <td>0.785143</td>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.431544</td>\n",
       "      <td>-0.349522</td>\n",
       "      <td>-0.344051</td>\n",
       "      <td>1.128396</td>\n",
       "      <td>1.087620</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>1.139624</td>\n",
       "      <td>0.947906</td>\n",
       "      <td>-0.815955</td>\n",
       "      <td>0.842638</td>\n",
       "      <td>-0.770910</td>\n",
       "      <td>0.363245</td>\n",
       "      <td>0.600480</td>\n",
       "      <td>2.655940</td>\n",
       "      <td>0.290083</td>\n",
       "      <td>-0.462693</td>\n",
       "      <td>1.415527</td>\n",
       "      <td>-0.235606</td>\n",
       "      <td>0.191409</td>\n",
       "      <td>1.141335</td>\n",
       "      <td>1.659823</td>\n",
       "      <td>-1.723043</td>\n",
       "      <td>0.166212</td>\n",
       "      <td>-0.169794</td>\n",
       "      <td>0.775279</td>\n",
       "      <td>0.050845</td>\n",
       "      <td>0.260609</td>\n",
       "      <td>1.409123</td>\n",
       "      <td>-1.614327</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>-0.075264</td>\n",
       "      <td>-1.912591</td>\n",
       "      <td>-0.217808</td>\n",
       "      <td>-1.151873</td>\n",
       "      <td>-1.110016</td>\n",
       "      <td>-0.522359</td>\n",
       "      <td>-1.122663</td>\n",
       "      <td>-0.470433</td>\n",
       "      <td>-0.157924</td>\n",
       "      <td>-1.077255</td>\n",
       "      <td>1.995448</td>\n",
       "      <td>0.941120</td>\n",
       "      <td>0.411349</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>-0.496642</td>\n",
       "      <td>-1.913870</td>\n",
       "      <td>-1.315482</td>\n",
       "      <td>2.474361</td>\n",
       "      <td>-1.572775</td>\n",
       "      <td>-1.606590</td>\n",
       "      <td>-0.424166</td>\n",
       "      <td>1.146642</td>\n",
       "      <td>-0.918600</td>\n",
       "      <td>-1.095451</td>\n",
       "      <td>-0.809045</td>\n",
       "      <td>-1.755196</td>\n",
       "      <td>-0.318788</td>\n",
       "      <td>-1.881025</td>\n",
       "      <td>0.180544</td>\n",
       "      <td>-1.566990</td>\n",
       "      <td>0.666360</td>\n",
       "      <td>-1.705021</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.193252</td>\n",
       "      <td>-1.125800</td>\n",
       "      <td>-0.210065</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>0.153166</td>\n",
       "      <td>2.219626</td>\n",
       "      <td>0.380430</td>\n",
       "      <td>-1.266216</td>\n",
       "      <td>-0.689489</td>\n",
       "      <td>0.074422</td>\n",
       "      <td>-0.740634</td>\n",
       "      <td>0.073070</td>\n",
       "      <td>-1.466129</td>\n",
       "      <td>-0.203739</td>\n",
       "      <td>2.331496</td>\n",
       "      <td>0.723769</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.190457</td>\n",
       "      <td>0.186374</td>\n",
       "      <td>2.178373</td>\n",
       "      <td>0.636959</td>\n",
       "      <td>0.194633</td>\n",
       "      <td>0.118961</td>\n",
       "      <td>-0.167677</td>\n",
       "      <td>0.635154</td>\n",
       "      <td>1.909486</td>\n",
       "      <td>-0.320237</td>\n",
       "      <td>-1.372088</td>\n",
       "      <td>-1.509946</td>\n",
       "      <td>0.147425</td>\n",
       "      <td>0.433623</td>\n",
       "      <td>0.369757</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>0.822510</td>\n",
       "      <td>1.470245</td>\n",
       "      <td>0.273960</td>\n",
       "      <td>0.825582</td>\n",
       "      <td>-1.463795</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>-0.414006</td>\n",
       "      <td>-1.238549</td>\n",
       "      <td>-0.730656</td>\n",
       "      <td>1.642916</td>\n",
       "      <td>-0.207779</td>\n",
       "      <td>-1.260039</td>\n",
       "      <td>0.926034</td>\n",
       "      <td>1.535006</td>\n",
       "      <td>-0.469058</td>\n",
       "      <td>-0.263767</td>\n",
       "      <td>-1.022944</td>\n",
       "      <td>-0.330201</td>\n",
       "      <td>-0.777267</td>\n",
       "      <td>0.495756</td>\n",
       "      <td>0.599326</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>-0.624992</td>\n",
       "      <td>1.910831</td>\n",
       "      <td>-0.536340</td>\n",
       "      <td>-1.555291</td>\n",
       "      <td>-1.388737</td>\n",
       "      <td>-0.734118</td>\n",
       "      <td>-1.335301</td>\n",
       "      <td>-0.742745</td>\n",
       "      <td>0.241108</td>\n",
       "      <td>-2.285619</td>\n",
       "      <td>-1.703257</td>\n",
       "      <td>2.406761</td>\n",
       "      <td>0.693531</td>\n",
       "      <td>-1.219720</td>\n",
       "      <td>-2.186469</td>\n",
       "      <td>0.206730</td>\n",
       "      <td>0.396434</td>\n",
       "      <td>0.773678</td>\n",
       "      <td>0.766135</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.344842</td>\n",
       "      <td>0.581571</td>\n",
       "      <td>0.246829</td>\n",
       "      <td>-1.274155</td>\n",
       "      <td>-1.781746</td>\n",
       "      <td>-0.283705</td>\n",
       "      <td>-1.055850</td>\n",
       "      <td>-0.255025</td>\n",
       "      <td>0.454014</td>\n",
       "      <td>-0.460979</td>\n",
       "      <td>0.647283</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>-0.345305</td>\n",
       "      <td>-0.664734</td>\n",
       "      <td>0.463897</td>\n",
       "      <td>1.195348</td>\n",
       "      <td>-0.579877</td>\n",
       "      <td>-0.186671</td>\n",
       "      <td>1.843797</td>\n",
       "      <td>-0.364136</td>\n",
       "      <td>-1.249263</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>-0.568542</td>\n",
       "      <td>-1.070019</td>\n",
       "      <td>-1.498215</td>\n",
       "      <td>-0.934520</td>\n",
       "      <td>-1.295658</td>\n",
       "      <td>1.673780</td>\n",
       "      <td>-0.691264</td>\n",
       "      <td>-0.071252</td>\n",
       "      <td>-1.397232</td>\n",
       "      <td>-0.320283</td>\n",
       "      <td>-0.634016</td>\n",
       "      <td>2.113779</td>\n",
       "      <td>-0.047233</td>\n",
       "      <td>0.606973</td>\n",
       "      <td>-0.375252</td>\n",
       "      <td>0.979778</td>\n",
       "      <td>1.109684</td>\n",
       "      <td>0.355278</td>\n",
       "      <td>-1.062198</td>\n",
       "      <td>-0.925620</td>\n",
       "      <td>-0.655785</td>\n",
       "      <td>0.602764</td>\n",
       "      <td>-1.194188</td>\n",
       "      <td>-0.417409</td>\n",
       "      <td>1.024592</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.933128</td>\n",
       "      <td>-1.407486</td>\n",
       "      <td>-0.536895</td>\n",
       "      <td>-0.096199</td>\n",
       "      <td>-0.891068</td>\n",
       "      <td>0.923379</td>\n",
       "      <td>-0.593660</td>\n",
       "      <td>-0.725371</td>\n",
       "      <td>1.719332</td>\n",
       "      <td>-0.930009</td>\n",
       "      <td>0.698971</td>\n",
       "      <td>0.925840</td>\n",
       "      <td>-0.792566</td>\n",
       "      <td>1.131312</td>\n",
       "      <td>0.345582</td>\n",
       "      <td>0.335430</td>\n",
       "      <td>1.205531</td>\n",
       "      <td>-1.470317</td>\n",
       "      <td>-0.966938</td>\n",
       "      <td>-0.016824</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.774624</td>\n",
       "      <td>-0.193286</td>\n",
       "      <td>0.894797</td>\n",
       "      <td>1.273448</td>\n",
       "      <td>0.150215</td>\n",
       "      <td>0.313529</td>\n",
       "      <td>1.629638</td>\n",
       "      <td>1.147445</td>\n",
       "      <td>0.705181</td>\n",
       "      <td>-0.356471</td>\n",
       "      <td>3.419476</td>\n",
       "      <td>-1.160626</td>\n",
       "      <td>-0.252537</td>\n",
       "      <td>1.491922</td>\n",
       "      <td>1.006057</td>\n",
       "      <td>-0.345155</td>\n",
       "      <td>-0.117146</td>\n",
       "      <td>0.366227</td>\n",
       "      <td>0.208760</td>\n",
       "      <td>-1.001146</td>\n",
       "      <td>-2.078865</td>\n",
       "      <td>-1.236059</td>\n",
       "      <td>0.069649</td>\n",
       "      <td>-2.290134</td>\n",
       "      <td>0.126157</td>\n",
       "      <td>-0.694779</td>\n",
       "      <td>2.003405</td>\n",
       "      <td>3.618411</td>\n",
       "      <td>2.377286</td>\n",
       "      <td>1.102849</td>\n",
       "      <td>0.234373</td>\n",
       "      <td>0.509235</td>\n",
       "      <td>-1.009023</td>\n",
       "      <td>-0.456700</td>\n",
       "      <td>-0.618851</td>\n",
       "      <td>-0.708283</td>\n",
       "      <td>-0.749282</td>\n",
       "      <td>-0.750049</td>\n",
       "      <td>0.695744</td>\n",
       "      <td>0.839485</td>\n",
       "      <td>-1.201910</td>\n",
       "      <td>1.971815</td>\n",
       "      <td>-0.711305</td>\n",
       "      <td>-0.730514</td>\n",
       "      <td>0.284711</td>\n",
       "      <td>-0.576796</td>\n",
       "      <td>-0.054767</td>\n",
       "      <td>-2.196403</td>\n",
       "      <td>-0.851484</td>\n",
       "      <td>-0.167122</td>\n",
       "      <td>-2.328930</td>\n",
       "      <td>-0.290622</td>\n",
       "      <td>0.471571</td>\n",
       "      <td>-0.785688</td>\n",
       "      <td>3.012218</td>\n",
       "      <td>0.284497</td>\n",
       "      <td>0.470605</td>\n",
       "      <td>-1.693588</td>\n",
       "      <td>0.088708</td>\n",
       "      <td>-2.321166</td>\n",
       "      <td>1.689323</td>\n",
       "      <td>-1.285264</td>\n",
       "      <td>-2.327423</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>-0.578767</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>0.729797</td>\n",
       "      <td>-0.949282</td>\n",
       "      <td>0.776537</td>\n",
       "      <td>0.555408</td>\n",
       "      <td>0.581477</td>\n",
       "      <td>0.719721</td>\n",
       "      <td>0.472878</td>\n",
       "      <td>-0.096230</td>\n",
       "      <td>0.149690</td>\n",
       "      <td>0.351422</td>\n",
       "      <td>-0.742504</td>\n",
       "      <td>2.345160</td>\n",
       "      <td>0.284957</td>\n",
       "      <td>-0.442649</td>\n",
       "      <td>-1.983393</td>\n",
       "      <td>0.649834</td>\n",
       "      <td>0.953195</td>\n",
       "      <td>0.678349</td>\n",
       "      <td>-1.079600</td>\n",
       "      <td>-0.716211</td>\n",
       "      <td>-0.029120</td>\n",
       "      <td>-0.109190</td>\n",
       "      <td>0.172565</td>\n",
       "      <td>-0.245101</td>\n",
       "      <td>-0.120989</td>\n",
       "      <td>1.263595</td>\n",
       "      <td>0.929777</td>\n",
       "      <td>0.527996</td>\n",
       "      <td>0.024496</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>-0.190330</td>\n",
       "      <td>1.205815</td>\n",
       "      <td>0.583818</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>1.628391</td>\n",
       "      <td>-0.575251</td>\n",
       "      <td>0.666299</td>\n",
       "      <td>-1.605922</td>\n",
       "      <td>-0.018630</td>\n",
       "      <td>-1.214314</td>\n",
       "      <td>2.439180</td>\n",
       "      <td>-0.244463</td>\n",
       "      <td>-2.140579</td>\n",
       "      <td>1.568572</td>\n",
       "      <td>-0.288285</td>\n",
       "      <td>0.469678</td>\n",
       "      <td>0.215252</td>\n",
       "      <td>1.315098</td>\n",
       "      <td>-1.479540</td>\n",
       "      <td>-0.830012</td>\n",
       "      <td>0.179096</td>\n",
       "      <td>0.884547</td>\n",
       "      <td>0.559770</td>\n",
       "      <td>0.686974</td>\n",
       "      <td>2.283891</td>\n",
       "      <td>-1.299231</td>\n",
       "      <td>0.768752</td>\n",
       "      <td>-0.661651</td>\n",
       "      <td>-1.557291</td>\n",
       "      <td>-0.064821</td>\n",
       "      <td>-1.365178</td>\n",
       "      <td>-0.225597</td>\n",
       "      <td>-0.325457</td>\n",
       "      <td>-1.404999</td>\n",
       "      <td>-0.946618</td>\n",
       "      <td>-0.102321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799363</td>\n",
       "      <td>0.799363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>4042.398947</td>\n",
       "      <td>0.718993</td>\n",
       "      <td>0.077561</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3700.781667</td>\n",
       "      <td>0.089866</td>\n",
       "      <td>-0.886623</td>\n",
       "      <td>-0.076803</td>\n",
       "      <td>1.131874</td>\n",
       "      <td>-1.042389</td>\n",
       "      <td>-0.162605</td>\n",
       "      <td>-0.837518</td>\n",
       "      <td>-0.157821</td>\n",
       "      <td>-0.578512</td>\n",
       "      <td>0.897857</td>\n",
       "      <td>1.512872</td>\n",
       "      <td>-0.242880</td>\n",
       "      <td>-0.586503</td>\n",
       "      <td>1.348188</td>\n",
       "      <td>0.505731</td>\n",
       "      <td>0.037068</td>\n",
       "      <td>0.078332</td>\n",
       "      <td>0.907070</td>\n",
       "      <td>-0.450082</td>\n",
       "      <td>0.409156</td>\n",
       "      <td>0.967267</td>\n",
       "      <td>1.214611</td>\n",
       "      <td>0.866596</td>\n",
       "      <td>1.257896</td>\n",
       "      <td>-0.121633</td>\n",
       "      <td>-0.963012</td>\n",
       "      <td>-0.217350</td>\n",
       "      <td>-0.383062</td>\n",
       "      <td>-0.254907</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.541575</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.155458</td>\n",
       "      <td>0.589412</td>\n",
       "      <td>-0.072538</td>\n",
       "      <td>-0.550539</td>\n",
       "      <td>1.053959</td>\n",
       "      <td>-0.025955</td>\n",
       "      <td>0.324548</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>1.114170</td>\n",
       "      <td>0.543327</td>\n",
       "      <td>0.084252</td>\n",
       "      <td>-1.044139</td>\n",
       "      <td>0.115153</td>\n",
       "      <td>-0.289116</td>\n",
       "      <td>-0.950469</td>\n",
       "      <td>0.291291</td>\n",
       "      <td>-0.375255</td>\n",
       "      <td>-0.209981</td>\n",
       "      <td>0.379528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077123</td>\n",
       "      <td>-0.077123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.018106</td>\n",
       "      <td>0.494008</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>1.397599</td>\n",
       "      <td>1.994062</td>\n",
       "      <td>0.631149</td>\n",
       "      <td>1.749432</td>\n",
       "      <td>0.796814</td>\n",
       "      <td>0.659818</td>\n",
       "      <td>-0.244618</td>\n",
       "      <td>1.542348</td>\n",
       "      <td>0.711170</td>\n",
       "      <td>1.179388</td>\n",
       "      <td>-1.197036</td>\n",
       "      <td>0.154268</td>\n",
       "      <td>0.677936</td>\n",
       "      <td>-1.001916</td>\n",
       "      <td>1.441179</td>\n",
       "      <td>3.089656</td>\n",
       "      <td>-0.125188</td>\n",
       "      <td>-0.932568</td>\n",
       "      <td>0.479088</td>\n",
       "      <td>-0.310349</td>\n",
       "      <td>-0.345520</td>\n",
       "      <td>-0.780219</td>\n",
       "      <td>1.833798</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>1.181364</td>\n",
       "      <td>0.503797</td>\n",
       "      <td>-1.511223</td>\n",
       "      <td>-1.077359</td>\n",
       "      <td>-1.389793</td>\n",
       "      <td>-0.953741</td>\n",
       "      <td>0.227868</td>\n",
       "      <td>-1.207585</td>\n",
       "      <td>-0.578707</td>\n",
       "      <td>-0.086977</td>\n",
       "      <td>1.343012</td>\n",
       "      <td>-1.462633</td>\n",
       "      <td>-2.283756</td>\n",
       "      <td>-0.588039</td>\n",
       "      <td>0.627008</td>\n",
       "      <td>-0.567177</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.519053</td>\n",
       "      <td>0.995983</td>\n",
       "      <td>-0.170127</td>\n",
       "      <td>-0.456256</td>\n",
       "      <td>2.485320</td>\n",
       "      <td>-0.688197</td>\n",
       "      <td>0.484480</td>\n",
       "      <td>-1.247692</td>\n",
       "      <td>0.088792</td>\n",
       "      <td>0.822095</td>\n",
       "      <td>-0.677754</td>\n",
       "      <td>0.482335</td>\n",
       "      <td>-0.333860</td>\n",
       "      <td>0.467046</td>\n",
       "      <td>-0.180385</td>\n",
       "      <td>0.623752</td>\n",
       "      <td>2.660661</td>\n",
       "      <td>0.666528</td>\n",
       "      <td>1.605643</td>\n",
       "      <td>-0.569248</td>\n",
       "      <td>-1.951421</td>\n",
       "      <td>0.227865</td>\n",
       "      <td>-0.864982</td>\n",
       "      <td>-0.800859</td>\n",
       "      <td>-0.327905</td>\n",
       "      <td>0.422415</td>\n",
       "      <td>-0.627474</td>\n",
       "      <td>-0.216761</td>\n",
       "      <td>-0.525077</td>\n",
       "      <td>-0.776940</td>\n",
       "      <td>-0.513917</td>\n",
       "      <td>-1.043778</td>\n",
       "      <td>0.670741</td>\n",
       "      <td>0.931028</td>\n",
       "      <td>2.239132</td>\n",
       "      <td>-0.969558</td>\n",
       "      <td>0.797527</td>\n",
       "      <td>-1.372364</td>\n",
       "      <td>1.561897</td>\n",
       "      <td>0.739932</td>\n",
       "      <td>0.764246</td>\n",
       "      <td>0.240476</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>-0.392429</td>\n",
       "      <td>1.675646</td>\n",
       "      <td>0.958615</td>\n",
       "      <td>0.146765</td>\n",
       "      <td>-0.492752</td>\n",
       "      <td>0.720502</td>\n",
       "      <td>1.309134</td>\n",
       "      <td>-0.796909</td>\n",
       "      <td>0.724607</td>\n",
       "      <td>0.274278</td>\n",
       "      <td>-0.727750</td>\n",
       "      <td>1.297018</td>\n",
       "      <td>-0.759486</td>\n",
       "      <td>1.347745</td>\n",
       "      <td>0.878679</td>\n",
       "      <td>-0.233632</td>\n",
       "      <td>0.490763</td>\n",
       "      <td>-0.593186</td>\n",
       "      <td>-0.368647</td>\n",
       "      <td>-1.624226</td>\n",
       "      <td>2.277198</td>\n",
       "      <td>0.370804</td>\n",
       "      <td>-0.123966</td>\n",
       "      <td>0.273008</td>\n",
       "      <td>-0.702423</td>\n",
       "      <td>0.969818</td>\n",
       "      <td>1.215280</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.634290</td>\n",
       "      <td>0.334738</td>\n",
       "      <td>-0.229331</td>\n",
       "      <td>0.446060</td>\n",
       "      <td>2.114131</td>\n",
       "      <td>-0.065895</td>\n",
       "      <td>-1.778740</td>\n",
       "      <td>0.537660</td>\n",
       "      <td>-0.300174</td>\n",
       "      <td>-0.419964</td>\n",
       "      <td>1.233326</td>\n",
       "      <td>-0.227759</td>\n",
       "      <td>0.419336</td>\n",
       "      <td>-0.922732</td>\n",
       "      <td>0.646081</td>\n",
       "      <td>-0.368378</td>\n",
       "      <td>-0.271640</td>\n",
       "      <td>-1.192123</td>\n",
       "      <td>0.569105</td>\n",
       "      <td>1.634192</td>\n",
       "      <td>0.632095</td>\n",
       "      <td>-0.108510</td>\n",
       "      <td>-1.319626</td>\n",
       "      <td>0.663339</td>\n",
       "      <td>-0.965716</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>0.222635</td>\n",
       "      <td>2.637844</td>\n",
       "      <td>-1.702098</td>\n",
       "      <td>-0.836944</td>\n",
       "      <td>-1.062185</td>\n",
       "      <td>-0.159830</td>\n",
       "      <td>-0.823870</td>\n",
       "      <td>-0.699394</td>\n",
       "      <td>-0.608839</td>\n",
       "      <td>-0.039563</td>\n",
       "      <td>-0.378062</td>\n",
       "      <td>-1.152376</td>\n",
       "      <td>-1.041815</td>\n",
       "      <td>0.063104</td>\n",
       "      <td>-0.258856</td>\n",
       "      <td>0.346515</td>\n",
       "      <td>0.508938</td>\n",
       "      <td>0.161040</td>\n",
       "      <td>0.793395</td>\n",
       "      <td>0.065921</td>\n",
       "      <td>0.813740</td>\n",
       "      <td>1.460270</td>\n",
       "      <td>1.040972</td>\n",
       "      <td>-0.162949</td>\n",
       "      <td>-0.275600</td>\n",
       "      <td>-0.286348</td>\n",
       "      <td>0.910457</td>\n",
       "      <td>0.138887</td>\n",
       "      <td>0.803870</td>\n",
       "      <td>-0.709799</td>\n",
       "      <td>-0.737442</td>\n",
       "      <td>-0.398212</td>\n",
       "      <td>0.390577</td>\n",
       "      <td>-0.493452</td>\n",
       "      <td>-2.210822</td>\n",
       "      <td>1.126979</td>\n",
       "      <td>-0.464982</td>\n",
       "      <td>0.079529</td>\n",
       "      <td>-1.802092</td>\n",
       "      <td>-0.642290</td>\n",
       "      <td>-0.752780</td>\n",
       "      <td>1.249796</td>\n",
       "      <td>2.587143</td>\n",
       "      <td>0.818629</td>\n",
       "      <td>-0.818634</td>\n",
       "      <td>-2.912952</td>\n",
       "      <td>0.234895</td>\n",
       "      <td>-0.996524</td>\n",
       "      <td>-0.524157</td>\n",
       "      <td>0.759298</td>\n",
       "      <td>-0.279653</td>\n",
       "      <td>-0.234903</td>\n",
       "      <td>-0.335483</td>\n",
       "      <td>1.192631</td>\n",
       "      <td>0.507342</td>\n",
       "      <td>0.134844</td>\n",
       "      <td>0.440250</td>\n",
       "      <td>-0.843684</td>\n",
       "      <td>0.878455</td>\n",
       "      <td>0.328051</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>-0.063802</td>\n",
       "      <td>1.596421</td>\n",
       "      <td>-1.206749</td>\n",
       "      <td>2.096175</td>\n",
       "      <td>-1.252516</td>\n",
       "      <td>-0.459212</td>\n",
       "      <td>-1.325565</td>\n",
       "      <td>1.129720</td>\n",
       "      <td>0.909634</td>\n",
       "      <td>-2.148198</td>\n",
       "      <td>-0.107243</td>\n",
       "      <td>-1.534632</td>\n",
       "      <td>0.740416</td>\n",
       "      <td>-0.806932</td>\n",
       "      <td>0.554193</td>\n",
       "      <td>-0.481628</td>\n",
       "      <td>-0.478353</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>0.487490</td>\n",
       "      <td>-0.624573</td>\n",
       "      <td>-0.351273</td>\n",
       "      <td>-0.162180</td>\n",
       "      <td>-2.017922</td>\n",
       "      <td>0.287496</td>\n",
       "      <td>-0.544664</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>1.340689</td>\n",
       "      <td>0.319743</td>\n",
       "      <td>-1.436630</td>\n",
       "      <td>-1.687503</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>-0.272453</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.754045</td>\n",
       "      <td>1.736012</td>\n",
       "      <td>-1.802402</td>\n",
       "      <td>0.092955</td>\n",
       "      <td>-0.857347</td>\n",
       "      <td>0.535757</td>\n",
       "      <td>-1.382867</td>\n",
       "      <td>1.059853</td>\n",
       "      <td>-0.399964</td>\n",
       "      <td>-1.653452</td>\n",
       "      <td>-1.310935</td>\n",
       "      <td>0.601547</td>\n",
       "      <td>-0.689430</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>1.145168</td>\n",
       "      <td>-1.369422</td>\n",
       "      <td>-1.305552</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>1.787140</td>\n",
       "      <td>0.158596</td>\n",
       "      <td>-0.684867</td>\n",
       "      <td>-0.235819</td>\n",
       "      <td>0.453656</td>\n",
       "      <td>-0.326701</td>\n",
       "      <td>-1.020275</td>\n",
       "      <td>-0.251110</td>\n",
       "      <td>0.386844</td>\n",
       "      <td>0.302311</td>\n",
       "      <td>-0.530493</td>\n",
       "      <td>-0.874808</td>\n",
       "      <td>0.601435</td>\n",
       "      <td>0.922316</td>\n",
       "      <td>-0.514702</td>\n",
       "      <td>-0.454278</td>\n",
       "      <td>0.959291</td>\n",
       "      <td>-1.406727</td>\n",
       "      <td>-0.679509</td>\n",
       "      <td>0.446671</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>0.953871</td>\n",
       "      <td>1.015880</td>\n",
       "      <td>-0.625187</td>\n",
       "      <td>0.276381</td>\n",
       "      <td>0.229385</td>\n",
       "      <td>0.199738</td>\n",
       "      <td>-0.573292</td>\n",
       "      <td>-1.605094</td>\n",
       "      <td>-0.553187</td>\n",
       "      <td>0.122965</td>\n",
       "      <td>0.742317</td>\n",
       "      <td>0.907898</td>\n",
       "      <td>0.259966</td>\n",
       "      <td>-0.709358</td>\n",
       "      <td>0.390832</td>\n",
       "      <td>0.330444</td>\n",
       "      <td>0.235441</td>\n",
       "      <td>1.705353</td>\n",
       "      <td>-0.038381</td>\n",
       "      <td>0.535561</td>\n",
       "      <td>1.694553</td>\n",
       "      <td>0.416229</td>\n",
       "      <td>-0.940729</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.373168</td>\n",
       "      <td>-0.249705</td>\n",
       "      <td>-0.876473</td>\n",
       "      <td>-0.349286</td>\n",
       "      <td>-0.782212</td>\n",
       "      <td>0.115110</td>\n",
       "      <td>-1.606943</td>\n",
       "      <td>0.730386</td>\n",
       "      <td>-0.175281</td>\n",
       "      <td>-0.561611</td>\n",
       "      <td>0.677692</td>\n",
       "      <td>0.146345</td>\n",
       "      <td>-1.054869</td>\n",
       "      <td>0.535591</td>\n",
       "      <td>1.166569</td>\n",
       "      <td>0.539618</td>\n",
       "      <td>-0.196041</td>\n",
       "      <td>0.166226</td>\n",
       "      <td>1.077625</td>\n",
       "      <td>0.197328</td>\n",
       "      <td>0.928485</td>\n",
       "      <td>-0.026666</td>\n",
       "      <td>-1.415432</td>\n",
       "      <td>0.618134</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.521865</td>\n",
       "      <td>0.524856</td>\n",
       "      <td>0.948269</td>\n",
       "      <td>-0.922798</td>\n",
       "      <td>-1.330018</td>\n",
       "      <td>1.122246</td>\n",
       "      <td>-2.215499</td>\n",
       "      <td>-2.324176</td>\n",
       "      <td>-0.900498</td>\n",
       "      <td>-0.163289</td>\n",
       "      <td>-0.956149</td>\n",
       "      <td>0.214306</td>\n",
       "      <td>-1.032150</td>\n",
       "      <td>-0.293202</td>\n",
       "      <td>-1.499261</td>\n",
       "      <td>0.566981</td>\n",
       "      <td>-0.285071</td>\n",
       "      <td>-0.825597</td>\n",
       "      <td>0.577352</td>\n",
       "      <td>-0.636103</td>\n",
       "      <td>0.502170</td>\n",
       "      <td>-0.505281</td>\n",
       "      <td>1.231648</td>\n",
       "      <td>-0.098052</td>\n",
       "      <td>0.794563</td>\n",
       "      <td>-0.920125</td>\n",
       "      <td>1.131048</td>\n",
       "      <td>2.313299</td>\n",
       "      <td>1.339820</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-1.317759</td>\n",
       "      <td>0.975986</td>\n",
       "      <td>0.103487</td>\n",
       "      <td>-1.569516</td>\n",
       "      <td>2.882508</td>\n",
       "      <td>0.346358</td>\n",
       "      <td>-1.369488</td>\n",
       "      <td>-0.394097</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.982176</td>\n",
       "      <td>0.694896</td>\n",
       "      <td>0.105734</td>\n",
       "      <td>0.457975</td>\n",
       "      <td>2.105963</td>\n",
       "      <td>0.302753</td>\n",
       "      <td>1.126286</td>\n",
       "      <td>0.330743</td>\n",
       "      <td>-3.052455</td>\n",
       "      <td>0.384429</td>\n",
       "      <td>0.910391</td>\n",
       "      <td>0.399869</td>\n",
       "      <td>0.544735</td>\n",
       "      <td>-1.015717</td>\n",
       "      <td>0.588012</td>\n",
       "      <td>-1.299321</td>\n",
       "      <td>0.082676</td>\n",
       "      <td>-0.878052</td>\n",
       "      <td>0.215041</td>\n",
       "      <td>0.809761</td>\n",
       "      <td>-0.048256</td>\n",
       "      <td>-0.299561</td>\n",
       "      <td>0.751424</td>\n",
       "      <td>0.205243</td>\n",
       "      <td>-1.469317</td>\n",
       "      <td>-0.442236</td>\n",
       "      <td>1.273625</td>\n",
       "      <td>1.634617</td>\n",
       "      <td>1.756182</td>\n",
       "      <td>2.770127</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>1.237391</td>\n",
       "      <td>1.131228</td>\n",
       "      <td>-0.050678</td>\n",
       "      <td>-0.014432</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>-1.486096</td>\n",
       "      <td>-0.039513</td>\n",
       "      <td>-0.271569</td>\n",
       "      <td>-1.882234</td>\n",
       "      <td>-0.253267</td>\n",
       "      <td>-0.650476</td>\n",
       "      <td>-0.907001</td>\n",
       "      <td>-0.484914</td>\n",
       "      <td>0.642708</td>\n",
       "      <td>-0.528811</td>\n",
       "      <td>-1.490364</td>\n",
       "      <td>-0.004965</td>\n",
       "      <td>-0.647583</td>\n",
       "      <td>-1.221881</td>\n",
       "      <td>-1.199177</td>\n",
       "      <td>-0.279149</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.565994</td>\n",
       "      <td>-0.745460</td>\n",
       "      <td>-0.717347</td>\n",
       "      <td>-0.416736</td>\n",
       "      <td>1.603607</td>\n",
       "      <td>1.361029</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>-1.062280</td>\n",
       "      <td>-0.767022</td>\n",
       "      <td>0.242592</td>\n",
       "      <td>-0.489035</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>-1.266902</td>\n",
       "      <td>-0.842713</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>-0.998945</td>\n",
       "      <td>-0.131972</td>\n",
       "      <td>-1.059639</td>\n",
       "      <td>-0.756152</td>\n",
       "      <td>0.581819</td>\n",
       "      <td>-0.041530</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>-1.017979</td>\n",
       "      <td>-0.767581</td>\n",
       "      <td>-0.201373</td>\n",
       "      <td>-0.499105</td>\n",
       "      <td>-0.069359</td>\n",
       "      <td>-2.125341</td>\n",
       "      <td>-0.455634</td>\n",
       "      <td>0.589070</td>\n",
       "      <td>1.455077</td>\n",
       "      <td>1.617816</td>\n",
       "      <td>-0.567132</td>\n",
       "      <td>-1.477221</td>\n",
       "      <td>-0.282963</td>\n",
       "      <td>-1.021762</td>\n",
       "      <td>-1.586082</td>\n",
       "      <td>-0.550894</td>\n",
       "      <td>-1.081480</td>\n",
       "      <td>0.648673</td>\n",
       "      <td>-0.895462</td>\n",
       "      <td>-1.673891</td>\n",
       "      <td>0.973307</td>\n",
       "      <td>-0.775476</td>\n",
       "      <td>-1.410603</td>\n",
       "      <td>-3.638368</td>\n",
       "      <td>-1.882796</td>\n",
       "      <td>1.172944</td>\n",
       "      <td>-0.375541</td>\n",
       "      <td>0.627113</td>\n",
       "      <td>-0.326476</td>\n",
       "      <td>0.925597</td>\n",
       "      <td>0.350290</td>\n",
       "      <td>-1.334499</td>\n",
       "      <td>0.158525</td>\n",
       "      <td>0.196728</td>\n",
       "      <td>-0.741670</td>\n",
       "      <td>0.866594</td>\n",
       "      <td>0.963809</td>\n",
       "      <td>-0.469244</td>\n",
       "      <td>-1.067686</td>\n",
       "      <td>-1.129254</td>\n",
       "      <td>0.535855</td>\n",
       "      <td>0.666599</td>\n",
       "      <td>0.686998</td>\n",
       "      <td>0.564275</td>\n",
       "      <td>1.308418</td>\n",
       "      <td>-1.396716</td>\n",
       "      <td>-0.437832</td>\n",
       "      <td>0.079933</td>\n",
       "      <td>0.360537</td>\n",
       "      <td>0.292971</td>\n",
       "      <td>-0.116028</td>\n",
       "      <td>-0.894167</td>\n",
       "      <td>-0.397535</td>\n",
       "      <td>-1.844476</td>\n",
       "      <td>1.590235</td>\n",
       "      <td>1.005100</td>\n",
       "      <td>-0.479105</td>\n",
       "      <td>-0.022247</td>\n",
       "      <td>-0.094020</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>-0.595798</td>\n",
       "      <td>-0.719045</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.415970</td>\n",
       "      <td>0.192198</td>\n",
       "      <td>1.908867</td>\n",
       "      <td>-0.212232</td>\n",
       "      <td>1.695208</td>\n",
       "      <td>-0.375671</td>\n",
       "      <td>-1.039667</td>\n",
       "      <td>-0.071945</td>\n",
       "      <td>-0.259404</td>\n",
       "      <td>-0.311296</td>\n",
       "      <td>1.177409</td>\n",
       "      <td>-0.381267</td>\n",
       "      <td>-0.204936</td>\n",
       "      <td>0.440749</td>\n",
       "      <td>1.140490</td>\n",
       "      <td>0.325559</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>0.370672</td>\n",
       "      <td>0.200354</td>\n",
       "      <td>1.304703</td>\n",
       "      <td>0.426546</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>-0.532798</td>\n",
       "      <td>0.213759</td>\n",
       "      <td>1.000327</td>\n",
       "      <td>-0.836702</td>\n",
       "      <td>-0.025703</td>\n",
       "      <td>-0.398938</td>\n",
       "      <td>-1.270004</td>\n",
       "      <td>1.334919</td>\n",
       "      <td>-0.696158</td>\n",
       "      <td>0.990074</td>\n",
       "      <td>-0.176205</td>\n",
       "      <td>0.728910</td>\n",
       "      <td>1.382891</td>\n",
       "      <td>1.358496</td>\n",
       "      <td>-0.736983</td>\n",
       "      <td>0.443725</td>\n",
       "      <td>2.087483</td>\n",
       "      <td>-0.342266</td>\n",
       "      <td>-1.108642</td>\n",
       "      <td>0.700594</td>\n",
       "      <td>0.300006</td>\n",
       "      <td>0.165156</td>\n",
       "      <td>-1.559318</td>\n",
       "      <td>-0.073724</td>\n",
       "      <td>-1.701669</td>\n",
       "      <td>0.690037</td>\n",
       "      <td>0.414104</td>\n",
       "      <td>3.115894</td>\n",
       "      <td>0.405025</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.156077</td>\n",
       "      <td>0.203942</td>\n",
       "      <td>-0.211834</td>\n",
       "      <td>0.886861</td>\n",
       "      <td>0.129278</td>\n",
       "      <td>-0.252172</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>1.262887</td>\n",
       "      <td>0.533767</td>\n",
       "      <td>1.771051</td>\n",
       "      <td>-0.013550</td>\n",
       "      <td>1.451406</td>\n",
       "      <td>-0.058412</td>\n",
       "      <td>-0.583447</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>0.330361</td>\n",
       "      <td>-0.513667</td>\n",
       "      <td>0.073637</td>\n",
       "      <td>-0.690162</td>\n",
       "      <td>1.654467</td>\n",
       "      <td>-0.111805</td>\n",
       "      <td>0.142819</td>\n",
       "      <td>0.671254</td>\n",
       "      <td>0.369632</td>\n",
       "      <td>0.967312</td>\n",
       "      <td>1.374435</td>\n",
       "      <td>-0.874151</td>\n",
       "      <td>-1.144225</td>\n",
       "      <td>1.019966</td>\n",
       "      <td>1.018998</td>\n",
       "      <td>1.117493</td>\n",
       "      <td>1.086630</td>\n",
       "      <td>-1.995437</td>\n",
       "      <td>-1.221640</td>\n",
       "      <td>-0.795003</td>\n",
       "      <td>0.477054</td>\n",
       "      <td>1.819049</td>\n",
       "      <td>-0.504848</td>\n",
       "      <td>-0.521066</td>\n",
       "      <td>-2.085869</td>\n",
       "      <td>0.362313</td>\n",
       "      <td>-0.447498</td>\n",
       "      <td>-0.529677</td>\n",
       "      <td>-0.112675</td>\n",
       "      <td>-0.968909</td>\n",
       "      <td>-0.345379</td>\n",
       "      <td>-0.906018</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>-0.838569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434153</td>\n",
       "      <td>1.206081</td>\n",
       "      <td>0.150773</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>2.109957</td>\n",
       "      <td>0.795794</td>\n",
       "      <td>1.860197</td>\n",
       "      <td>1.422438</td>\n",
       "      <td>0.186060</td>\n",
       "      <td>-1.208392</td>\n",
       "      <td>3.726376</td>\n",
       "      <td>-1.124753</td>\n",
       "      <td>-0.374307</td>\n",
       "      <td>-0.941007</td>\n",
       "      <td>1.069548</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>-1.299383</td>\n",
       "      <td>-1.150289</td>\n",
       "      <td>-1.456446</td>\n",
       "      <td>-0.104901</td>\n",
       "      <td>-1.764054</td>\n",
       "      <td>-0.709223</td>\n",
       "      <td>-0.684062</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>-0.205188</td>\n",
       "      <td>2.997497</td>\n",
       "      <td>0.584322</td>\n",
       "      <td>0.107091</td>\n",
       "      <td>-0.817427</td>\n",
       "      <td>-0.402662</td>\n",
       "      <td>-0.217559</td>\n",
       "      <td>3.208972</td>\n",
       "      <td>1.936535</td>\n",
       "      <td>-2.353572</td>\n",
       "      <td>-1.043239</td>\n",
       "      <td>-0.395480</td>\n",
       "      <td>-0.756785</td>\n",
       "      <td>-0.633285</td>\n",
       "      <td>-0.619825</td>\n",
       "      <td>0.808968</td>\n",
       "      <td>2.700574</td>\n",
       "      <td>0.961883</td>\n",
       "      <td>1.883774</td>\n",
       "      <td>0.921742</td>\n",
       "      <td>0.448055</td>\n",
       "      <td>2.020965</td>\n",
       "      <td>0.177011</td>\n",
       "      <td>0.868984</td>\n",
       "      <td>-0.961136</td>\n",
       "      <td>0.330802</td>\n",
       "      <td>1.564309</td>\n",
       "      <td>1.625489</td>\n",
       "      <td>-0.281779</td>\n",
       "      <td>-0.715430</td>\n",
       "      <td>-1.958948</td>\n",
       "      <td>0.447220</td>\n",
       "      <td>0.329269</td>\n",
       "      <td>1.169679</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.403721</td>\n",
       "      <td>0.537984</td>\n",
       "      <td>-0.079475</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>-0.506511</td>\n",
       "      <td>-0.274696</td>\n",
       "      <td>-1.112889</td>\n",
       "      <td>-0.444293</td>\n",
       "      <td>-1.437797</td>\n",
       "      <td>1.970968</td>\n",
       "      <td>-0.130872</td>\n",
       "      <td>0.800040</td>\n",
       "      <td>0.999203</td>\n",
       "      <td>3.181453</td>\n",
       "      <td>-1.009423</td>\n",
       "      <td>-0.192768</td>\n",
       "      <td>-0.843526</td>\n",
       "      <td>-0.047717</td>\n",
       "      <td>-1.389858</td>\n",
       "      <td>0.076108</td>\n",
       "      <td>0.417925</td>\n",
       "      <td>0.194227</td>\n",
       "      <td>0.079506</td>\n",
       "      <td>1.761204</td>\n",
       "      <td>-0.196529</td>\n",
       "      <td>-0.345359</td>\n",
       "      <td>0.167509</td>\n",
       "      <td>-0.856075</td>\n",
       "      <td>-0.480276</td>\n",
       "      <td>-0.595143</td>\n",
       "      <td>1.359228</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>-0.774653</td>\n",
       "      <td>1.507355</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>-3.513256</td>\n",
       "      <td>-1.201888</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>-0.283312</td>\n",
       "      <td>1.438410</td>\n",
       "      <td>0.162633</td>\n",
       "      <td>-1.017552</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>-0.076950</td>\n",
       "      <td>-1.455438</td>\n",
       "      <td>-1.510636</td>\n",
       "      <td>-1.598739</td>\n",
       "      <td>1.097092</td>\n",
       "      <td>-0.129344</td>\n",
       "      <td>0.893002</td>\n",
       "      <td>0.668402</td>\n",
       "      <td>-0.576933</td>\n",
       "      <td>0.587953</td>\n",
       "      <td>-0.423664</td>\n",
       "      <td>-2.433777</td>\n",
       "      <td>-0.656909</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.385636</td>\n",
       "      <td>-2.035265</td>\n",
       "      <td>-0.328600</td>\n",
       "      <td>0.909439</td>\n",
       "      <td>-2.173843</td>\n",
       "      <td>-1.034031</td>\n",
       "      <td>-1.667850</td>\n",
       "      <td>-0.482389</td>\n",
       "      <td>-1.581094</td>\n",
       "      <td>-0.831508</td>\n",
       "      <td>1.381166</td>\n",
       "      <td>-1.574602</td>\n",
       "      <td>2.155435</td>\n",
       "      <td>-0.826005</td>\n",
       "      <td>0.547146</td>\n",
       "      <td>-1.230535</td>\n",
       "      <td>0.466566</td>\n",
       "      <td>-0.639817</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>-0.620772</td>\n",
       "      <td>1.156983</td>\n",
       "      <td>-0.819543</td>\n",
       "      <td>-0.082317</td>\n",
       "      <td>1.225233</td>\n",
       "      <td>0.333338</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>-1.935874</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>1.094999</td>\n",
       "      <td>-0.855543</td>\n",
       "      <td>0.398542</td>\n",
       "      <td>2.056795</td>\n",
       "      <td>0.645930</td>\n",
       "      <td>0.502006</td>\n",
       "      <td>-0.143065</td>\n",
       "      <td>-0.301165</td>\n",
       "      <td>-0.421267</td>\n",
       "      <td>0.138832</td>\n",
       "      <td>0.880904</td>\n",
       "      <td>-0.677348</td>\n",
       "      <td>0.176504</td>\n",
       "      <td>0.645967</td>\n",
       "      <td>0.650823</td>\n",
       "      <td>0.200482</td>\n",
       "      <td>0.237994</td>\n",
       "      <td>-0.032162</td>\n",
       "      <td>0.745519</td>\n",
       "      <td>-0.629411</td>\n",
       "      <td>1.143689</td>\n",
       "      <td>-1.604109</td>\n",
       "      <td>-2.672071</td>\n",
       "      <td>-1.086073</td>\n",
       "      <td>-1.153193</td>\n",
       "      <td>-1.244856</td>\n",
       "      <td>-1.808230</td>\n",
       "      <td>-0.343819</td>\n",
       "      <td>0.696333</td>\n",
       "      <td>0.605657</td>\n",
       "      <td>1.485467</td>\n",
       "      <td>0.958307</td>\n",
       "      <td>1.364136</td>\n",
       "      <td>1.615932</td>\n",
       "      <td>-1.589324</td>\n",
       "      <td>0.124813</td>\n",
       "      <td>3.476538</td>\n",
       "      <td>-1.651713</td>\n",
       "      <td>0.196496</td>\n",
       "      <td>0.838101</td>\n",
       "      <td>0.552354</td>\n",
       "      <td>0.365145</td>\n",
       "      <td>0.398903</td>\n",
       "      <td>0.463653</td>\n",
       "      <td>0.482275</td>\n",
       "      <td>-1.225037</td>\n",
       "      <td>-1.567086</td>\n",
       "      <td>-1.059002</td>\n",
       "      <td>0.976637</td>\n",
       "      <td>-0.361295</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>-0.533372</td>\n",
       "      <td>1.971480</td>\n",
       "      <td>3.340997</td>\n",
       "      <td>1.492394</td>\n",
       "      <td>-0.061122</td>\n",
       "      <td>0.039361</td>\n",
       "      <td>-0.047655</td>\n",
       "      <td>-2.270126</td>\n",
       "      <td>-0.784527</td>\n",
       "      <td>-0.584845</td>\n",
       "      <td>-0.637789</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-1.473687</td>\n",
       "      <td>-0.336676</td>\n",
       "      <td>0.682635</td>\n",
       "      <td>-0.865179</td>\n",
       "      <td>1.934080</td>\n",
       "      <td>0.562626</td>\n",
       "      <td>-0.925091</td>\n",
       "      <td>-0.589816</td>\n",
       "      <td>-1.527986</td>\n",
       "      <td>0.813502</td>\n",
       "      <td>-0.159169</td>\n",
       "      <td>-0.911981</td>\n",
       "      <td>-0.050088</td>\n",
       "      <td>-1.227765</td>\n",
       "      <td>-0.242872</td>\n",
       "      <td>-0.083652</td>\n",
       "      <td>-0.549532</td>\n",
       "      <td>1.754941</td>\n",
       "      <td>-0.684007</td>\n",
       "      <td>-0.341277</td>\n",
       "      <td>-1.912943</td>\n",
       "      <td>-1.304353</td>\n",
       "      <td>-1.080000</td>\n",
       "      <td>1.173887</td>\n",
       "      <td>-1.701301</td>\n",
       "      <td>-2.270804</td>\n",
       "      <td>-0.452933</td>\n",
       "      <td>-0.393757</td>\n",
       "      <td>0.422478</td>\n",
       "      <td>0.191194</td>\n",
       "      <td>-0.894515</td>\n",
       "      <td>1.162432</td>\n",
       "      <td>-1.287716</td>\n",
       "      <td>0.646284</td>\n",
       "      <td>0.828576</td>\n",
       "      <td>1.578059</td>\n",
       "      <td>-0.528061</td>\n",
       "      <td>0.434836</td>\n",
       "      <td>-0.139940</td>\n",
       "      <td>-0.479459</td>\n",
       "      <td>1.917953</td>\n",
       "      <td>-0.577839</td>\n",
       "      <td>-0.113396</td>\n",
       "      <td>-0.718580</td>\n",
       "      <td>0.133175</td>\n",
       "      <td>0.231806</td>\n",
       "      <td>-0.255969</td>\n",
       "      <td>-0.453090</td>\n",
       "      <td>-0.086771</td>\n",
       "      <td>-0.375448</td>\n",
       "      <td>-0.459839</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.392651</td>\n",
       "      <td>0.447061</td>\n",
       "      <td>1.573578</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.257810</td>\n",
       "      <td>-1.009131</td>\n",
       "      <td>-0.481152</td>\n",
       "      <td>1.610021</td>\n",
       "      <td>1.194109</td>\n",
       "      <td>0.879124</td>\n",
       "      <td>1.638457</td>\n",
       "      <td>0.535169</td>\n",
       "      <td>-0.412800</td>\n",
       "      <td>0.844973</td>\n",
       "      <td>0.199191</td>\n",
       "      <td>-0.088917</td>\n",
       "      <td>0.832241</td>\n",
       "      <td>3.758020</td>\n",
       "      <td>0.307153</td>\n",
       "      <td>0.245970</td>\n",
       "      <td>1.069626</td>\n",
       "      <td>-0.304140</td>\n",
       "      <td>1.523145</td>\n",
       "      <td>2.136030</td>\n",
       "      <td>1.750513</td>\n",
       "      <td>-0.703684</td>\n",
       "      <td>0.398442</td>\n",
       "      <td>0.088812</td>\n",
       "      <td>1.995421</td>\n",
       "      <td>0.172252</td>\n",
       "      <td>0.445806</td>\n",
       "      <td>1.657680</td>\n",
       "      <td>-1.380028</td>\n",
       "      <td>1.228994</td>\n",
       "      <td>1.310563</td>\n",
       "      <td>-1.473397</td>\n",
       "      <td>0.575366</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>-2.515727</td>\n",
       "      <td>-0.539719</td>\n",
       "      <td>-0.135895</td>\n",
       "      <td>-0.416555</td>\n",
       "      <td>0.386393</td>\n",
       "      <td>0.867638</td>\n",
       "      <td>2.497003</td>\n",
       "      <td>2.317963</td>\n",
       "      <td>0.588795</td>\n",
       "      <td>2.048123</td>\n",
       "      <td>0.654592</td>\n",
       "      <td>0.522593</td>\n",
       "      <td>-0.333932</td>\n",
       "      <td>3.291314</td>\n",
       "      <td>-0.762360</td>\n",
       "      <td>-0.518113</td>\n",
       "      <td>0.112524</td>\n",
       "      <td>1.582081</td>\n",
       "      <td>-0.243944</td>\n",
       "      <td>-1.898263</td>\n",
       "      <td>-0.916908</td>\n",
       "      <td>-1.615048</td>\n",
       "      <td>0.608734</td>\n",
       "      <td>-2.784957</td>\n",
       "      <td>-0.310580</td>\n",
       "      <td>-0.609623</td>\n",
       "      <td>1.085464</td>\n",
       "      <td>-0.423747</td>\n",
       "      <td>2.339907</td>\n",
       "      <td>-0.126940</td>\n",
       "      <td>0.526940</td>\n",
       "      <td>-0.483808</td>\n",
       "      <td>-0.118178</td>\n",
       "      <td>0.130625</td>\n",
       "      <td>3.239778</td>\n",
       "      <td>1.446435</td>\n",
       "      <td>-2.000875</td>\n",
       "      <td>-1.359139</td>\n",
       "      <td>-0.135077</td>\n",
       "      <td>-0.795243</td>\n",
       "      <td>-0.977312</td>\n",
       "      <td>-1.104910</td>\n",
       "      <td>1.216258</td>\n",
       "      <td>1.925100</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>2.084423</td>\n",
       "      <td>0.956260</td>\n",
       "      <td>0.198140</td>\n",
       "      <td>2.322518</td>\n",
       "      <td>-0.098558</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-0.486408</td>\n",
       "      <td>-0.083068</td>\n",
       "      <td>1.011507</td>\n",
       "      <td>1.924402</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.837520</td>\n",
       "      <td>-0.572303</td>\n",
       "      <td>0.337962</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>1.690042</td>\n",
       "      <td>-0.332293</td>\n",
       "      <td>0.243604</td>\n",
       "      <td>1.591646</td>\n",
       "      <td>-1.002984</td>\n",
       "      <td>0.426982</td>\n",
       "      <td>0.189514</td>\n",
       "      <td>-0.027883</td>\n",
       "      <td>-0.664231</td>\n",
       "      <td>-0.542474</td>\n",
       "      <td>-0.997227</td>\n",
       "      <td>2.106505</td>\n",
       "      <td>-0.808882</td>\n",
       "      <td>0.215036</td>\n",
       "      <td>1.016699</td>\n",
       "      <td>1.974719</td>\n",
       "      <td>-1.465513</td>\n",
       "      <td>-0.605051</td>\n",
       "      <td>-1.078684</td>\n",
       "      <td>-0.240947</td>\n",
       "      <td>-1.797558</td>\n",
       "      <td>-0.066982</td>\n",
       "      <td>0.642976</td>\n",
       "      <td>0.590408</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>2.131639</td>\n",
       "      <td>-0.321352</td>\n",
       "      <td>0.165624</td>\n",
       "      <td>0.571824</td>\n",
       "      <td>-1.157328</td>\n",
       "      <td>-0.228136</td>\n",
       "      <td>-1.693766</td>\n",
       "      <td>0.980970</td>\n",
       "      <td>-0.857211</td>\n",
       "      <td>-1.092012</td>\n",
       "      <td>2.712574</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>-3.041883</td>\n",
       "      <td>-1.357169</td>\n",
       "      <td>0.678533</td>\n",
       "      <td>-0.430885</td>\n",
       "      <td>1.561432</td>\n",
       "      <td>0.377032</td>\n",
       "      <td>-0.456671</td>\n",
       "      <td>0.375580</td>\n",
       "      <td>0.766604</td>\n",
       "      <td>-0.213509</td>\n",
       "      <td>-1.601295</td>\n",
       "      <td>-0.848659</td>\n",
       "      <td>-0.136543</td>\n",
       "      <td>-0.920087</td>\n",
       "      <td>0.381922</td>\n",
       "      <td>0.349931</td>\n",
       "      <td>-1.011542</td>\n",
       "      <td>0.202610</td>\n",
       "      <td>-0.466574</td>\n",
       "      <td>-2.041902</td>\n",
       "      <td>-0.496363</td>\n",
       "      <td>1.042316</td>\n",
       "      <td>-0.404857</td>\n",
       "      <td>-1.593709</td>\n",
       "      <td>-0.116089</td>\n",
       "      <td>1.728275</td>\n",
       "      <td>-1.909610</td>\n",
       "      <td>-0.650960</td>\n",
       "      <td>-0.947501</td>\n",
       "      <td>-1.300341</td>\n",
       "      <td>-1.109327</td>\n",
       "      <td>-0.737327</td>\n",
       "      <td>0.527147</td>\n",
       "      <td>-1.412024</td>\n",
       "      <td>2.024745</td>\n",
       "      <td>-0.867578</td>\n",
       "      <td>0.321822</td>\n",
       "      <td>-1.240001</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>-1.034443</td>\n",
       "      <td>1.136397</td>\n",
       "      <td>-0.797087</td>\n",
       "      <td>0.305660</td>\n",
       "      <td>-0.504389</td>\n",
       "      <td>0.425315</td>\n",
       "      <td>0.776376</td>\n",
       "      <td>0.420396</td>\n",
       "      <td>-0.083177</td>\n",
       "      <td>-2.033573</td>\n",
       "      <td>0.522294</td>\n",
       "      <td>1.122542</td>\n",
       "      <td>-0.566058</td>\n",
       "      <td>0.482305</td>\n",
       "      <td>1.832744</td>\n",
       "      <td>1.469187</td>\n",
       "      <td>-0.040361</td>\n",
       "      <td>-0.324278</td>\n",
       "      <td>-0.730243</td>\n",
       "      <td>-0.789079</td>\n",
       "      <td>-0.716367</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>-0.255326</td>\n",
       "      <td>-0.393352</td>\n",
       "      <td>1.192755</td>\n",
       "      <td>0.483635</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.700571</td>\n",
       "      <td>-0.770126</td>\n",
       "      <td>0.544596</td>\n",
       "      <td>-0.292172</td>\n",
       "      <td>0.547082</td>\n",
       "      <td>-0.857410</td>\n",
       "      <td>-3.624099</td>\n",
       "      <td>-1.063880</td>\n",
       "      <td>-0.926626</td>\n",
       "      <td>-1.274943</td>\n",
       "      <td>-1.332040</td>\n",
       "      <td>-0.742028</td>\n",
       "      <td>0.294205</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>1.286825</td>\n",
       "      <td>0.381482</td>\n",
       "      <td>2.440165</td>\n",
       "      <td>1.234699</td>\n",
       "      <td>-0.920676</td>\n",
       "      <td>-0.709399</td>\n",
       "      <td>3.313163</td>\n",
       "      <td>-1.694287</td>\n",
       "      <td>0.691302</td>\n",
       "      <td>0.810359</td>\n",
       "      <td>1.600314</td>\n",
       "      <td>0.918687</td>\n",
       "      <td>-1.238990</td>\n",
       "      <td>0.894379</td>\n",
       "      <td>0.719688</td>\n",
       "      <td>-0.795664</td>\n",
       "      <td>-1.368401</td>\n",
       "      <td>-0.841390</td>\n",
       "      <td>0.854525</td>\n",
       "      <td>0.067995</td>\n",
       "      <td>-0.546375</td>\n",
       "      <td>0.186418</td>\n",
       "      <td>2.695565</td>\n",
       "      <td>3.062319</td>\n",
       "      <td>1.936745</td>\n",
       "      <td>-0.062617</td>\n",
       "      <td>-0.742697</td>\n",
       "      <td>-0.185129</td>\n",
       "      <td>-2.177635</td>\n",
       "      <td>-1.181660</td>\n",
       "      <td>-0.190314</td>\n",
       "      <td>-1.354935</td>\n",
       "      <td>-0.344484</td>\n",
       "      <td>-1.955473</td>\n",
       "      <td>-0.279924</td>\n",
       "      <td>0.224604</td>\n",
       "      <td>-0.997600</td>\n",
       "      <td>2.454962</td>\n",
       "      <td>-0.049400</td>\n",
       "      <td>-0.706331</td>\n",
       "      <td>-0.245401</td>\n",
       "      <td>-1.817734</td>\n",
       "      <td>0.209763</td>\n",
       "      <td>-0.698237</td>\n",
       "      <td>-0.516894</td>\n",
       "      <td>0.441319</td>\n",
       "      <td>-1.507942</td>\n",
       "      <td>-0.480132</td>\n",
       "      <td>-1.188236</td>\n",
       "      <td>-0.186589</td>\n",
       "      <td>2.428046</td>\n",
       "      <td>-1.389688</td>\n",
       "      <td>-0.842454</td>\n",
       "      <td>-2.011715</td>\n",
       "      <td>-0.835351</td>\n",
       "      <td>-1.849395</td>\n",
       "      <td>0.651426</td>\n",
       "      <td>-3.437734</td>\n",
       "      <td>-1.431448</td>\n",
       "      <td>-0.079648</td>\n",
       "      <td>0.129953</td>\n",
       "      <td>-0.318190</td>\n",
       "      <td>0.275246</td>\n",
       "      <td>-0.352045</td>\n",
       "      <td>0.801457</td>\n",
       "      <td>-1.751329</td>\n",
       "      <td>0.931245</td>\n",
       "      <td>1.041881</td>\n",
       "      <td>0.690224</td>\n",
       "      <td>-0.433844</td>\n",
       "      <td>0.545124</td>\n",
       "      <td>-0.594270</td>\n",
       "      <td>-1.397727</td>\n",
       "      <td>2.254061</td>\n",
       "      <td>-0.532189</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>-1.023834</td>\n",
       "      <td>0.337781</td>\n",
       "      <td>1.208348</td>\n",
       "      <td>0.657064</td>\n",
       "      <td>-0.952555</td>\n",
       "      <td>-0.213997</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>-0.521551</td>\n",
       "      <td>1.076055</td>\n",
       "      <td>0.978732</td>\n",
       "      <td>0.507640</td>\n",
       "      <td>1.640890</td>\n",
       "      <td>-0.260969</td>\n",
       "      <td>0.756040</td>\n",
       "      <td>-0.922523</td>\n",
       "      <td>-1.098445</td>\n",
       "      <td>1.085845</td>\n",
       "      <td>0.983436</td>\n",
       "      <td>1.516064</td>\n",
       "      <td>1.090084</td>\n",
       "      <td>1.575156</td>\n",
       "      <td>-0.952378</td>\n",
       "      <td>0.918275</td>\n",
       "      <td>-0.637056</td>\n",
       "      <td>-0.971134</td>\n",
       "      <td>0.966550</td>\n",
       "      <td>3.597453</td>\n",
       "      <td>0.358422</td>\n",
       "      <td>0.110659</td>\n",
       "      <td>1.031254</td>\n",
       "      <td>-0.302844</td>\n",
       "      <td>1.651601</td>\n",
       "      <td>1.917125</td>\n",
       "      <td>1.546345</td>\n",
       "      <td>-0.253397</td>\n",
       "      <td>0.089964</td>\n",
       "      <td>-0.281379</td>\n",
       "      <td>1.739010</td>\n",
       "      <td>0.506656</td>\n",
       "      <td>0.908107</td>\n",
       "      <td>1.035577</td>\n",
       "      <td>-0.709105</td>\n",
       "      <td>1.692271</td>\n",
       "      <td>0.135749</td>\n",
       "      <td>-1.743576</td>\n",
       "      <td>1.470809</td>\n",
       "      <td>-0.821352</td>\n",
       "      <td>-2.076550</td>\n",
       "      <td>-0.763551</td>\n",
       "      <td>-0.629763</td>\n",
       "      <td>-0.849662</td>\n",
       "      <td>-0.091016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900839</td>\n",
       "      <td>0.900839</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>4031.773204</td>\n",
       "      <td>0.943992</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3671.518900</td>\n",
       "      <td>0.650968</td>\n",
       "      <td>-0.839539</td>\n",
       "      <td>-0.211711</td>\n",
       "      <td>0.974679</td>\n",
       "      <td>-0.889926</td>\n",
       "      <td>-0.872017</td>\n",
       "      <td>-1.082224</td>\n",
       "      <td>-1.094154</td>\n",
       "      <td>-0.431798</td>\n",
       "      <td>-0.208143</td>\n",
       "      <td>1.339280</td>\n",
       "      <td>-0.841586</td>\n",
       "      <td>-1.119783</td>\n",
       "      <td>1.155976</td>\n",
       "      <td>0.091337</td>\n",
       "      <td>-0.760947</td>\n",
       "      <td>-0.331795</td>\n",
       "      <td>0.409410</td>\n",
       "      <td>-0.503205</td>\n",
       "      <td>-0.122574</td>\n",
       "      <td>0.720503</td>\n",
       "      <td>1.093278</td>\n",
       "      <td>-0.055583</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>-0.122841</td>\n",
       "      <td>-0.768435</td>\n",
       "      <td>0.566846</td>\n",
       "      <td>-0.260990</td>\n",
       "      <td>-0.311526</td>\n",
       "      <td>0.234926</td>\n",
       "      <td>0.399198</td>\n",
       "      <td>0.600884</td>\n",
       "      <td>-0.267569</td>\n",
       "      <td>0.536874</td>\n",
       "      <td>-0.033552</td>\n",
       "      <td>-0.069780</td>\n",
       "      <td>0.649860</td>\n",
       "      <td>-0.349039</td>\n",
       "      <td>0.193341</td>\n",
       "      <td>0.577582</td>\n",
       "      <td>1.001017</td>\n",
       "      <td>0.673161</td>\n",
       "      <td>0.388687</td>\n",
       "      <td>-0.688430</td>\n",
       "      <td>0.103020</td>\n",
       "      <td>-0.338772</td>\n",
       "      <td>-0.205373</td>\n",
       "      <td>-0.839584</td>\n",
       "      <td>-0.511054</td>\n",
       "      <td>-0.026620</td>\n",
       "      <td>0.357749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.485972</td>\n",
       "      <td>-0.485972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918824</td>\n",
       "      <td>0.544205</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.437657</td>\n",
       "      <td>2.562041</td>\n",
       "      <td>-1.973382</td>\n",
       "      <td>0.776680</td>\n",
       "      <td>0.633268</td>\n",
       "      <td>0.121370</td>\n",
       "      <td>0.512068</td>\n",
       "      <td>1.071055</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>0.279853</td>\n",
       "      <td>0.331998</td>\n",
       "      <td>0.356469</td>\n",
       "      <td>0.544885</td>\n",
       "      <td>-1.406893</td>\n",
       "      <td>-0.239091</td>\n",
       "      <td>2.118357</td>\n",
       "      <td>0.217145</td>\n",
       "      <td>0.563323</td>\n",
       "      <td>0.240454</td>\n",
       "      <td>-2.339355</td>\n",
       "      <td>-0.386535</td>\n",
       "      <td>-0.732332</td>\n",
       "      <td>0.438491</td>\n",
       "      <td>0.424989</td>\n",
       "      <td>1.026062</td>\n",
       "      <td>0.809266</td>\n",
       "      <td>-2.063265</td>\n",
       "      <td>-1.443029</td>\n",
       "      <td>0.278436</td>\n",
       "      <td>-0.780422</td>\n",
       "      <td>1.193820</td>\n",
       "      <td>-0.994855</td>\n",
       "      <td>-0.982404</td>\n",
       "      <td>-0.742882</td>\n",
       "      <td>0.186565</td>\n",
       "      <td>-2.376219</td>\n",
       "      <td>-1.697286</td>\n",
       "      <td>0.054877</td>\n",
       "      <td>-0.058728</td>\n",
       "      <td>-2.851856</td>\n",
       "      <td>1.478205</td>\n",
       "      <td>-0.430847</td>\n",
       "      <td>1.174317</td>\n",
       "      <td>-1.395007</td>\n",
       "      <td>-2.036987</td>\n",
       "      <td>2.325831</td>\n",
       "      <td>-1.832412</td>\n",
       "      <td>0.171078</td>\n",
       "      <td>-1.051681</td>\n",
       "      <td>0.188340</td>\n",
       "      <td>1.034116</td>\n",
       "      <td>0.204263</td>\n",
       "      <td>0.850631</td>\n",
       "      <td>-0.553500</td>\n",
       "      <td>-0.643710</td>\n",
       "      <td>-0.527655</td>\n",
       "      <td>1.796899</td>\n",
       "      <td>2.432998</td>\n",
       "      <td>0.585732</td>\n",
       "      <td>0.601812</td>\n",
       "      <td>0.933818</td>\n",
       "      <td>-0.719510</td>\n",
       "      <td>-0.253820</td>\n",
       "      <td>-2.121101</td>\n",
       "      <td>0.102637</td>\n",
       "      <td>-0.423979</td>\n",
       "      <td>-0.145309</td>\n",
       "      <td>-1.061021</td>\n",
       "      <td>-0.322560</td>\n",
       "      <td>-0.697297</td>\n",
       "      <td>1.122057</td>\n",
       "      <td>-0.672309</td>\n",
       "      <td>-0.666380</td>\n",
       "      <td>-0.333801</td>\n",
       "      <td>1.304955</td>\n",
       "      <td>1.770791</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.258699</td>\n",
       "      <td>-0.399684</td>\n",
       "      <td>1.342896</td>\n",
       "      <td>1.388841</td>\n",
       "      <td>0.433723</td>\n",
       "      <td>-0.075009</td>\n",
       "      <td>0.344631</td>\n",
       "      <td>-0.293901</td>\n",
       "      <td>2.612565</td>\n",
       "      <td>0.752659</td>\n",
       "      <td>0.265860</td>\n",
       "      <td>-0.186673</td>\n",
       "      <td>1.433210</td>\n",
       "      <td>-1.350801</td>\n",
       "      <td>-1.919876</td>\n",
       "      <td>-1.201913</td>\n",
       "      <td>0.400730</td>\n",
       "      <td>-0.672398</td>\n",
       "      <td>1.049490</td>\n",
       "      <td>0.073956</td>\n",
       "      <td>1.593532</td>\n",
       "      <td>0.495343</td>\n",
       "      <td>0.616688</td>\n",
       "      <td>-0.352269</td>\n",
       "      <td>-0.415953</td>\n",
       "      <td>-1.157527</td>\n",
       "      <td>-1.507581</td>\n",
       "      <td>-0.813093</td>\n",
       "      <td>-0.413244</td>\n",
       "      <td>0.682313</td>\n",
       "      <td>0.097441</td>\n",
       "      <td>-0.206794</td>\n",
       "      <td>0.983427</td>\n",
       "      <td>-0.423916</td>\n",
       "      <td>0.211599</td>\n",
       "      <td>-1.090864</td>\n",
       "      <td>0.487847</td>\n",
       "      <td>0.276650</td>\n",
       "      <td>0.881760</td>\n",
       "      <td>1.089920</td>\n",
       "      <td>-0.559290</td>\n",
       "      <td>0.569919</td>\n",
       "      <td>0.260578</td>\n",
       "      <td>1.599541</td>\n",
       "      <td>-1.161874</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>0.137455</td>\n",
       "      <td>-1.543321</td>\n",
       "      <td>0.115305</td>\n",
       "      <td>-1.981614</td>\n",
       "      <td>-1.253748</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.064887</td>\n",
       "      <td>-1.476125</td>\n",
       "      <td>1.506110</td>\n",
       "      <td>1.547394</td>\n",
       "      <td>-0.177550</td>\n",
       "      <td>0.321237</td>\n",
       "      <td>0.463852</td>\n",
       "      <td>-0.383651</td>\n",
       "      <td>0.858723</td>\n",
       "      <td>1.604267</td>\n",
       "      <td>2.159848</td>\n",
       "      <td>-0.893472</td>\n",
       "      <td>-0.665985</td>\n",
       "      <td>-2.231206</td>\n",
       "      <td>-1.036411</td>\n",
       "      <td>-0.039208</td>\n",
       "      <td>0.394180</td>\n",
       "      <td>1.070104</td>\n",
       "      <td>-0.155360</td>\n",
       "      <td>0.143959</td>\n",
       "      <td>-0.632057</td>\n",
       "      <td>-0.277500</td>\n",
       "      <td>-0.058644</td>\n",
       "      <td>1.106276</td>\n",
       "      <td>0.976601</td>\n",
       "      <td>-0.091989</td>\n",
       "      <td>0.178986</td>\n",
       "      <td>0.186994</td>\n",
       "      <td>0.795719</td>\n",
       "      <td>-1.449248</td>\n",
       "      <td>1.612446</td>\n",
       "      <td>1.160928</td>\n",
       "      <td>-0.690812</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>1.092277</td>\n",
       "      <td>0.113299</td>\n",
       "      <td>-1.155190</td>\n",
       "      <td>0.329129</td>\n",
       "      <td>-0.514367</td>\n",
       "      <td>-0.532714</td>\n",
       "      <td>-0.222083</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>-1.903709</td>\n",
       "      <td>-0.152132</td>\n",
       "      <td>1.000410</td>\n",
       "      <td>0.158749</td>\n",
       "      <td>0.139780</td>\n",
       "      <td>-0.226797</td>\n",
       "      <td>-0.596755</td>\n",
       "      <td>0.434450</td>\n",
       "      <td>2.131264</td>\n",
       "      <td>0.853967</td>\n",
       "      <td>1.419958</td>\n",
       "      <td>0.953190</td>\n",
       "      <td>-0.409257</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>-1.694101</td>\n",
       "      <td>0.968050</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>-0.843586</td>\n",
       "      <td>0.680137</td>\n",
       "      <td>0.326001</td>\n",
       "      <td>0.868159</td>\n",
       "      <td>2.212918</td>\n",
       "      <td>0.330471</td>\n",
       "      <td>1.394387</td>\n",
       "      <td>-0.217301</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>-0.099003</td>\n",
       "      <td>-1.240654</td>\n",
       "      <td>0.448395</td>\n",
       "      <td>1.507743</td>\n",
       "      <td>0.519082</td>\n",
       "      <td>-0.222595</td>\n",
       "      <td>-0.946407</td>\n",
       "      <td>-0.847145</td>\n",
       "      <td>-0.740313</td>\n",
       "      <td>-0.459758</td>\n",
       "      <td>0.490638</td>\n",
       "      <td>-1.950370</td>\n",
       "      <td>-0.622510</td>\n",
       "      <td>-0.534922</td>\n",
       "      <td>1.077276</td>\n",
       "      <td>-0.378494</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.179031</td>\n",
       "      <td>-1.862846</td>\n",
       "      <td>0.587634</td>\n",
       "      <td>0.944031</td>\n",
       "      <td>0.422150</td>\n",
       "      <td>1.329961</td>\n",
       "      <td>-0.866196</td>\n",
       "      <td>-0.805107</td>\n",
       "      <td>-1.185908</td>\n",
       "      <td>-0.988003</td>\n",
       "      <td>-0.141820</td>\n",
       "      <td>-0.736000</td>\n",
       "      <td>2.522639</td>\n",
       "      <td>0.912305</td>\n",
       "      <td>1.185656</td>\n",
       "      <td>-0.025061</td>\n",
       "      <td>-0.483935</td>\n",
       "      <td>-0.626872</td>\n",
       "      <td>-0.526157</td>\n",
       "      <td>1.277105</td>\n",
       "      <td>0.760258</td>\n",
       "      <td>-0.274568</td>\n",
       "      <td>-0.270635</td>\n",
       "      <td>-0.507063</td>\n",
       "      <td>0.516650</td>\n",
       "      <td>1.133784</td>\n",
       "      <td>-0.647120</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>0.230096</td>\n",
       "      <td>-1.024919</td>\n",
       "      <td>0.402066</td>\n",
       "      <td>-1.542951</td>\n",
       "      <td>0.386366</td>\n",
       "      <td>-0.450826</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>-1.351828</td>\n",
       "      <td>-0.539576</td>\n",
       "      <td>1.332920</td>\n",
       "      <td>1.342855</td>\n",
       "      <td>-0.847843</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>-0.777971</td>\n",
       "      <td>-0.503098</td>\n",
       "      <td>0.028709</td>\n",
       "      <td>0.461681</td>\n",
       "      <td>1.254190</td>\n",
       "      <td>0.576517</td>\n",
       "      <td>-1.259330</td>\n",
       "      <td>1.422039</td>\n",
       "      <td>1.206135</td>\n",
       "      <td>-1.333255</td>\n",
       "      <td>0.163894</td>\n",
       "      <td>1.930248</td>\n",
       "      <td>0.267424</td>\n",
       "      <td>0.818141</td>\n",
       "      <td>-0.163666</td>\n",
       "      <td>-0.665025</td>\n",
       "      <td>0.507948</td>\n",
       "      <td>-0.088976</td>\n",
       "      <td>1.929185</td>\n",
       "      <td>0.332618</td>\n",
       "      <td>0.745332</td>\n",
       "      <td>-1.237791</td>\n",
       "      <td>-0.254801</td>\n",
       "      <td>0.711287</td>\n",
       "      <td>0.256910</td>\n",
       "      <td>-0.502800</td>\n",
       "      <td>1.166874</td>\n",
       "      <td>0.248282</td>\n",
       "      <td>0.658714</td>\n",
       "      <td>2.121927</td>\n",
       "      <td>-0.534511</td>\n",
       "      <td>-1.455228</td>\n",
       "      <td>0.908396</td>\n",
       "      <td>-0.195731</td>\n",
       "      <td>1.478527</td>\n",
       "      <td>0.149412</td>\n",
       "      <td>1.101536</td>\n",
       "      <td>-0.617558</td>\n",
       "      <td>0.142885</td>\n",
       "      <td>-0.423314</td>\n",
       "      <td>-2.025983</td>\n",
       "      <td>0.568714</td>\n",
       "      <td>-0.086980</td>\n",
       "      <td>0.307637</td>\n",
       "      <td>0.192920</td>\n",
       "      <td>0.272594</td>\n",
       "      <td>-0.460424</td>\n",
       "      <td>-0.433137</td>\n",
       "      <td>0.370446</td>\n",
       "      <td>-0.077101</td>\n",
       "      <td>0.210270</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.100652</td>\n",
       "      <td>-1.066337</td>\n",
       "      <td>-0.285520</td>\n",
       "      <td>2.233902</td>\n",
       "      <td>-0.540235</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>0.881088</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>-0.145468</td>\n",
       "      <td>0.279766</td>\n",
       "      <td>-0.226982</td>\n",
       "      <td>-1.608228</td>\n",
       "      <td>1.068846</td>\n",
       "      <td>0.668085</td>\n",
       "      <td>-0.710997</td>\n",
       "      <td>1.301457</td>\n",
       "      <td>-0.321273</td>\n",
       "      <td>-1.008095</td>\n",
       "      <td>-0.726460</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>-2.884139</td>\n",
       "      <td>0.919232</td>\n",
       "      <td>-0.737601</td>\n",
       "      <td>-0.193718</td>\n",
       "      <td>-0.149832</td>\n",
       "      <td>1.053995</td>\n",
       "      <td>-1.692510</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>-2.582842</td>\n",
       "      <td>0.544625</td>\n",
       "      <td>0.498196</td>\n",
       "      <td>1.027926</td>\n",
       "      <td>1.138160</td>\n",
       "      <td>0.434688</td>\n",
       "      <td>1.059954</td>\n",
       "      <td>0.229085</td>\n",
       "      <td>0.599388</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>1.056808</td>\n",
       "      <td>-0.675476</td>\n",
       "      <td>0.771202</td>\n",
       "      <td>1.386451</td>\n",
       "      <td>1.341247</td>\n",
       "      <td>-0.438266</td>\n",
       "      <td>0.480418</td>\n",
       "      <td>-1.097940</td>\n",
       "      <td>0.730400</td>\n",
       "      <td>-1.130413</td>\n",
       "      <td>3.477477</td>\n",
       "      <td>-0.856292</td>\n",
       "      <td>-0.821568</td>\n",
       "      <td>-1.579323</td>\n",
       "      <td>0.232314</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>1.059071</td>\n",
       "      <td>-1.028322</td>\n",
       "      <td>-0.038565</td>\n",
       "      <td>0.757480</td>\n",
       "      <td>0.214033</td>\n",
       "      <td>-0.398716</td>\n",
       "      <td>-0.202130</td>\n",
       "      <td>0.206025</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-0.419664</td>\n",
       "      <td>0.638257</td>\n",
       "      <td>-0.696088</td>\n",
       "      <td>-1.987984</td>\n",
       "      <td>-0.541385</td>\n",
       "      <td>-0.894179</td>\n",
       "      <td>-1.244731</td>\n",
       "      <td>-0.986726</td>\n",
       "      <td>0.116398</td>\n",
       "      <td>-0.075759</td>\n",
       "      <td>0.280948</td>\n",
       "      <td>-0.320632</td>\n",
       "      <td>-0.353044</td>\n",
       "      <td>0.254274</td>\n",
       "      <td>-1.404474</td>\n",
       "      <td>-0.315717</td>\n",
       "      <td>1.567673</td>\n",
       "      <td>1.526419</td>\n",
       "      <td>3.053079</td>\n",
       "      <td>0.792237</td>\n",
       "      <td>1.582020</td>\n",
       "      <td>0.994448</td>\n",
       "      <td>0.615992</td>\n",
       "      <td>-0.332766</td>\n",
       "      <td>0.136453</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>-0.156905</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-1.179923</td>\n",
       "      <td>0.500368</td>\n",
       "      <td>-2.293601</td>\n",
       "      <td>-0.491580</td>\n",
       "      <td>-0.753630</td>\n",
       "      <td>-0.057181</td>\n",
       "      <td>-0.910655</td>\n",
       "      <td>-0.682927</td>\n",
       "      <td>-0.488964</td>\n",
       "      <td>-0.485346</td>\n",
       "      <td>-0.137074</td>\n",
       "      <td>-2.422071</td>\n",
       "      <td>0.803092</td>\n",
       "      <td>-0.337353</td>\n",
       "      <td>-0.160241</td>\n",
       "      <td>1.398258</td>\n",
       "      <td>-0.303171</td>\n",
       "      <td>-0.177206</td>\n",
       "      <td>1.476771</td>\n",
       "      <td>2.246683</td>\n",
       "      <td>0.237326</td>\n",
       "      <td>-1.112413</td>\n",
       "      <td>-0.584382</td>\n",
       "      <td>0.830218</td>\n",
       "      <td>0.306113</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>-0.968239</td>\n",
       "      <td>-0.511667</td>\n",
       "      <td>-1.760786</td>\n",
       "      <td>1.315366</td>\n",
       "      <td>-0.943056</td>\n",
       "      <td>2.496364</td>\n",
       "      <td>-1.742019</td>\n",
       "      <td>0.327766</td>\n",
       "      <td>-0.371923</td>\n",
       "      <td>-0.324404</td>\n",
       "      <td>-0.486523</td>\n",
       "      <td>-0.253413</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.760083</td>\n",
       "      <td>-0.108056</td>\n",
       "      <td>0.539889</td>\n",
       "      <td>-0.263306</td>\n",
       "      <td>-0.368366</td>\n",
       "      <td>1.475588</td>\n",
       "      <td>1.055376</td>\n",
       "      <td>-0.789983</td>\n",
       "      <td>0.838024</td>\n",
       "      <td>-0.520997</td>\n",
       "      <td>0.400584</td>\n",
       "      <td>-1.330011</td>\n",
       "      <td>1.256356</td>\n",
       "      <td>-2.526202</td>\n",
       "      <td>-0.746436</td>\n",
       "      <td>-1.805335</td>\n",
       "      <td>-0.223712</td>\n",
       "      <td>0.627709</td>\n",
       "      <td>0.297980</td>\n",
       "      <td>-1.638036</td>\n",
       "      <td>-1.659034</td>\n",
       "      <td>-0.935066</td>\n",
       "      <td>-0.128931</td>\n",
       "      <td>-0.391013</td>\n",
       "      <td>0.439912</td>\n",
       "      <td>-0.538392</td>\n",
       "      <td>-0.168932</td>\n",
       "      <td>0.436978</td>\n",
       "      <td>-1.107113</td>\n",
       "      <td>-0.035451</td>\n",
       "      <td>0.351214</td>\n",
       "      <td>-1.806823</td>\n",
       "      <td>0.989469</td>\n",
       "      <td>0.344223</td>\n",
       "      <td>-0.477662</td>\n",
       "      <td>-0.066688</td>\n",
       "      <td>0.384417</td>\n",
       "      <td>0.145089</td>\n",
       "      <td>-0.255522</td>\n",
       "      <td>0.440796</td>\n",
       "      <td>0.101217</td>\n",
       "      <td>0.539149</td>\n",
       "      <td>-1.155940</td>\n",
       "      <td>-0.833961</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>-0.291243</td>\n",
       "      <td>1.403322</td>\n",
       "      <td>-1.127266</td>\n",
       "      <td>-1.200699</td>\n",
       "      <td>-2.315492</td>\n",
       "      <td>-0.236222</td>\n",
       "      <td>2.007709</td>\n",
       "      <td>1.149008</td>\n",
       "      <td>-0.216890</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.065379</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>-0.637307</td>\n",
       "      <td>-1.765990</td>\n",
       "      <td>0.819612</td>\n",
       "      <td>-0.673463</td>\n",
       "      <td>0.893520</td>\n",
       "      <td>-0.322952</td>\n",
       "      <td>1.084269</td>\n",
       "      <td>-0.838756</td>\n",
       "      <td>-1.634543</td>\n",
       "      <td>-0.205709</td>\n",
       "      <td>-0.880008</td>\n",
       "      <td>-0.212725</td>\n",
       "      <td>0.638357</td>\n",
       "      <td>-1.086961</td>\n",
       "      <td>-0.581592</td>\n",
       "      <td>-0.441600</td>\n",
       "      <td>-0.252946</td>\n",
       "      <td>0.263518</td>\n",
       "      <td>0.423076</td>\n",
       "      <td>-0.316567</td>\n",
       "      <td>-0.401965</td>\n",
       "      <td>0.813574</td>\n",
       "      <td>0.874442</td>\n",
       "      <td>0.690837</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.573135</td>\n",
       "      <td>1.354777</td>\n",
       "      <td>-1.544929</td>\n",
       "      <td>-0.886890</td>\n",
       "      <td>0.450444</td>\n",
       "      <td>-1.533121</td>\n",
       "      <td>0.365734</td>\n",
       "      <td>0.585115</td>\n",
       "      <td>-0.533361</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>0.852503</td>\n",
       "      <td>0.632852</td>\n",
       "      <td>0.321781</td>\n",
       "      <td>0.354586</td>\n",
       "      <td>-0.263692</td>\n",
       "      <td>1.970611</td>\n",
       "      <td>0.089999</td>\n",
       "      <td>-0.704449</td>\n",
       "      <td>1.004763</td>\n",
       "      <td>0.660697</td>\n",
       "      <td>0.870158</td>\n",
       "      <td>-0.168570</td>\n",
       "      <td>-2.369758</td>\n",
       "      <td>0.617121</td>\n",
       "      <td>-2.885632</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.323713</td>\n",
       "      <td>2.394321</td>\n",
       "      <td>1.554342</td>\n",
       "      <td>-0.864331</td>\n",
       "      <td>0.099196</td>\n",
       "      <td>-0.425443</td>\n",
       "      <td>-1.491097</td>\n",
       "      <td>0.581486</td>\n",
       "      <td>1.000219</td>\n",
       "      <td>-0.728757</td>\n",
       "      <td>-1.110799</td>\n",
       "      <td>1.009554</td>\n",
       "      <td>0.449013</td>\n",
       "      <td>1.211449</td>\n",
       "      <td>-0.461054</td>\n",
       "      <td>2.098341</td>\n",
       "      <td>-0.602972</td>\n",
       "      <td>-0.870070</td>\n",
       "      <td>-1.789200</td>\n",
       "      <td>-0.147982</td>\n",
       "      <td>0.219806</td>\n",
       "      <td>0.713491</td>\n",
       "      <td>-0.116881</td>\n",
       "      <td>0.956688</td>\n",
       "      <td>0.618796</td>\n",
       "      <td>0.802726</td>\n",
       "      <td>-0.119150</td>\n",
       "      <td>-0.275146</td>\n",
       "      <td>1.384049</td>\n",
       "      <td>1.442437</td>\n",
       "      <td>-0.450161</td>\n",
       "      <td>-1.955015</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>1.973306</td>\n",
       "      <td>-1.849791</td>\n",
       "      <td>0.494718</td>\n",
       "      <td>-2.492603</td>\n",
       "      <td>-1.170297</td>\n",
       "      <td>-0.483610</td>\n",
       "      <td>0.146898</td>\n",
       "      <td>-0.759364</td>\n",
       "      <td>-0.336091</td>\n",
       "      <td>0.926268</td>\n",
       "      <td>-1.611962</td>\n",
       "      <td>1.832074</td>\n",
       "      <td>0.465896</td>\n",
       "      <td>-1.188417</td>\n",
       "      <td>-1.108075</td>\n",
       "      <td>0.667061</td>\n",
       "      <td>0.209503</td>\n",
       "      <td>0.549506</td>\n",
       "      <td>0.688728</td>\n",
       "      <td>-0.834518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509838</td>\n",
       "      <td>1.090496</td>\n",
       "      <td>0.382982</td>\n",
       "      <td>2.793897</td>\n",
       "      <td>0.846967</td>\n",
       "      <td>0.132354</td>\n",
       "      <td>1.167981</td>\n",
       "      <td>0.305179</td>\n",
       "      <td>0.388728</td>\n",
       "      <td>-1.534211</td>\n",
       "      <td>2.310061</td>\n",
       "      <td>0.614302</td>\n",
       "      <td>-2.551058</td>\n",
       "      <td>-0.798606</td>\n",
       "      <td>0.463448</td>\n",
       "      <td>0.882501</td>\n",
       "      <td>-1.573618</td>\n",
       "      <td>-0.851047</td>\n",
       "      <td>-1.084885</td>\n",
       "      <td>-0.810110</td>\n",
       "      <td>-2.591259</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>-3.109939</td>\n",
       "      <td>-0.469837</td>\n",
       "      <td>-1.521249</td>\n",
       "      <td>2.536310</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>0.205385</td>\n",
       "      <td>0.222748</td>\n",
       "      <td>-0.603589</td>\n",
       "      <td>-0.575406</td>\n",
       "      <td>2.653175</td>\n",
       "      <td>0.656274</td>\n",
       "      <td>-0.784623</td>\n",
       "      <td>-2.313053</td>\n",
       "      <td>-0.462348</td>\n",
       "      <td>-1.157040</td>\n",
       "      <td>-0.760399</td>\n",
       "      <td>-0.733150</td>\n",
       "      <td>-0.364009</td>\n",
       "      <td>1.931041</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>1.464423</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.375819</td>\n",
       "      <td>2.848992</td>\n",
       "      <td>0.289920</td>\n",
       "      <td>1.562910</td>\n",
       "      <td>-2.093618</td>\n",
       "      <td>0.436995</td>\n",
       "      <td>1.144465</td>\n",
       "      <td>1.737741</td>\n",
       "      <td>0.672496</td>\n",
       "      <td>-0.453596</td>\n",
       "      <td>-1.644011</td>\n",
       "      <td>-0.450641</td>\n",
       "      <td>0.106259</td>\n",
       "      <td>1.072424</td>\n",
       "      <td>0.230748</td>\n",
       "      <td>0.531996</td>\n",
       "      <td>0.961556</td>\n",
       "      <td>-0.609904</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>-1.267019</td>\n",
       "      <td>0.149894</td>\n",
       "      <td>0.125739</td>\n",
       "      <td>-1.367208</td>\n",
       "      <td>0.070759</td>\n",
       "      <td>1.642407</td>\n",
       "      <td>-0.193618</td>\n",
       "      <td>0.505829</td>\n",
       "      <td>0.936434</td>\n",
       "      <td>2.355306</td>\n",
       "      <td>-0.726254</td>\n",
       "      <td>-1.130202</td>\n",
       "      <td>0.429852</td>\n",
       "      <td>-0.169420</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>-0.063951</td>\n",
       "      <td>1.064980</td>\n",
       "      <td>0.195184</td>\n",
       "      <td>0.867728</td>\n",
       "      <td>1.758366</td>\n",
       "      <td>-0.753328</td>\n",
       "      <td>1.191124</td>\n",
       "      <td>-1.259730</td>\n",
       "      <td>-0.560915</td>\n",
       "      <td>-0.242180</td>\n",
       "      <td>-2.075988</td>\n",
       "      <td>1.090943</td>\n",
       "      <td>0.152430</td>\n",
       "      <td>-0.650759</td>\n",
       "      <td>2.324136</td>\n",
       "      <td>1.548459</td>\n",
       "      <td>-0.446293</td>\n",
       "      <td>-1.847411</td>\n",
       "      <td>0.770710</td>\n",
       "      <td>0.741687</td>\n",
       "      <td>0.946724</td>\n",
       "      <td>0.360378</td>\n",
       "      <td>-0.236966</td>\n",
       "      <td>-0.107962</td>\n",
       "      <td>0.488973</td>\n",
       "      <td>0.566057</td>\n",
       "      <td>-1.032053</td>\n",
       "      <td>-0.807309</td>\n",
       "      <td>0.535039</td>\n",
       "      <td>-0.678845</td>\n",
       "      <td>1.174765</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>-2.031427</td>\n",
       "      <td>1.029462</td>\n",
       "      <td>1.450317</td>\n",
       "      <td>-0.877966</td>\n",
       "      <td>-1.077413</td>\n",
       "      <td>-0.802605</td>\n",
       "      <td>0.994865</td>\n",
       "      <td>-0.027329</td>\n",
       "      <td>-0.683601</td>\n",
       "      <td>1.392678</td>\n",
       "      <td>-0.299415</td>\n",
       "      <td>-0.552950</td>\n",
       "      <td>1.236387</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-1.117671</td>\n",
       "      <td>-1.682583</td>\n",
       "      <td>-0.491625</td>\n",
       "      <td>-1.474163</td>\n",
       "      <td>1.453544</td>\n",
       "      <td>-0.924569</td>\n",
       "      <td>-0.848374</td>\n",
       "      <td>0.031307</td>\n",
       "      <td>1.367690</td>\n",
       "      <td>-1.373294</td>\n",
       "      <td>1.315286</td>\n",
       "      <td>0.178725</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>-0.178477</td>\n",
       "      <td>0.553915</td>\n",
       "      <td>2.103769</td>\n",
       "      <td>0.812782</td>\n",
       "      <td>-0.277859</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>1.272471</td>\n",
       "      <td>0.718325</td>\n",
       "      <td>-0.582883</td>\n",
       "      <td>0.990603</td>\n",
       "      <td>1.612328</td>\n",
       "      <td>1.201221</td>\n",
       "      <td>0.155815</td>\n",
       "      <td>-2.209327</td>\n",
       "      <td>-0.094851</td>\n",
       "      <td>0.210379</td>\n",
       "      <td>-0.502091</td>\n",
       "      <td>0.403970</td>\n",
       "      <td>0.229298</td>\n",
       "      <td>0.109760</td>\n",
       "      <td>-0.311358</td>\n",
       "      <td>-0.589125</td>\n",
       "      <td>0.960823</td>\n",
       "      <td>-0.158633</td>\n",
       "      <td>-0.247523</td>\n",
       "      <td>1.165572</td>\n",
       "      <td>-0.775340</td>\n",
       "      <td>-0.350347</td>\n",
       "      <td>-0.792202</td>\n",
       "      <td>-3.145142</td>\n",
       "      <td>-0.804351</td>\n",
       "      <td>-0.163392</td>\n",
       "      <td>-1.845676</td>\n",
       "      <td>-2.816580</td>\n",
       "      <td>0.543281</td>\n",
       "      <td>1.241159</td>\n",
       "      <td>1.155876</td>\n",
       "      <td>0.653630</td>\n",
       "      <td>1.152445</td>\n",
       "      <td>0.840993</td>\n",
       "      <td>1.462625</td>\n",
       "      <td>0.523895</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>3.792176</td>\n",
       "      <td>-0.895917</td>\n",
       "      <td>0.253338</td>\n",
       "      <td>1.154912</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>0.233402</td>\n",
       "      <td>-0.220422</td>\n",
       "      <td>0.136225</td>\n",
       "      <td>-0.457642</td>\n",
       "      <td>-0.759081</td>\n",
       "      <td>-0.590379</td>\n",
       "      <td>-1.357375</td>\n",
       "      <td>0.126931</td>\n",
       "      <td>0.306373</td>\n",
       "      <td>-0.384993</td>\n",
       "      <td>-1.531574</td>\n",
       "      <td>1.709542</td>\n",
       "      <td>3.329371</td>\n",
       "      <td>1.725187</td>\n",
       "      <td>0.671737</td>\n",
       "      <td>0.148802</td>\n",
       "      <td>-0.171104</td>\n",
       "      <td>-1.286702</td>\n",
       "      <td>-2.501164</td>\n",
       "      <td>-0.821831</td>\n",
       "      <td>-0.993066</td>\n",
       "      <td>-0.533214</td>\n",
       "      <td>-0.149479</td>\n",
       "      <td>0.875769</td>\n",
       "      <td>-0.174742</td>\n",
       "      <td>-0.330607</td>\n",
       "      <td>1.610413</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>-0.637267</td>\n",
       "      <td>0.333815</td>\n",
       "      <td>-1.055861</td>\n",
       "      <td>-1.920131</td>\n",
       "      <td>-1.028400</td>\n",
       "      <td>-1.899665</td>\n",
       "      <td>-0.405581</td>\n",
       "      <td>-0.530552</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>-0.117834</td>\n",
       "      <td>-0.287134</td>\n",
       "      <td>1.609124</td>\n",
       "      <td>-0.861474</td>\n",
       "      <td>-0.568146</td>\n",
       "      <td>-1.450373</td>\n",
       "      <td>-2.754814</td>\n",
       "      <td>-1.968711</td>\n",
       "      <td>0.684514</td>\n",
       "      <td>-1.786272</td>\n",
       "      <td>-1.019687</td>\n",
       "      <td>-0.426398</td>\n",
       "      <td>-0.587114</td>\n",
       "      <td>0.476523</td>\n",
       "      <td>-0.038659</td>\n",
       "      <td>-1.970334</td>\n",
       "      <td>0.375374</td>\n",
       "      <td>-0.072723</td>\n",
       "      <td>0.158219</td>\n",
       "      <td>0.480686</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>-0.909432</td>\n",
       "      <td>-0.317599</td>\n",
       "      <td>-1.229279</td>\n",
       "      <td>-2.525036</td>\n",
       "      <td>2.189399</td>\n",
       "      <td>-0.236518</td>\n",
       "      <td>0.071296</td>\n",
       "      <td>-0.694981</td>\n",
       "      <td>0.893783</td>\n",
       "      <td>0.974381</td>\n",
       "      <td>1.182391</td>\n",
       "      <td>-1.782464</td>\n",
       "      <td>-0.959645</td>\n",
       "      <td>0.696126</td>\n",
       "      <td>-0.634224</td>\n",
       "      <td>-0.275836</td>\n",
       "      <td>0.461363</td>\n",
       "      <td>-0.438341</td>\n",
       "      <td>0.953575</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>1.477379</td>\n",
       "      <td>-0.967150</td>\n",
       "      <td>-1.671863</td>\n",
       "      <td>0.638065</td>\n",
       "      <td>0.819670</td>\n",
       "      <td>0.690123</td>\n",
       "      <td>0.386674</td>\n",
       "      <td>2.148944</td>\n",
       "      <td>-0.768200</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>-0.183825</td>\n",
       "      <td>0.672968</td>\n",
       "      <td>1.004103</td>\n",
       "      <td>2.610999</td>\n",
       "      <td>-0.942549</td>\n",
       "      <td>-0.463944</td>\n",
       "      <td>0.634108</td>\n",
       "      <td>-0.794707</td>\n",
       "      <td>1.100915</td>\n",
       "      <td>1.321081</td>\n",
       "      <td>2.288233</td>\n",
       "      <td>-0.948808</td>\n",
       "      <td>-0.161374</td>\n",
       "      <td>0.778059</td>\n",
       "      <td>1.043264</td>\n",
       "      <td>0.875370</td>\n",
       "      <td>-0.300045</td>\n",
       "      <td>1.572972</td>\n",
       "      <td>-2.131937</td>\n",
       "      <td>2.151883</td>\n",
       "      <td>0.539488</td>\n",
       "      <td>-1.276205</td>\n",
       "      <td>0.160191</td>\n",
       "      <td>-0.366506</td>\n",
       "      <td>-1.757839</td>\n",
       "      <td>0.508058</td>\n",
       "      <td>-1.208352</td>\n",
       "      <td>0.228462</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.572795</td>\n",
       "      <td>1.306354</td>\n",
       "      <td>1.080702</td>\n",
       "      <td>0.398558</td>\n",
       "      <td>0.619434</td>\n",
       "      <td>0.447119</td>\n",
       "      <td>0.637355</td>\n",
       "      <td>-1.452765</td>\n",
       "      <td>2.108005</td>\n",
       "      <td>0.662153</td>\n",
       "      <td>-2.409504</td>\n",
       "      <td>-0.443226</td>\n",
       "      <td>0.969157</td>\n",
       "      <td>-0.387937</td>\n",
       "      <td>-1.198934</td>\n",
       "      <td>-0.068395</td>\n",
       "      <td>-1.479488</td>\n",
       "      <td>-0.593188</td>\n",
       "      <td>-3.172834</td>\n",
       "      <td>0.018830</td>\n",
       "      <td>-1.853542</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>-2.441202</td>\n",
       "      <td>1.163136</td>\n",
       "      <td>-0.424218</td>\n",
       "      <td>0.751630</td>\n",
       "      <td>0.664554</td>\n",
       "      <td>-0.877137</td>\n",
       "      <td>0.504029</td>\n",
       "      <td>2.608101</td>\n",
       "      <td>1.083754</td>\n",
       "      <td>-0.816106</td>\n",
       "      <td>-1.932788</td>\n",
       "      <td>-0.478533</td>\n",
       "      <td>-1.174703</td>\n",
       "      <td>-0.030312</td>\n",
       "      <td>-1.001199</td>\n",
       "      <td>0.412378</td>\n",
       "      <td>1.823739</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>2.031963</td>\n",
       "      <td>0.365182</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>2.869365</td>\n",
       "      <td>0.145624</td>\n",
       "      <td>0.593512</td>\n",
       "      <td>-2.469313</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>1.025667</td>\n",
       "      <td>1.770326</td>\n",
       "      <td>0.382675</td>\n",
       "      <td>-1.033772</td>\n",
       "      <td>-1.866355</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>-0.023561</td>\n",
       "      <td>0.686887</td>\n",
       "      <td>-0.407988</td>\n",
       "      <td>0.611471</td>\n",
       "      <td>1.433167</td>\n",
       "      <td>-0.207820</td>\n",
       "      <td>1.133761</td>\n",
       "      <td>-0.656600</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.993561</td>\n",
       "      <td>-0.816158</td>\n",
       "      <td>-0.759818</td>\n",
       "      <td>2.273229</td>\n",
       "      <td>0.012036</td>\n",
       "      <td>0.221849</td>\n",
       "      <td>1.697521</td>\n",
       "      <td>1.529452</td>\n",
       "      <td>-1.865273</td>\n",
       "      <td>-0.994079</td>\n",
       "      <td>0.964742</td>\n",
       "      <td>-0.065709</td>\n",
       "      <td>-0.747230</td>\n",
       "      <td>0.560049</td>\n",
       "      <td>0.865027</td>\n",
       "      <td>0.271875</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>2.158119</td>\n",
       "      <td>-0.650199</td>\n",
       "      <td>1.087680</td>\n",
       "      <td>-0.900721</td>\n",
       "      <td>-0.778715</td>\n",
       "      <td>-0.198539</td>\n",
       "      <td>-1.870493</td>\n",
       "      <td>1.026767</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>-0.318284</td>\n",
       "      <td>2.474171</td>\n",
       "      <td>1.862045</td>\n",
       "      <td>-0.378896</td>\n",
       "      <td>-1.051060</td>\n",
       "      <td>0.194005</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>2.044768</td>\n",
       "      <td>1.085268</td>\n",
       "      <td>-0.109828</td>\n",
       "      <td>-0.782651</td>\n",
       "      <td>1.258919</td>\n",
       "      <td>0.363205</td>\n",
       "      <td>-1.358838</td>\n",
       "      <td>-0.950119</td>\n",
       "      <td>-0.624081</td>\n",
       "      <td>-0.881394</td>\n",
       "      <td>0.800182</td>\n",
       "      <td>0.126781</td>\n",
       "      <td>-1.420866</td>\n",
       "      <td>1.120321</td>\n",
       "      <td>0.766081</td>\n",
       "      <td>-1.414625</td>\n",
       "      <td>-1.005716</td>\n",
       "      <td>0.712070</td>\n",
       "      <td>1.515050</td>\n",
       "      <td>-0.292567</td>\n",
       "      <td>-0.880612</td>\n",
       "      <td>1.620766</td>\n",
       "      <td>-0.408044</td>\n",
       "      <td>-0.188442</td>\n",
       "      <td>0.703844</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>-0.737960</td>\n",
       "      <td>-1.232666</td>\n",
       "      <td>-0.413096</td>\n",
       "      <td>-1.568170</td>\n",
       "      <td>1.997037</td>\n",
       "      <td>-0.750763</td>\n",
       "      <td>-1.009542</td>\n",
       "      <td>0.283616</td>\n",
       "      <td>1.497113</td>\n",
       "      <td>-0.390785</td>\n",
       "      <td>0.390243</td>\n",
       "      <td>1.226924</td>\n",
       "      <td>0.705743</td>\n",
       "      <td>-0.523277</td>\n",
       "      <td>0.427049</td>\n",
       "      <td>1.994738</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.156425</td>\n",
       "      <td>-0.038532</td>\n",
       "      <td>1.232709</td>\n",
       "      <td>1.797695</td>\n",
       "      <td>-1.310509</td>\n",
       "      <td>0.743365</td>\n",
       "      <td>1.470108</td>\n",
       "      <td>0.690028</td>\n",
       "      <td>-0.101309</td>\n",
       "      <td>-1.584427</td>\n",
       "      <td>0.089441</td>\n",
       "      <td>0.332539</td>\n",
       "      <td>-0.672748</td>\n",
       "      <td>0.304657</td>\n",
       "      <td>0.242268</td>\n",
       "      <td>-0.498435</td>\n",
       "      <td>0.974144</td>\n",
       "      <td>-0.138297</td>\n",
       "      <td>0.855552</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>-1.107074</td>\n",
       "      <td>1.374147</td>\n",
       "      <td>0.056577</td>\n",
       "      <td>-0.861870</td>\n",
       "      <td>-0.197714</td>\n",
       "      <td>-2.194602</td>\n",
       "      <td>-0.799662</td>\n",
       "      <td>0.445435</td>\n",
       "      <td>-1.577665</td>\n",
       "      <td>-2.120222</td>\n",
       "      <td>1.038871</td>\n",
       "      <td>1.309408</td>\n",
       "      <td>1.121732</td>\n",
       "      <td>0.619259</td>\n",
       "      <td>0.615866</td>\n",
       "      <td>1.494315</td>\n",
       "      <td>1.014587</td>\n",
       "      <td>-0.159738</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>2.786219</td>\n",
       "      <td>-1.648797</td>\n",
       "      <td>0.226457</td>\n",
       "      <td>0.421815</td>\n",
       "      <td>0.384962</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>-0.075077</td>\n",
       "      <td>-0.519901</td>\n",
       "      <td>-0.038840</td>\n",
       "      <td>-1.758287</td>\n",
       "      <td>-1.005028</td>\n",
       "      <td>-1.716306</td>\n",
       "      <td>0.067075</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>-0.189828</td>\n",
       "      <td>-1.493099</td>\n",
       "      <td>2.319321</td>\n",
       "      <td>3.304625</td>\n",
       "      <td>2.037017</td>\n",
       "      <td>0.392865</td>\n",
       "      <td>0.598807</td>\n",
       "      <td>-0.147980</td>\n",
       "      <td>-0.828719</td>\n",
       "      <td>-2.424984</td>\n",
       "      <td>-0.738788</td>\n",
       "      <td>-1.233997</td>\n",
       "      <td>-0.728549</td>\n",
       "      <td>-1.475206</td>\n",
       "      <td>0.565838</td>\n",
       "      <td>0.627073</td>\n",
       "      <td>-0.382933</td>\n",
       "      <td>2.634494</td>\n",
       "      <td>-0.395835</td>\n",
       "      <td>-0.086640</td>\n",
       "      <td>0.571673</td>\n",
       "      <td>-1.192801</td>\n",
       "      <td>-0.920520</td>\n",
       "      <td>0.503218</td>\n",
       "      <td>-1.451996</td>\n",
       "      <td>-0.529270</td>\n",
       "      <td>-0.597310</td>\n",
       "      <td>0.457543</td>\n",
       "      <td>0.198796</td>\n",
       "      <td>-0.451816</td>\n",
       "      <td>1.971045</td>\n",
       "      <td>-0.275179</td>\n",
       "      <td>-0.266044</td>\n",
       "      <td>-0.549209</td>\n",
       "      <td>-2.784886</td>\n",
       "      <td>-1.818003</td>\n",
       "      <td>0.754537</td>\n",
       "      <td>-2.459061</td>\n",
       "      <td>-0.948889</td>\n",
       "      <td>-0.122237</td>\n",
       "      <td>-0.599000</td>\n",
       "      <td>-0.205590</td>\n",
       "      <td>0.162009</td>\n",
       "      <td>-1.144899</td>\n",
       "      <td>0.057355</td>\n",
       "      <td>0.151165</td>\n",
       "      <td>-0.005953</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>-0.136887</td>\n",
       "      <td>-0.622735</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>-1.725073</td>\n",
       "      <td>-2.303547</td>\n",
       "      <td>2.522296</td>\n",
       "      <td>-0.189288</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>-1.579720</td>\n",
       "      <td>0.394466</td>\n",
       "      <td>0.658677</td>\n",
       "      <td>0.550848</td>\n",
       "      <td>-1.647770</td>\n",
       "      <td>-0.943824</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.791123</td>\n",
       "      <td>-0.090784</td>\n",
       "      <td>0.220893</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>1.204422</td>\n",
       "      <td>0.336578</td>\n",
       "      <td>0.412002</td>\n",
       "      <td>-0.581575</td>\n",
       "      <td>-1.234915</td>\n",
       "      <td>0.252373</td>\n",
       "      <td>1.179109</td>\n",
       "      <td>0.772595</td>\n",
       "      <td>0.186038</td>\n",
       "      <td>1.898711</td>\n",
       "      <td>-0.102235</td>\n",
       "      <td>1.103602</td>\n",
       "      <td>-1.475669</td>\n",
       "      <td>-1.025408</td>\n",
       "      <td>1.043777</td>\n",
       "      <td>3.110343</td>\n",
       "      <td>-0.755696</td>\n",
       "      <td>-1.228132</td>\n",
       "      <td>1.101603</td>\n",
       "      <td>-1.301240</td>\n",
       "      <td>1.196725</td>\n",
       "      <td>0.880152</td>\n",
       "      <td>1.633261</td>\n",
       "      <td>-1.810984</td>\n",
       "      <td>-0.016619</td>\n",
       "      <td>0.604358</td>\n",
       "      <td>1.241526</td>\n",
       "      <td>0.686810</td>\n",
       "      <td>0.511378</td>\n",
       "      <td>1.102903</td>\n",
       "      <td>-1.801215</td>\n",
       "      <td>0.822762</td>\n",
       "      <td>-0.921722</td>\n",
       "      <td>-1.366757</td>\n",
       "      <td>-0.284381</td>\n",
       "      <td>0.199689</td>\n",
       "      <td>-0.493627</td>\n",
       "      <td>-0.223664</td>\n",
       "      <td>-0.668640</td>\n",
       "      <td>0.502052</td>\n",
       "      <td>0.182139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860271</td>\n",
       "      <td>0.860271</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>4056.623119</td>\n",
       "      <td>0.838001</td>\n",
       "      <td>0.085521</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3745.579168</td>\n",
       "      <td>0.513203</td>\n",
       "      <td>-0.134643</td>\n",
       "      <td>0.344839</td>\n",
       "      <td>1.573494</td>\n",
       "      <td>-0.310542</td>\n",
       "      <td>-0.017450</td>\n",
       "      <td>-0.919747</td>\n",
       "      <td>-0.491099</td>\n",
       "      <td>-0.116723</td>\n",
       "      <td>0.544085</td>\n",
       "      <td>1.718473</td>\n",
       "      <td>-0.183365</td>\n",
       "      <td>-0.756296</td>\n",
       "      <td>1.043739</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>-0.207678</td>\n",
       "      <td>-0.003896</td>\n",
       "      <td>1.112408</td>\n",
       "      <td>-0.176996</td>\n",
       "      <td>0.366981</td>\n",
       "      <td>1.260020</td>\n",
       "      <td>1.627329</td>\n",
       "      <td>0.512943</td>\n",
       "      <td>1.352826</td>\n",
       "      <td>-0.210047</td>\n",
       "      <td>-0.724794</td>\n",
       "      <td>0.374443</td>\n",
       "      <td>-0.216642</td>\n",
       "      <td>-0.595549</td>\n",
       "      <td>0.326554</td>\n",
       "      <td>0.314021</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.330001</td>\n",
       "      <td>-0.202695</td>\n",
       "      <td>-0.702228</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>-0.180156</td>\n",
       "      <td>-0.646589</td>\n",
       "      <td>0.079705</td>\n",
       "      <td>0.631839</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>0.250621</td>\n",
       "      <td>-0.740247</td>\n",
       "      <td>-0.593579</td>\n",
       "      <td>-0.464074</td>\n",
       "      <td>-0.517004</td>\n",
       "      <td>-0.589986</td>\n",
       "      <td>-0.757559</td>\n",
       "      <td>-0.269576</td>\n",
       "      <td>0.197135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.709122</td>\n",
       "      <td>-0.709122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.910038</td>\n",
       "      <td>0.452168</td>\n",
       "      <td>0.102062</td>\n",
       "      <td>-0.407110</td>\n",
       "      <td>1.502529</td>\n",
       "      <td>-1.041085</td>\n",
       "      <td>-0.530039</td>\n",
       "      <td>-0.288933</td>\n",
       "      <td>-0.136886</td>\n",
       "      <td>-0.835341</td>\n",
       "      <td>1.042775</td>\n",
       "      <td>0.346085</td>\n",
       "      <td>0.358182</td>\n",
       "      <td>-0.653969</td>\n",
       "      <td>-0.440389</td>\n",
       "      <td>2.197132</td>\n",
       "      <td>-0.889050</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>2.215014</td>\n",
       "      <td>-0.224949</td>\n",
       "      <td>-0.837645</td>\n",
       "      <td>0.607330</td>\n",
       "      <td>-1.561464</td>\n",
       "      <td>1.110006</td>\n",
       "      <td>-0.400626</td>\n",
       "      <td>-0.368928</td>\n",
       "      <td>0.408462</td>\n",
       "      <td>1.350903</td>\n",
       "      <td>-0.082781</td>\n",
       "      <td>-1.207240</td>\n",
       "      <td>-1.240699</td>\n",
       "      <td>-0.738045</td>\n",
       "      <td>0.203270</td>\n",
       "      <td>-0.870177</td>\n",
       "      <td>-1.329879</td>\n",
       "      <td>0.964113</td>\n",
       "      <td>-1.049506</td>\n",
       "      <td>0.479628</td>\n",
       "      <td>-1.806399</td>\n",
       "      <td>-0.729495</td>\n",
       "      <td>-0.523350</td>\n",
       "      <td>0.249450</td>\n",
       "      <td>-1.797520</td>\n",
       "      <td>-0.725987</td>\n",
       "      <td>0.578449</td>\n",
       "      <td>-0.523559</td>\n",
       "      <td>-0.911803</td>\n",
       "      <td>-1.138672</td>\n",
       "      <td>1.474807</td>\n",
       "      <td>-1.824941</td>\n",
       "      <td>-1.034353</td>\n",
       "      <td>0.442725</td>\n",
       "      <td>-0.245630</td>\n",
       "      <td>1.393651</td>\n",
       "      <td>-0.224751</td>\n",
       "      <td>-0.570471</td>\n",
       "      <td>0.053449</td>\n",
       "      <td>-1.059456</td>\n",
       "      <td>-1.290450</td>\n",
       "      <td>1.471272</td>\n",
       "      <td>1.997289</td>\n",
       "      <td>0.803297</td>\n",
       "      <td>0.860406</td>\n",
       "      <td>-0.833329</td>\n",
       "      <td>-1.638752</td>\n",
       "      <td>-0.412184</td>\n",
       "      <td>-1.728637</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>-0.560778</td>\n",
       "      <td>0.157874</td>\n",
       "      <td>-0.163801</td>\n",
       "      <td>-1.155484</td>\n",
       "      <td>-0.836271</td>\n",
       "      <td>0.120652</td>\n",
       "      <td>-0.336099</td>\n",
       "      <td>-0.839191</td>\n",
       "      <td>-0.121924</td>\n",
       "      <td>0.800179</td>\n",
       "      <td>1.679181</td>\n",
       "      <td>-1.193043</td>\n",
       "      <td>-0.288518</td>\n",
       "      <td>0.490767</td>\n",
       "      <td>1.381152</td>\n",
       "      <td>0.302169</td>\n",
       "      <td>-0.597085</td>\n",
       "      <td>-0.410621</td>\n",
       "      <td>-0.768665</td>\n",
       "      <td>-0.136807</td>\n",
       "      <td>2.059733</td>\n",
       "      <td>0.754316</td>\n",
       "      <td>0.306486</td>\n",
       "      <td>-0.633149</td>\n",
       "      <td>1.051518</td>\n",
       "      <td>-0.102166</td>\n",
       "      <td>-1.701119</td>\n",
       "      <td>-1.001339</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.794186</td>\n",
       "      <td>0.603894</td>\n",
       "      <td>0.213329</td>\n",
       "      <td>1.367538</td>\n",
       "      <td>0.719871</td>\n",
       "      <td>-0.790216</td>\n",
       "      <td>0.194103</td>\n",
       "      <td>-0.337849</td>\n",
       "      <td>0.706034</td>\n",
       "      <td>-0.467019</td>\n",
       "      <td>0.583481</td>\n",
       "      <td>-0.238843</td>\n",
       "      <td>0.992170</td>\n",
       "      <td>0.277780</td>\n",
       "      <td>0.081665</td>\n",
       "      <td>0.237491</td>\n",
       "      <td>0.917066</td>\n",
       "      <td>0.293123</td>\n",
       "      <td>0.636386</td>\n",
       "      <td>0.569247</td>\n",
       "      <td>-1.323818</td>\n",
       "      <td>0.106672</td>\n",
       "      <td>2.461601</td>\n",
       "      <td>-0.108164</td>\n",
       "      <td>-0.344839</td>\n",
       "      <td>-0.343076</td>\n",
       "      <td>0.241372</td>\n",
       "      <td>-2.826155</td>\n",
       "      <td>-0.424691</td>\n",
       "      <td>-0.307247</td>\n",
       "      <td>-0.021264</td>\n",
       "      <td>-1.065068</td>\n",
       "      <td>-1.544515</td>\n",
       "      <td>-0.518257</td>\n",
       "      <td>-1.815791</td>\n",
       "      <td>-0.349475</td>\n",
       "      <td>-0.703358</td>\n",
       "      <td>1.424585</td>\n",
       "      <td>1.138114</td>\n",
       "      <td>-1.195488</td>\n",
       "      <td>0.164165</td>\n",
       "      <td>-0.485293</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>-0.157324</td>\n",
       "      <td>1.858642</td>\n",
       "      <td>1.949754</td>\n",
       "      <td>-0.749730</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.315473</td>\n",
       "      <td>-1.294698</td>\n",
       "      <td>-0.552058</td>\n",
       "      <td>-0.967977</td>\n",
       "      <td>-0.619697</td>\n",
       "      <td>-0.017290</td>\n",
       "      <td>0.519882</td>\n",
       "      <td>-0.402537</td>\n",
       "      <td>-1.298324</td>\n",
       "      <td>0.617236</td>\n",
       "      <td>-0.164998</td>\n",
       "      <td>-0.078906</td>\n",
       "      <td>1.912512</td>\n",
       "      <td>0.181241</td>\n",
       "      <td>-0.699496</td>\n",
       "      <td>0.124082</td>\n",
       "      <td>-1.183508</td>\n",
       "      <td>1.496033</td>\n",
       "      <td>0.807804</td>\n",
       "      <td>-0.295526</td>\n",
       "      <td>-2.093629</td>\n",
       "      <td>-1.222004</td>\n",
       "      <td>-0.176936</td>\n",
       "      <td>-0.100508</td>\n",
       "      <td>-1.127789</td>\n",
       "      <td>-0.184313</td>\n",
       "      <td>-1.651225</td>\n",
       "      <td>-0.268099</td>\n",
       "      <td>-1.944681</td>\n",
       "      <td>-0.913354</td>\n",
       "      <td>0.616712</td>\n",
       "      <td>0.636540</td>\n",
       "      <td>-0.453260</td>\n",
       "      <td>-0.445722</td>\n",
       "      <td>-0.687724</td>\n",
       "      <td>-1.372432</td>\n",
       "      <td>0.937028</td>\n",
       "      <td>1.957371</td>\n",
       "      <td>1.017766</td>\n",
       "      <td>-0.687951</td>\n",
       "      <td>0.907990</td>\n",
       "      <td>-1.132779</td>\n",
       "      <td>-1.806994</td>\n",
       "      <td>0.164750</td>\n",
       "      <td>-1.382515</td>\n",
       "      <td>-0.076601</td>\n",
       "      <td>0.902886</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>0.712190</td>\n",
       "      <td>2.073319</td>\n",
       "      <td>0.548786</td>\n",
       "      <td>1.243071</td>\n",
       "      <td>-0.601272</td>\n",
       "      <td>-0.524671</td>\n",
       "      <td>0.363112</td>\n",
       "      <td>0.604872</td>\n",
       "      <td>0.216217</td>\n",
       "      <td>0.591611</td>\n",
       "      <td>-1.332342</td>\n",
       "      <td>-0.540301</td>\n",
       "      <td>-0.271519</td>\n",
       "      <td>-1.020867</td>\n",
       "      <td>-0.503275</td>\n",
       "      <td>-0.261662</td>\n",
       "      <td>-0.696485</td>\n",
       "      <td>-0.613335</td>\n",
       "      <td>-1.682268</td>\n",
       "      <td>0.899553</td>\n",
       "      <td>-0.522523</td>\n",
       "      <td>0.218718</td>\n",
       "      <td>-0.454235</td>\n",
       "      <td>1.129081</td>\n",
       "      <td>-0.759248</td>\n",
       "      <td>1.456453</td>\n",
       "      <td>0.059578</td>\n",
       "      <td>0.411233</td>\n",
       "      <td>0.512639</td>\n",
       "      <td>0.240019</td>\n",
       "      <td>-0.841739</td>\n",
       "      <td>-0.785417</td>\n",
       "      <td>-2.662714</td>\n",
       "      <td>-0.436723</td>\n",
       "      <td>0.874549</td>\n",
       "      <td>-0.817463</td>\n",
       "      <td>0.997775</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>-1.197184</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.402943</td>\n",
       "      <td>0.061332</td>\n",
       "      <td>2.082289</td>\n",
       "      <td>0.158073</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>0.497475</td>\n",
       "      <td>-0.493597</td>\n",
       "      <td>0.828992</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.602120</td>\n",
       "      <td>-0.477122</td>\n",
       "      <td>-0.392298</td>\n",
       "      <td>-0.872326</td>\n",
       "      <td>0.827462</td>\n",
       "      <td>-1.625548</td>\n",
       "      <td>-0.899495</td>\n",
       "      <td>-1.116072</td>\n",
       "      <td>0.730306</td>\n",
       "      <td>0.146423</td>\n",
       "      <td>-1.436381</td>\n",
       "      <td>1.283729</td>\n",
       "      <td>1.096357</td>\n",
       "      <td>0.113720</td>\n",
       "      <td>-0.163864</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>-1.250597</td>\n",
       "      <td>-1.742497</td>\n",
       "      <td>2.199018</td>\n",
       "      <td>0.398922</td>\n",
       "      <td>0.765183</td>\n",
       "      <td>0.187670</td>\n",
       "      <td>-2.707682</td>\n",
       "      <td>-0.278809</td>\n",
       "      <td>-1.249379</td>\n",
       "      <td>-0.348406</td>\n",
       "      <td>1.135144</td>\n",
       "      <td>0.162428</td>\n",
       "      <td>0.592387</td>\n",
       "      <td>-0.307259</td>\n",
       "      <td>-0.322215</td>\n",
       "      <td>0.599164</td>\n",
       "      <td>0.969389</td>\n",
       "      <td>0.791730</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.451808</td>\n",
       "      <td>-1.422291</td>\n",
       "      <td>-0.353153</td>\n",
       "      <td>0.527711</td>\n",
       "      <td>-0.955488</td>\n",
       "      <td>-0.192202</td>\n",
       "      <td>-0.192708</td>\n",
       "      <td>0.359985</td>\n",
       "      <td>0.491788</td>\n",
       "      <td>0.104434</td>\n",
       "      <td>-0.144988</td>\n",
       "      <td>-0.524958</td>\n",
       "      <td>-0.755321</td>\n",
       "      <td>1.388478</td>\n",
       "      <td>0.876046</td>\n",
       "      <td>0.173980</td>\n",
       "      <td>0.663672</td>\n",
       "      <td>0.975462</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>1.162155</td>\n",
       "      <td>-0.659965</td>\n",
       "      <td>-0.895932</td>\n",
       "      <td>-0.434752</td>\n",
       "      <td>-0.967429</td>\n",
       "      <td>0.231060</td>\n",
       "      <td>0.593265</td>\n",
       "      <td>0.853844</td>\n",
       "      <td>-0.924924</td>\n",
       "      <td>0.394384</td>\n",
       "      <td>0.207515</td>\n",
       "      <td>-1.276813</td>\n",
       "      <td>-0.027631</td>\n",
       "      <td>-0.093170</td>\n",
       "      <td>-0.235682</td>\n",
       "      <td>-0.381888</td>\n",
       "      <td>1.407560</td>\n",
       "      <td>0.514162</td>\n",
       "      <td>-1.400397</td>\n",
       "      <td>0.657296</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>0.624080</td>\n",
       "      <td>0.197405</td>\n",
       "      <td>-2.033129</td>\n",
       "      <td>1.072446</td>\n",
       "      <td>-1.475036</td>\n",
       "      <td>-0.372629</td>\n",
       "      <td>-0.661642</td>\n",
       "      <td>0.415522</td>\n",
       "      <td>0.653628</td>\n",
       "      <td>0.206730</td>\n",
       "      <td>-0.996967</td>\n",
       "      <td>-1.732660</td>\n",
       "      <td>-0.749303</td>\n",
       "      <td>-1.879080</td>\n",
       "      <td>2.330789</td>\n",
       "      <td>-1.403135</td>\n",
       "      <td>0.185810</td>\n",
       "      <td>-0.532576</td>\n",
       "      <td>0.724498</td>\n",
       "      <td>-0.875821</td>\n",
       "      <td>1.916473</td>\n",
       "      <td>0.304590</td>\n",
       "      <td>-0.071785</td>\n",
       "      <td>1.080003</td>\n",
       "      <td>0.311288</td>\n",
       "      <td>0.876954</td>\n",
       "      <td>0.630058</td>\n",
       "      <td>1.325421</td>\n",
       "      <td>-1.361807</td>\n",
       "      <td>1.397939</td>\n",
       "      <td>-1.818124</td>\n",
       "      <td>0.299082</td>\n",
       "      <td>2.061115</td>\n",
       "      <td>0.859143</td>\n",
       "      <td>-0.228209</td>\n",
       "      <td>-0.348985</td>\n",
       "      <td>0.996746</td>\n",
       "      <td>-0.655084</td>\n",
       "      <td>0.748798</td>\n",
       "      <td>3.220701</td>\n",
       "      <td>-0.059716</td>\n",
       "      <td>-0.828887</td>\n",
       "      <td>-0.393443</td>\n",
       "      <td>0.128353</td>\n",
       "      <td>-0.290156</td>\n",
       "      <td>0.802193</td>\n",
       "      <td>-0.577578</td>\n",
       "      <td>0.902422</td>\n",
       "      <td>0.855858</td>\n",
       "      <td>0.311351</td>\n",
       "      <td>0.657669</td>\n",
       "      <td>0.234858</td>\n",
       "      <td>1.466561</td>\n",
       "      <td>0.395842</td>\n",
       "      <td>0.811860</td>\n",
       "      <td>-0.014691</td>\n",
       "      <td>1.269668</td>\n",
       "      <td>-0.163332</td>\n",
       "      <td>1.198955</td>\n",
       "      <td>-0.241296</td>\n",
       "      <td>-0.253273</td>\n",
       "      <td>-0.971378</td>\n",
       "      <td>-0.465004</td>\n",
       "      <td>-0.200239</td>\n",
       "      <td>1.947265</td>\n",
       "      <td>0.276758</td>\n",
       "      <td>-0.988564</td>\n",
       "      <td>-0.216303</td>\n",
       "      <td>0.406169</td>\n",
       "      <td>-0.564838</td>\n",
       "      <td>0.232358</td>\n",
       "      <td>1.042576</td>\n",
       "      <td>1.726759</td>\n",
       "      <td>2.489394</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>1.870459</td>\n",
       "      <td>0.995005</td>\n",
       "      <td>1.083828</td>\n",
       "      <td>0.085560</td>\n",
       "      <td>-0.364794</td>\n",
       "      <td>1.164369</td>\n",
       "      <td>-0.892238</td>\n",
       "      <td>1.442207</td>\n",
       "      <td>-0.571101</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>-0.953247</td>\n",
       "      <td>-1.946072</td>\n",
       "      <td>-2.117796</td>\n",
       "      <td>0.808255</td>\n",
       "      <td>-1.710126</td>\n",
       "      <td>-0.058752</td>\n",
       "      <td>-0.415447</td>\n",
       "      <td>-0.187659</td>\n",
       "      <td>-0.955788</td>\n",
       "      <td>-0.467790</td>\n",
       "      <td>0.095417</td>\n",
       "      <td>-0.467312</td>\n",
       "      <td>-0.978177</td>\n",
       "      <td>1.551117</td>\n",
       "      <td>-1.430768</td>\n",
       "      <td>1.041120</td>\n",
       "      <td>2.123037</td>\n",
       "      <td>0.846223</td>\n",
       "      <td>1.005733</td>\n",
       "      <td>-2.626757</td>\n",
       "      <td>-1.239907</td>\n",
       "      <td>0.333053</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.455504</td>\n",
       "      <td>-0.961842</td>\n",
       "      <td>-0.438593</td>\n",
       "      <td>-0.807869</td>\n",
       "      <td>-0.303028</td>\n",
       "      <td>-0.192681</td>\n",
       "      <td>-0.333225</td>\n",
       "      <td>-1.008253</td>\n",
       "      <td>-0.210258</td>\n",
       "      <td>-0.813878</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>-0.515664</td>\n",
       "      <td>-2.415008</td>\n",
       "      <td>0.368638</td>\n",
       "      <td>0.090693</td>\n",
       "      <td>0.221116</td>\n",
       "      <td>-0.311374</td>\n",
       "      <td>0.567206</td>\n",
       "      <td>-1.251229</td>\n",
       "      <td>2.074985</td>\n",
       "      <td>2.130637</td>\n",
       "      <td>-0.053061</td>\n",
       "      <td>-0.407399</td>\n",
       "      <td>0.075314</td>\n",
       "      <td>0.556859</td>\n",
       "      <td>-1.537894</td>\n",
       "      <td>-0.756932</td>\n",
       "      <td>-0.694657</td>\n",
       "      <td>-1.153431</td>\n",
       "      <td>-0.124652</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>1.738789</td>\n",
       "      <td>-1.081498</td>\n",
       "      <td>-0.341102</td>\n",
       "      <td>-2.386888</td>\n",
       "      <td>-1.641152</td>\n",
       "      <td>1.276184</td>\n",
       "      <td>-0.725222</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>-0.070774</td>\n",
       "      <td>0.696829</td>\n",
       "      <td>0.421438</td>\n",
       "      <td>1.195706</td>\n",
       "      <td>0.818134</td>\n",
       "      <td>-0.332315</td>\n",
       "      <td>-0.800306</td>\n",
       "      <td>-0.232420</td>\n",
       "      <td>0.654312</td>\n",
       "      <td>-0.505913</td>\n",
       "      <td>-0.207640</td>\n",
       "      <td>0.702062</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>-0.508543</td>\n",
       "      <td>0.092716</td>\n",
       "      <td>0.555971</td>\n",
       "      <td>0.450542</td>\n",
       "      <td>-0.401951</td>\n",
       "      <td>-0.843721</td>\n",
       "      <td>-0.637528</td>\n",
       "      <td>-0.087800</td>\n",
       "      <td>0.925674</td>\n",
       "      <td>0.838143</td>\n",
       "      <td>-1.542975</td>\n",
       "      <td>-0.438723</td>\n",
       "      <td>0.608588</td>\n",
       "      <td>1.762849</td>\n",
       "      <td>1.192745</td>\n",
       "      <td>-0.407296</td>\n",
       "      <td>-1.340445</td>\n",
       "      <td>-0.303574</td>\n",
       "      <td>0.352191</td>\n",
       "      <td>-0.437060</td>\n",
       "      <td>-0.417015</td>\n",
       "      <td>-0.743630</td>\n",
       "      <td>1.421361</td>\n",
       "      <td>0.599395</td>\n",
       "      <td>0.737444</td>\n",
       "      <td>0.194268</td>\n",
       "      <td>0.144520</td>\n",
       "      <td>-1.956624</td>\n",
       "      <td>-1.339995</td>\n",
       "      <td>0.781010</td>\n",
       "      <td>-0.449250</td>\n",
       "      <td>-0.762302</td>\n",
       "      <td>-0.623648</td>\n",
       "      <td>-0.919502</td>\n",
       "      <td>-0.312337</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.761398</td>\n",
       "      <td>0.527249</td>\n",
       "      <td>0.127949</td>\n",
       "      <td>-0.626320</td>\n",
       "      <td>0.467841</td>\n",
       "      <td>1.522530</td>\n",
       "      <td>0.651665</td>\n",
       "      <td>0.044173</td>\n",
       "      <td>0.247796</td>\n",
       "      <td>-0.901564</td>\n",
       "      <td>-0.580486</td>\n",
       "      <td>1.718071</td>\n",
       "      <td>-0.733565</td>\n",
       "      <td>-0.252685</td>\n",
       "      <td>0.278499</td>\n",
       "      <td>-0.401694</td>\n",
       "      <td>1.004687</td>\n",
       "      <td>0.702079</td>\n",
       "      <td>0.438185</td>\n",
       "      <td>1.347507</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>-1.365090</td>\n",
       "      <td>1.097420</td>\n",
       "      <td>1.298756</td>\n",
       "      <td>-0.854144</td>\n",
       "      <td>-1.929992</td>\n",
       "      <td>0.488976</td>\n",
       "      <td>-0.209868</td>\n",
       "      <td>-1.393670</td>\n",
       "      <td>1.048011</td>\n",
       "      <td>0.674210</td>\n",
       "      <td>-2.023455</td>\n",
       "      <td>-0.278525</td>\n",
       "      <td>0.642006</td>\n",
       "      <td>2.293807</td>\n",
       "      <td>1.022229</td>\n",
       "      <td>1.044840</td>\n",
       "      <td>-1.635892</td>\n",
       "      <td>0.229693</td>\n",
       "      <td>-1.174964</td>\n",
       "      <td>0.786642</td>\n",
       "      <td>1.949829</td>\n",
       "      <td>-1.860060</td>\n",
       "      <td>1.155555</td>\n",
       "      <td>0.442130</td>\n",
       "      <td>2.500341</td>\n",
       "      <td>1.095743</td>\n",
       "      <td>0.526430</td>\n",
       "      <td>2.001278</td>\n",
       "      <td>0.699613</td>\n",
       "      <td>-0.574228</td>\n",
       "      <td>1.328853</td>\n",
       "      <td>-0.440579</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.091197</td>\n",
       "      <td>-0.316332</td>\n",
       "      <td>0.543587</td>\n",
       "      <td>0.862026</td>\n",
       "      <td>-0.111124</td>\n",
       "      <td>0.592892</td>\n",
       "      <td>0.468751</td>\n",
       "      <td>0.295554</td>\n",
       "      <td>0.987141</td>\n",
       "      <td>-0.090093</td>\n",
       "      <td>-1.848511</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>1.348099</td>\n",
       "      <td>-0.692253</td>\n",
       "      <td>0.253229</td>\n",
       "      <td>-1.422510</td>\n",
       "      <td>-2.037156</td>\n",
       "      <td>-0.701889</td>\n",
       "      <td>-0.300033</td>\n",
       "      <td>1.998114</td>\n",
       "      <td>0.035517</td>\n",
       "      <td>-1.509244</td>\n",
       "      <td>-0.812803</td>\n",
       "      <td>0.702133</td>\n",
       "      <td>-0.564444</td>\n",
       "      <td>0.341874</td>\n",
       "      <td>-0.654984</td>\n",
       "      <td>0.691311</td>\n",
       "      <td>-0.601548</td>\n",
       "      <td>-0.598587</td>\n",
       "      <td>-0.261288</td>\n",
       "      <td>1.343921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438836</td>\n",
       "      <td>1.108480</td>\n",
       "      <td>0.113134</td>\n",
       "      <td>1.665523</td>\n",
       "      <td>-0.587537</td>\n",
       "      <td>-0.151735</td>\n",
       "      <td>1.155895</td>\n",
       "      <td>0.397038</td>\n",
       "      <td>-0.488162</td>\n",
       "      <td>-0.985494</td>\n",
       "      <td>2.455298</td>\n",
       "      <td>-0.928513</td>\n",
       "      <td>-1.730851</td>\n",
       "      <td>-0.444086</td>\n",
       "      <td>0.452772</td>\n",
       "      <td>-0.091761</td>\n",
       "      <td>-1.375290</td>\n",
       "      <td>0.225321</td>\n",
       "      <td>-1.474144</td>\n",
       "      <td>-1.163356</td>\n",
       "      <td>-2.002357</td>\n",
       "      <td>-0.580123</td>\n",
       "      <td>-1.992514</td>\n",
       "      <td>0.641199</td>\n",
       "      <td>-1.010715</td>\n",
       "      <td>1.634793</td>\n",
       "      <td>-1.146559</td>\n",
       "      <td>-0.272275</td>\n",
       "      <td>-0.249132</td>\n",
       "      <td>0.059248</td>\n",
       "      <td>-1.430438</td>\n",
       "      <td>2.213955</td>\n",
       "      <td>0.953743</td>\n",
       "      <td>-1.816524</td>\n",
       "      <td>-1.916159</td>\n",
       "      <td>-0.621611</td>\n",
       "      <td>-0.181570</td>\n",
       "      <td>-0.926989</td>\n",
       "      <td>-0.372559</td>\n",
       "      <td>-0.135151</td>\n",
       "      <td>1.861338</td>\n",
       "      <td>-0.319816</td>\n",
       "      <td>1.530980</td>\n",
       "      <td>-0.661857</td>\n",
       "      <td>-0.852049</td>\n",
       "      <td>2.283172</td>\n",
       "      <td>0.339733</td>\n",
       "      <td>1.165587</td>\n",
       "      <td>-1.885656</td>\n",
       "      <td>0.175949</td>\n",
       "      <td>0.669404</td>\n",
       "      <td>1.515888</td>\n",
       "      <td>-0.875939</td>\n",
       "      <td>-0.374499</td>\n",
       "      <td>-0.517681</td>\n",
       "      <td>-0.264752</td>\n",
       "      <td>0.307913</td>\n",
       "      <td>0.263254</td>\n",
       "      <td>0.324921</td>\n",
       "      <td>0.630999</td>\n",
       "      <td>0.118244</td>\n",
       "      <td>-0.119898</td>\n",
       "      <td>-0.380293</td>\n",
       "      <td>-3.132735</td>\n",
       "      <td>-0.340577</td>\n",
       "      <td>-1.180606</td>\n",
       "      <td>-0.574477</td>\n",
       "      <td>-0.387386</td>\n",
       "      <td>1.579124</td>\n",
       "      <td>-1.325174</td>\n",
       "      <td>-0.537937</td>\n",
       "      <td>-0.174390</td>\n",
       "      <td>2.161263</td>\n",
       "      <td>0.270691</td>\n",
       "      <td>-1.435147</td>\n",
       "      <td>-1.072983</td>\n",
       "      <td>-0.019166</td>\n",
       "      <td>-0.446204</td>\n",
       "      <td>0.684194</td>\n",
       "      <td>-0.087465</td>\n",
       "      <td>0.200902</td>\n",
       "      <td>0.137542</td>\n",
       "      <td>1.658322</td>\n",
       "      <td>-0.327585</td>\n",
       "      <td>-1.354566</td>\n",
       "      <td>-0.111411</td>\n",
       "      <td>-0.204307</td>\n",
       "      <td>-0.297183</td>\n",
       "      <td>-1.012435</td>\n",
       "      <td>0.705592</td>\n",
       "      <td>-0.494073</td>\n",
       "      <td>-1.521313</td>\n",
       "      <td>2.169706</td>\n",
       "      <td>-0.762580</td>\n",
       "      <td>-1.255663</td>\n",
       "      <td>0.182622</td>\n",
       "      <td>-0.084911</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.789448</td>\n",
       "      <td>0.608318</td>\n",
       "      <td>-0.666498</td>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.239672</td>\n",
       "      <td>-1.476874</td>\n",
       "      <td>-0.300973</td>\n",
       "      <td>-0.557870</td>\n",
       "      <td>-0.772040</td>\n",
       "      <td>-1.864760</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.503510</td>\n",
       "      <td>-0.841610</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.568250</td>\n",
       "      <td>-0.933050</td>\n",
       "      <td>-2.951564</td>\n",
       "      <td>0.969420</td>\n",
       "      <td>1.106014</td>\n",
       "      <td>-1.327055</td>\n",
       "      <td>0.446654</td>\n",
       "      <td>2.308175</td>\n",
       "      <td>-0.126596</td>\n",
       "      <td>-0.547142</td>\n",
       "      <td>0.042876</td>\n",
       "      <td>-0.528881</td>\n",
       "      <td>-0.966956</td>\n",
       "      <td>-1.801886</td>\n",
       "      <td>-1.237144</td>\n",
       "      <td>0.162307</td>\n",
       "      <td>1.422988</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>1.123466</td>\n",
       "      <td>-1.931522</td>\n",
       "      <td>0.442197</td>\n",
       "      <td>0.208029</td>\n",
       "      <td>-0.309055</td>\n",
       "      <td>-0.386201</td>\n",
       "      <td>0.180048</td>\n",
       "      <td>-0.340591</td>\n",
       "      <td>0.664161</td>\n",
       "      <td>0.877617</td>\n",
       "      <td>0.500820</td>\n",
       "      <td>-0.391463</td>\n",
       "      <td>-1.059139</td>\n",
       "      <td>-0.213613</td>\n",
       "      <td>0.545138</td>\n",
       "      <td>-0.160716</td>\n",
       "      <td>-0.837258</td>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.735667</td>\n",
       "      <td>0.118522</td>\n",
       "      <td>-0.731558</td>\n",
       "      <td>-0.481913</td>\n",
       "      <td>0.256125</td>\n",
       "      <td>0.946468</td>\n",
       "      <td>0.437167</td>\n",
       "      <td>-1.415321</td>\n",
       "      <td>-0.103277</td>\n",
       "      <td>-0.423315</td>\n",
       "      <td>0.569938</td>\n",
       "      <td>0.728599</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>0.218820</td>\n",
       "      <td>1.188785</td>\n",
       "      <td>-0.413051</td>\n",
       "      <td>0.460598</td>\n",
       "      <td>0.229156</td>\n",
       "      <td>-1.920618</td>\n",
       "      <td>-2.082923</td>\n",
       "      <td>-1.555346</td>\n",
       "      <td>-0.590349</td>\n",
       "      <td>-0.970830</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.197161</td>\n",
       "      <td>0.972086</td>\n",
       "      <td>1.469203</td>\n",
       "      <td>1.549587</td>\n",
       "      <td>0.331526</td>\n",
       "      <td>0.952342</td>\n",
       "      <td>-0.386842</td>\n",
       "      <td>-0.726148</td>\n",
       "      <td>3.570082</td>\n",
       "      <td>-0.918804</td>\n",
       "      <td>0.142277</td>\n",
       "      <td>0.889214</td>\n",
       "      <td>1.000316</td>\n",
       "      <td>0.345126</td>\n",
       "      <td>0.260336</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>-0.016285</td>\n",
       "      <td>-0.181050</td>\n",
       "      <td>-0.267472</td>\n",
       "      <td>-1.076753</td>\n",
       "      <td>-0.221961</td>\n",
       "      <td>0.306781</td>\n",
       "      <td>-0.239767</td>\n",
       "      <td>-0.626111</td>\n",
       "      <td>1.155674</td>\n",
       "      <td>2.759443</td>\n",
       "      <td>2.073366</td>\n",
       "      <td>1.201401</td>\n",
       "      <td>-0.404367</td>\n",
       "      <td>-0.989027</td>\n",
       "      <td>-0.633053</td>\n",
       "      <td>-1.056655</td>\n",
       "      <td>-2.347534</td>\n",
       "      <td>-1.895640</td>\n",
       "      <td>-0.460514</td>\n",
       "      <td>-1.059471</td>\n",
       "      <td>0.105768</td>\n",
       "      <td>-1.084289</td>\n",
       "      <td>-1.585977</td>\n",
       "      <td>2.353343</td>\n",
       "      <td>1.114835</td>\n",
       "      <td>-1.374411</td>\n",
       "      <td>-0.334970</td>\n",
       "      <td>-1.066182</td>\n",
       "      <td>-0.895507</td>\n",
       "      <td>-0.213583</td>\n",
       "      <td>-1.117628</td>\n",
       "      <td>-0.902167</td>\n",
       "      <td>-0.571603</td>\n",
       "      <td>0.408628</td>\n",
       "      <td>0.245102</td>\n",
       "      <td>0.628736</td>\n",
       "      <td>2.300079</td>\n",
       "      <td>-0.058817</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>-1.704724</td>\n",
       "      <td>-0.770013</td>\n",
       "      <td>-0.138175</td>\n",
       "      <td>1.927412</td>\n",
       "      <td>-0.378105</td>\n",
       "      <td>-1.819184</td>\n",
       "      <td>-0.803894</td>\n",
       "      <td>-0.078451</td>\n",
       "      <td>0.467156</td>\n",
       "      <td>0.906885</td>\n",
       "      <td>-0.887123</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>-0.230165</td>\n",
       "      <td>0.522759</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>0.499417</td>\n",
       "      <td>-0.935247</td>\n",
       "      <td>-0.097325</td>\n",
       "      <td>0.929064</td>\n",
       "      <td>-0.486316</td>\n",
       "      <td>1.954082</td>\n",
       "      <td>-0.451479</td>\n",
       "      <td>-0.336505</td>\n",
       "      <td>-0.484472</td>\n",
       "      <td>-0.824298</td>\n",
       "      <td>0.664417</td>\n",
       "      <td>0.215342</td>\n",
       "      <td>-2.168878</td>\n",
       "      <td>0.865734</td>\n",
       "      <td>-0.844997</td>\n",
       "      <td>-1.019249</td>\n",
       "      <td>0.940418</td>\n",
       "      <td>0.843995</td>\n",
       "      <td>0.141829</td>\n",
       "      <td>0.518592</td>\n",
       "      <td>0.722358</td>\n",
       "      <td>0.274676</td>\n",
       "      <td>-0.643457</td>\n",
       "      <td>-0.813142</td>\n",
       "      <td>0.308710</td>\n",
       "      <td>1.113675</td>\n",
       "      <td>0.485719</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>1.216468</td>\n",
       "      <td>-0.946802</td>\n",
       "      <td>0.542020</td>\n",
       "      <td>-1.544855</td>\n",
       "      <td>0.747348</td>\n",
       "      <td>-0.308739</td>\n",
       "      <td>2.542639</td>\n",
       "      <td>1.158184</td>\n",
       "      <td>0.254610</td>\n",
       "      <td>0.871976</td>\n",
       "      <td>-2.061838</td>\n",
       "      <td>0.490092</td>\n",
       "      <td>1.214609</td>\n",
       "      <td>2.218377</td>\n",
       "      <td>-0.636521</td>\n",
       "      <td>-0.488372</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>0.602555</td>\n",
       "      <td>-0.123178</td>\n",
       "      <td>0.519601</td>\n",
       "      <td>1.094225</td>\n",
       "      <td>-2.049037</td>\n",
       "      <td>1.494340</td>\n",
       "      <td>0.280699</td>\n",
       "      <td>-2.258147</td>\n",
       "      <td>-0.332580</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>-0.900976</td>\n",
       "      <td>-0.625674</td>\n",
       "      <td>-0.726037</td>\n",
       "      <td>-0.666804</td>\n",
       "      <td>-0.289633</td>\n",
       "      <td>-0.096377</td>\n",
       "      <td>0.990157</td>\n",
       "      <td>-0.668491</td>\n",
       "      <td>-0.542688</td>\n",
       "      <td>1.207000</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.630129</td>\n",
       "      <td>-0.834764</td>\n",
       "      <td>2.096825</td>\n",
       "      <td>-0.538901</td>\n",
       "      <td>-1.015333</td>\n",
       "      <td>-0.578503</td>\n",
       "      <td>1.063981</td>\n",
       "      <td>-0.669704</td>\n",
       "      <td>-1.594806</td>\n",
       "      <td>-0.220824</td>\n",
       "      <td>-0.855632</td>\n",
       "      <td>-0.812043</td>\n",
       "      <td>-2.154108</td>\n",
       "      <td>-0.399936</td>\n",
       "      <td>-2.143558</td>\n",
       "      <td>0.321479</td>\n",
       "      <td>-1.462092</td>\n",
       "      <td>0.581245</td>\n",
       "      <td>-0.814900</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>-0.501363</td>\n",
       "      <td>-0.462125</td>\n",
       "      <td>-0.569657</td>\n",
       "      <td>2.380143</td>\n",
       "      <td>0.451636</td>\n",
       "      <td>-1.832772</td>\n",
       "      <td>-1.710702</td>\n",
       "      <td>-0.481763</td>\n",
       "      <td>-0.725228</td>\n",
       "      <td>-0.774272</td>\n",
       "      <td>-0.742986</td>\n",
       "      <td>0.267798</td>\n",
       "      <td>1.092192</td>\n",
       "      <td>-0.048647</td>\n",
       "      <td>1.522675</td>\n",
       "      <td>-0.794466</td>\n",
       "      <td>-0.832172</td>\n",
       "      <td>2.418513</td>\n",
       "      <td>-0.002717</td>\n",
       "      <td>0.997660</td>\n",
       "      <td>-2.181480</td>\n",
       "      <td>0.544427</td>\n",
       "      <td>0.705277</td>\n",
       "      <td>1.712302</td>\n",
       "      <td>-0.692670</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>-0.181342</td>\n",
       "      <td>0.244735</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>0.682650</td>\n",
       "      <td>0.601528</td>\n",
       "      <td>-0.076965</td>\n",
       "      <td>1.303674</td>\n",
       "      <td>-0.275480</td>\n",
       "      <td>-0.224306</td>\n",
       "      <td>-3.021560</td>\n",
       "      <td>-0.316375</td>\n",
       "      <td>-1.812170</td>\n",
       "      <td>-1.399482</td>\n",
       "      <td>-0.690235</td>\n",
       "      <td>1.972575</td>\n",
       "      <td>-1.110901</td>\n",
       "      <td>-0.437143</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>1.577340</td>\n",
       "      <td>0.396693</td>\n",
       "      <td>-1.558119</td>\n",
       "      <td>-1.265593</td>\n",
       "      <td>0.235670</td>\n",
       "      <td>-1.032503</td>\n",
       "      <td>0.534532</td>\n",
       "      <td>0.851731</td>\n",
       "      <td>-0.159740</td>\n",
       "      <td>-0.452116</td>\n",
       "      <td>1.883062</td>\n",
       "      <td>-1.312784</td>\n",
       "      <td>-1.303237</td>\n",
       "      <td>-0.648713</td>\n",
       "      <td>-0.986807</td>\n",
       "      <td>-1.213012</td>\n",
       "      <td>-0.609747</td>\n",
       "      <td>0.413537</td>\n",
       "      <td>-0.778495</td>\n",
       "      <td>-0.911193</td>\n",
       "      <td>2.444710</td>\n",
       "      <td>-0.243546</td>\n",
       "      <td>-2.007294</td>\n",
       "      <td>-0.508414</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.197385</td>\n",
       "      <td>1.717920</td>\n",
       "      <td>1.151295</td>\n",
       "      <td>-0.854115</td>\n",
       "      <td>0.655910</td>\n",
       "      <td>0.503145</td>\n",
       "      <td>-1.589895</td>\n",
       "      <td>-0.767036</td>\n",
       "      <td>-0.628567</td>\n",
       "      <td>-0.992081</td>\n",
       "      <td>-1.238032</td>\n",
       "      <td>-0.414063</td>\n",
       "      <td>0.096794</td>\n",
       "      <td>-0.047765</td>\n",
       "      <td>0.259382</td>\n",
       "      <td>0.627366</td>\n",
       "      <td>-1.220467</td>\n",
       "      <td>-2.864618</td>\n",
       "      <td>0.473441</td>\n",
       "      <td>1.010430</td>\n",
       "      <td>-0.967070</td>\n",
       "      <td>0.431183</td>\n",
       "      <td>2.150943</td>\n",
       "      <td>0.128237</td>\n",
       "      <td>-0.088388</td>\n",
       "      <td>0.331423</td>\n",
       "      <td>-0.666064</td>\n",
       "      <td>-0.466363</td>\n",
       "      <td>-2.056667</td>\n",
       "      <td>-0.756405</td>\n",
       "      <td>-0.552871</td>\n",
       "      <td>1.811963</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.401168</td>\n",
       "      <td>-0.665909</td>\n",
       "      <td>0.769560</td>\n",
       "      <td>-1.130200</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>0.205154</td>\n",
       "      <td>0.449947</td>\n",
       "      <td>-0.462782</td>\n",
       "      <td>1.068344</td>\n",
       "      <td>1.227803</td>\n",
       "      <td>-0.241841</td>\n",
       "      <td>-0.095055</td>\n",
       "      <td>-1.045202</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>0.540644</td>\n",
       "      <td>-0.399775</td>\n",
       "      <td>-0.076919</td>\n",
       "      <td>0.957211</td>\n",
       "      <td>1.135551</td>\n",
       "      <td>0.671821</td>\n",
       "      <td>-1.093172</td>\n",
       "      <td>-0.903629</td>\n",
       "      <td>0.518734</td>\n",
       "      <td>0.400544</td>\n",
       "      <td>0.493768</td>\n",
       "      <td>-1.285202</td>\n",
       "      <td>-0.207447</td>\n",
       "      <td>0.304319</td>\n",
       "      <td>-0.169084</td>\n",
       "      <td>0.724919</td>\n",
       "      <td>0.324934</td>\n",
       "      <td>-0.792374</td>\n",
       "      <td>0.350685</td>\n",
       "      <td>-0.693004</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>-0.279054</td>\n",
       "      <td>-2.090296</td>\n",
       "      <td>-0.737854</td>\n",
       "      <td>-1.307197</td>\n",
       "      <td>-0.178043</td>\n",
       "      <td>0.059895</td>\n",
       "      <td>0.268465</td>\n",
       "      <td>1.227153</td>\n",
       "      <td>1.179970</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>0.507997</td>\n",
       "      <td>1.300510</td>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>-0.288246</td>\n",
       "      <td>3.178910</td>\n",
       "      <td>-1.016994</td>\n",
       "      <td>-0.013298</td>\n",
       "      <td>0.518061</td>\n",
       "      <td>1.315176</td>\n",
       "      <td>0.630037</td>\n",
       "      <td>0.947325</td>\n",
       "      <td>0.789198</td>\n",
       "      <td>0.602985</td>\n",
       "      <td>0.420535</td>\n",
       "      <td>-0.363544</td>\n",
       "      <td>-1.193731</td>\n",
       "      <td>0.747783</td>\n",
       "      <td>-0.205215</td>\n",
       "      <td>-0.017870</td>\n",
       "      <td>-0.449574</td>\n",
       "      <td>1.878417</td>\n",
       "      <td>2.956714</td>\n",
       "      <td>2.347069</td>\n",
       "      <td>1.121160</td>\n",
       "      <td>0.203047</td>\n",
       "      <td>-0.187159</td>\n",
       "      <td>-0.558691</td>\n",
       "      <td>-1.896125</td>\n",
       "      <td>-1.716248</td>\n",
       "      <td>-1.731939</td>\n",
       "      <td>-0.505088</td>\n",
       "      <td>-1.179558</td>\n",
       "      <td>-0.132280</td>\n",
       "      <td>-0.219779</td>\n",
       "      <td>-0.918663</td>\n",
       "      <td>2.526274</td>\n",
       "      <td>-0.276009</td>\n",
       "      <td>-1.072990</td>\n",
       "      <td>-0.079417</td>\n",
       "      <td>-1.171386</td>\n",
       "      <td>-0.952078</td>\n",
       "      <td>-0.354013</td>\n",
       "      <td>-1.106541</td>\n",
       "      <td>-0.800179</td>\n",
       "      <td>-1.688383</td>\n",
       "      <td>0.411297</td>\n",
       "      <td>0.068776</td>\n",
       "      <td>-0.043688</td>\n",
       "      <td>3.103205</td>\n",
       "      <td>-0.251027</td>\n",
       "      <td>0.345895</td>\n",
       "      <td>-1.900012</td>\n",
       "      <td>-1.252985</td>\n",
       "      <td>0.327173</td>\n",
       "      <td>1.205824</td>\n",
       "      <td>-1.500833</td>\n",
       "      <td>-1.013870</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>0.268473</td>\n",
       "      <td>1.001412</td>\n",
       "      <td>0.653245</td>\n",
       "      <td>-0.910198</td>\n",
       "      <td>0.405626</td>\n",
       "      <td>0.134694</td>\n",
       "      <td>0.222358</td>\n",
       "      <td>0.362797</td>\n",
       "      <td>0.253234</td>\n",
       "      <td>-1.150502</td>\n",
       "      <td>0.362833</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>-0.140945</td>\n",
       "      <td>2.336074</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>-0.131052</td>\n",
       "      <td>-0.638184</td>\n",
       "      <td>-0.049279</td>\n",
       "      <td>0.955746</td>\n",
       "      <td>0.263799</td>\n",
       "      <td>-2.600711</td>\n",
       "      <td>0.559386</td>\n",
       "      <td>-1.062654</td>\n",
       "      <td>-1.067797</td>\n",
       "      <td>1.196998</td>\n",
       "      <td>1.014862</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>1.206611</td>\n",
       "      <td>0.670574</td>\n",
       "      <td>-0.191743</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>-0.853580</td>\n",
       "      <td>0.081996</td>\n",
       "      <td>1.342232</td>\n",
       "      <td>1.091934</td>\n",
       "      <td>-0.522706</td>\n",
       "      <td>1.724846</td>\n",
       "      <td>-1.789593</td>\n",
       "      <td>0.384953</td>\n",
       "      <td>-0.878360</td>\n",
       "      <td>-0.312750</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>2.781986</td>\n",
       "      <td>0.244941</td>\n",
       "      <td>-0.342767</td>\n",
       "      <td>1.732006</td>\n",
       "      <td>-1.290590</td>\n",
       "      <td>1.656650</td>\n",
       "      <td>1.347485</td>\n",
       "      <td>2.333681</td>\n",
       "      <td>0.074453</td>\n",
       "      <td>-0.431244</td>\n",
       "      <td>-0.063041</td>\n",
       "      <td>0.960761</td>\n",
       "      <td>0.177723</td>\n",
       "      <td>0.610666</td>\n",
       "      <td>0.939410</td>\n",
       "      <td>-1.508207</td>\n",
       "      <td>1.006024</td>\n",
       "      <td>-0.439741</td>\n",
       "      <td>-2.370524</td>\n",
       "      <td>0.673120</td>\n",
       "      <td>-0.698782</td>\n",
       "      <td>-0.468041</td>\n",
       "      <td>-0.395909</td>\n",
       "      <td>-0.316111</td>\n",
       "      <td>-0.890346</td>\n",
       "      <td>0.393484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>4046.151644</td>\n",
       "      <td>0.965745</td>\n",
       "      <td>0.081578</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3730.829652</td>\n",
       "      <td>0.577026</td>\n",
       "      <td>-0.703452</td>\n",
       "      <td>-0.030281</td>\n",
       "      <td>1.424215</td>\n",
       "      <td>-0.927767</td>\n",
       "      <td>-0.524914</td>\n",
       "      <td>-1.071491</td>\n",
       "      <td>-0.747763</td>\n",
       "      <td>-0.739650</td>\n",
       "      <td>0.166366</td>\n",
       "      <td>1.225336</td>\n",
       "      <td>-0.968892</td>\n",
       "      <td>-0.609357</td>\n",
       "      <td>1.331344</td>\n",
       "      <td>0.248343</td>\n",
       "      <td>-0.777860</td>\n",
       "      <td>-0.192054</td>\n",
       "      <td>0.524203</td>\n",
       "      <td>-0.513850</td>\n",
       "      <td>-0.166118</td>\n",
       "      <td>0.579482</td>\n",
       "      <td>1.198196</td>\n",
       "      <td>0.440756</td>\n",
       "      <td>1.636821</td>\n",
       "      <td>-0.197944</td>\n",
       "      <td>-1.237955</td>\n",
       "      <td>0.266253</td>\n",
       "      <td>-0.380820</td>\n",
       "      <td>0.020749</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.243680</td>\n",
       "      <td>0.297456</td>\n",
       "      <td>-0.176722</td>\n",
       "      <td>0.320439</td>\n",
       "      <td>-0.258626</td>\n",
       "      <td>-0.437150</td>\n",
       "      <td>0.322894</td>\n",
       "      <td>0.020964</td>\n",
       "      <td>-0.016534</td>\n",
       "      <td>0.303550</td>\n",
       "      <td>0.748919</td>\n",
       "      <td>0.415279</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.569398</td>\n",
       "      <td>-0.209047</td>\n",
       "      <td>-0.327886</td>\n",
       "      <td>-0.410781</td>\n",
       "      <td>-0.429688</td>\n",
       "      <td>-0.057528</td>\n",
       "      <td>-0.133819</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410055</td>\n",
       "      <td>-0.410055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.317591</td>\n",
       "      <td>-0.491524</td>\n",
       "      <td>1.558877</td>\n",
       "      <td>1.161390</td>\n",
       "      <td>-0.380766</td>\n",
       "      <td>0.633816</td>\n",
       "      <td>1.564410</td>\n",
       "      <td>0.395460</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.601129</td>\n",
       "      <td>-0.378828</td>\n",
       "      <td>-0.151586</td>\n",
       "      <td>-0.196149</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>-0.313500</td>\n",
       "      <td>-1.046052</td>\n",
       "      <td>1.116012</td>\n",
       "      <td>2.686497</td>\n",
       "      <td>0.384889</td>\n",
       "      <td>-0.362598</td>\n",
       "      <td>-1.021422</td>\n",
       "      <td>-0.151914</td>\n",
       "      <td>-1.798530</td>\n",
       "      <td>-0.477272</td>\n",
       "      <td>-1.042822</td>\n",
       "      <td>0.402447</td>\n",
       "      <td>1.498183</td>\n",
       "      <td>1.215138</td>\n",
       "      <td>-0.545063</td>\n",
       "      <td>-1.531632</td>\n",
       "      <td>1.486482</td>\n",
       "      <td>-0.056883</td>\n",
       "      <td>-0.474879</td>\n",
       "      <td>-0.727821</td>\n",
       "      <td>-1.449163</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>-1.017975</td>\n",
       "      <td>-0.573017</td>\n",
       "      <td>-0.183317</td>\n",
       "      <td>-0.529956</td>\n",
       "      <td>-0.533232</td>\n",
       "      <td>-0.535414</td>\n",
       "      <td>-0.462716</td>\n",
       "      <td>1.137093</td>\n",
       "      <td>-1.592213</td>\n",
       "      <td>0.280977</td>\n",
       "      <td>2.659923</td>\n",
       "      <td>-1.450332</td>\n",
       "      <td>-0.005186</td>\n",
       "      <td>0.919738</td>\n",
       "      <td>0.299053</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.615516</td>\n",
       "      <td>1.638530</td>\n",
       "      <td>1.187709</td>\n",
       "      <td>0.581360</td>\n",
       "      <td>-0.386432</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>2.732231</td>\n",
       "      <td>0.895528</td>\n",
       "      <td>1.706269</td>\n",
       "      <td>-0.372007</td>\n",
       "      <td>-2.243075</td>\n",
       "      <td>0.439891</td>\n",
       "      <td>-0.993274</td>\n",
       "      <td>1.889407</td>\n",
       "      <td>-1.345201</td>\n",
       "      <td>-0.063929</td>\n",
       "      <td>-0.284827</td>\n",
       "      <td>0.359111</td>\n",
       "      <td>-1.560618</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.092347</td>\n",
       "      <td>1.632836</td>\n",
       "      <td>-0.078210</td>\n",
       "      <td>-0.164117</td>\n",
       "      <td>2.071807</td>\n",
       "      <td>0.362004</td>\n",
       "      <td>0.347906</td>\n",
       "      <td>-1.468258</td>\n",
       "      <td>1.041199</td>\n",
       "      <td>0.755897</td>\n",
       "      <td>0.743015</td>\n",
       "      <td>0.957750</td>\n",
       "      <td>0.240857</td>\n",
       "      <td>-0.414104</td>\n",
       "      <td>2.311493</td>\n",
       "      <td>1.476827</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>-0.780171</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>-0.192481</td>\n",
       "      <td>-0.370405</td>\n",
       "      <td>-0.027169</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>-0.363819</td>\n",
       "      <td>0.657369</td>\n",
       "      <td>0.015123</td>\n",
       "      <td>1.215948</td>\n",
       "      <td>1.107320</td>\n",
       "      <td>-0.745226</td>\n",
       "      <td>-0.793370</td>\n",
       "      <td>-2.075607</td>\n",
       "      <td>-0.838992</td>\n",
       "      <td>-0.704564</td>\n",
       "      <td>-0.966085</td>\n",
       "      <td>-0.598969</td>\n",
       "      <td>1.795014</td>\n",
       "      <td>0.463757</td>\n",
       "      <td>-0.726845</td>\n",
       "      <td>-0.053690</td>\n",
       "      <td>-1.123345</td>\n",
       "      <td>-0.516755</td>\n",
       "      <td>-0.798879</td>\n",
       "      <td>-0.202976</td>\n",
       "      <td>-0.164112</td>\n",
       "      <td>-0.072735</td>\n",
       "      <td>1.218566</td>\n",
       "      <td>-1.204320</td>\n",
       "      <td>0.256120</td>\n",
       "      <td>0.032810</td>\n",
       "      <td>0.347686</td>\n",
       "      <td>-1.534398</td>\n",
       "      <td>0.272711</td>\n",
       "      <td>-0.059414</td>\n",
       "      <td>-0.542941</td>\n",
       "      <td>-0.774984</td>\n",
       "      <td>-1.010295</td>\n",
       "      <td>-0.614713</td>\n",
       "      <td>-0.399746</td>\n",
       "      <td>-0.667718</td>\n",
       "      <td>0.527916</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>0.351395</td>\n",
       "      <td>-0.235945</td>\n",
       "      <td>-1.693862</td>\n",
       "      <td>-0.439292</td>\n",
       "      <td>0.080968</td>\n",
       "      <td>0.493102</td>\n",
       "      <td>2.109114</td>\n",
       "      <td>1.795596</td>\n",
       "      <td>-0.456493</td>\n",
       "      <td>-0.380323</td>\n",
       "      <td>-0.282655</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>-0.937610</td>\n",
       "      <td>-1.169676</td>\n",
       "      <td>-1.256632</td>\n",
       "      <td>0.797957</td>\n",
       "      <td>-0.640208</td>\n",
       "      <td>-0.409060</td>\n",
       "      <td>0.227162</td>\n",
       "      <td>1.138371</td>\n",
       "      <td>-0.291029</td>\n",
       "      <td>0.989344</td>\n",
       "      <td>-0.952980</td>\n",
       "      <td>0.258547</td>\n",
       "      <td>1.165252</td>\n",
       "      <td>0.386510</td>\n",
       "      <td>-0.682780</td>\n",
       "      <td>1.647708</td>\n",
       "      <td>1.261674</td>\n",
       "      <td>-0.559734</td>\n",
       "      <td>0.449096</td>\n",
       "      <td>0.112368</td>\n",
       "      <td>0.676839</td>\n",
       "      <td>-0.141681</td>\n",
       "      <td>0.087552</td>\n",
       "      <td>-0.938565</td>\n",
       "      <td>-0.430906</td>\n",
       "      <td>-1.022101</td>\n",
       "      <td>0.307358</td>\n",
       "      <td>-1.013223</td>\n",
       "      <td>0.652779</td>\n",
       "      <td>0.622699</td>\n",
       "      <td>-0.927422</td>\n",
       "      <td>0.172374</td>\n",
       "      <td>-1.097157</td>\n",
       "      <td>0.600669</td>\n",
       "      <td>-1.448389</td>\n",
       "      <td>2.589260</td>\n",
       "      <td>1.275879</td>\n",
       "      <td>0.531916</td>\n",
       "      <td>-0.941550</td>\n",
       "      <td>-0.789747</td>\n",
       "      <td>-0.528524</td>\n",
       "      <td>-0.928410</td>\n",
       "      <td>-0.117118</td>\n",
       "      <td>1.448559</td>\n",
       "      <td>-0.338207</td>\n",
       "      <td>0.702552</td>\n",
       "      <td>0.452944</td>\n",
       "      <td>0.812444</td>\n",
       "      <td>1.056288</td>\n",
       "      <td>0.209089</td>\n",
       "      <td>0.641092</td>\n",
       "      <td>-0.707244</td>\n",
       "      <td>0.165736</td>\n",
       "      <td>0.762573</td>\n",
       "      <td>-1.397415</td>\n",
       "      <td>1.538658</td>\n",
       "      <td>-0.569526</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>1.098030</td>\n",
       "      <td>0.227961</td>\n",
       "      <td>-0.429727</td>\n",
       "      <td>-0.242542</td>\n",
       "      <td>-0.436138</td>\n",
       "      <td>0.518419</td>\n",
       "      <td>-0.480073</td>\n",
       "      <td>0.154450</td>\n",
       "      <td>-0.237176</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>0.235070</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-1.362408</td>\n",
       "      <td>1.513781</td>\n",
       "      <td>0.305847</td>\n",
       "      <td>-0.066949</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>-0.090698</td>\n",
       "      <td>-0.496738</td>\n",
       "      <td>-0.394309</td>\n",
       "      <td>0.069956</td>\n",
       "      <td>-2.589997</td>\n",
       "      <td>0.821558</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>1.288650</td>\n",
       "      <td>0.836472</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>-0.418244</td>\n",
       "      <td>-0.057169</td>\n",
       "      <td>0.698660</td>\n",
       "      <td>2.042742</td>\n",
       "      <td>0.589625</td>\n",
       "      <td>-0.904998</td>\n",
       "      <td>0.306099</td>\n",
       "      <td>0.145415</td>\n",
       "      <td>0.465076</td>\n",
       "      <td>-0.021075</td>\n",
       "      <td>0.538020</td>\n",
       "      <td>-1.201893</td>\n",
       "      <td>-0.334906</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>-2.076847</td>\n",
       "      <td>-0.557216</td>\n",
       "      <td>-0.445896</td>\n",
       "      <td>-0.450035</td>\n",
       "      <td>1.371100</td>\n",
       "      <td>-0.012645</td>\n",
       "      <td>0.120183</td>\n",
       "      <td>1.347723</td>\n",
       "      <td>0.232282</td>\n",
       "      <td>0.136311</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>-0.168662</td>\n",
       "      <td>-1.641346</td>\n",
       "      <td>-0.673302</td>\n",
       "      <td>0.531285</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>1.928628</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>-0.348698</td>\n",
       "      <td>0.820292</td>\n",
       "      <td>-0.360188</td>\n",
       "      <td>-0.457881</td>\n",
       "      <td>2.484554</td>\n",
       "      <td>0.640159</td>\n",
       "      <td>-0.442163</td>\n",
       "      <td>-0.334919</td>\n",
       "      <td>-2.667480</td>\n",
       "      <td>1.382226</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>1.116073</td>\n",
       "      <td>-0.946438</td>\n",
       "      <td>-0.098407</td>\n",
       "      <td>0.854197</td>\n",
       "      <td>-0.350128</td>\n",
       "      <td>0.436362</td>\n",
       "      <td>-1.272784</td>\n",
       "      <td>-0.144762</td>\n",
       "      <td>-0.111897</td>\n",
       "      <td>1.008923</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>2.861920</td>\n",
       "      <td>-0.162575</td>\n",
       "      <td>-1.269843</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>-1.271030</td>\n",
       "      <td>1.141186</td>\n",
       "      <td>0.688494</td>\n",
       "      <td>-0.063256</td>\n",
       "      <td>-0.280843</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.625377</td>\n",
       "      <td>-0.115619</td>\n",
       "      <td>-0.908581</td>\n",
       "      <td>-0.771301</td>\n",
       "      <td>-0.097373</td>\n",
       "      <td>0.447107</td>\n",
       "      <td>-0.253180</td>\n",
       "      <td>-0.041595</td>\n",
       "      <td>-0.664525</td>\n",
       "      <td>1.124908</td>\n",
       "      <td>0.069510</td>\n",
       "      <td>-0.643086</td>\n",
       "      <td>-0.146357</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>-1.443381</td>\n",
       "      <td>1.039074</td>\n",
       "      <td>0.254276</td>\n",
       "      <td>0.303534</td>\n",
       "      <td>0.209770</td>\n",
       "      <td>1.069085</td>\n",
       "      <td>0.846496</td>\n",
       "      <td>-0.932502</td>\n",
       "      <td>1.590306</td>\n",
       "      <td>-0.370002</td>\n",
       "      <td>-1.185666</td>\n",
       "      <td>0.875085</td>\n",
       "      <td>-0.484567</td>\n",
       "      <td>-1.168479</td>\n",
       "      <td>0.969472</td>\n",
       "      <td>-0.187051</td>\n",
       "      <td>-0.889438</td>\n",
       "      <td>-0.586498</td>\n",
       "      <td>1.239712</td>\n",
       "      <td>-0.951498</td>\n",
       "      <td>-0.305577</td>\n",
       "      <td>-1.139748</td>\n",
       "      <td>-0.810219</td>\n",
       "      <td>-0.922617</td>\n",
       "      <td>-0.466963</td>\n",
       "      <td>-0.444436</td>\n",
       "      <td>1.022452</td>\n",
       "      <td>-1.176326</td>\n",
       "      <td>1.779446</td>\n",
       "      <td>0.761250</td>\n",
       "      <td>-0.158379</td>\n",
       "      <td>1.240046</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>1.211477</td>\n",
       "      <td>0.163705</td>\n",
       "      <td>1.022031</td>\n",
       "      <td>-0.178397</td>\n",
       "      <td>1.949606</td>\n",
       "      <td>-0.684831</td>\n",
       "      <td>1.113583</td>\n",
       "      <td>2.013963</td>\n",
       "      <td>0.977258</td>\n",
       "      <td>0.214376</td>\n",
       "      <td>-0.250112</td>\n",
       "      <td>-0.174051</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>-0.598606</td>\n",
       "      <td>3.502398</td>\n",
       "      <td>0.048835</td>\n",
       "      <td>-1.614039</td>\n",
       "      <td>-2.357212</td>\n",
       "      <td>0.275074</td>\n",
       "      <td>0.920687</td>\n",
       "      <td>0.443874</td>\n",
       "      <td>-2.182236</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>0.103318</td>\n",
       "      <td>1.055180</td>\n",
       "      <td>0.107601</td>\n",
       "      <td>0.283396</td>\n",
       "      <td>0.270237</td>\n",
       "      <td>0.174600</td>\n",
       "      <td>-0.219063</td>\n",
       "      <td>-0.383257</td>\n",
       "      <td>-1.036883</td>\n",
       "      <td>0.421588</td>\n",
       "      <td>-0.653390</td>\n",
       "      <td>-0.723013</td>\n",
       "      <td>-0.620543</td>\n",
       "      <td>-0.214125</td>\n",
       "      <td>0.124311</td>\n",
       "      <td>0.019941</td>\n",
       "      <td>-0.207182</td>\n",
       "      <td>-0.206831</td>\n",
       "      <td>-0.659480</td>\n",
       "      <td>0.898771</td>\n",
       "      <td>-0.691873</td>\n",
       "      <td>-1.857792</td>\n",
       "      <td>1.669726</td>\n",
       "      <td>1.761148</td>\n",
       "      <td>3.342970</td>\n",
       "      <td>-0.434832</td>\n",
       "      <td>1.704352</td>\n",
       "      <td>1.406380</td>\n",
       "      <td>1.259622</td>\n",
       "      <td>-0.571441</td>\n",
       "      <td>-0.067719</td>\n",
       "      <td>0.462158</td>\n",
       "      <td>0.473267</td>\n",
       "      <td>-0.672258</td>\n",
       "      <td>-0.885180</td>\n",
       "      <td>0.263232</td>\n",
       "      <td>-0.503416</td>\n",
       "      <td>-0.635334</td>\n",
       "      <td>-0.545901</td>\n",
       "      <td>1.714043</td>\n",
       "      <td>-0.582340</td>\n",
       "      <td>0.677611</td>\n",
       "      <td>-1.432580</td>\n",
       "      <td>-0.115756</td>\n",
       "      <td>-1.515664</td>\n",
       "      <td>-0.179515</td>\n",
       "      <td>-0.166178</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.732734</td>\n",
       "      <td>0.197024</td>\n",
       "      <td>-0.164538</td>\n",
       "      <td>-0.323547</td>\n",
       "      <td>1.850738</td>\n",
       "      <td>0.310548</td>\n",
       "      <td>-0.679769</td>\n",
       "      <td>-1.062913</td>\n",
       "      <td>-0.358207</td>\n",
       "      <td>0.323807</td>\n",
       "      <td>-0.277752</td>\n",
       "      <td>-0.203353</td>\n",
       "      <td>-0.726128</td>\n",
       "      <td>-0.538159</td>\n",
       "      <td>-1.165088</td>\n",
       "      <td>-1.636069</td>\n",
       "      <td>0.347768</td>\n",
       "      <td>-0.329004</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>0.796850</td>\n",
       "      <td>-0.153530</td>\n",
       "      <td>-0.367293</td>\n",
       "      <td>-1.269914</td>\n",
       "      <td>-0.318175</td>\n",
       "      <td>-0.561987</td>\n",
       "      <td>0.721104</td>\n",
       "      <td>0.771318</td>\n",
       "      <td>-0.280007</td>\n",
       "      <td>-0.734842</td>\n",
       "      <td>1.203725</td>\n",
       "      <td>1.635496</td>\n",
       "      <td>1.429582</td>\n",
       "      <td>-0.605417</td>\n",
       "      <td>-0.603124</td>\n",
       "      <td>-0.838933</td>\n",
       "      <td>1.146618</td>\n",
       "      <td>-2.209169</td>\n",
       "      <td>-0.030196</td>\n",
       "      <td>-1.592760</td>\n",
       "      <td>-0.620985</td>\n",
       "      <td>-1.791198</td>\n",
       "      <td>0.507036</td>\n",
       "      <td>0.516725</td>\n",
       "      <td>0.792697</td>\n",
       "      <td>-0.790422</td>\n",
       "      <td>-1.760003</td>\n",
       "      <td>-1.501593</td>\n",
       "      <td>-1.733025</td>\n",
       "      <td>-0.542215</td>\n",
       "      <td>-1.383063</td>\n",
       "      <td>-1.090096</td>\n",
       "      <td>-0.669537</td>\n",
       "      <td>0.406426</td>\n",
       "      <td>0.161907</td>\n",
       "      <td>0.589573</td>\n",
       "      <td>-0.154162</td>\n",
       "      <td>-1.598715</td>\n",
       "      <td>0.783966</td>\n",
       "      <td>0.203730</td>\n",
       "      <td>-0.558706</td>\n",
       "      <td>-0.220178</td>\n",
       "      <td>-0.434650</td>\n",
       "      <td>-0.137269</td>\n",
       "      <td>-0.433743</td>\n",
       "      <td>0.682797</td>\n",
       "      <td>0.409113</td>\n",
       "      <td>-0.097499</td>\n",
       "      <td>1.170121</td>\n",
       "      <td>-0.103542</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>-0.312999</td>\n",
       "      <td>-0.706021</td>\n",
       "      <td>-1.115671</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>-1.420490</td>\n",
       "      <td>-0.747259</td>\n",
       "      <td>2.034692</td>\n",
       "      <td>0.897575</td>\n",
       "      <td>-0.257355</td>\n",
       "      <td>1.160356</td>\n",
       "      <td>-0.767375</td>\n",
       "      <td>0.880113</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>-1.248645</td>\n",
       "      <td>0.645034</td>\n",
       "      <td>0.914156</td>\n",
       "      <td>1.200565</td>\n",
       "      <td>-0.211043</td>\n",
       "      <td>0.570824</td>\n",
       "      <td>0.395849</td>\n",
       "      <td>-1.078518</td>\n",
       "      <td>-0.839751</td>\n",
       "      <td>-0.357005</td>\n",
       "      <td>1.161223</td>\n",
       "      <td>0.024166</td>\n",
       "      <td>-0.612974</td>\n",
       "      <td>-0.097271</td>\n",
       "      <td>-0.609567</td>\n",
       "      <td>-0.158096</td>\n",
       "      <td>1.694520</td>\n",
       "      <td>0.981647</td>\n",
       "      <td>1.073253</td>\n",
       "      <td>-0.189001</td>\n",
       "      <td>1.510972</td>\n",
       "      <td>0.658110</td>\n",
       "      <td>1.512686</td>\n",
       "      <td>1.117440</td>\n",
       "      <td>-0.953309</td>\n",
       "      <td>-0.547964</td>\n",
       "      <td>-0.622197</td>\n",
       "      <td>-0.948518</td>\n",
       "      <td>0.663267</td>\n",
       "      <td>0.325001</td>\n",
       "      <td>-1.127563</td>\n",
       "      <td>-0.902593</td>\n",
       "      <td>0.672022</td>\n",
       "      <td>1.444596</td>\n",
       "      <td>0.983530</td>\n",
       "      <td>-0.104268</td>\n",
       "      <td>2.206342</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.110014</td>\n",
       "      <td>1.735063</td>\n",
       "      <td>-0.044940</td>\n",
       "      <td>-1.054074</td>\n",
       "      <td>0.408526</td>\n",
       "      <td>1.056725</td>\n",
       "      <td>-0.423049</td>\n",
       "      <td>-0.341425</td>\n",
       "      <td>-2.039501</td>\n",
       "      <td>0.703974</td>\n",
       "      <td>-0.394638</td>\n",
       "      <td>0.716357</td>\n",
       "      <td>-0.519693</td>\n",
       "      <td>2.720093</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>-0.827245</td>\n",
       "      <td>0.239297</td>\n",
       "      <td>-1.789863</td>\n",
       "      <td>-1.445927</td>\n",
       "      <td>0.640736</td>\n",
       "      <td>1.958144</td>\n",
       "      <td>-0.428607</td>\n",
       "      <td>-0.505283</td>\n",
       "      <td>0.332040</td>\n",
       "      <td>2.017696</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.250104</td>\n",
       "      <td>2.052971</td>\n",
       "      <td>-0.340422</td>\n",
       "      <td>-0.670429</td>\n",
       "      <td>-0.342517</td>\n",
       "      <td>0.399839</td>\n",
       "      <td>-1.467299</td>\n",
       "      <td>0.477283</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.651682</td>\n",
       "      <td>0.430207</td>\n",
       "      <td>-0.711643</td>\n",
       "      <td>0.821332</td>\n",
       "      <td>1.152101</td>\n",
       "      <td>-0.827455</td>\n",
       "      <td>-1.646252</td>\n",
       "      <td>1.192287</td>\n",
       "      <td>1.409831</td>\n",
       "      <td>-1.150681</td>\n",
       "      <td>0.074427</td>\n",
       "      <td>-1.843403</td>\n",
       "      <td>-2.016044</td>\n",
       "      <td>-1.041591</td>\n",
       "      <td>0.183752</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>-0.606398</td>\n",
       "      <td>-0.710955</td>\n",
       "      <td>-1.961302</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>-0.738659</td>\n",
       "      <td>0.137407</td>\n",
       "      <td>-0.816052</td>\n",
       "      <td>0.154895</td>\n",
       "      <td>-0.305983</td>\n",
       "      <td>-0.632948</td>\n",
       "      <td>-0.228820</td>\n",
       "      <td>-1.603944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503265</td>\n",
       "      <td>1.055216</td>\n",
       "      <td>-0.518664</td>\n",
       "      <td>1.225518</td>\n",
       "      <td>0.668813</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>1.689538</td>\n",
       "      <td>-0.159956</td>\n",
       "      <td>0.171020</td>\n",
       "      <td>-1.103811</td>\n",
       "      <td>2.834835</td>\n",
       "      <td>-0.382619</td>\n",
       "      <td>-0.160303</td>\n",
       "      <td>-0.503625</td>\n",
       "      <td>0.424668</td>\n",
       "      <td>1.282233</td>\n",
       "      <td>-1.616203</td>\n",
       "      <td>-0.060024</td>\n",
       "      <td>-0.768009</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>-1.074184</td>\n",
       "      <td>-0.193439</td>\n",
       "      <td>-0.562675</td>\n",
       "      <td>-0.488265</td>\n",
       "      <td>-1.680129</td>\n",
       "      <td>2.806794</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.315566</td>\n",
       "      <td>-0.649502</td>\n",
       "      <td>1.253290</td>\n",
       "      <td>-0.407769</td>\n",
       "      <td>2.883094</td>\n",
       "      <td>1.800483</td>\n",
       "      <td>-2.366929</td>\n",
       "      <td>-1.048119</td>\n",
       "      <td>-1.419479</td>\n",
       "      <td>-0.300554</td>\n",
       "      <td>-1.646790</td>\n",
       "      <td>-0.097446</td>\n",
       "      <td>-0.082528</td>\n",
       "      <td>2.186205</td>\n",
       "      <td>0.367116</td>\n",
       "      <td>1.098691</td>\n",
       "      <td>0.784042</td>\n",
       "      <td>0.254156</td>\n",
       "      <td>2.439126</td>\n",
       "      <td>0.516438</td>\n",
       "      <td>0.749158</td>\n",
       "      <td>-0.390857</td>\n",
       "      <td>0.681974</td>\n",
       "      <td>0.693667</td>\n",
       "      <td>1.283088</td>\n",
       "      <td>-0.786374</td>\n",
       "      <td>-2.190214</td>\n",
       "      <td>-0.743467</td>\n",
       "      <td>-0.632042</td>\n",
       "      <td>0.489364</td>\n",
       "      <td>-0.056654</td>\n",
       "      <td>-0.545288</td>\n",
       "      <td>-0.214183</td>\n",
       "      <td>-0.076751</td>\n",
       "      <td>-1.270818</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-1.619122</td>\n",
       "      <td>-0.062694</td>\n",
       "      <td>-0.817776</td>\n",
       "      <td>-0.648656</td>\n",
       "      <td>-0.704587</td>\n",
       "      <td>-0.009421</td>\n",
       "      <td>-0.248973</td>\n",
       "      <td>-0.463548</td>\n",
       "      <td>0.520329</td>\n",
       "      <td>1.894742</td>\n",
       "      <td>-0.401323</td>\n",
       "      <td>0.255256</td>\n",
       "      <td>-1.234262</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>-0.431646</td>\n",
       "      <td>1.201227</td>\n",
       "      <td>1.043972</td>\n",
       "      <td>0.272823</td>\n",
       "      <td>0.407852</td>\n",
       "      <td>1.738688</td>\n",
       "      <td>-0.590641</td>\n",
       "      <td>0.118572</td>\n",
       "      <td>-0.149504</td>\n",
       "      <td>-0.990389</td>\n",
       "      <td>-1.078538</td>\n",
       "      <td>-1.069169</td>\n",
       "      <td>0.657082</td>\n",
       "      <td>0.181892</td>\n",
       "      <td>0.633836</td>\n",
       "      <td>2.732229</td>\n",
       "      <td>0.561286</td>\n",
       "      <td>-0.833354</td>\n",
       "      <td>-0.979673</td>\n",
       "      <td>1.528543</td>\n",
       "      <td>0.741344</td>\n",
       "      <td>0.857304</td>\n",
       "      <td>0.220634</td>\n",
       "      <td>-0.746295</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>1.623617</td>\n",
       "      <td>-0.414383</td>\n",
       "      <td>0.240548</td>\n",
       "      <td>-0.255935</td>\n",
       "      <td>0.547045</td>\n",
       "      <td>0.162978</td>\n",
       "      <td>0.450820</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>-1.437635</td>\n",
       "      <td>0.322734</td>\n",
       "      <td>1.045192</td>\n",
       "      <td>-0.524167</td>\n",
       "      <td>0.073819</td>\n",
       "      <td>0.866922</td>\n",
       "      <td>1.359804</td>\n",
       "      <td>-0.012718</td>\n",
       "      <td>-0.060325</td>\n",
       "      <td>2.155535</td>\n",
       "      <td>-0.954969</td>\n",
       "      <td>0.153444</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>-1.268257</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>-0.587983</td>\n",
       "      <td>-0.474885</td>\n",
       "      <td>-0.013344</td>\n",
       "      <td>1.422140</td>\n",
       "      <td>0.143838</td>\n",
       "      <td>-0.177975</td>\n",
       "      <td>-0.710480</td>\n",
       "      <td>0.683557</td>\n",
       "      <td>0.302737</td>\n",
       "      <td>0.865585</td>\n",
       "      <td>-0.483163</td>\n",
       "      <td>0.675506</td>\n",
       "      <td>-0.353412</td>\n",
       "      <td>1.458548</td>\n",
       "      <td>1.177698</td>\n",
       "      <td>-0.103841</td>\n",
       "      <td>-0.369460</td>\n",
       "      <td>-1.343062</td>\n",
       "      <td>-0.118076</td>\n",
       "      <td>0.043328</td>\n",
       "      <td>-0.171552</td>\n",
       "      <td>0.676045</td>\n",
       "      <td>1.204198</td>\n",
       "      <td>-0.066749</td>\n",
       "      <td>0.908615</td>\n",
       "      <td>-0.122003</td>\n",
       "      <td>-0.813889</td>\n",
       "      <td>0.471795</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1.187021</td>\n",
       "      <td>-0.678595</td>\n",
       "      <td>0.596846</td>\n",
       "      <td>1.096448</td>\n",
       "      <td>0.320294</td>\n",
       "      <td>1.128116</td>\n",
       "      <td>-0.983991</td>\n",
       "      <td>-0.390432</td>\n",
       "      <td>0.923404</td>\n",
       "      <td>-1.232998</td>\n",
       "      <td>-0.197379</td>\n",
       "      <td>-0.618883</td>\n",
       "      <td>-1.004036</td>\n",
       "      <td>-1.202681</td>\n",
       "      <td>-0.973561</td>\n",
       "      <td>-0.468977</td>\n",
       "      <td>-1.241278</td>\n",
       "      <td>0.803284</td>\n",
       "      <td>1.308516</td>\n",
       "      <td>1.278371</td>\n",
       "      <td>1.078464</td>\n",
       "      <td>2.057256</td>\n",
       "      <td>1.175071</td>\n",
       "      <td>1.031219</td>\n",
       "      <td>-0.263922</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>3.695788</td>\n",
       "      <td>-1.703160</td>\n",
       "      <td>0.290263</td>\n",
       "      <td>0.468383</td>\n",
       "      <td>0.572648</td>\n",
       "      <td>0.109023</td>\n",
       "      <td>0.113542</td>\n",
       "      <td>0.285158</td>\n",
       "      <td>-0.231159</td>\n",
       "      <td>-1.094136</td>\n",
       "      <td>-0.689468</td>\n",
       "      <td>-0.654807</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>-0.218622</td>\n",
       "      <td>-0.695894</td>\n",
       "      <td>-0.730076</td>\n",
       "      <td>1.761922</td>\n",
       "      <td>3.527557</td>\n",
       "      <td>1.798460</td>\n",
       "      <td>1.329174</td>\n",
       "      <td>-0.071458</td>\n",
       "      <td>0.499399</td>\n",
       "      <td>-0.934057</td>\n",
       "      <td>-0.531213</td>\n",
       "      <td>-0.576044</td>\n",
       "      <td>-0.614495</td>\n",
       "      <td>-1.511682</td>\n",
       "      <td>-1.599353</td>\n",
       "      <td>-0.175354</td>\n",
       "      <td>0.773193</td>\n",
       "      <td>-0.173623</td>\n",
       "      <td>1.952929</td>\n",
       "      <td>-0.717303</td>\n",
       "      <td>-0.377986</td>\n",
       "      <td>-0.293089</td>\n",
       "      <td>-0.766222</td>\n",
       "      <td>-1.229420</td>\n",
       "      <td>0.366970</td>\n",
       "      <td>0.087754</td>\n",
       "      <td>-0.162007</td>\n",
       "      <td>-1.340034</td>\n",
       "      <td>-0.593018</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>-0.775417</td>\n",
       "      <td>1.725802</td>\n",
       "      <td>-0.638846</td>\n",
       "      <td>-0.885256</td>\n",
       "      <td>-2.331151</td>\n",
       "      <td>-1.680706</td>\n",
       "      <td>-1.890101</td>\n",
       "      <td>0.545256</td>\n",
       "      <td>-0.834067</td>\n",
       "      <td>-1.584506</td>\n",
       "      <td>-0.572154</td>\n",
       "      <td>-1.150287</td>\n",
       "      <td>0.428867</td>\n",
       "      <td>0.622127</td>\n",
       "      <td>-1.686991</td>\n",
       "      <td>0.214979</td>\n",
       "      <td>-0.232335</td>\n",
       "      <td>-0.144848</td>\n",
       "      <td>0.720499</td>\n",
       "      <td>-0.102883</td>\n",
       "      <td>-0.109260</td>\n",
       "      <td>-0.330281</td>\n",
       "      <td>-1.177274</td>\n",
       "      <td>-1.498925</td>\n",
       "      <td>2.147040</td>\n",
       "      <td>-0.271565</td>\n",
       "      <td>-0.809746</td>\n",
       "      <td>0.044565</td>\n",
       "      <td>0.680650</td>\n",
       "      <td>1.266855</td>\n",
       "      <td>0.602343</td>\n",
       "      <td>-1.138070</td>\n",
       "      <td>-0.376717</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>-0.102642</td>\n",
       "      <td>-0.166825</td>\n",
       "      <td>1.035850</td>\n",
       "      <td>-0.199437</td>\n",
       "      <td>0.694448</td>\n",
       "      <td>1.179141</td>\n",
       "      <td>-0.578221</td>\n",
       "      <td>-1.000892</td>\n",
       "      <td>0.342946</td>\n",
       "      <td>-0.952431</td>\n",
       "      <td>1.524361</td>\n",
       "      <td>-0.110026</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>1.830866</td>\n",
       "      <td>-1.112276</td>\n",
       "      <td>1.115073</td>\n",
       "      <td>-0.360277</td>\n",
       "      <td>0.742845</td>\n",
       "      <td>0.755912</td>\n",
       "      <td>2.870287</td>\n",
       "      <td>-0.872922</td>\n",
       "      <td>-1.888692</td>\n",
       "      <td>0.676115</td>\n",
       "      <td>-0.452273</td>\n",
       "      <td>0.350374</td>\n",
       "      <td>1.538758</td>\n",
       "      <td>2.166328</td>\n",
       "      <td>-0.707447</td>\n",
       "      <td>0.421916</td>\n",
       "      <td>0.503637</td>\n",
       "      <td>0.834142</td>\n",
       "      <td>0.687666</td>\n",
       "      <td>-0.750938</td>\n",
       "      <td>1.215715</td>\n",
       "      <td>-1.737152</td>\n",
       "      <td>1.487677</td>\n",
       "      <td>0.078537</td>\n",
       "      <td>-2.127363</td>\n",
       "      <td>0.193898</td>\n",
       "      <td>-0.639881</td>\n",
       "      <td>-2.069597</td>\n",
       "      <td>-0.779445</td>\n",
       "      <td>-0.861112</td>\n",
       "      <td>-0.322879</td>\n",
       "      <td>-0.241454</td>\n",
       "      <td>0.379653</td>\n",
       "      <td>0.856802</td>\n",
       "      <td>1.408728</td>\n",
       "      <td>0.728642</td>\n",
       "      <td>1.258806</td>\n",
       "      <td>-0.242389</td>\n",
       "      <td>-0.018701</td>\n",
       "      <td>-0.361177</td>\n",
       "      <td>2.654069</td>\n",
       "      <td>-0.873063</td>\n",
       "      <td>-1.093638</td>\n",
       "      <td>-0.988992</td>\n",
       "      <td>1.162585</td>\n",
       "      <td>0.818562</td>\n",
       "      <td>-0.607212</td>\n",
       "      <td>-0.304055</td>\n",
       "      <td>-1.433244</td>\n",
       "      <td>0.422877</td>\n",
       "      <td>-1.232539</td>\n",
       "      <td>-0.448591</td>\n",
       "      <td>-0.770559</td>\n",
       "      <td>0.181931</td>\n",
       "      <td>-1.302640</td>\n",
       "      <td>1.655238</td>\n",
       "      <td>0.483701</td>\n",
       "      <td>0.109703</td>\n",
       "      <td>0.308891</td>\n",
       "      <td>1.391742</td>\n",
       "      <td>0.137471</td>\n",
       "      <td>2.966948</td>\n",
       "      <td>1.358300</td>\n",
       "      <td>-1.811734</td>\n",
       "      <td>0.097662</td>\n",
       "      <td>-1.260567</td>\n",
       "      <td>-0.069011</td>\n",
       "      <td>-1.425748</td>\n",
       "      <td>0.782916</td>\n",
       "      <td>-0.158470</td>\n",
       "      <td>2.081414</td>\n",
       "      <td>-0.462487</td>\n",
       "      <td>1.350835</td>\n",
       "      <td>1.186132</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>2.892001</td>\n",
       "      <td>0.031959</td>\n",
       "      <td>0.545154</td>\n",
       "      <td>-0.352180</td>\n",
       "      <td>0.396108</td>\n",
       "      <td>0.607451</td>\n",
       "      <td>1.696803</td>\n",
       "      <td>-1.100853</td>\n",
       "      <td>-2.338184</td>\n",
       "      <td>-1.155497</td>\n",
       "      <td>0.407080</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>-0.645513</td>\n",
       "      <td>-0.895448</td>\n",
       "      <td>-0.272235</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>-0.962142</td>\n",
       "      <td>0.214557</td>\n",
       "      <td>-1.254312</td>\n",
       "      <td>-0.342507</td>\n",
       "      <td>-1.243187</td>\n",
       "      <td>-0.772811</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>0.178469</td>\n",
       "      <td>-1.114676</td>\n",
       "      <td>-0.357569</td>\n",
       "      <td>1.569685</td>\n",
       "      <td>1.394886</td>\n",
       "      <td>-0.496901</td>\n",
       "      <td>-0.277345</td>\n",
       "      <td>-1.733904</td>\n",
       "      <td>0.387629</td>\n",
       "      <td>-0.252365</td>\n",
       "      <td>0.883467</td>\n",
       "      <td>0.396047</td>\n",
       "      <td>0.854566</td>\n",
       "      <td>-0.010155</td>\n",
       "      <td>2.172472</td>\n",
       "      <td>-0.271898</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>-0.082696</td>\n",
       "      <td>-1.084661</td>\n",
       "      <td>-0.768776</td>\n",
       "      <td>-0.577243</td>\n",
       "      <td>0.075295</td>\n",
       "      <td>-0.425470</td>\n",
       "      <td>-0.221454</td>\n",
       "      <td>3.038567</td>\n",
       "      <td>-0.014987</td>\n",
       "      <td>-1.000803</td>\n",
       "      <td>-0.908763</td>\n",
       "      <td>1.141257</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>1.301769</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>-0.556883</td>\n",
       "      <td>-0.046752</td>\n",
       "      <td>1.100571</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>-0.020343</td>\n",
       "      <td>-0.452774</td>\n",
       "      <td>0.217775</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>-0.031223</td>\n",
       "      <td>-0.438408</td>\n",
       "      <td>0.243332</td>\n",
       "      <td>0.855018</td>\n",
       "      <td>-0.662348</td>\n",
       "      <td>-1.311637</td>\n",
       "      <td>1.118934</td>\n",
       "      <td>1.619262</td>\n",
       "      <td>-0.233100</td>\n",
       "      <td>0.318896</td>\n",
       "      <td>2.175789</td>\n",
       "      <td>-0.662665</td>\n",
       "      <td>0.379576</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>-1.273795</td>\n",
       "      <td>-0.967866</td>\n",
       "      <td>-0.744889</td>\n",
       "      <td>0.317764</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>1.352271</td>\n",
       "      <td>0.163264</td>\n",
       "      <td>-1.025436</td>\n",
       "      <td>-0.331808</td>\n",
       "      <td>1.614888</td>\n",
       "      <td>0.076428</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>0.901914</td>\n",
       "      <td>0.348914</td>\n",
       "      <td>-1.721968</td>\n",
       "      <td>1.400576</td>\n",
       "      <td>0.515078</td>\n",
       "      <td>0.363892</td>\n",
       "      <td>-0.087531</td>\n",
       "      <td>-1.237460</td>\n",
       "      <td>0.433759</td>\n",
       "      <td>1.557273</td>\n",
       "      <td>-0.822598</td>\n",
       "      <td>-0.090792</td>\n",
       "      <td>1.406213</td>\n",
       "      <td>-0.206822</td>\n",
       "      <td>1.117272</td>\n",
       "      <td>-0.587932</td>\n",
       "      <td>-0.755018</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>-0.390826</td>\n",
       "      <td>1.062657</td>\n",
       "      <td>-0.664119</td>\n",
       "      <td>-0.250758</td>\n",
       "      <td>1.082510</td>\n",
       "      <td>0.388175</td>\n",
       "      <td>1.424376</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>-0.967037</td>\n",
       "      <td>0.540612</td>\n",
       "      <td>-0.550632</td>\n",
       "      <td>-0.642900</td>\n",
       "      <td>0.123557</td>\n",
       "      <td>-1.029898</td>\n",
       "      <td>-1.469545</td>\n",
       "      <td>-1.089267</td>\n",
       "      <td>0.137719</td>\n",
       "      <td>-0.127648</td>\n",
       "      <td>0.610036</td>\n",
       "      <td>1.386465</td>\n",
       "      <td>1.191618</td>\n",
       "      <td>0.837197</td>\n",
       "      <td>1.414060</td>\n",
       "      <td>2.084938</td>\n",
       "      <td>1.004954</td>\n",
       "      <td>-0.320494</td>\n",
       "      <td>-0.264041</td>\n",
       "      <td>3.219583</td>\n",
       "      <td>-2.723561</td>\n",
       "      <td>0.739760</td>\n",
       "      <td>-0.754138</td>\n",
       "      <td>0.631280</td>\n",
       "      <td>0.654567</td>\n",
       "      <td>0.248614</td>\n",
       "      <td>0.339136</td>\n",
       "      <td>-0.403282</td>\n",
       "      <td>-0.721593</td>\n",
       "      <td>-0.979750</td>\n",
       "      <td>-0.679552</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>-0.298757</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>-1.617468</td>\n",
       "      <td>2.457797</td>\n",
       "      <td>2.817357</td>\n",
       "      <td>2.300969</td>\n",
       "      <td>0.845116</td>\n",
       "      <td>0.183681</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>-0.667359</td>\n",
       "      <td>-0.796434</td>\n",
       "      <td>0.412470</td>\n",
       "      <td>-0.171157</td>\n",
       "      <td>-1.367766</td>\n",
       "      <td>-1.477385</td>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.772771</td>\n",
       "      <td>-0.321854</td>\n",
       "      <td>1.852506</td>\n",
       "      <td>-1.184308</td>\n",
       "      <td>-0.154671</td>\n",
       "      <td>-0.361259</td>\n",
       "      <td>-0.947908</td>\n",
       "      <td>-1.931221</td>\n",
       "      <td>0.142392</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>-0.335048</td>\n",
       "      <td>-1.326935</td>\n",
       "      <td>-0.129501</td>\n",
       "      <td>0.554625</td>\n",
       "      <td>-0.030821</td>\n",
       "      <td>2.250505</td>\n",
       "      <td>-0.872338</td>\n",
       "      <td>-0.156063</td>\n",
       "      <td>-2.030459</td>\n",
       "      <td>-1.782128</td>\n",
       "      <td>-1.364034</td>\n",
       "      <td>0.892138</td>\n",
       "      <td>-1.655399</td>\n",
       "      <td>-2.289551</td>\n",
       "      <td>-1.228897</td>\n",
       "      <td>-1.349560</td>\n",
       "      <td>0.456579</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>-1.041456</td>\n",
       "      <td>-0.110932</td>\n",
       "      <td>-0.431590</td>\n",
       "      <td>-0.355509</td>\n",
       "      <td>0.839867</td>\n",
       "      <td>0.532492</td>\n",
       "      <td>0.020230</td>\n",
       "      <td>-0.660341</td>\n",
       "      <td>-0.983935</td>\n",
       "      <td>-1.692103</td>\n",
       "      <td>2.331987</td>\n",
       "      <td>0.381542</td>\n",
       "      <td>-0.232341</td>\n",
       "      <td>-0.624587</td>\n",
       "      <td>1.073637</td>\n",
       "      <td>0.982656</td>\n",
       "      <td>0.730721</td>\n",
       "      <td>-1.429395</td>\n",
       "      <td>0.291138</td>\n",
       "      <td>-0.303486</td>\n",
       "      <td>-0.412409</td>\n",
       "      <td>0.755721</td>\n",
       "      <td>1.465066</td>\n",
       "      <td>0.630066</td>\n",
       "      <td>1.403412</td>\n",
       "      <td>0.512676</td>\n",
       "      <td>-0.830079</td>\n",
       "      <td>-0.512672</td>\n",
       "      <td>-0.302445</td>\n",
       "      <td>-0.466146</td>\n",
       "      <td>1.839556</td>\n",
       "      <td>1.076609</td>\n",
       "      <td>0.446778</td>\n",
       "      <td>1.558245</td>\n",
       "      <td>-0.744205</td>\n",
       "      <td>0.738909</td>\n",
       "      <td>-1.394410</td>\n",
       "      <td>0.432342</td>\n",
       "      <td>0.377223</td>\n",
       "      <td>2.964271</td>\n",
       "      <td>-0.627241</td>\n",
       "      <td>-2.399944</td>\n",
       "      <td>1.624132</td>\n",
       "      <td>-0.659156</td>\n",
       "      <td>1.374274</td>\n",
       "      <td>1.462509</td>\n",
       "      <td>1.691212</td>\n",
       "      <td>-0.793223</td>\n",
       "      <td>-0.414623</td>\n",
       "      <td>0.448220</td>\n",
       "      <td>0.735249</td>\n",
       "      <td>0.822697</td>\n",
       "      <td>-0.212738</td>\n",
       "      <td>0.611116</td>\n",
       "      <td>-0.867961</td>\n",
       "      <td>0.674476</td>\n",
       "      <td>-0.911079</td>\n",
       "      <td>-2.391463</td>\n",
       "      <td>0.578134</td>\n",
       "      <td>-0.930497</td>\n",
       "      <td>-1.721426</td>\n",
       "      <td>-0.600573</td>\n",
       "      <td>-0.661857</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>-1.060428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864132</td>\n",
       "      <td>0.864132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>4039.923304</td>\n",
       "      <td>0.980425</td>\n",
       "      <td>0.077561</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3716.700945</td>\n",
       "      <td>0.565869</td>\n",
       "      <td>-0.194951</td>\n",
       "      <td>0.817012</td>\n",
       "      <td>1.365198</td>\n",
       "      <td>-0.375600</td>\n",
       "      <td>-0.638228</td>\n",
       "      <td>-0.886599</td>\n",
       "      <td>-0.324619</td>\n",
       "      <td>-0.696173</td>\n",
       "      <td>0.539154</td>\n",
       "      <td>1.192676</td>\n",
       "      <td>-1.014723</td>\n",
       "      <td>-0.457427</td>\n",
       "      <td>0.694822</td>\n",
       "      <td>0.540547</td>\n",
       "      <td>-1.194756</td>\n",
       "      <td>0.263363</td>\n",
       "      <td>0.495460</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.441584</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>1.562352</td>\n",
       "      <td>0.406163</td>\n",
       "      <td>0.759495</td>\n",
       "      <td>-0.342052</td>\n",
       "      <td>-0.749658</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>-0.189946</td>\n",
       "      <td>-0.335913</td>\n",
       "      <td>0.211071</td>\n",
       "      <td>0.213537</td>\n",
       "      <td>0.430720</td>\n",
       "      <td>0.270526</td>\n",
       "      <td>0.081180</td>\n",
       "      <td>-0.108306</td>\n",
       "      <td>-0.576988</td>\n",
       "      <td>0.392167</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>-0.844703</td>\n",
       "      <td>0.204616</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.449083</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>-0.666154</td>\n",
       "      <td>-0.135457</td>\n",
       "      <td>-0.465042</td>\n",
       "      <td>-0.295165</td>\n",
       "      <td>-0.528455</td>\n",
       "      <td>-0.980306</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>0.062441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791238</td>\n",
       "      <td>0.361548</td>\n",
       "      <td>0.173842</td>\n",
       "      <td>-0.825246</td>\n",
       "      <td>1.932059</td>\n",
       "      <td>-1.230378</td>\n",
       "      <td>0.450481</td>\n",
       "      <td>1.553234</td>\n",
       "      <td>0.278715</td>\n",
       "      <td>-0.623450</td>\n",
       "      <td>0.966802</td>\n",
       "      <td>-0.830932</td>\n",
       "      <td>-0.444525</td>\n",
       "      <td>1.328755</td>\n",
       "      <td>0.800686</td>\n",
       "      <td>0.503918</td>\n",
       "      <td>-0.804420</td>\n",
       "      <td>-1.955507</td>\n",
       "      <td>2.050044</td>\n",
       "      <td>1.203810</td>\n",
       "      <td>-0.077942</td>\n",
       "      <td>-1.216834</td>\n",
       "      <td>-0.875247</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.957749</td>\n",
       "      <td>-1.188893</td>\n",
       "      <td>0.252008</td>\n",
       "      <td>1.280950</td>\n",
       "      <td>0.496807</td>\n",
       "      <td>-1.995887</td>\n",
       "      <td>-1.139911</td>\n",
       "      <td>1.051043</td>\n",
       "      <td>-0.391777</td>\n",
       "      <td>-0.819441</td>\n",
       "      <td>-0.818705</td>\n",
       "      <td>-0.332717</td>\n",
       "      <td>-0.764796</td>\n",
       "      <td>0.921482</td>\n",
       "      <td>-1.438210</td>\n",
       "      <td>0.683035</td>\n",
       "      <td>0.454172</td>\n",
       "      <td>-0.618783</td>\n",
       "      <td>-1.293471</td>\n",
       "      <td>-0.635391</td>\n",
       "      <td>1.057120</td>\n",
       "      <td>0.369398</td>\n",
       "      <td>-0.979836</td>\n",
       "      <td>0.857004</td>\n",
       "      <td>1.900004</td>\n",
       "      <td>-1.075099</td>\n",
       "      <td>-1.081066</td>\n",
       "      <td>0.491852</td>\n",
       "      <td>-0.142297</td>\n",
       "      <td>-0.374557</td>\n",
       "      <td>-0.546556</td>\n",
       "      <td>0.270015</td>\n",
       "      <td>-0.915636</td>\n",
       "      <td>-1.395192</td>\n",
       "      <td>-0.637735</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>2.240972</td>\n",
       "      <td>0.099878</td>\n",
       "      <td>0.221896</td>\n",
       "      <td>1.448714</td>\n",
       "      <td>-0.258215</td>\n",
       "      <td>-1.329676</td>\n",
       "      <td>-1.168996</td>\n",
       "      <td>-1.271628</td>\n",
       "      <td>-1.217927</td>\n",
       "      <td>-0.661539</td>\n",
       "      <td>-0.143898</td>\n",
       "      <td>-0.417832</td>\n",
       "      <td>-1.219235</td>\n",
       "      <td>-0.352627</td>\n",
       "      <td>-0.428237</td>\n",
       "      <td>0.584553</td>\n",
       "      <td>-0.119335</td>\n",
       "      <td>0.482549</td>\n",
       "      <td>1.401183</td>\n",
       "      <td>1.365027</td>\n",
       "      <td>-0.280656</td>\n",
       "      <td>1.680634</td>\n",
       "      <td>0.792832</td>\n",
       "      <td>1.426756</td>\n",
       "      <td>-0.728069</td>\n",
       "      <td>1.301497</td>\n",
       "      <td>-0.890270</td>\n",
       "      <td>-0.405239</td>\n",
       "      <td>1.815641</td>\n",
       "      <td>0.958664</td>\n",
       "      <td>0.173015</td>\n",
       "      <td>-1.201416</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>-1.641177</td>\n",
       "      <td>-1.709291</td>\n",
       "      <td>0.074809</td>\n",
       "      <td>-0.138275</td>\n",
       "      <td>-0.230227</td>\n",
       "      <td>0.713584</td>\n",
       "      <td>1.300477</td>\n",
       "      <td>1.283754</td>\n",
       "      <td>0.379641</td>\n",
       "      <td>-0.262952</td>\n",
       "      <td>-1.070452</td>\n",
       "      <td>-1.983113</td>\n",
       "      <td>0.056746</td>\n",
       "      <td>-1.346568</td>\n",
       "      <td>-2.810750</td>\n",
       "      <td>0.127639</td>\n",
       "      <td>1.778513</td>\n",
       "      <td>0.602328</td>\n",
       "      <td>1.015359</td>\n",
       "      <td>-0.442900</td>\n",
       "      <td>-0.937223</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>-0.973247</td>\n",
       "      <td>0.332701</td>\n",
       "      <td>0.500761</td>\n",
       "      <td>0.650849</td>\n",
       "      <td>0.623133</td>\n",
       "      <td>-0.931118</td>\n",
       "      <td>2.030491</td>\n",
       "      <td>0.473891</td>\n",
       "      <td>1.362653</td>\n",
       "      <td>-2.024846</td>\n",
       "      <td>-1.331298</td>\n",
       "      <td>-1.335496</td>\n",
       "      <td>-1.754971</td>\n",
       "      <td>-0.280954</td>\n",
       "      <td>-1.957459</td>\n",
       "      <td>-0.509778</td>\n",
       "      <td>-0.042258</td>\n",
       "      <td>-1.315013</td>\n",
       "      <td>-1.910744</td>\n",
       "      <td>1.801798</td>\n",
       "      <td>1.131574</td>\n",
       "      <td>-0.373484</td>\n",
       "      <td>0.719155</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>0.867076</td>\n",
       "      <td>0.345127</td>\n",
       "      <td>2.041838</td>\n",
       "      <td>2.206598</td>\n",
       "      <td>-0.351819</td>\n",
       "      <td>-0.875264</td>\n",
       "      <td>0.641113</td>\n",
       "      <td>-1.668061</td>\n",
       "      <td>0.307259</td>\n",
       "      <td>-1.616258</td>\n",
       "      <td>-0.481389</td>\n",
       "      <td>0.427815</td>\n",
       "      <td>-0.143668</td>\n",
       "      <td>0.341094</td>\n",
       "      <td>-1.864514</td>\n",
       "      <td>-0.927631</td>\n",
       "      <td>0.406877</td>\n",
       "      <td>0.649714</td>\n",
       "      <td>0.205058</td>\n",
       "      <td>-0.217502</td>\n",
       "      <td>0.929749</td>\n",
       "      <td>0.343038</td>\n",
       "      <td>0.066201</td>\n",
       "      <td>1.272163</td>\n",
       "      <td>0.919435</td>\n",
       "      <td>-0.072207</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>-0.329024</td>\n",
       "      <td>-0.591585</td>\n",
       "      <td>-0.473714</td>\n",
       "      <td>0.475744</td>\n",
       "      <td>-0.960328</td>\n",
       "      <td>0.178671</td>\n",
       "      <td>-0.526646</td>\n",
       "      <td>-0.531861</td>\n",
       "      <td>-1.927095</td>\n",
       "      <td>1.144331</td>\n",
       "      <td>0.282744</td>\n",
       "      <td>0.776339</td>\n",
       "      <td>-0.634078</td>\n",
       "      <td>1.042779</td>\n",
       "      <td>-1.607201</td>\n",
       "      <td>0.324094</td>\n",
       "      <td>2.098300</td>\n",
       "      <td>1.251156</td>\n",
       "      <td>-0.597863</td>\n",
       "      <td>1.559430</td>\n",
       "      <td>0.571724</td>\n",
       "      <td>-0.164708</td>\n",
       "      <td>-0.731976</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.721155</td>\n",
       "      <td>-0.545242</td>\n",
       "      <td>-0.300306</td>\n",
       "      <td>0.517033</td>\n",
       "      <td>0.480043</td>\n",
       "      <td>2.275954</td>\n",
       "      <td>1.501927</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>0.065946</td>\n",
       "      <td>-1.035754</td>\n",
       "      <td>0.981107</td>\n",
       "      <td>-0.589126</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>-0.851634</td>\n",
       "      <td>0.864457</td>\n",
       "      <td>-1.482050</td>\n",
       "      <td>-0.159491</td>\n",
       "      <td>-0.926711</td>\n",
       "      <td>0.375833</td>\n",
       "      <td>-2.027254</td>\n",
       "      <td>-0.682262</td>\n",
       "      <td>-0.536917</td>\n",
       "      <td>-1.522379</td>\n",
       "      <td>-0.331838</td>\n",
       "      <td>-0.162530</td>\n",
       "      <td>1.559547</td>\n",
       "      <td>-0.098326</td>\n",
       "      <td>1.492856</td>\n",
       "      <td>-2.051076</td>\n",
       "      <td>-0.012754</td>\n",
       "      <td>0.472696</td>\n",
       "      <td>-0.413519</td>\n",
       "      <td>-0.843732</td>\n",
       "      <td>-0.015646</td>\n",
       "      <td>-1.528639</td>\n",
       "      <td>-1.802665</td>\n",
       "      <td>-1.805658</td>\n",
       "      <td>-0.932811</td>\n",
       "      <td>0.917433</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.423369</td>\n",
       "      <td>1.214396</td>\n",
       "      <td>-0.414594</td>\n",
       "      <td>-1.337777</td>\n",
       "      <td>0.585998</td>\n",
       "      <td>0.147297</td>\n",
       "      <td>1.633551</td>\n",
       "      <td>-0.449635</td>\n",
       "      <td>0.381003</td>\n",
       "      <td>-0.362328</td>\n",
       "      <td>0.285398</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>-1.669052</td>\n",
       "      <td>-2.338128</td>\n",
       "      <td>0.343073</td>\n",
       "      <td>-0.401335</td>\n",
       "      <td>-1.459433</td>\n",
       "      <td>-2.571274</td>\n",
       "      <td>-1.345469</td>\n",
       "      <td>-2.229134</td>\n",
       "      <td>1.391976</td>\n",
       "      <td>-0.342358</td>\n",
       "      <td>-1.589367</td>\n",
       "      <td>1.909097</td>\n",
       "      <td>0.208813</td>\n",
       "      <td>-0.938359</td>\n",
       "      <td>0.178104</td>\n",
       "      <td>0.344523</td>\n",
       "      <td>-0.484381</td>\n",
       "      <td>-1.433688</td>\n",
       "      <td>-1.173840</td>\n",
       "      <td>-0.394206</td>\n",
       "      <td>1.108125</td>\n",
       "      <td>-0.950039</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>0.883031</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>-1.284136</td>\n",
       "      <td>-0.063606</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>0.414114</td>\n",
       "      <td>-0.151016</td>\n",
       "      <td>-1.494915</td>\n",
       "      <td>0.105802</td>\n",
       "      <td>-0.148888</td>\n",
       "      <td>0.692591</td>\n",
       "      <td>-0.851735</td>\n",
       "      <td>0.309875</td>\n",
       "      <td>-0.127803</td>\n",
       "      <td>-0.915938</td>\n",
       "      <td>0.708021</td>\n",
       "      <td>-0.428317</td>\n",
       "      <td>-0.047052</td>\n",
       "      <td>-0.220690</td>\n",
       "      <td>0.577507</td>\n",
       "      <td>-0.288849</td>\n",
       "      <td>0.683229</td>\n",
       "      <td>-0.440618</td>\n",
       "      <td>-0.066410</td>\n",
       "      <td>0.158397</td>\n",
       "      <td>0.823294</td>\n",
       "      <td>0.821315</td>\n",
       "      <td>0.249425</td>\n",
       "      <td>0.537330</td>\n",
       "      <td>-0.758475</td>\n",
       "      <td>0.643766</td>\n",
       "      <td>0.662780</td>\n",
       "      <td>-0.503751</td>\n",
       "      <td>0.574039</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>-0.659074</td>\n",
       "      <td>-0.517903</td>\n",
       "      <td>0.822551</td>\n",
       "      <td>0.094558</td>\n",
       "      <td>0.749206</td>\n",
       "      <td>-0.543886</td>\n",
       "      <td>-0.685556</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>1.236177</td>\n",
       "      <td>0.702077</td>\n",
       "      <td>-0.172354</td>\n",
       "      <td>1.242556</td>\n",
       "      <td>0.826235</td>\n",
       "      <td>0.135730</td>\n",
       "      <td>0.640135</td>\n",
       "      <td>0.168826</td>\n",
       "      <td>-1.405411</td>\n",
       "      <td>0.912484</td>\n",
       "      <td>1.254458</td>\n",
       "      <td>-0.328924</td>\n",
       "      <td>0.299672</td>\n",
       "      <td>-0.117583</td>\n",
       "      <td>-0.105412</td>\n",
       "      <td>1.374715</td>\n",
       "      <td>0.756338</td>\n",
       "      <td>-0.863363</td>\n",
       "      <td>-1.091845</td>\n",
       "      <td>1.071401</td>\n",
       "      <td>-1.755264</td>\n",
       "      <td>0.114599</td>\n",
       "      <td>-0.836031</td>\n",
       "      <td>-0.900004</td>\n",
       "      <td>-1.342033</td>\n",
       "      <td>0.809631</td>\n",
       "      <td>-0.217264</td>\n",
       "      <td>-0.633005</td>\n",
       "      <td>1.125255</td>\n",
       "      <td>0.615951</td>\n",
       "      <td>0.260963</td>\n",
       "      <td>0.571133</td>\n",
       "      <td>0.602429</td>\n",
       "      <td>-0.039376</td>\n",
       "      <td>0.578215</td>\n",
       "      <td>0.199289</td>\n",
       "      <td>0.640560</td>\n",
       "      <td>0.059373</td>\n",
       "      <td>0.948452</td>\n",
       "      <td>0.972260</td>\n",
       "      <td>0.212771</td>\n",
       "      <td>1.933770</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>-0.686253</td>\n",
       "      <td>-1.090212</td>\n",
       "      <td>0.625351</td>\n",
       "      <td>3.060437</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>-1.046978</td>\n",
       "      <td>0.268066</td>\n",
       "      <td>0.932033</td>\n",
       "      <td>-1.188955</td>\n",
       "      <td>0.544965</td>\n",
       "      <td>-1.239705</td>\n",
       "      <td>1.630522</td>\n",
       "      <td>0.131212</td>\n",
       "      <td>0.657435</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.698825</td>\n",
       "      <td>2.433834</td>\n",
       "      <td>0.372451</td>\n",
       "      <td>-1.127563</td>\n",
       "      <td>0.468507</td>\n",
       "      <td>1.462701</td>\n",
       "      <td>-0.148704</td>\n",
       "      <td>-0.715995</td>\n",
       "      <td>0.454146</td>\n",
       "      <td>-0.183801</td>\n",
       "      <td>-0.198391</td>\n",
       "      <td>-1.301124</td>\n",
       "      <td>-0.062060</td>\n",
       "      <td>-0.127658</td>\n",
       "      <td>0.207185</td>\n",
       "      <td>-1.756979</td>\n",
       "      <td>-0.042742</td>\n",
       "      <td>-0.129621</td>\n",
       "      <td>-0.726083</td>\n",
       "      <td>-1.581759</td>\n",
       "      <td>1.757948</td>\n",
       "      <td>1.532520</td>\n",
       "      <td>3.116335</td>\n",
       "      <td>-0.084914</td>\n",
       "      <td>2.719274</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>0.427639</td>\n",
       "      <td>0.438111</td>\n",
       "      <td>-0.814974</td>\n",
       "      <td>1.459938</td>\n",
       "      <td>-0.548870</td>\n",
       "      <td>0.475448</td>\n",
       "      <td>-0.856790</td>\n",
       "      <td>-0.843569</td>\n",
       "      <td>-1.099090</td>\n",
       "      <td>-0.197499</td>\n",
       "      <td>-0.813265</td>\n",
       "      <td>-0.599152</td>\n",
       "      <td>-1.289894</td>\n",
       "      <td>0.292906</td>\n",
       "      <td>-0.742077</td>\n",
       "      <td>0.998885</td>\n",
       "      <td>-2.162448</td>\n",
       "      <td>0.407606</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.183846</td>\n",
       "      <td>-0.385094</td>\n",
       "      <td>1.748256</td>\n",
       "      <td>-0.271294</td>\n",
       "      <td>-0.698630</td>\n",
       "      <td>2.561905</td>\n",
       "      <td>-0.091668</td>\n",
       "      <td>0.313518</td>\n",
       "      <td>-1.635574</td>\n",
       "      <td>0.178460</td>\n",
       "      <td>-0.713147</td>\n",
       "      <td>-0.468777</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>-1.469499</td>\n",
       "      <td>2.092914</td>\n",
       "      <td>-1.657286</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>-0.600777</td>\n",
       "      <td>1.202361</td>\n",
       "      <td>-0.982442</td>\n",
       "      <td>-1.367377</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>-1.580557</td>\n",
       "      <td>-0.979499</td>\n",
       "      <td>-0.027481</td>\n",
       "      <td>-0.074498</td>\n",
       "      <td>0.508188</td>\n",
       "      <td>-1.090371</td>\n",
       "      <td>1.228268</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>-0.911200</td>\n",
       "      <td>2.527987</td>\n",
       "      <td>1.516036</td>\n",
       "      <td>-0.354244</td>\n",
       "      <td>1.512053</td>\n",
       "      <td>-0.096952</td>\n",
       "      <td>0.469165</td>\n",
       "      <td>-2.232217</td>\n",
       "      <td>-0.135588</td>\n",
       "      <td>-0.587575</td>\n",
       "      <td>-0.391613</td>\n",
       "      <td>-0.438010</td>\n",
       "      <td>1.418632</td>\n",
       "      <td>1.017589</td>\n",
       "      <td>0.704699</td>\n",
       "      <td>-1.700592</td>\n",
       "      <td>0.515187</td>\n",
       "      <td>-0.747152</td>\n",
       "      <td>-1.771321</td>\n",
       "      <td>1.161145</td>\n",
       "      <td>-0.268552</td>\n",
       "      <td>-0.401139</td>\n",
       "      <td>-0.251150</td>\n",
       "      <td>0.603337</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>-0.139369</td>\n",
       "      <td>-0.014860</td>\n",
       "      <td>-1.569516</td>\n",
       "      <td>-0.548250</td>\n",
       "      <td>0.612693</td>\n",
       "      <td>1.315784</td>\n",
       "      <td>-2.112829</td>\n",
       "      <td>0.278851</td>\n",
       "      <td>-0.128415</td>\n",
       "      <td>0.030782</td>\n",
       "      <td>0.214230</td>\n",
       "      <td>0.368063</td>\n",
       "      <td>-0.359224</td>\n",
       "      <td>1.637869</td>\n",
       "      <td>-1.261576</td>\n",
       "      <td>0.386654</td>\n",
       "      <td>0.549211</td>\n",
       "      <td>0.538989</td>\n",
       "      <td>-0.444763</td>\n",
       "      <td>0.629904</td>\n",
       "      <td>-2.131197</td>\n",
       "      <td>0.736745</td>\n",
       "      <td>2.312745</td>\n",
       "      <td>0.906142</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>0.451170</td>\n",
       "      <td>-0.018734</td>\n",
       "      <td>0.163278</td>\n",
       "      <td>-0.121093</td>\n",
       "      <td>-0.136882</td>\n",
       "      <td>0.903745</td>\n",
       "      <td>-0.101422</td>\n",
       "      <td>2.128245</td>\n",
       "      <td>-1.362926</td>\n",
       "      <td>1.157047</td>\n",
       "      <td>-1.761911</td>\n",
       "      <td>-0.498332</td>\n",
       "      <td>0.858829</td>\n",
       "      <td>-0.334365</td>\n",
       "      <td>0.345017</td>\n",
       "      <td>-0.216210</td>\n",
       "      <td>-0.204819</td>\n",
       "      <td>-0.279132</td>\n",
       "      <td>-0.302813</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>0.162822</td>\n",
       "      <td>0.591432</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.472255</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>0.540872</td>\n",
       "      <td>1.319473</td>\n",
       "      <td>-0.767702</td>\n",
       "      <td>1.553380</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>-0.488153</td>\n",
       "      <td>-0.959591</td>\n",
       "      <td>-0.589164</td>\n",
       "      <td>-0.240999</td>\n",
       "      <td>0.707993</td>\n",
       "      <td>0.160263</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>1.399700</td>\n",
       "      <td>0.957316</td>\n",
       "      <td>-0.531733</td>\n",
       "      <td>-0.359155</td>\n",
       "      <td>0.764543</td>\n",
       "      <td>1.671533</td>\n",
       "      <td>-0.417895</td>\n",
       "      <td>-0.586414</td>\n",
       "      <td>0.010057</td>\n",
       "      <td>0.707935</td>\n",
       "      <td>-0.137830</td>\n",
       "      <td>-1.762182</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>-0.264837</td>\n",
       "      <td>0.577119</td>\n",
       "      <td>0.694032</td>\n",
       "      <td>-0.779780</td>\n",
       "      <td>2.351233</td>\n",
       "      <td>0.673321</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.241396</td>\n",
       "      <td>-1.191747</td>\n",
       "      <td>-0.043301</td>\n",
       "      <td>0.547934</td>\n",
       "      <td>-0.015136</td>\n",
       "      <td>-0.315675</td>\n",
       "      <td>0.115192</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>2.061263</td>\n",
       "      <td>0.893651</td>\n",
       "      <td>0.119003</td>\n",
       "      <td>1.742773</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>0.332636</td>\n",
       "      <td>0.097790</td>\n",
       "      <td>-0.316208</td>\n",
       "      <td>-0.180232</td>\n",
       "      <td>0.391625</td>\n",
       "      <td>0.831131</td>\n",
       "      <td>0.555874</td>\n",
       "      <td>0.317654</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.848737</td>\n",
       "      <td>0.750065</td>\n",
       "      <td>-0.025215</td>\n",
       "      <td>0.692848</td>\n",
       "      <td>1.258413</td>\n",
       "      <td>-1.504180</td>\n",
       "      <td>-0.398196</td>\n",
       "      <td>1.009436</td>\n",
       "      <td>-0.232500</td>\n",
       "      <td>0.469581</td>\n",
       "      <td>-1.141193</td>\n",
       "      <td>-1.744912</td>\n",
       "      <td>-0.994475</td>\n",
       "      <td>0.213869</td>\n",
       "      <td>-0.469427</td>\n",
       "      <td>-0.125585</td>\n",
       "      <td>-0.286840</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>-0.028133</td>\n",
       "      <td>-0.243528</td>\n",
       "      <td>0.230339</td>\n",
       "      <td>-0.630239</td>\n",
       "      <td>0.173625</td>\n",
       "      <td>0.297307</td>\n",
       "      <td>0.109020</td>\n",
       "      <td>-1.023336</td>\n",
       "      <td>0.470630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415861</td>\n",
       "      <td>1.097247</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>2.119945</td>\n",
       "      <td>0.494289</td>\n",
       "      <td>0.305819</td>\n",
       "      <td>1.060821</td>\n",
       "      <td>-0.487754</td>\n",
       "      <td>0.878551</td>\n",
       "      <td>-0.882648</td>\n",
       "      <td>2.249404</td>\n",
       "      <td>-0.085522</td>\n",
       "      <td>-0.960362</td>\n",
       "      <td>1.050887</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.545120</td>\n",
       "      <td>-1.250764</td>\n",
       "      <td>-0.429876</td>\n",
       "      <td>-0.898322</td>\n",
       "      <td>-0.839170</td>\n",
       "      <td>-1.578071</td>\n",
       "      <td>0.498339</td>\n",
       "      <td>-1.419257</td>\n",
       "      <td>1.159922</td>\n",
       "      <td>-1.075122</td>\n",
       "      <td>2.084774</td>\n",
       "      <td>-1.186197</td>\n",
       "      <td>-0.156135</td>\n",
       "      <td>-0.599706</td>\n",
       "      <td>-1.004679</td>\n",
       "      <td>-0.699753</td>\n",
       "      <td>2.458900</td>\n",
       "      <td>0.243475</td>\n",
       "      <td>-0.283325</td>\n",
       "      <td>-1.282677</td>\n",
       "      <td>-1.336366</td>\n",
       "      <td>-0.157892</td>\n",
       "      <td>-1.337802</td>\n",
       "      <td>-0.469881</td>\n",
       "      <td>-0.130940</td>\n",
       "      <td>1.537444</td>\n",
       "      <td>-0.307948</td>\n",
       "      <td>0.869933</td>\n",
       "      <td>-0.798872</td>\n",
       "      <td>-0.976847</td>\n",
       "      <td>1.992207</td>\n",
       "      <td>0.189840</td>\n",
       "      <td>0.275615</td>\n",
       "      <td>-1.875514</td>\n",
       "      <td>-0.151722</td>\n",
       "      <td>0.782978</td>\n",
       "      <td>1.408595</td>\n",
       "      <td>-0.288523</td>\n",
       "      <td>-2.175964</td>\n",
       "      <td>-1.477517</td>\n",
       "      <td>0.140051</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>-0.485971</td>\n",
       "      <td>1.060990</td>\n",
       "      <td>0.365056</td>\n",
       "      <td>0.714142</td>\n",
       "      <td>-1.021666</td>\n",
       "      <td>0.519976</td>\n",
       "      <td>-2.221756</td>\n",
       "      <td>-1.465369</td>\n",
       "      <td>-0.308276</td>\n",
       "      <td>-0.559353</td>\n",
       "      <td>-1.442894</td>\n",
       "      <td>1.977017</td>\n",
       "      <td>-0.409804</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>2.421183</td>\n",
       "      <td>-0.960381</td>\n",
       "      <td>-1.830275</td>\n",
       "      <td>-1.773434</td>\n",
       "      <td>0.469418</td>\n",
       "      <td>0.374265</td>\n",
       "      <td>-1.017841</td>\n",
       "      <td>0.712897</td>\n",
       "      <td>-0.238653</td>\n",
       "      <td>0.376397</td>\n",
       "      <td>1.395878</td>\n",
       "      <td>-0.079229</td>\n",
       "      <td>-0.361021</td>\n",
       "      <td>-0.519781</td>\n",
       "      <td>-1.053717</td>\n",
       "      <td>-0.577861</td>\n",
       "      <td>-2.114499</td>\n",
       "      <td>0.310240</td>\n",
       "      <td>-0.695740</td>\n",
       "      <td>-1.763496</td>\n",
       "      <td>2.302353</td>\n",
       "      <td>-0.656003</td>\n",
       "      <td>0.627323</td>\n",
       "      <td>-0.803159</td>\n",
       "      <td>0.791286</td>\n",
       "      <td>-0.329510</td>\n",
       "      <td>0.526725</td>\n",
       "      <td>1.647985</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>1.076517</td>\n",
       "      <td>0.973352</td>\n",
       "      <td>0.948523</td>\n",
       "      <td>-0.175001</td>\n",
       "      <td>0.412381</td>\n",
       "      <td>-0.748610</td>\n",
       "      <td>-1.670426</td>\n",
       "      <td>-0.178335</td>\n",
       "      <td>-0.107888</td>\n",
       "      <td>-2.250536</td>\n",
       "      <td>0.518664</td>\n",
       "      <td>-0.925782</td>\n",
       "      <td>-1.677294</td>\n",
       "      <td>-1.981252</td>\n",
       "      <td>1.006651</td>\n",
       "      <td>0.464541</td>\n",
       "      <td>-0.454912</td>\n",
       "      <td>0.642984</td>\n",
       "      <td>1.792409</td>\n",
       "      <td>0.418054</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.264337</td>\n",
       "      <td>-2.565504</td>\n",
       "      <td>-0.440364</td>\n",
       "      <td>-2.821323</td>\n",
       "      <td>-2.445911</td>\n",
       "      <td>-0.375651</td>\n",
       "      <td>2.094750</td>\n",
       "      <td>-1.029611</td>\n",
       "      <td>0.378026</td>\n",
       "      <td>-1.573110</td>\n",
       "      <td>-0.432541</td>\n",
       "      <td>-1.042428</td>\n",
       "      <td>0.968903</td>\n",
       "      <td>-1.409014</td>\n",
       "      <td>0.277124</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>0.116091</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.340009</td>\n",
       "      <td>-1.005010</td>\n",
       "      <td>-0.469970</td>\n",
       "      <td>-0.242151</td>\n",
       "      <td>-0.316939</td>\n",
       "      <td>-0.483466</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.901185</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>0.706371</td>\n",
       "      <td>-0.552739</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.049002</td>\n",
       "      <td>-0.568267</td>\n",
       "      <td>0.103754</td>\n",
       "      <td>-0.596777</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>1.356391</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.906584</td>\n",
       "      <td>0.702386</td>\n",
       "      <td>-1.542083</td>\n",
       "      <td>1.376450</td>\n",
       "      <td>0.328814</td>\n",
       "      <td>-0.115663</td>\n",
       "      <td>0.829889</td>\n",
       "      <td>-1.198023</td>\n",
       "      <td>-1.925958</td>\n",
       "      <td>-0.917333</td>\n",
       "      <td>-1.472541</td>\n",
       "      <td>-0.238393</td>\n",
       "      <td>1.234683</td>\n",
       "      <td>0.286341</td>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.634444</td>\n",
       "      <td>0.702852</td>\n",
       "      <td>1.040686</td>\n",
       "      <td>0.233462</td>\n",
       "      <td>0.029680</td>\n",
       "      <td>-1.196232</td>\n",
       "      <td>3.358056</td>\n",
       "      <td>-1.148794</td>\n",
       "      <td>1.022671</td>\n",
       "      <td>0.597961</td>\n",
       "      <td>1.789085</td>\n",
       "      <td>0.721369</td>\n",
       "      <td>0.766783</td>\n",
       "      <td>0.408671</td>\n",
       "      <td>0.514068</td>\n",
       "      <td>-0.163165</td>\n",
       "      <td>0.498311</td>\n",
       "      <td>-0.217684</td>\n",
       "      <td>-0.068095</td>\n",
       "      <td>0.227333</td>\n",
       "      <td>-0.046898</td>\n",
       "      <td>-0.796693</td>\n",
       "      <td>1.928903</td>\n",
       "      <td>3.419389</td>\n",
       "      <td>2.983715</td>\n",
       "      <td>0.469226</td>\n",
       "      <td>-0.894228</td>\n",
       "      <td>-0.602246</td>\n",
       "      <td>-0.940110</td>\n",
       "      <td>-1.205974</td>\n",
       "      <td>-0.892352</td>\n",
       "      <td>-1.415333</td>\n",
       "      <td>-0.814242</td>\n",
       "      <td>-2.372739</td>\n",
       "      <td>0.765467</td>\n",
       "      <td>-0.422543</td>\n",
       "      <td>-0.297676</td>\n",
       "      <td>2.811042</td>\n",
       "      <td>0.344006</td>\n",
       "      <td>0.195814</td>\n",
       "      <td>-0.514364</td>\n",
       "      <td>-1.612403</td>\n",
       "      <td>-1.818452</td>\n",
       "      <td>-0.659200</td>\n",
       "      <td>-1.077981</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>-1.074753</td>\n",
       "      <td>-0.081743</td>\n",
       "      <td>-1.196406</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>2.773826</td>\n",
       "      <td>-0.388693</td>\n",
       "      <td>-0.106381</td>\n",
       "      <td>-2.449294</td>\n",
       "      <td>-0.644714</td>\n",
       "      <td>-0.480606</td>\n",
       "      <td>1.116546</td>\n",
       "      <td>-1.865969</td>\n",
       "      <td>-0.819810</td>\n",
       "      <td>1.274063</td>\n",
       "      <td>-0.440149</td>\n",
       "      <td>0.662010</td>\n",
       "      <td>-0.152922</td>\n",
       "      <td>-1.722147</td>\n",
       "      <td>0.672275</td>\n",
       "      <td>-2.318295</td>\n",
       "      <td>-0.140903</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>-0.394157</td>\n",
       "      <td>-1.384261</td>\n",
       "      <td>0.602620</td>\n",
       "      <td>-0.488015</td>\n",
       "      <td>-2.338450</td>\n",
       "      <td>2.537653</td>\n",
       "      <td>-0.131133</td>\n",
       "      <td>-0.020555</td>\n",
       "      <td>-0.132869</td>\n",
       "      <td>0.991631</td>\n",
       "      <td>2.335211</td>\n",
       "      <td>1.269566</td>\n",
       "      <td>-0.546794</td>\n",
       "      <td>-0.366881</td>\n",
       "      <td>-0.237236</td>\n",
       "      <td>-0.306277</td>\n",
       "      <td>0.508084</td>\n",
       "      <td>0.648947</td>\n",
       "      <td>0.518181</td>\n",
       "      <td>0.593471</td>\n",
       "      <td>-0.842359</td>\n",
       "      <td>0.880160</td>\n",
       "      <td>-1.052908</td>\n",
       "      <td>-0.264436</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>0.758804</td>\n",
       "      <td>1.050412</td>\n",
       "      <td>-0.394082</td>\n",
       "      <td>1.834085</td>\n",
       "      <td>-0.643441</td>\n",
       "      <td>0.776780</td>\n",
       "      <td>-1.933549</td>\n",
       "      <td>-0.290592</td>\n",
       "      <td>0.761524</td>\n",
       "      <td>2.579884</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>-1.307640</td>\n",
       "      <td>0.601219</td>\n",
       "      <td>-0.346374</td>\n",
       "      <td>0.505192</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>1.912252</td>\n",
       "      <td>0.364983</td>\n",
       "      <td>-0.346958</td>\n",
       "      <td>0.429709</td>\n",
       "      <td>0.609931</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>0.760226</td>\n",
       "      <td>-1.650457</td>\n",
       "      <td>1.107601</td>\n",
       "      <td>0.515247</td>\n",
       "      <td>-1.914599</td>\n",
       "      <td>0.234667</td>\n",
       "      <td>-0.137798</td>\n",
       "      <td>0.113597</td>\n",
       "      <td>-0.267210</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>0.326220</td>\n",
       "      <td>-1.122852</td>\n",
       "      <td>-0.203091</td>\n",
       "      <td>1.366514</td>\n",
       "      <td>1.158265</td>\n",
       "      <td>-0.006361</td>\n",
       "      <td>0.585584</td>\n",
       "      <td>0.162737</td>\n",
       "      <td>1.028918</td>\n",
       "      <td>-1.695007</td>\n",
       "      <td>2.594973</td>\n",
       "      <td>-0.633020</td>\n",
       "      <td>-0.851499</td>\n",
       "      <td>0.413211</td>\n",
       "      <td>0.835971</td>\n",
       "      <td>-0.414981</td>\n",
       "      <td>-0.657887</td>\n",
       "      <td>-0.764855</td>\n",
       "      <td>-0.968778</td>\n",
       "      <td>-0.342691</td>\n",
       "      <td>-1.123472</td>\n",
       "      <td>0.170851</td>\n",
       "      <td>-1.580643</td>\n",
       "      <td>1.223423</td>\n",
       "      <td>-0.586693</td>\n",
       "      <td>1.405382</td>\n",
       "      <td>-0.854327</td>\n",
       "      <td>-0.312905</td>\n",
       "      <td>-0.422181</td>\n",
       "      <td>-1.550313</td>\n",
       "      <td>-0.572648</td>\n",
       "      <td>2.281767</td>\n",
       "      <td>0.882474</td>\n",
       "      <td>-0.864399</td>\n",
       "      <td>-1.746750</td>\n",
       "      <td>-1.517191</td>\n",
       "      <td>-0.334249</td>\n",
       "      <td>-1.377539</td>\n",
       "      <td>-0.160590</td>\n",
       "      <td>0.101108</td>\n",
       "      <td>2.021060</td>\n",
       "      <td>0.486820</td>\n",
       "      <td>1.442174</td>\n",
       "      <td>-0.132640</td>\n",
       "      <td>-1.073283</td>\n",
       "      <td>2.249209</td>\n",
       "      <td>-0.375563</td>\n",
       "      <td>-0.498221</td>\n",
       "      <td>-1.671510</td>\n",
       "      <td>-0.243033</td>\n",
       "      <td>1.305472</td>\n",
       "      <td>1.454247</td>\n",
       "      <td>-0.750841</td>\n",
       "      <td>-1.952990</td>\n",
       "      <td>-2.626248</td>\n",
       "      <td>0.938906</td>\n",
       "      <td>1.064354</td>\n",
       "      <td>-0.869613</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>0.560490</td>\n",
       "      <td>0.933798</td>\n",
       "      <td>-0.002614</td>\n",
       "      <td>1.094662</td>\n",
       "      <td>-2.628002</td>\n",
       "      <td>-2.133445</td>\n",
       "      <td>-1.173548</td>\n",
       "      <td>-0.527974</td>\n",
       "      <td>-2.184086</td>\n",
       "      <td>2.314295</td>\n",
       "      <td>-0.044535</td>\n",
       "      <td>0.426907</td>\n",
       "      <td>1.276087</td>\n",
       "      <td>2.041356</td>\n",
       "      <td>-0.580856</td>\n",
       "      <td>-1.524300</td>\n",
       "      <td>-1.832469</td>\n",
       "      <td>0.361346</td>\n",
       "      <td>-0.510415</td>\n",
       "      <td>-0.739994</td>\n",
       "      <td>0.741897</td>\n",
       "      <td>0.207209</td>\n",
       "      <td>0.372514</td>\n",
       "      <td>1.688991</td>\n",
       "      <td>-0.058066</td>\n",
       "      <td>-0.598264</td>\n",
       "      <td>-0.255620</td>\n",
       "      <td>-0.876752</td>\n",
       "      <td>-0.768212</td>\n",
       "      <td>-1.400823</td>\n",
       "      <td>0.636386</td>\n",
       "      <td>-0.156903</td>\n",
       "      <td>-1.455888</td>\n",
       "      <td>2.664730</td>\n",
       "      <td>0.114984</td>\n",
       "      <td>0.495348</td>\n",
       "      <td>-0.727089</td>\n",
       "      <td>0.470822</td>\n",
       "      <td>-0.063742</td>\n",
       "      <td>1.517542</td>\n",
       "      <td>1.441675</td>\n",
       "      <td>-0.406812</td>\n",
       "      <td>0.710195</td>\n",
       "      <td>0.496591</td>\n",
       "      <td>0.186350</td>\n",
       "      <td>-0.582011</td>\n",
       "      <td>-0.550010</td>\n",
       "      <td>-0.925803</td>\n",
       "      <td>-1.670551</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.583078</td>\n",
       "      <td>-2.052521</td>\n",
       "      <td>0.282998</td>\n",
       "      <td>-0.849072</td>\n",
       "      <td>-2.347939</td>\n",
       "      <td>-2.227451</td>\n",
       "      <td>0.957984</td>\n",
       "      <td>0.976598</td>\n",
       "      <td>-1.024141</td>\n",
       "      <td>0.651960</td>\n",
       "      <td>1.424898</td>\n",
       "      <td>0.214859</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>-0.521198</td>\n",
       "      <td>-2.176597</td>\n",
       "      <td>-1.066422</td>\n",
       "      <td>-3.179731</td>\n",
       "      <td>-1.589218</td>\n",
       "      <td>-1.066860</td>\n",
       "      <td>2.000307</td>\n",
       "      <td>-0.855088</td>\n",
       "      <td>0.122763</td>\n",
       "      <td>-1.966257</td>\n",
       "      <td>0.112275</td>\n",
       "      <td>-0.943196</td>\n",
       "      <td>0.888617</td>\n",
       "      <td>-1.310420</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>-0.832827</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.302465</td>\n",
       "      <td>0.250897</td>\n",
       "      <td>-0.590912</td>\n",
       "      <td>-0.448874</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>-0.469981</td>\n",
       "      <td>0.533730</td>\n",
       "      <td>0.933376</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.944822</td>\n",
       "      <td>-0.240741</td>\n",
       "      <td>0.112141</td>\n",
       "      <td>-0.256173</td>\n",
       "      <td>-0.141466</td>\n",
       "      <td>0.436221</td>\n",
       "      <td>-0.855547</td>\n",
       "      <td>0.263996</td>\n",
       "      <td>1.553899</td>\n",
       "      <td>0.394995</td>\n",
       "      <td>0.886407</td>\n",
       "      <td>0.715805</td>\n",
       "      <td>-0.986045</td>\n",
       "      <td>1.101694</td>\n",
       "      <td>0.245380</td>\n",
       "      <td>0.522098</td>\n",
       "      <td>0.360770</td>\n",
       "      <td>-0.600633</td>\n",
       "      <td>-1.699228</td>\n",
       "      <td>-1.244922</td>\n",
       "      <td>-0.969734</td>\n",
       "      <td>-0.505642</td>\n",
       "      <td>1.403915</td>\n",
       "      <td>0.521016</td>\n",
       "      <td>0.583177</td>\n",
       "      <td>0.667918</td>\n",
       "      <td>0.666286</td>\n",
       "      <td>1.390074</td>\n",
       "      <td>1.094701</td>\n",
       "      <td>-0.286147</td>\n",
       "      <td>-0.802538</td>\n",
       "      <td>2.988857</td>\n",
       "      <td>-0.922426</td>\n",
       "      <td>0.387522</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>1.686917</td>\n",
       "      <td>1.002716</td>\n",
       "      <td>1.807899</td>\n",
       "      <td>-0.142853</td>\n",
       "      <td>1.134942</td>\n",
       "      <td>-0.475097</td>\n",
       "      <td>0.369309</td>\n",
       "      <td>-0.791673</td>\n",
       "      <td>-0.120178</td>\n",
       "      <td>-0.594971</td>\n",
       "      <td>-0.101797</td>\n",
       "      <td>-1.446295</td>\n",
       "      <td>2.453492</td>\n",
       "      <td>3.070942</td>\n",
       "      <td>2.712284</td>\n",
       "      <td>0.626638</td>\n",
       "      <td>-0.147062</td>\n",
       "      <td>-0.330751</td>\n",
       "      <td>-1.239885</td>\n",
       "      <td>-1.186865</td>\n",
       "      <td>-1.084925</td>\n",
       "      <td>-1.153490</td>\n",
       "      <td>-0.284701</td>\n",
       "      <td>-1.971844</td>\n",
       "      <td>0.780027</td>\n",
       "      <td>0.413461</td>\n",
       "      <td>-0.589502</td>\n",
       "      <td>2.514612</td>\n",
       "      <td>-0.433468</td>\n",
       "      <td>-0.147332</td>\n",
       "      <td>-0.047645</td>\n",
       "      <td>-0.511363</td>\n",
       "      <td>-1.248252</td>\n",
       "      <td>-0.050855</td>\n",
       "      <td>-1.604284</td>\n",
       "      <td>-0.143100</td>\n",
       "      <td>-0.989950</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>-0.527584</td>\n",
       "      <td>-0.374693</td>\n",
       "      <td>3.214366</td>\n",
       "      <td>0.336465</td>\n",
       "      <td>0.117335</td>\n",
       "      <td>-2.289326</td>\n",
       "      <td>-0.765015</td>\n",
       "      <td>0.210249</td>\n",
       "      <td>1.336974</td>\n",
       "      <td>-1.461884</td>\n",
       "      <td>-1.553816</td>\n",
       "      <td>1.036128</td>\n",
       "      <td>-0.514884</td>\n",
       "      <td>0.623252</td>\n",
       "      <td>-0.145852</td>\n",
       "      <td>-1.816336</td>\n",
       "      <td>1.211782</td>\n",
       "      <td>-1.981082</td>\n",
       "      <td>-0.114095</td>\n",
       "      <td>0.381721</td>\n",
       "      <td>0.388906</td>\n",
       "      <td>-1.082455</td>\n",
       "      <td>0.793981</td>\n",
       "      <td>-0.156388</td>\n",
       "      <td>-1.790473</td>\n",
       "      <td>2.721288</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.055811</td>\n",
       "      <td>-0.183295</td>\n",
       "      <td>0.855538</td>\n",
       "      <td>1.501800</td>\n",
       "      <td>0.350615</td>\n",
       "      <td>-0.105384</td>\n",
       "      <td>-0.176219</td>\n",
       "      <td>-0.309209</td>\n",
       "      <td>-0.416712</td>\n",
       "      <td>0.536362</td>\n",
       "      <td>0.613664</td>\n",
       "      <td>0.482011</td>\n",
       "      <td>1.141798</td>\n",
       "      <td>-0.057254</td>\n",
       "      <td>0.577697</td>\n",
       "      <td>-1.226381</td>\n",
       "      <td>0.082574</td>\n",
       "      <td>0.212885</td>\n",
       "      <td>1.328764</td>\n",
       "      <td>0.712643</td>\n",
       "      <td>-0.009526</td>\n",
       "      <td>1.477282</td>\n",
       "      <td>-0.580575</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>-1.670641</td>\n",
       "      <td>-0.000932</td>\n",
       "      <td>0.336736</td>\n",
       "      <td>2.653457</td>\n",
       "      <td>0.141986</td>\n",
       "      <td>-1.208963</td>\n",
       "      <td>0.539859</td>\n",
       "      <td>-0.262439</td>\n",
       "      <td>1.399995</td>\n",
       "      <td>0.946046</td>\n",
       "      <td>2.065417</td>\n",
       "      <td>0.376548</td>\n",
       "      <td>-0.397774</td>\n",
       "      <td>0.770037</td>\n",
       "      <td>0.699635</td>\n",
       "      <td>0.399896</td>\n",
       "      <td>0.736960</td>\n",
       "      <td>1.265587</td>\n",
       "      <td>-1.682670</td>\n",
       "      <td>0.901193</td>\n",
       "      <td>-0.052149</td>\n",
       "      <td>-2.194972</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.256203</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-0.137904</td>\n",
       "      <td>-0.549669</td>\n",
       "      <td>0.346420</td>\n",
       "      <td>-0.806404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909428</td>\n",
       "      <td>0.909428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows  1273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "parameters         lp__  accept_stat__  stepsize__  treedepth__  n_leapfrog__  \\\n",
       "draws                                                                           \n",
       "0           4048.459180       0.975809    0.081819          6.0          63.0   \n",
       "1           4000.317830       0.853466    0.085521          6.0          63.0   \n",
       "2           4076.728618       0.815608    0.081578          6.0          63.0   \n",
       "3           4055.168882       0.732131    0.077561          6.0          63.0   \n",
       "4           4062.418611       0.873030    0.081819          6.0          63.0   \n",
       "...                 ...            ...         ...          ...           ...   \n",
       "7995        4042.398947       0.718993    0.077561          6.0          63.0   \n",
       "7996        4031.773204       0.943992    0.081819          6.0          63.0   \n",
       "7997        4056.623119       0.838001    0.085521          6.0          63.0   \n",
       "7998        4046.151644       0.965745    0.081578          6.0          63.0   \n",
       "7999        4039.923304       0.980425    0.077561          6.0          63.0   \n",
       "\n",
       "parameters  divergent__     energy__         a    gr.1.1    gr.2.1    gr.3.1  \\\n",
       "draws                                                                          \n",
       "0                   0.0 -3743.302273  0.433051 -0.220741  0.401745  1.242820   \n",
       "1                   0.0 -3626.271650  0.592820 -0.759868  0.140981  0.977731   \n",
       "2                   0.0 -3750.717653  0.519060 -0.544211  0.410085  1.383205   \n",
       "3                   0.0 -3692.125460  0.409729 -0.084470  0.181364  1.487987   \n",
       "4                   0.0 -3735.737037  0.657536 -0.599347  0.291509  0.891327   \n",
       "...                 ...          ...       ...       ...       ...       ...   \n",
       "7995                0.0 -3700.781667  0.089866 -0.886623 -0.076803  1.131874   \n",
       "7996                0.0 -3671.518900  0.650968 -0.839539 -0.211711  0.974679   \n",
       "7997                0.0 -3745.579168  0.513203 -0.134643  0.344839  1.573494   \n",
       "7998                0.0 -3730.829652  0.577026 -0.703452 -0.030281  1.424215   \n",
       "7999                0.0 -3716.700945  0.565869 -0.194951  0.817012  1.365198   \n",
       "\n",
       "parameters    gr.4.1    gr.5.1    gr.6.1    gr.7.1    gr.8.1    gr.9.1  \\\n",
       "draws                                                                    \n",
       "0          -0.622549 -0.318421 -0.709739 -0.088533 -0.765039  0.385500   \n",
       "1          -0.559760 -0.823520 -1.452902 -0.343682 -0.786345  0.119280   \n",
       "2          -1.102180 -0.126573 -0.751257 -1.166125  0.015930  0.467768   \n",
       "3          -0.563458 -0.471456 -0.975806  0.308908 -0.696337  0.665534   \n",
       "4          -0.452046 -0.364742 -0.905138 -1.057678 -0.762324  0.469060   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.042389 -0.162605 -0.837518 -0.157821 -0.578512  0.897857   \n",
       "7996       -0.889926 -0.872017 -1.082224 -1.094154 -0.431798 -0.208143   \n",
       "7997       -0.310542 -0.017450 -0.919747 -0.491099 -0.116723  0.544085   \n",
       "7998       -0.927767 -0.524914 -1.071491 -0.747763 -0.739650  0.166366   \n",
       "7999       -0.375600 -0.638228 -0.886599 -0.324619 -0.696173  0.539154   \n",
       "\n",
       "parameters   gr.10.1   gr.11.1   gr.12.1   gr.13.1   gr.14.1   gr.15.1  \\\n",
       "draws                                                                    \n",
       "0           1.300275 -1.044434 -0.673696  1.260101  0.461959 -0.942580   \n",
       "1           1.383189 -1.215400 -1.280178  0.185032 -0.036604 -1.153484   \n",
       "2           1.666830 -0.402227 -0.409941  1.243718  0.583777 -0.660820   \n",
       "3           1.676413 -0.758495 -0.348640  1.417454  0.104315 -0.765200   \n",
       "4           1.518425 -1.115048 -1.029767  0.995560  0.086230 -0.456640   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.512872 -0.242880 -0.586503  1.348188  0.505731  0.037068   \n",
       "7996        1.339280 -0.841586 -1.119783  1.155976  0.091337 -0.760947   \n",
       "7997        1.718473 -0.183365 -0.756296  1.043739  0.282600 -0.207678   \n",
       "7998        1.225336 -0.968892 -0.609357  1.331344  0.248343 -0.777860   \n",
       "7999        1.192676 -1.014723 -0.457427  0.694822  0.540547 -1.194756   \n",
       "\n",
       "parameters   gr.16.1   gr.17.1   gr.18.1   gr.19.1   gr.20.1   gr.21.1  \\\n",
       "draws                                                                    \n",
       "0          -0.132762  0.614654 -0.270887 -0.156980  1.502897  1.702542   \n",
       "1          -0.256516  0.254112 -0.826525 -0.234021  0.741035  1.305643   \n",
       "2           0.226999  0.937196 -0.390602  0.486926  0.871450  1.317343   \n",
       "3          -0.167886  0.650347 -0.551643  0.179427  1.167825  1.619838   \n",
       "4          -0.119099  0.335472 -0.463306  0.228852  0.896316  1.487407   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.078332  0.907070 -0.450082  0.409156  0.967267  1.214611   \n",
       "7996       -0.331795  0.409410 -0.503205 -0.122574  0.720503  1.093278   \n",
       "7997       -0.003896  1.112408 -0.176996  0.366981  1.260020  1.627329   \n",
       "7998       -0.192054  0.524203 -0.513850 -0.166118  0.579482  1.198196   \n",
       "7999        0.263363  0.495460  0.110110  0.441584  0.945169  1.562352   \n",
       "\n",
       "parameters   gr.22.1   gr.23.1   gr.24.1   gr.25.1    gr.1.2    gr.2.2  \\\n",
       "draws                                                                    \n",
       "0           0.573123  1.225790 -0.047847 -1.211805  0.030144 -0.021407   \n",
       "1           0.157998  0.745974 -0.456016 -1.180467 -0.060042  0.092258   \n",
       "2           0.116498  1.026098  0.033741 -0.756651 -0.117320  0.029672   \n",
       "3           0.392076  1.468229  0.345566 -0.944737  0.039823  0.104401   \n",
       "4           0.361845  1.000504 -0.436321 -0.742161  0.066231 -0.362446   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.866596  1.257896 -0.121633 -0.963012 -0.217350 -0.383062   \n",
       "7996       -0.055583  0.634134 -0.122841 -0.768435  0.566846 -0.260990   \n",
       "7997        0.512943  1.352826 -0.210047 -0.724794  0.374443 -0.216642   \n",
       "7998        0.440756  1.636821 -0.197944 -1.237955  0.266253 -0.380820   \n",
       "7999        0.406163  0.759495 -0.342052 -0.749658  0.276003 -0.189946   \n",
       "\n",
       "parameters    gr.3.2    gr.4.2    gr.5.2    gr.6.2    gr.7.2    gr.8.2  \\\n",
       "draws                                                                    \n",
       "0           0.021177  0.141976  0.319627  0.483374  0.071446  0.286244   \n",
       "1          -0.087628  0.817547  0.608606  0.750173  0.639276  0.407494   \n",
       "2          -0.544048  0.195070  0.134134  0.672954 -0.198248  0.494765   \n",
       "3          -0.059609  0.338477  0.160966  0.522734  0.363621  0.407103   \n",
       "4          -0.307655  0.309673  0.346564  0.559064  0.265252  0.085800   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.254907  0.395400  0.541575  0.762384  0.155458  0.589412   \n",
       "7996       -0.311526  0.234926  0.399198  0.600884 -0.267569  0.536874   \n",
       "7997       -0.595549  0.326554  0.314021  0.376900  0.040592  0.330001   \n",
       "7998        0.020749  0.205165  0.243680  0.297456 -0.176722  0.320439   \n",
       "7999       -0.335913  0.211071  0.213537  0.430720  0.270526  0.081180   \n",
       "\n",
       "parameters    gr.9.2   gr.10.2   gr.11.2   gr.12.2   gr.13.2   gr.14.2  \\\n",
       "draws                                                                    \n",
       "0          -0.116576 -0.272807  0.591954  0.089988  0.198853  0.395958   \n",
       "1          -0.054557 -0.260005  0.560006  0.017121 -0.536984  0.321488   \n",
       "2          -0.445202 -0.353934  0.404414  0.024310 -0.231080  0.257195   \n",
       "3          -0.225792 -0.843825 -0.138331 -0.241210  0.021414 -0.016069   \n",
       "4          -0.304625 -0.391085  0.369321 -0.004250 -0.575777 -0.039055   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.072538 -0.550539  1.053959 -0.025955  0.324548  0.424389   \n",
       "7996       -0.033552 -0.069780  0.649860 -0.349039  0.193341  0.577582   \n",
       "7997       -0.202695 -0.702228  0.548500 -0.180156 -0.646589  0.079705   \n",
       "7998       -0.258626 -0.437150  0.322894  0.020964 -0.016534  0.303550   \n",
       "7999       -0.108306 -0.576988  0.392167  0.060038 -0.844703  0.204616   \n",
       "\n",
       "parameters   gr.15.2   gr.16.2   gr.17.2   gr.18.2   gr.19.2   gr.20.2  \\\n",
       "draws                                                                    \n",
       "0           0.173881  0.126640 -0.078914 -0.393609 -0.330482  0.374049   \n",
       "1           0.377634  0.580639  0.503633 -0.318153  0.055859 -0.505933   \n",
       "2           0.531735  0.309292  0.141346 -0.898221  0.067316 -0.528505   \n",
       "3           0.354229 -0.065427  0.080874 -1.086291 -0.025150 -0.457107   \n",
       "4           0.440368  0.248530  0.191769 -0.528783  0.270046 -0.515687   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.114170  0.543327  0.084252 -1.044139  0.115153 -0.289116   \n",
       "7996        1.001017  0.673161  0.388687 -0.688430  0.103020 -0.338772   \n",
       "7997        0.631839  0.178606  0.250621 -0.740247 -0.593579 -0.464074   \n",
       "7998        0.748919  0.415279  0.359961 -0.569398 -0.209047 -0.327886   \n",
       "7999        0.151916  0.449083  0.026013 -0.666154 -0.135457 -0.465042   \n",
       "\n",
       "parameters   gr.21.2   gr.22.2   gr.23.2   gr.24.2   gr.25.2  Rho_gr.1.1  \\\n",
       "draws                                                                      \n",
       "0           0.036281 -0.194554 -0.588709  0.062139  0.103976         1.0   \n",
       "1          -0.159597 -0.175171 -0.609359  0.140080  0.317619         1.0   \n",
       "2          -0.603799 -0.475617 -1.119679 -0.193074  0.153844         1.0   \n",
       "3          -0.079732 -0.226263 -0.427232 -0.126720  0.298414         1.0   \n",
       "4          -0.171994 -0.282391 -0.900829 -0.376512  0.126440         1.0   \n",
       "...              ...       ...       ...       ...       ...         ...   \n",
       "7995       -0.950469  0.291291 -0.375255 -0.209981  0.379528         1.0   \n",
       "7996       -0.205373 -0.839584 -0.511054 -0.026620  0.357749         1.0   \n",
       "7997       -0.517004 -0.589986 -0.757559 -0.269576  0.197135         1.0   \n",
       "7998       -0.410781 -0.429688 -0.057528 -0.133819  0.275185         1.0   \n",
       "7999       -0.295165 -0.528455 -0.980306 -0.179000  0.062441         1.0   \n",
       "\n",
       "parameters  Rho_gr.2.1  Rho_gr.1.2  Rho_gr.2.2  sigma_gr.1  sigma_gr.2  \\\n",
       "draws                                                                    \n",
       "0            -0.305117   -0.305117         1.0    0.758852    0.257449   \n",
       "1            -0.563858   -0.563858         1.0    0.713273    0.413273   \n",
       "2            -0.622202   -0.622202         1.0    0.883341    0.552263   \n",
       "3            -0.355538   -0.355538         1.0    0.851807    0.359705   \n",
       "4            -0.605239   -0.605239         1.0    0.819467    0.330803   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "7995         -0.077123   -0.077123         1.0    1.018106    0.494008   \n",
       "7996         -0.485972   -0.485972         1.0    0.918824    0.544205   \n",
       "7997         -0.709122   -0.709122         1.0    0.910038    0.452168   \n",
       "7998         -0.410055   -0.410055         1.0    0.925926    0.317591   \n",
       "7999         -0.274734   -0.274734         1.0    0.791238    0.361548   \n",
       "\n",
       "parameters     z.1.1     z.2.1     z.1.2     z.2.2     z.1.3     z.2.3  \\\n",
       "draws                                                                    \n",
       "0          -0.407745 -0.229848  0.745506  1.532677  0.263228 -0.105839   \n",
       "1           0.032451 -0.199629  1.423530  1.070036  0.665557  2.117824   \n",
       "2          -0.477849  0.248305  0.945412  1.217739  1.079517  0.790909   \n",
       "3          -0.285118  0.405777  1.653049 -0.298667  0.922738  1.011133   \n",
       "4          -1.036967 -0.339240  2.175442  0.289644  0.144783  1.308984   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.125011  1.397599  1.994062  0.631149  1.749432  0.796814   \n",
       "7996        0.351200  0.437657  2.562041 -1.973382  0.776680  0.633268   \n",
       "7997        0.102062 -0.407110  1.502529 -1.041085 -0.530039 -0.288933   \n",
       "7998       -0.491524  1.558877  1.161390 -0.380766  0.633816  1.564410   \n",
       "7999        0.173842 -0.825246  1.932059 -1.230378  0.450481  1.553234   \n",
       "\n",
       "parameters     z.1.4     z.2.4     z.1.5     z.2.5     z.1.6     z.2.6  \\\n",
       "draws                                                                    \n",
       "0          -0.319586  0.401045  0.849274 -0.321751  0.238768  0.472407   \n",
       "1          -0.247921  1.360856  0.850230  0.235428  0.151449 -1.552373   \n",
       "2           0.913664 -1.214741  0.792083 -0.568536  0.728442  1.461994   \n",
       "3           1.011660 -0.312802  1.327599 -1.983745 -1.081870  0.274117   \n",
       "4           0.804418 -0.413863  1.164383  0.012704 -0.043738 -0.734228   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.659818 -0.244618  1.542348  0.711170  1.179388 -1.197036   \n",
       "7996        0.121370  0.512068  1.071055 -0.693098  0.279853  0.331998   \n",
       "7997       -0.136886 -0.835341  1.042775  0.346085  0.358182 -0.653969   \n",
       "7998        0.395460  0.693043  1.601129 -0.378828 -0.151586 -0.196149   \n",
       "7999        0.278715 -0.623450  0.966802 -0.830932 -0.444525  1.328755   \n",
       "\n",
       "parameters     z.1.7     z.2.7     z.1.8     z.2.8     z.1.9     z.2.9  \\\n",
       "draws                                                                    \n",
       "0           0.877066  0.612783 -1.050062 -0.001516  2.260091  1.262163   \n",
       "1          -0.157621 -0.794261 -1.139913 -0.026146  2.379607  0.706867   \n",
       "2           0.008673 -0.452482 -0.854899 -0.568953  2.345650  0.274084   \n",
       "3          -1.235188  2.093716 -0.578111 -0.658953  2.120344  0.932049   \n",
       "4          -1.982793 -0.415779 -0.895637 -0.907366  2.219420  0.995263   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.154268  0.677936 -1.001916  1.441179  3.089656 -0.125188   \n",
       "7996        0.356469  0.544885 -1.406893 -0.239091  2.118357  0.217145   \n",
       "7997       -0.440389  2.197132 -0.889050  0.104367  2.215014 -0.224949   \n",
       "7998        0.162071 -0.313500 -1.046052  1.116012  2.686497  0.384889   \n",
       "7999        0.800686  0.503918 -0.804420 -1.955507  2.050044  1.203810   \n",
       "\n",
       "parameters    z.1.10    z.2.10    z.1.11    z.2.11    z.1.12    z.2.12  \\\n",
       "draws                                                                    \n",
       "0          -0.480780  0.704697  0.497196 -1.933527 -1.193025  0.778337   \n",
       "1          -1.333687  0.367995 -1.055634  1.657169  0.477517  1.660216   \n",
       "2          -0.509614 -0.198938 -0.182595  0.661121 -1.408162  1.182050   \n",
       "3          -0.600898 -0.519813 -0.720554 -0.887870 -0.786204  0.636922   \n",
       "4          -0.642637 -1.654480 -3.077215  1.530508  0.164108 -0.895104   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.932568  0.479088 -0.310349 -0.345520 -0.780219  1.833798   \n",
       "7996        0.563323  0.240454 -2.339355 -0.386535 -0.732332  0.438491   \n",
       "7997       -0.837645  0.607330 -1.561464  1.110006 -0.400626 -0.368928   \n",
       "7998       -0.362598 -1.021422 -0.151914 -1.798530 -0.477272 -1.042822   \n",
       "7999       -0.077942 -1.216834 -0.875247  0.047953  0.957749 -1.188893   \n",
       "\n",
       "parameters    z.1.13    z.2.13    z.1.14    z.2.14    z.1.15    z.2.15  \\\n",
       "draws                                                                    \n",
       "0           0.324471  1.366866  0.961185  0.306431 -0.124357 -0.490751   \n",
       "1           0.579685  2.477001 -0.038977 -0.938574 -0.560492  1.132672   \n",
       "2           1.022638  0.993028  1.155076 -0.288149 -0.279598 -0.380838   \n",
       "3           0.680370  1.383218  1.050668 -0.242659  0.080210 -0.591254   \n",
       "4           0.736261  0.850008  0.595061 -2.257333 -1.520728  0.275320   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.886796  1.181364  0.503797 -1.511223 -1.077359 -1.389793   \n",
       "7996        0.424989  1.026062  0.809266 -2.063265 -1.443029  0.278436   \n",
       "7997        0.408462  1.350903 -0.082781 -1.207240 -1.240699 -0.738045   \n",
       "7998        0.402447  1.498183  1.215138 -0.545063 -1.531632  1.486482   \n",
       "7999        0.252008  1.280950  0.496807 -1.995887 -1.139911  1.051043   \n",
       "\n",
       "parameters    z.1.16    z.2.16    z.1.17    z.2.17    z.1.18    z.2.18  \\\n",
       "draws                                                                    \n",
       "0          -1.485669 -0.191628 -1.674750  0.754830 -0.312898 -0.349709   \n",
       "1          -0.489051  0.333424 -1.533959 -0.532571 -0.364614 -0.585120   \n",
       "2          -1.489876  0.518357 -1.492988 -1.439540 -1.773317  0.509189   \n",
       "3          -0.428144 -0.065150 -0.447022 -1.344697 -1.711217  0.554897   \n",
       "4          -0.572879 -0.528718 -0.796492 -1.740853 -0.968844  0.780300   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.953741  0.227868 -1.207585 -0.578707 -0.086977  1.343012   \n",
       "7996       -0.780422  1.193820 -0.994855 -0.982404 -0.742882  0.186565   \n",
       "7997        0.203270 -0.870177 -1.329879  0.964113 -1.049506  0.479628   \n",
       "7998       -0.056883 -0.474879 -0.727821 -1.449163  0.017423  0.766384   \n",
       "7999       -0.391777 -0.819441 -0.818705 -0.332717 -0.764796  0.921482   \n",
       "\n",
       "parameters    z.1.19    z.2.19    z.1.20    z.2.20    z.1.21    z.2.21  \\\n",
       "draws                                                                    \n",
       "0          -1.749415 -2.414545 -0.749000  1.034366 -1.185957 -0.086775   \n",
       "1          -1.702427 -1.012436  0.139679  0.816663 -0.035366 -0.422700   \n",
       "2          -1.309460  0.185584 -0.647301  1.131877 -4.384728 -0.927009   \n",
       "3           0.164807 -1.257286  0.249592 -0.298079 -1.821185  0.810949   \n",
       "4          -1.791443 -0.617944  0.448155 -0.308155 -0.808820 -1.424160   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.462633 -2.283756 -0.588039  0.627008 -0.567177  0.012618   \n",
       "7996       -2.376219 -1.697286  0.054877 -0.058728 -2.851856  1.478205   \n",
       "7997       -1.806399 -0.729495 -0.523350  0.249450 -1.797520 -0.725987   \n",
       "7998       -1.017975 -0.573017 -0.183317 -0.529956 -0.533232 -0.535414   \n",
       "7999       -1.438210  0.683035  0.454172 -0.618783 -1.293471 -0.635391   \n",
       "\n",
       "parameters    z.1.22    z.2.22    z.1.23    z.2.23    z.1.24    z.2.24  \\\n",
       "draws                                                                    \n",
       "0          -0.293986  1.944776 -1.060016  0.405065  1.941936 -0.417049   \n",
       "1           0.417432  0.469441 -0.863028 -0.733371  2.660222 -1.784547   \n",
       "2           0.834160 -0.216239 -2.132970 -0.397237  1.955279 -2.537978   \n",
       "3           0.044947  1.094537 -0.923004  0.796656  1.556535 -0.153883   \n",
       "4           0.870526 -0.094931 -1.583877 -0.613265  2.211515 -1.347715   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.519053  0.995983 -0.170127 -0.456256  2.485320 -0.688197   \n",
       "7996       -0.430847  1.174317 -1.395007 -2.036987  2.325831 -1.832412   \n",
       "7997        0.578449 -0.523559 -0.911803 -1.138672  1.474807 -1.824941   \n",
       "7998       -0.462716  1.137093 -1.592213  0.280977  2.659923 -1.450332   \n",
       "7999        1.057120  0.369398 -0.979836  0.857004  1.900004 -1.075099   \n",
       "\n",
       "parameters    z.1.25    z.2.25    z.1.26    z.2.26    z.1.27    z.2.27  \\\n",
       "draws                                                                    \n",
       "0           0.067733 -1.119269  0.054135  0.731391 -2.030987 -0.047180   \n",
       "1          -1.293091 -0.114571 -0.327806 -0.611696 -0.388008  0.923100   \n",
       "2          -0.122483 -0.915963  0.574112 -0.423051 -0.842613  2.131898   \n",
       "3          -1.064906 -0.271044 -0.102455  1.180990 -0.364190  1.027025   \n",
       "4          -0.734069  1.284942 -0.714206 -0.846094 -0.273410  0.028574   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.484480 -1.247692  0.088792  0.822095 -0.677754  0.482335   \n",
       "7996        0.171078 -1.051681  0.188340  1.034116  0.204263  0.850631   \n",
       "7997       -1.034353  0.442725 -0.245630  1.393651 -0.224751 -0.570471   \n",
       "7998       -0.005186  0.919738  0.299053 -0.306913 -0.615516  1.638530   \n",
       "7999       -1.081066  0.491852 -0.142297 -0.374557 -0.546556  0.270015   \n",
       "\n",
       "parameters    z.1.28    z.2.28    z.1.29    z.2.29    z.1.30    z.2.30  \\\n",
       "draws                                                                    \n",
       "0          -0.067319 -0.633767 -2.100427  0.748536  2.290921  0.322586   \n",
       "1          -0.939498 -0.669807 -0.730806  0.084760  2.046776  0.233848   \n",
       "2          -0.482536 -1.419383 -0.291420  0.448921  1.977976  0.014829   \n",
       "3          -0.663895  0.222891 -1.107675  0.206399  2.596629  0.322181   \n",
       "4          -0.268027  0.322494  0.212969 -0.038949  2.667067 -0.006724   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.333860  0.467046 -0.180385  0.623752  2.660661  0.666528   \n",
       "7996       -0.553500 -0.643710 -0.527655  1.796899  2.432998  0.585732   \n",
       "7997        0.053449 -1.059456 -1.290450  1.471272  1.997289  0.803297   \n",
       "7998        1.187709  0.581360 -0.386432  0.922388  2.732231  0.895528   \n",
       "7999       -0.915636 -1.395192 -0.637735  0.139660  2.240972  0.099878   \n",
       "\n",
       "parameters    z.1.31    z.2.31    z.1.32    z.2.32    z.1.33    z.2.33  \\\n",
       "draws                                                                    \n",
       "0           1.001075 -1.643911 -0.791191 -0.555883 -0.996328  0.249450   \n",
       "1           0.191640  0.596165 -1.253260  0.662783 -0.238446 -1.237495   \n",
       "2           1.081682 -0.441748 -1.254173 -0.032522 -1.525957 -0.253144   \n",
       "3          -0.096853 -0.792260 -0.133292 -0.766049 -0.660631 -0.603100   \n",
       "4          -0.058786  0.685202 -1.647806  0.171919 -0.373607 -0.603068   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.605643 -0.569248 -1.951421  0.227865 -0.864982 -0.800859   \n",
       "7996        0.601812  0.933818 -0.719510 -0.253820 -2.121101  0.102637   \n",
       "7997        0.860406 -0.833329 -1.638752 -0.412184 -1.728637  0.022810   \n",
       "7998        1.706269 -0.372007 -2.243075  0.439891 -0.993274  1.889407   \n",
       "7999        0.221896  1.448714 -0.258215 -1.329676 -1.168996 -1.271628   \n",
       "\n",
       "parameters    z.1.34    z.2.34    z.1.35    z.2.35    z.1.36    z.2.36  \\\n",
       "draws                                                                    \n",
       "0          -1.043384 -2.008439 -0.369917 -0.256396 -1.620561 -1.049313   \n",
       "1           0.138887  0.866105 -0.432057 -0.722960 -0.295695  0.290195   \n",
       "2          -1.715876  0.712936 -1.152601 -0.387493 -1.318359 -1.048490   \n",
       "3          -1.249820  2.113088  0.027775 -0.812743 -1.780777  0.123686   \n",
       "4          -0.934357  1.361805 -0.734280 -0.204837 -0.417016  0.671381   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.327905  0.422415 -0.627474 -0.216761 -0.525077 -0.776940   \n",
       "7996       -0.423979 -0.145309 -1.061021 -0.322560 -0.697297  1.122057   \n",
       "7997       -0.560778  0.157874 -0.163801 -1.155484 -0.836271  0.120652   \n",
       "7998       -1.345201 -0.063929 -0.284827  0.359111 -1.560618 -0.005091   \n",
       "7999       -1.217927 -0.661539 -0.143898 -0.417832 -1.219235 -0.352627   \n",
       "\n",
       "parameters    z.1.37    z.2.37    z.1.38    z.2.38    z.1.39    z.2.39  \\\n",
       "draws                                                                    \n",
       "0           0.383279  0.104765  0.260491  0.260654  2.223554 -0.389354   \n",
       "1          -0.232082 -1.071746  0.196197 -0.253616  1.635417 -0.348175   \n",
       "2          -1.008816 -1.249758  0.546879 -1.786857  1.714262 -1.377044   \n",
       "3           0.000503 -0.551475  0.620656  0.394846  1.868764 -0.535296   \n",
       "4          -1.078292 -0.904728  0.154059 -0.530033  2.021051  1.031225   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.513917 -1.043778  0.670741  0.931028  2.239132 -0.969558   \n",
       "7996       -0.672309 -0.666380 -0.333801  1.304955  1.770791  0.292317   \n",
       "7997       -0.336099 -0.839191 -0.121924  0.800179  1.679181 -1.193043   \n",
       "7998       -0.092347  1.632836 -0.078210 -0.164117  2.071807  0.362004   \n",
       "7999       -0.428237  0.584553 -0.119335  0.482549  1.401183  1.365027   \n",
       "\n",
       "parameters    z.1.40    z.2.40    z.1.41    z.2.41    z.1.42    z.2.42  \\\n",
       "draws                                                                    \n",
       "0          -1.086489 -0.466568  1.303266 -0.343015 -0.388987  0.287837   \n",
       "1          -0.811127  0.179085  1.069834  1.124860 -0.217365  1.577169   \n",
       "2           0.292190  0.383550  0.441229  1.070662  0.488727  0.016192   \n",
       "3           0.094466 -0.522489  1.012734  0.760800 -0.376113 -0.000416   \n",
       "4           0.403782  0.617619  0.034811  1.377703 -0.907499  1.511212   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.797527 -1.372364  1.561897  0.739932  0.764246  0.240476   \n",
       "7996        0.258699 -0.399684  1.342896  1.388841  0.433723 -0.075009   \n",
       "7997       -0.288518  0.490767  1.381152  0.302169 -0.597085 -0.410621   \n",
       "7998        0.347906 -1.468258  1.041199  0.755897  0.743015  0.957750   \n",
       "7999       -0.280656  1.680634  0.792832  1.426756 -0.728069  1.301497   \n",
       "\n",
       "parameters    z.1.43    z.2.43    z.1.44    z.2.44    z.1.45    z.2.45  \\\n",
       "draws                                                                    \n",
       "0          -1.464585 -1.734827  1.674691  1.022999  0.555116 -0.201714   \n",
       "1          -1.348581  0.528206  1.936467  0.672239 -0.357275 -0.639551   \n",
       "2          -0.689693  0.235307  1.823351  1.046317  0.631064 -1.175797   \n",
       "3          -0.860865 -1.413640  1.999030  0.636520 -0.296653 -1.049413   \n",
       "4          -0.305179  0.703376  2.182323  0.572354  0.392887  0.493605   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.371496 -0.392429  1.675646  0.958615  0.146765 -0.492752   \n",
       "7996        0.344631 -0.293901  2.612565  0.752659  0.265860 -0.186673   \n",
       "7997       -0.768665 -0.136807  2.059733  0.754316  0.306486 -0.633149   \n",
       "7998        0.240857 -0.414104  2.311493  1.476827  0.489415 -0.780171   \n",
       "7999       -0.890270 -0.405239  1.815641  0.958664  0.173015 -1.201416   \n",
       "\n",
       "parameters    z.1.46    z.2.46    z.1.47    z.2.47    z.1.48    z.2.48  \\\n",
       "draws                                                                    \n",
       "0           0.416743  1.014936 -0.721373 -1.217924  0.298772 -0.104211   \n",
       "1           0.999469 -1.160964 -1.732336 -1.516764  0.228672 -0.901420   \n",
       "2           0.607319 -0.098467 -1.383710  0.089452  0.552594 -2.522122   \n",
       "3           1.272486 -0.956749 -0.294148  0.248534 -0.047569 -0.692646   \n",
       "4           0.594619 -0.480529 -0.336430  0.637393  0.217214 -0.556516   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.720502  1.309134 -0.796909  0.724607  0.274278 -0.727750   \n",
       "7996        1.433210 -1.350801 -1.919876 -1.201913  0.400730 -0.672398   \n",
       "7997        1.051518 -0.102166 -1.701119 -1.001339  0.158730  0.794186   \n",
       "7998        0.709957 -0.192481 -0.370405 -0.027169  0.646288 -0.363819   \n",
       "7999        0.251188 -1.641177 -1.709291  0.074809 -0.138275 -0.230227   \n",
       "\n",
       "parameters    z.1.49    z.2.49    z.1.50    z.2.50    z.1.51    z.2.51  \\\n",
       "draws                                                                    \n",
       "0           0.874799 -0.092232  1.548656  0.165177  0.120429 -0.790525   \n",
       "1           0.879513  0.800832  1.280497  0.731519 -0.988749 -0.519766   \n",
       "2           1.119062  1.653892  1.147259  0.678807  0.028873  0.749810   \n",
       "3           1.038218 -0.171632  1.331722  1.625692 -0.490659 -1.051846   \n",
       "4           0.761182  0.000749  1.354182  1.245085 -0.404319  0.026950   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.297018 -0.759486  1.347745  0.878679 -0.233632  0.490763   \n",
       "7996        1.049490  0.073956  1.593532  0.495343  0.616688 -0.352269   \n",
       "7997        0.603894  0.213329  1.367538  0.719871 -0.790216  0.194103   \n",
       "7998        0.657369  0.015123  1.215948  1.107320 -0.745226 -0.793370   \n",
       "7999        0.713584  1.300477  1.283754  0.379641 -0.262952 -1.070452   \n",
       "\n",
       "parameters    z.1.52    z.2.52    z.1.53    z.2.53    z.1.54    z.2.54  \\\n",
       "draws                                                                    \n",
       "0          -0.212109  0.105493 -2.423640  1.280650 -0.020982 -0.089133   \n",
       "1          -1.378319  0.008854 -1.271321 -1.503426 -0.912829  1.426416   \n",
       "2          -1.528499  0.097721 -2.580648 -0.576350  0.146343 -0.897146   \n",
       "3          -0.537964  0.427878 -1.316384 -1.110096 -1.342565  0.887751   \n",
       "4          -1.226069 -0.558079 -0.700018 -1.477893 -0.294654  0.627229   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.593186 -0.368647 -1.624226  2.277198  0.370804 -0.123966   \n",
       "7996       -0.415953 -1.157527 -1.507581 -0.813093 -0.413244  0.682313   \n",
       "7997       -0.337849  0.706034 -0.467019  0.583481 -0.238843  0.992170   \n",
       "7998       -2.075607 -0.838992 -0.704564 -0.966085 -0.598969  1.795014   \n",
       "7999       -1.983113  0.056746 -1.346568 -2.810750  0.127639  1.778513   \n",
       "\n",
       "parameters    z.1.55    z.2.55    z.1.56    z.2.56    z.1.57    z.2.57  \\\n",
       "draws                                                                    \n",
       "0           0.026839  0.284171 -0.103780 -0.857248 -0.086808  0.031664   \n",
       "1          -0.124897  2.014694  0.797348  1.282970  0.509578 -1.286556   \n",
       "2           0.618766 -0.074857  0.017458 -0.486478 -0.442482  0.240351   \n",
       "3           0.583107 -1.729338 -0.311059 -0.109466 -0.058496 -1.637134   \n",
       "4           0.642513 -0.162928  0.554091 -0.147193  0.376622 -1.478061   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.273008 -0.702423  0.969818  1.215280 -0.000151 -0.634290   \n",
       "7996        0.097441 -0.206794  0.983427 -0.423916  0.211599 -1.090864   \n",
       "7997        0.277780  0.081665  0.237491  0.917066  0.293123  0.636386   \n",
       "7998        0.463757 -0.726845 -0.053690 -1.123345 -0.516755 -0.798879   \n",
       "7999        0.602328  1.015359 -0.442900 -0.937223  0.966957 -0.973247   \n",
       "\n",
       "parameters    z.1.58    z.2.58    z.1.59    z.2.59    z.1.60    z.2.60  \\\n",
       "draws                                                                    \n",
       "0           0.421852 -0.720321  1.080155  1.266750 -0.164728 -1.038069   \n",
       "1           0.177890 -0.181982  1.106896  0.406250 -0.212558 -0.327489   \n",
       "2          -0.303637 -0.516523  0.470631 -1.410381 -0.799205 -0.739280   \n",
       "3           0.498233  0.019469  0.741406  1.521551  0.077421 -0.852036   \n",
       "4           0.718518  0.356444  1.247978  0.685547 -0.321107  0.864315   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.334738 -0.229331  0.446060  2.114131 -0.065895 -1.778740   \n",
       "7996        0.487847  0.276650  0.881760  1.089920 -0.559290  0.569919   \n",
       "7997        0.569247 -1.323818  0.106672  2.461601 -0.108164 -0.344839   \n",
       "7998       -0.202976 -0.164112 -0.072735  1.218566 -1.204320  0.256120   \n",
       "7999        0.332701  0.500761  0.650849  0.623133 -0.931118  2.030491   \n",
       "\n",
       "parameters    z.1.61    z.2.61    z.1.62    z.2.62    z.1.63    z.2.63  \\\n",
       "draws                                                                    \n",
       "0           0.507673  0.098148 -1.619776  0.328938 -1.033245 -1.687531   \n",
       "1           0.252539  0.124555 -2.684077 -0.588774 -1.431945 -1.706941   \n",
       "2           0.377443  0.504710 -0.958683  0.483551 -0.918463 -1.592223   \n",
       "3           0.235890  0.329996 -1.627502  1.502486 -0.965720 -0.052865   \n",
       "4           0.366150  0.830132 -1.083764 -0.893724 -0.387184  0.546351   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.537660 -0.300174 -0.419964  1.233326 -0.227759  0.419336   \n",
       "7996        0.260578  1.599541 -1.161874  0.779492  0.137455 -1.543321   \n",
       "7997       -0.343076  0.241372 -2.826155 -0.424691 -0.307247 -0.021264   \n",
       "7998        0.032810  0.347686 -1.534398  0.272711 -0.059414 -0.542941   \n",
       "7999        0.473891  1.362653 -2.024846 -1.331298 -1.335496 -1.754971   \n",
       "\n",
       "parameters    z.1.64    z.2.64    z.1.65    z.2.65    z.1.66    z.2.66  \\\n",
       "draws                                                                    \n",
       "0          -1.086015 -0.236832 -0.598458 -1.058645 -0.777863 -0.096043   \n",
       "1           0.214785 -1.122459 -1.651631  0.796036 -0.033439  1.122536   \n",
       "2           0.064131 -1.613022 -0.762804 -0.203612 -0.543591  0.898989   \n",
       "3          -0.891102 -0.126900 -0.916214 -1.001230 -0.145483  0.900813   \n",
       "4           0.164963 -0.880032 -0.793657 -0.920289 -1.349705  0.629840   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.922732  0.646081 -0.368378 -0.271640 -1.192123  0.569105   \n",
       "7996        0.115305 -1.981614 -1.253748  0.647528  0.064887 -1.476125   \n",
       "7997       -1.065068 -1.544515 -0.518257 -1.815791 -0.349475 -0.703358   \n",
       "7998       -0.774984 -1.010295 -0.614713 -0.399746 -0.667718  0.527916   \n",
       "7999       -0.280954 -1.957459 -0.509778 -0.042258 -1.315013 -1.910744   \n",
       "\n",
       "parameters    z.1.67    z.2.67    z.1.68    z.2.68    z.1.69    z.2.69  \\\n",
       "draws                                                                    \n",
       "0           1.031097  1.108616 -0.846200 -1.242557 -0.107453  1.103464   \n",
       "1           1.515252  1.085802 -1.545437 -1.633067  0.178389 -1.996615   \n",
       "2           1.550943  0.981527 -1.467820 -0.963223  0.155268 -0.213300   \n",
       "3           1.197273  0.848045 -0.868675  0.462872 -0.029981 -0.707439   \n",
       "4           1.418349  0.734392 -0.720336  0.626807  0.184249 -2.255575   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.634192  0.632095 -0.108510 -1.319626  0.663339 -0.965716   \n",
       "7996        1.506110  1.547394 -0.177550  0.321237  0.463852 -0.383651   \n",
       "7997        1.424585  1.138114 -1.195488  0.164165 -0.485293  0.095037   \n",
       "7998       -0.008928  0.351395 -0.235945 -1.693862 -0.439292  0.080968   \n",
       "7999        1.801798  1.131574 -0.373484  0.719155  0.031325  0.867076   \n",
       "\n",
       "parameters    z.1.70    z.2.70    z.1.71    z.2.71    z.1.72    z.2.72  \\\n",
       "draws                                                                    \n",
       "0           0.596517  1.019058  2.489772 -0.638243 -1.290517  0.731291   \n",
       "1           0.138445  1.989090  1.694810 -0.356188 -0.531155 -0.000350   \n",
       "2           0.363040 -1.096934  2.086288  0.082222  0.166183  0.490820   \n",
       "3           0.578180  0.957454  2.371285 -0.160592 -0.006200 -1.414939   \n",
       "4           0.586541  0.697202  2.135226 -0.391511 -0.198696 -0.484061   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.828471  0.222635  2.637844 -1.702098 -0.836944 -1.062185   \n",
       "7996        0.858723  1.604267  2.159848 -0.893472 -0.665985 -2.231206   \n",
       "7997       -0.157324  1.858642  1.949754 -0.749730  0.244200  0.315473   \n",
       "7998        0.493102  2.109114  1.795596 -0.456493 -0.380323 -0.282655   \n",
       "7999        0.345127  2.041838  2.206598 -0.351819 -0.875264  0.641113   \n",
       "\n",
       "parameters    z.1.73    z.2.73    z.1.74    z.2.74    z.1.75    z.2.75  \\\n",
       "draws                                                                    \n",
       "0          -1.020852 -1.599648 -1.804380  1.193622 -0.136760  0.135593   \n",
       "1          -1.483828  0.960308 -1.950884 -0.435862 -0.897392  0.139550   \n",
       "2          -1.333572 -1.263228 -0.441280 -0.211867  0.267667 -0.066594   \n",
       "3          -0.942772 -0.570482 -0.315899 -0.640316  0.882068 -1.232861   \n",
       "4          -0.751352  0.578739  0.083347 -1.743041  0.204799 -0.799315   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.159830 -0.823870 -0.699394 -0.608839 -0.039563 -0.378062   \n",
       "7996       -1.036411 -0.039208  0.394180  1.070104 -0.155360  0.143959   \n",
       "7997       -1.294698 -0.552058 -0.967977 -0.619697 -0.017290  0.519882   \n",
       "7998        0.241900 -0.937610 -1.169676 -1.256632  0.797957 -0.640208   \n",
       "7999       -1.668061  0.307259 -1.616258 -0.481389  0.427815 -0.143668   \n",
       "\n",
       "parameters    z.1.76    z.2.76    z.1.77    z.2.77    z.1.78    z.2.78  \\\n",
       "draws                                                                    \n",
       "0           0.351336 -0.287122  0.772360 -1.046923 -0.842048  2.763843   \n",
       "1           0.208612  0.441890  0.104347  1.172613 -0.116262  0.728767   \n",
       "2           0.723358 -2.710476 -0.501903  1.364723  0.760223 -0.762381   \n",
       "3           0.071896 -1.667103 -0.482745  1.074750  0.930528 -0.808302   \n",
       "4          -0.202736 -0.970448 -0.775741  1.823041  0.884970 -0.221103   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.152376 -1.041815  0.063104 -0.258856  0.346515  0.508938   \n",
       "7996       -0.632057 -0.277500 -0.058644  1.106276  0.976601 -0.091989   \n",
       "7997       -0.402537 -1.298324  0.617236 -0.164998 -0.078906  1.912512   \n",
       "7998       -0.409060  0.227162  1.138371 -0.291029  0.989344 -0.952980   \n",
       "7999        0.341094 -1.864514 -0.927631  0.406877  0.649714  0.205058   \n",
       "\n",
       "parameters    z.1.79    z.2.79    z.1.80    z.2.80    z.1.81    z.2.81  \\\n",
       "draws                                                                    \n",
       "0           0.734349  0.087597  1.456988  0.159415  2.185086  0.705207   \n",
       "1          -0.250864 -0.072925  0.287911  1.155447  1.223913  1.288444   \n",
       "2          -0.339300  1.528382  0.950937 -2.103084  1.306236  0.298729   \n",
       "3           0.731952 -0.413760  0.562538 -0.258239  1.860032  0.667257   \n",
       "4          -1.069471  1.481746 -0.965789  0.287672  1.315301  1.298957   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.161040  0.793395  0.065921  0.813740  1.460270  1.040972   \n",
       "7996        0.178986  0.186994  0.795719 -1.449248  1.612446  1.160928   \n",
       "7997        0.181241 -0.699496  0.124082 -1.183508  1.496033  0.807804   \n",
       "7998        0.258547  1.165252  0.386510 -0.682780  1.647708  1.261674   \n",
       "7999       -0.217502  0.929749  0.343038  0.066201  1.272163  0.919435   \n",
       "\n",
       "parameters    z.1.82    z.2.82    z.1.83    z.2.83    z.1.84    z.2.84  \\\n",
       "draws                                                                    \n",
       "0           0.288196 -1.496956 -0.526712  1.017949 -0.349215  1.599696   \n",
       "1          -0.140799 -0.372711 -0.162507  0.452874 -0.379135  0.930371   \n",
       "2           0.155191 -0.662007  0.293944 -0.952797 -0.427309 -0.426850   \n",
       "3           0.269687 -1.911067 -1.225897 -0.876473 -0.110690 -1.880575   \n",
       "4          -0.389352 -0.337766 -1.549889 -0.419583 -0.808692 -1.139919   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.162949 -0.275600 -0.286348  0.910457  0.138887  0.803870   \n",
       "7996       -0.690812 -0.003836  1.092277  0.113299 -1.155190  0.329129   \n",
       "7997       -0.295526 -2.093629 -1.222004 -0.176936 -0.100508 -1.127789   \n",
       "7998       -0.559734  0.449096  0.112368  0.676839 -0.141681  0.087552   \n",
       "7999       -0.072207  0.030652 -0.329024 -0.591585 -0.473714  0.475744   \n",
       "\n",
       "parameters    z.1.85    z.2.85    z.1.86    z.2.86    z.1.87    z.2.87  \\\n",
       "draws                                                                    \n",
       "0          -1.281741 -1.474860 -0.614036 -0.381978 -0.206835 -0.721385   \n",
       "1          -1.024412  0.177973 -0.827499 -1.371405 -0.746969 -1.846273   \n",
       "2          -1.199208  0.862368 -0.220573  0.764875 -0.416196 -0.435559   \n",
       "3          -0.780035 -0.327461 -0.477785 -0.734616 -0.243673  1.153620   \n",
       "4          -1.052158  0.228460 -0.897440 -0.936589 -1.261927  0.493772   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.709799 -0.737442 -0.398212  0.390577 -0.493452 -2.210822   \n",
       "7996       -0.514367 -0.532714 -0.222083  0.017629 -1.903709 -0.152132   \n",
       "7997       -0.184313 -1.651225 -0.268099 -1.944681 -0.913354  0.616712   \n",
       "7998       -0.938565 -0.430906 -1.022101  0.307358 -1.013223  0.652779   \n",
       "7999       -0.960328  0.178671 -0.526646 -0.531861 -1.927095  1.144331   \n",
       "\n",
       "parameters    z.1.88    z.2.88    z.1.89    z.2.89    z.1.90    z.2.90  \\\n",
       "draws                                                                    \n",
       "0           0.489974  0.460484  0.050791  0.531157  0.022168  1.007295   \n",
       "1           0.672606 -1.620297 -0.533657 -0.147648 -0.977057  0.112389   \n",
       "2           0.745336  0.045365 -0.913414 -0.409874  1.017311 -0.312572   \n",
       "3           0.207475 -0.506123  0.229015 -0.820618 -0.331310 -0.322671   \n",
       "4          -0.211824  0.666508 -0.973221 -2.352049 -0.472930 -2.088445   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.126979 -0.464982  0.079529 -1.802092 -0.642290 -0.752780   \n",
       "7996        1.000410  0.158749  0.139780 -0.226797 -0.596755  0.434450   \n",
       "7997        0.636540 -0.453260 -0.445722 -0.687724 -1.372432  0.937028   \n",
       "7998        0.622699 -0.927422  0.172374 -1.097157  0.600669 -1.448389   \n",
       "7999        0.282744  0.776339 -0.634078  1.042779 -1.607201  0.324094   \n",
       "\n",
       "parameters    z.1.91    z.2.91    z.1.92    z.2.92    z.1.93    z.2.93  \\\n",
       "draws                                                                    \n",
       "0           1.960641  1.302999 -0.169176  0.692012 -1.269539 -1.065533   \n",
       "1           1.874142  3.086769 -0.722104  1.083863 -1.877257 -0.504853   \n",
       "2           1.354477  2.131161  0.746993  0.072755 -0.834732  1.085008   \n",
       "3           2.243803  0.658727 -0.206132 -0.102983  0.560646 -1.797792   \n",
       "4           1.453805  1.905972  0.134254  0.927951 -2.152600  0.917679   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.249796  2.587143  0.818629 -0.818634 -2.912952  0.234895   \n",
       "7996        2.131264  0.853967  1.419958  0.953190 -0.409257  0.009059   \n",
       "7997        1.957371  1.017766 -0.687951  0.907990 -1.132779 -1.806994   \n",
       "7998        2.589260  1.275879  0.531916 -0.941550 -0.789747 -0.528524   \n",
       "7999        2.098300  1.251156 -0.597863  1.559430  0.571724 -0.164708   \n",
       "\n",
       "parameters    z.1.94    z.2.94    z.1.95    z.2.95    z.1.96    z.2.96  \\\n",
       "draws                                                                    \n",
       "0          -0.796902  1.692118  1.425208 -1.222763  0.138387  0.822405   \n",
       "1           0.102076  0.209604 -0.733907  2.130679 -0.072846 -0.527030   \n",
       "2          -0.372841  0.222031  0.395946 -0.315272  0.111767 -0.288567   \n",
       "3          -0.131800 -0.296205  0.333294  0.163465 -0.093406 -0.122367   \n",
       "4          -1.093427 -2.033931 -0.490332  0.982181  0.114844  0.479742   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.996524 -0.524157  0.759298 -0.279653 -0.234903 -0.335483   \n",
       "7996       -1.694101  0.968050  0.706752 -0.843586  0.680137  0.326001   \n",
       "7997        0.164750 -1.382515 -0.076601  0.902886  0.023298  0.358069   \n",
       "7998       -0.928410 -0.117118  1.448559 -0.338207  0.702552  0.452944   \n",
       "7999       -0.731976  0.007290  0.721155 -0.545242 -0.300306  0.517033   \n",
       "\n",
       "parameters    z.1.97    z.2.97    z.1.98    z.2.98    z.1.99    z.2.99  \\\n",
       "draws                                                                    \n",
       "0           1.035881  0.585491 -0.428275  2.392275  0.057786 -1.074735   \n",
       "1           0.537864  0.932215  1.183489  0.264282 -1.094703  0.429551   \n",
       "2           0.821708  0.439607  0.733257 -0.327657 -0.680554 -1.080868   \n",
       "3           1.369165 -1.181823  1.446019 -1.034380 -0.066791 -0.110820   \n",
       "4           0.265104  0.881749  1.337529 -0.557033 -0.405437  0.571190   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.192631  0.507342  0.134844  0.440250 -0.843684  0.878455   \n",
       "7996        0.868159  2.212918  0.330471  1.394387 -0.217301  0.169121   \n",
       "7997        0.712190  2.073319  0.548786  1.243071 -0.601272 -0.524671   \n",
       "7998        0.812444  1.056288  0.209089  0.641092 -0.707244  0.165736   \n",
       "7999        0.480043  2.275954  1.501927 -0.125023  0.065946 -1.035754   \n",
       "\n",
       "parameters   z.1.100   z.2.100   z.1.101   z.2.101   z.1.102   z.2.102  \\\n",
       "draws                                                                    \n",
       "0           0.471482  0.667781  0.459728  0.589836 -0.918103  0.095939   \n",
       "1           1.200935 -1.387576  0.920645  0.175354 -0.556458  0.377342   \n",
       "2           0.472120 -0.870400  0.395791 -0.006176 -0.717764 -0.667639   \n",
       "3           0.633619  0.970541  0.498484  1.599172 -0.010571  0.064114   \n",
       "4           0.682782 -0.358157  0.876576 -0.238264  0.204925  0.121197   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.328051  0.036585 -0.063802  1.596421 -1.206749  2.096175   \n",
       "7996       -0.099003 -1.240654  0.448395  1.507743  0.519082 -0.222595   \n",
       "7997        0.363112  0.604872  0.216217  0.591611 -1.332342 -0.540301   \n",
       "7998        0.762573 -1.397415  1.538658 -0.569526 -0.392699  1.098030   \n",
       "7999        0.981107 -0.589126  0.887086 -0.851634  0.864457 -1.482050   \n",
       "\n",
       "parameters   z.1.103   z.2.103   z.1.104   z.2.104   z.1.105   z.2.105  \\\n",
       "draws                                                                    \n",
       "0          -1.118690 -0.035443  0.446277  0.760289 -0.027739  0.225159   \n",
       "1          -0.806093 -0.037180 -0.731136  0.259564  0.812796 -1.885443   \n",
       "2          -1.314597 -0.708519 -0.491111  0.091919  0.228649 -0.994099   \n",
       "3           0.349609  0.406307  0.022582  0.611187  0.313328 -0.799393   \n",
       "4          -0.810561 -0.954611 -1.285289 -1.132923  0.274064 -0.817277   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.252516 -0.459212 -1.325565  1.129720  0.909634 -2.148198   \n",
       "7996       -0.946407 -0.847145 -0.740313 -0.459758  0.490638 -1.950370   \n",
       "7997       -0.271519 -1.020867 -0.503275 -0.261662 -0.696485 -0.613335   \n",
       "7998        0.227961 -0.429727 -0.242542 -0.436138  0.518419 -0.480073   \n",
       "7999       -0.159491 -0.926711  0.375833 -2.027254 -0.682262 -0.536917   \n",
       "\n",
       "parameters   z.1.106   z.2.106   z.1.107   z.2.107   z.1.108   z.2.108  \\\n",
       "draws                                                                    \n",
       "0          -0.967839 -0.342213 -0.499825  0.911231  0.009145  0.836272   \n",
       "1          -1.746999  0.135861 -0.536543  0.737920  0.596928 -0.231204   \n",
       "2          -1.353445  0.549188  0.038436  0.550655 -0.133454  1.145093   \n",
       "3          -0.450504 -1.760621 -0.701216  0.330177 -0.242090  0.826249   \n",
       "4          -0.257297 -1.342353  0.049238 -0.472411  0.185282  0.477903   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.107243 -1.534632  0.740416 -0.806932  0.554193 -0.481628   \n",
       "7996       -0.622510 -0.534922  1.077276 -0.378494  0.029041  0.179031   \n",
       "7997       -1.682268  0.899553 -0.522523  0.218718 -0.454235  1.129081   \n",
       "7998        0.154450 -0.237176  0.427230  0.235070  0.006197 -0.069436   \n",
       "7999       -1.522379 -0.331838 -0.162530  1.559547 -0.098326  1.492856   \n",
       "\n",
       "parameters   z.1.109   z.2.109   z.1.110   z.2.110   z.1.111   z.2.111  \\\n",
       "draws                                                                    \n",
       "0          -0.697026 -0.201204  0.830182 -2.256811 -0.288981 -1.866656   \n",
       "1          -0.809170 -0.007993  0.751349 -1.082185 -1.514102 -0.989855   \n",
       "2          -1.297613 -1.069393  0.197911 -1.203810  0.091049  0.617568   \n",
       "3          -1.136835 -0.748174  0.602642 -0.051621 -1.020181 -1.111574   \n",
       "4          -0.506570 -0.061578  0.087854  0.915890 -0.697742  1.314842   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.478353 -0.939260  0.487490 -0.624573 -0.351273 -0.162180   \n",
       "7996       -1.862846  0.587634  0.944031  0.422150  1.329961 -0.866196   \n",
       "7997       -0.759248  1.456453  0.059578  0.411233  0.512639  0.240019   \n",
       "7998       -1.362408  1.513781  0.305847 -0.066949  0.990500 -0.090698   \n",
       "7999       -2.051076 -0.012754  0.472696 -0.413519 -0.843732 -0.015646   \n",
       "\n",
       "parameters   z.1.112   z.2.112   z.1.113   z.2.113   z.1.114   z.2.114  \\\n",
       "draws                                                                    \n",
       "0          -1.704418 -0.500388 -1.182197 -2.068117  0.359677  0.892811   \n",
       "1          -1.118389  1.429890 -1.699497 -0.366827  0.103048  0.923215   \n",
       "2          -1.891563 -0.032179 -0.483659 -1.667509 -0.153547  1.634203   \n",
       "3          -2.537954  0.327959 -1.263636  0.107016 -0.072795  1.363701   \n",
       "4          -0.249932 -0.218442 -1.503723  0.939925 -0.006544  0.748876   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -2.017922  0.287496 -0.544664  0.182203  0.313212  1.340689   \n",
       "7996       -0.805107 -1.185908 -0.988003 -0.141820 -0.736000  2.522639   \n",
       "7997       -0.841739 -0.785417 -2.662714 -0.436723  0.874549 -0.817463   \n",
       "7998       -0.496738 -0.394309  0.069956 -2.589997  0.821558  0.696350   \n",
       "7999       -1.528639 -1.802665 -1.805658 -0.932811  0.917433  0.093157   \n",
       "\n",
       "parameters   z.1.115   z.2.115   z.1.116   z.2.116   z.1.117   z.2.117  \\\n",
       "draws                                                                    \n",
       "0           0.276389  1.055525 -1.644336  0.232529  0.134439 -0.110337   \n",
       "1           1.367391  0.431371 -0.763896 -0.199512  0.495769 -0.030586   \n",
       "2           0.282840  0.440186 -0.709753 -1.184122 -0.251957  0.081310   \n",
       "3           1.113044  0.731276 -0.016962  0.118595  0.265416 -1.128841   \n",
       "4           1.356459  0.102613 -0.277292 -0.556315 -0.615303  0.520751   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.319743 -1.436630 -1.687503  0.457843 -0.272453  0.343618   \n",
       "7996        0.912305  1.185656 -0.025061 -0.483935 -0.626872 -0.526157   \n",
       "7997        0.997775  0.034131 -1.197184  0.463320  0.402943  0.061332   \n",
       "7998        1.288650  0.836472 -0.012052 -0.418244 -0.057169  0.698660   \n",
       "7999        0.423369  1.214396 -0.414594 -1.337777  0.585998  0.147297   \n",
       "\n",
       "parameters   z.1.118   z.2.118   z.1.119   z.2.119   z.1.120   z.2.120  \\\n",
       "draws                                                                    \n",
       "0           1.155801  1.614495 -0.501635  1.622383  0.015280  1.382536   \n",
       "1           0.849340  2.129651 -0.136289  1.075759 -1.116050  0.821959   \n",
       "2           1.634089 -0.630729 -0.057776 -1.006898 -0.941499  0.649928   \n",
       "3           2.127662  0.516819 -1.041771  1.693425 -0.385051 -1.316113   \n",
       "4           2.155388  0.074356 -0.029390 -0.541897 -0.792718 -0.938633   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.754045  1.736012 -1.802402  0.092955 -0.857347  0.535757   \n",
       "7996        1.277105  0.760258 -0.274568 -0.270635 -0.507063  0.516650   \n",
       "7997        2.082289  0.158073 -0.114207  0.497475 -0.493597  0.828992   \n",
       "7998        2.042742  0.589625 -0.904998  0.306099  0.145415  0.465076   \n",
       "7999        1.633551 -0.449635  0.381003 -0.362328  0.285398  0.653963   \n",
       "\n",
       "parameters   z.1.121   z.2.121   z.1.122   z.2.122   z.1.123   z.2.123  \\\n",
       "draws                                                                    \n",
       "0           0.203832  0.494538 -1.860905 -0.553706 -0.171643  0.550548   \n",
       "1          -0.128255 -0.388867 -2.332194  1.602850 -1.585078 -1.120535   \n",
       "2          -0.101452 -0.185905 -0.844065 -0.196751 -0.915483  0.236645   \n",
       "3           0.495767 -1.191193  0.666189 -0.851244 -0.233789 -1.333151   \n",
       "4           0.188063  0.571190 -0.577383 -0.138990 -1.250142 -0.044088   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.382867  1.059853 -0.399964 -1.653452 -1.310935  0.601547   \n",
       "7996        1.133784 -0.647120 -0.001672  0.230096 -1.024919  0.402066   \n",
       "7997        0.038680  0.602120 -0.477122 -0.392298 -0.872326  0.827462   \n",
       "7998       -0.021075  0.538020 -1.201893 -0.334906  0.148106 -2.076847   \n",
       "7999        0.240909 -1.669052 -2.338128  0.343073 -0.401335 -1.459433   \n",
       "\n",
       "parameters   z.1.124   z.2.124   z.1.125   z.2.125   z.1.126   z.2.126  \\\n",
       "draws                                                                    \n",
       "0          -1.272862 -0.756821 -0.478944 -0.362341 -0.668495  0.242355   \n",
       "1          -2.620574 -1.040520 -1.117670  0.980866  0.266947 -1.701556   \n",
       "2          -0.903566 -1.181377  0.255018 -2.457474  0.248068 -1.168868   \n",
       "3          -1.459939 -0.452787 -1.314317  0.893076 -0.978523 -0.497490   \n",
       "4          -0.990438 -1.072802 -1.818917  0.928800 -0.257523 -1.724678   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.689430  0.022398  1.145168 -1.369422 -1.305552  0.012297   \n",
       "7996       -1.542951  0.386366 -0.450826  0.017688 -1.351828 -0.539576   \n",
       "7997       -1.625548 -0.899495 -1.116072  0.730306  0.146423 -1.436381   \n",
       "7998       -0.557216 -0.445896 -0.450035  1.371100 -0.012645  0.120183   \n",
       "7999       -2.571274 -1.345469 -2.229134  1.391976 -0.342358 -1.589367   \n",
       "\n",
       "parameters   z.1.127   z.2.127   z.1.128   z.2.128   z.1.129   z.2.129  \\\n",
       "draws                                                                    \n",
       "0           1.059903  1.033359 -0.323507 -1.081084  1.019081 -0.851183   \n",
       "1           2.342002 -0.957553 -1.200572  0.653476  1.232093 -2.295682   \n",
       "2           1.711816 -0.068314 -1.326105 -0.217509  0.051117 -0.289936   \n",
       "3           1.183981  0.457466 -0.295013 -1.866267  0.427631 -1.038555   \n",
       "4           2.525503 -0.689312 -0.716477 -0.149750 -0.008334 -0.102597   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.787140  0.158596 -0.684867 -0.235819  0.453656 -0.326701   \n",
       "7996        1.332920  1.342855 -0.847843  0.080250 -0.777971 -0.503098   \n",
       "7997        1.283729  1.096357  0.113720 -0.163864  1.013520 -1.250597   \n",
       "7998        1.347723  0.232282  0.136311  0.073381 -0.168662 -1.641346   \n",
       "7999        1.909097  0.208813 -0.938359  0.178104  0.344523 -0.484381   \n",
       "\n",
       "parameters   z.1.130   z.2.130   z.1.131   z.2.131   z.1.132   z.2.132  \\\n",
       "draws                                                                    \n",
       "0           0.137213 -0.013310  0.390288  0.637840 -0.987354  1.277181   \n",
       "1          -0.617676  0.237318  0.369793  0.524519 -0.791921  0.777930   \n",
       "2          -0.375619  1.650580  0.027187  1.721621 -0.904158  1.119111   \n",
       "3          -1.489938 -0.362210  0.331062 -0.601377 -1.671971  0.731664   \n",
       "4          -1.726208  0.067183 -0.748452  0.484706 -0.325678 -0.578324   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.020275 -0.251110  0.386844  0.302311 -0.530493 -0.874808   \n",
       "7996        0.028709  0.461681  1.254190  0.576517 -1.259330  1.422039   \n",
       "7997       -1.742497  2.199018  0.398922  0.765183  0.187670 -2.707682   \n",
       "7998       -0.673302  0.531285  0.647788  1.928628  0.286896 -0.348698   \n",
       "7999       -1.433688 -1.173840 -0.394206  1.108125 -0.950039  0.010556   \n",
       "\n",
       "parameters   z.1.133   z.2.133   z.1.134   z.2.134   z.1.135   z.2.135  \\\n",
       "draws                                                                    \n",
       "0          -0.030232 -1.991862 -0.854215  1.014998  0.657532 -0.611398   \n",
       "1           0.071869 -0.421980 -0.726124  0.638399  0.222652 -0.012250   \n",
       "2           1.034891 -0.410894  0.187660  1.380473  0.926150 -1.120997   \n",
       "3          -0.045461 -0.581446 -0.867031  0.406182 -0.719129  1.268360   \n",
       "4           0.740673  2.387250 -0.227316  0.227056  0.988796 -0.347031   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.601435  0.922316 -0.514702 -0.454278  0.959291 -1.406727   \n",
       "7996        1.206135 -1.333255  0.163894  1.930248  0.267424  0.818141   \n",
       "7997       -0.278809 -1.249379 -0.348406  1.135144  0.162428  0.592387   \n",
       "7998        0.820292 -0.360188 -0.457881  2.484554  0.640159 -0.442163   \n",
       "7999        0.883031  0.016370 -1.284136 -0.063606  0.252563  0.414114   \n",
       "\n",
       "parameters   z.1.136   z.2.136   z.1.137   z.2.137   z.1.138   z.2.138  \\\n",
       "draws                                                                    \n",
       "0          -0.467277 -0.842790  0.178724  1.877258  0.878334  0.230417   \n",
       "1           0.708897 -1.551183  0.830761  2.386426  1.201632 -1.241883   \n",
       "2          -0.004882 -0.583486  1.389918  0.032643  1.810088 -1.274165   \n",
       "3          -0.089959  0.539472  0.508317  0.806898  1.309377  0.133092   \n",
       "4           0.181107 -0.839675  1.557306 -0.508544  2.164569 -1.109170   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.679509  0.446671 -0.068252  0.953871  1.015880 -0.625187   \n",
       "7996       -0.163666 -0.665025  0.507948 -0.088976  1.929185  0.332618   \n",
       "7997       -0.307259 -0.322215  0.599164  0.969389  0.791730  0.902895   \n",
       "7998       -0.334919 -2.667480  1.382226  0.264000  1.116073 -0.946438   \n",
       "7999       -0.151016 -1.494915  0.105802 -0.148888  0.692591 -0.851735   \n",
       "\n",
       "parameters   z.1.139   z.2.139   z.1.140   z.2.140   z.1.141   z.2.141  \\\n",
       "draws                                                                    \n",
       "0          -0.142293 -0.296493 -0.530164 -0.232112 -0.774382 -1.124009   \n",
       "1          -0.133010  0.789604 -1.376960  0.755083 -1.546680 -0.727240   \n",
       "2          -0.186252  0.132843  0.087116  0.167818 -1.145285 -0.135244   \n",
       "3          -0.114487  0.152128  0.232162  0.458293 -0.821656 -1.026838   \n",
       "4           0.063040  0.482996 -0.868239 -0.539690 -0.880146 -0.305932   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.276381  0.229385  0.199738 -0.573292 -1.605094 -0.553187   \n",
       "7996        0.745332 -1.237791 -0.254801  0.711287  0.256910 -0.502800   \n",
       "7997        0.451808 -1.422291 -0.353153  0.527711 -0.955488 -0.192202   \n",
       "7998       -0.098407  0.854197 -0.350128  0.436362 -1.272784 -0.144762   \n",
       "7999        0.309875 -0.127803 -0.915938  0.708021 -0.428317 -0.047052   \n",
       "\n",
       "parameters   z.1.142   z.2.142   z.1.143   z.2.143   z.1.144   z.2.144  \\\n",
       "draws                                                                    \n",
       "0          -0.069369 -0.222869  0.205650  0.569872 -0.183099 -0.378692   \n",
       "1          -0.130014  1.828757 -0.260097  1.021324 -0.080298 -0.975998   \n",
       "2           0.384378  0.173818  0.939236  0.301775 -1.194826  1.534230   \n",
       "3          -0.588132  1.372060  0.117968  0.556803 -1.846453  1.813139   \n",
       "4          -1.477497  0.919313 -0.060237  1.041878 -1.308110 -0.165086   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.122965  0.742317  0.907898  0.259966 -0.709358  0.390832   \n",
       "7996        1.166874  0.248282  0.658714  2.121927 -0.534511 -1.455228   \n",
       "7997       -0.192708  0.359985  0.491788  0.104434 -0.144988 -0.524958   \n",
       "7998       -0.111897  1.008923  0.041061  2.861920 -0.162575 -1.269843   \n",
       "7999       -0.220690  0.577507 -0.288849  0.683229 -0.440618 -0.066410   \n",
       "\n",
       "parameters   z.1.145   z.2.145   z.1.146   z.2.146   z.1.147   z.2.147  \\\n",
       "draws                                                                    \n",
       "0          -1.103668  1.097842  1.157225  0.186577  0.512074  1.608333   \n",
       "1           0.236623  0.032964  0.225526 -0.226727  0.009751 -0.439470   \n",
       "2           0.875701 -1.121229  2.033307 -0.479138 -0.008581  0.919947   \n",
       "3          -0.693386  1.427753  0.732330 -0.480106 -0.052404 -0.022492   \n",
       "4          -0.693327  0.256400  1.530379 -0.401217  0.480855 -0.636019   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.330444  0.235441  1.705353 -0.038381  0.535561  1.694553   \n",
       "7996        0.908396 -0.195731  1.478527  0.149412  1.101536 -0.617558   \n",
       "7997       -0.755321  1.388478  0.876046  0.173980  0.663672  0.975462   \n",
       "7998        0.640670 -1.271030  1.141186  0.688494 -0.063256 -0.280843   \n",
       "7999        0.158397  0.823294  0.821315  0.249425  0.537330 -0.758475   \n",
       "\n",
       "parameters   z.1.148   z.2.148   z.1.149   z.2.149   z.1.150   z.2.150  \\\n",
       "draws                                                                    \n",
       "0           0.149923  0.951102 -1.609562  0.192476  0.577872 -0.532397   \n",
       "1           0.852087  0.990138 -1.897289  0.424397 -0.083966 -0.710408   \n",
       "2           0.249215  0.045518 -0.378709 -0.686520 -0.706487 -1.368280   \n",
       "3           0.768021 -1.069563 -0.919992  0.197537  1.183008 -1.382627   \n",
       "4           1.248863 -0.172627 -0.346142 -1.785206 -0.848510  0.272208   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.416229 -0.940729 -0.118619 -0.373168 -0.249705 -0.876473   \n",
       "7996        0.142885 -0.423314 -2.025983  0.568714 -0.086980  0.307637   \n",
       "7997        0.106923  1.162155 -0.659965 -0.895932 -0.434752 -0.967429   \n",
       "7998        0.861070  0.625377 -0.115619 -0.908581 -0.771301 -0.097373   \n",
       "7999        0.643766  0.662780 -0.503751  0.574039  0.006345  0.231884   \n",
       "\n",
       "parameters   z.1.151   z.2.151   z.1.152   z.2.152   z.1.153   z.2.153  \\\n",
       "draws                                                                    \n",
       "0           0.347975 -0.710726 -0.587099 -0.182126  0.860099  0.482700   \n",
       "1           0.212363  1.406536 -0.304735 -0.480709  0.565026  1.369861   \n",
       "2          -0.113121 -0.896983  0.330392 -2.663619  0.415593  0.190554   \n",
       "3           1.031120 -0.481680 -0.193260 -1.126306  0.913665  0.281344   \n",
       "4           0.042337 -0.209815 -0.217377 -1.132545  0.123129  1.309486   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.349286 -0.782212  0.115110 -1.606943  0.730386 -0.175281   \n",
       "7996        0.192920  0.272594 -0.460424 -0.433137  0.370446 -0.077101   \n",
       "7997        0.231060  0.593265  0.853844 -0.924924  0.394384  0.207515   \n",
       "7998        0.447107 -0.253180 -0.041595 -0.664525  1.124908  0.069510   \n",
       "7999        0.044659 -0.659074 -0.517903  0.822551  0.094558  0.749206   \n",
       "\n",
       "parameters   z.1.154   z.2.154   z.1.155   z.2.155   z.1.156   z.2.156  \\\n",
       "draws                                                                    \n",
       "0          -0.273606 -0.442736  0.124064  1.007144  1.004323  0.885385   \n",
       "1          -0.536017  1.121768 -0.252996  0.500366  0.678141  1.155191   \n",
       "2          -0.288286 -1.571392 -1.305867 -0.492824 -0.314600  1.416678   \n",
       "3          -0.254246 -0.082714 -0.375480  0.780076  0.909704 -0.171177   \n",
       "4          -0.047297 -0.884290  0.570448 -1.916283  0.867504  1.589157   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.561611  0.677692  0.146345 -1.054869  0.535591  1.166569   \n",
       "7996        0.210270  0.080955  0.100652 -1.066337 -0.285520  2.233902   \n",
       "7997       -1.276813 -0.027631 -0.093170 -0.235682 -0.381888  1.407560   \n",
       "7998       -0.643086 -0.146357  0.565615 -1.443381  1.039074  0.254276   \n",
       "7999       -0.543886 -0.685556  0.006152  0.565100  1.236177  0.702077   \n",
       "\n",
       "parameters   z.1.157   z.2.157   z.1.158   z.2.158   z.1.159   z.2.159  \\\n",
       "draws                                                                    \n",
       "0          -0.719621  0.762079  0.649594  1.639052  0.218945  0.921334   \n",
       "1          -0.836983  0.458582  0.735660  0.596172  0.260916 -0.063499   \n",
       "2          -1.327251  0.378493  0.950476 -0.694245 -0.226502  0.805719   \n",
       "3          -0.241654  1.137462  1.204758 -0.552063 -0.843273  1.324540   \n",
       "4          -0.525725 -0.784453  0.086689  0.999911 -0.240026  1.796550   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.539618 -0.196041  0.166226  1.077625  0.197328  0.928485   \n",
       "7996       -0.540235  0.662815  0.881088  0.052132 -0.145468  0.279766   \n",
       "7997        0.514162 -1.400397  0.657296  0.144363  0.021441  0.624080   \n",
       "7998        0.303534  0.209770  1.069085  0.846496 -0.932502  1.590306   \n",
       "7999       -0.172354  1.242556  0.826235  0.135730  0.640135  0.168826   \n",
       "\n",
       "parameters   z.1.160   z.2.160   z.1.161   z.2.161   z.1.162   z.2.162  \\\n",
       "draws                                                                    \n",
       "0          -1.496541  0.940202  0.562574 -0.387609  0.049469  0.485171   \n",
       "1          -0.445095  0.006640  1.206005 -1.268302  0.818413 -0.551326   \n",
       "2          -0.283369 -0.422526  1.093486 -1.254696 -0.103765  0.056502   \n",
       "3          -1.601353 -0.277398  0.575406 -0.962586 -0.571055  1.081831   \n",
       "4           0.095700 -1.391895  1.191840  0.219449 -0.141133  0.739154   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.026666 -1.415432  0.618134 -0.242536 -0.521865  0.524856   \n",
       "7996       -0.226982 -1.608228  1.068846  0.668085 -0.710997  1.301457   \n",
       "7997        0.197405 -2.033129  1.072446 -1.475036 -0.372629 -0.661642   \n",
       "7998       -0.370002 -1.185666  0.875085 -0.484567 -1.168479  0.969472   \n",
       "7999       -1.405411  0.912484  1.254458 -0.328924  0.299672 -0.117583   \n",
       "\n",
       "parameters   z.1.163   z.2.163   z.1.164   z.2.164   z.1.165   z.2.165  \\\n",
       "draws                                                                    \n",
       "0           0.020380 -1.545164 -1.111940  0.080055 -2.177462 -0.457252   \n",
       "1          -0.106251  0.755536 -0.017240  0.395501 -1.491857 -1.531709   \n",
       "2           0.061417 -0.073706 -0.667549 -0.008747 -1.198921 -0.742022   \n",
       "3           0.475545 -0.368258 -0.096840 -0.447416 -0.906761 -1.484180   \n",
       "4           0.084006  0.423434  0.604698  1.118998 -1.363806 -0.531565   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.948269 -0.922798 -1.330018  1.122246 -2.215499 -2.324176   \n",
       "7996       -0.321273 -1.008095 -0.726460  0.870170 -2.884139  0.919232   \n",
       "7997        0.415522  0.653628  0.206730 -0.996967 -1.732660 -0.749303   \n",
       "7998       -0.187051 -0.889438 -0.586498  1.239712 -0.951498 -0.305577   \n",
       "7999       -0.105412  1.374715  0.756338 -0.863363 -1.091845  1.071401   \n",
       "\n",
       "parameters   z.1.166   z.2.166   z.1.167   z.2.167   z.1.168   z.2.168  \\\n",
       "draws                                                                    \n",
       "0          -1.048763 -0.849832 -1.993255 -1.256607 -0.394906 -1.735839   \n",
       "1          -2.105942 -0.336488 -0.265552  0.081830 -1.147754  0.341580   \n",
       "2          -2.152284  0.078743 -1.251353  0.924700 -0.422887 -0.465372   \n",
       "3          -1.271660 -0.710865 -2.288414 -1.160996 -0.913291  1.090702   \n",
       "4          -1.508123  0.463599 -0.020091 -0.000114 -1.262085  1.680026   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.900498 -0.163289 -0.956149  0.214306 -1.032150 -0.293202   \n",
       "7996       -0.737601 -0.193718 -0.149832  1.053995 -1.692510  0.018195   \n",
       "7997       -1.879080  2.330789 -1.403135  0.185810 -0.532576  0.724498   \n",
       "7998       -1.139748 -0.810219 -0.922617 -0.466963 -0.444436  1.022452   \n",
       "7999       -1.755264  0.114599 -0.836031 -0.900004 -1.342033  0.809631   \n",
       "\n",
       "parameters   z.1.169   z.2.169   z.1.170   z.2.170   z.1.171   z.2.171  \\\n",
       "draws                                                                    \n",
       "0          -0.351334 -0.269150  0.915090 -0.382552  0.858676  0.394325   \n",
       "1          -0.137328 -0.177554  0.630829 -1.480606  0.832355 -0.051371   \n",
       "2          -0.813787  0.222424  0.350794 -0.084223  0.909434  0.767841   \n",
       "3          -0.525932 -1.032769  0.510182 -0.390301  1.249191  0.257019   \n",
       "4          -1.086741  0.209841  0.572442 -1.069968  1.074539 -0.001866   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.499261  0.566981 -0.285071 -0.825597  0.577352 -0.636103   \n",
       "7996       -2.582842  0.544625  0.498196  1.027926  1.138160  0.434688   \n",
       "7997       -0.875821  1.916473  0.304590 -0.071785  1.080003  0.311288   \n",
       "7998       -1.176326  1.779446  0.761250 -0.158379  1.240046  0.481560   \n",
       "7999       -0.217264 -0.633005  1.125255  0.615951  0.260963  0.571133   \n",
       "\n",
       "parameters   z.1.172   z.2.172   z.1.173   z.2.173   z.1.174   z.2.174  \\\n",
       "draws                                                                    \n",
       "0           1.014967 -0.150683  0.870288  0.560541  0.858278  1.134295   \n",
       "1           1.072925 -0.038436  0.911512 -0.100041  1.443372 -0.558760   \n",
       "2           0.900905  0.179267  0.881224 -0.613312  0.438182  0.039736   \n",
       "3           0.811666  0.644727  0.867438  0.819504  1.111360 -2.299784   \n",
       "4           1.111427  0.553215  0.212641 -0.043222  1.003507 -0.834806   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.502170 -0.505281  1.231648 -0.098052  0.794563 -0.920125   \n",
       "7996        1.059954  0.229085  0.599388  0.102452  1.056808 -0.675476   \n",
       "7997        0.876954  0.630058  1.325421 -1.361807  1.397939 -1.818124   \n",
       "7998        1.211477  0.163705  1.022031 -0.178397  1.949606 -0.684831   \n",
       "7999        0.602429 -0.039376  0.578215  0.199289  0.640560  0.059373   \n",
       "\n",
       "parameters   z.1.175   z.2.175   z.1.176   z.2.176   z.1.177   z.2.177  \\\n",
       "draws                                                                    \n",
       "0           0.260536  1.691566  0.469394  0.185033 -0.063194 -0.266999   \n",
       "1           1.337643  1.023709  0.405004  0.381058 -0.529059  0.838514   \n",
       "2           1.241677  1.032885  0.273309  1.674452  0.185430  0.855174   \n",
       "3           0.118286  2.685036  0.224304  0.915740 -0.675624  0.170311   \n",
       "4           1.035909  1.222001  0.293826  1.439900  0.203877  0.853915   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.131048  2.313299  1.339820 -0.422050 -1.317759  0.975986   \n",
       "7996        0.771202  1.386451  1.341247 -0.438266  0.480418 -1.097940   \n",
       "7997        0.299082  2.061115  0.859143 -0.228209 -0.348985  0.996746   \n",
       "7998        1.113583  2.013963  0.977258  0.214376 -0.250112 -0.174051   \n",
       "7999        0.948452  0.972260  0.212771  1.933770  0.027050 -0.686253   \n",
       "\n",
       "parameters   z.1.178   z.2.178   z.1.179   z.2.179   z.1.180   z.2.180  \\\n",
       "draws                                                                    \n",
       "0          -1.294115 -0.193082  2.953827 -0.380779 -0.717379 -0.981844   \n",
       "1          -0.115977 -0.852715  3.211665 -0.535774 -1.047202 -1.772947   \n",
       "2           0.020085 -0.109069  2.863246  0.413239 -1.854232  0.515844   \n",
       "3          -0.981117  0.143401  3.046258 -0.302474 -0.836490 -1.389416   \n",
       "4           0.433642 -1.145680  3.196986  1.202695 -2.072165  0.904956   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.103487 -1.569516  2.882508  0.346358 -1.369488 -0.394097   \n",
       "7996        0.730400 -1.130413  3.477477 -0.856292 -0.821568 -1.579323   \n",
       "7997       -0.655084  0.748798  3.220701 -0.059716 -0.828887 -0.393443   \n",
       "7998        0.059056 -0.598606  3.502398  0.048835 -1.614039 -2.357212   \n",
       "7999       -1.090212  0.625351  3.060437 -0.142566 -1.046978  0.268066   \n",
       "\n",
       "parameters   z.1.181   z.2.181   z.1.182   z.2.182   z.1.183   z.2.183  \\\n",
       "draws                                                                    \n",
       "0           0.371068  1.282060  0.865336 -3.044838  0.007585  0.678863   \n",
       "1           0.296972 -1.131994  0.801422  0.040765  0.940442  1.667801   \n",
       "2           0.020855  1.053780  0.476365 -0.588165  0.708927  0.018512   \n",
       "3           0.805599 -0.598141  0.652311  0.977233  0.172501  2.416750   \n",
       "4           0.331675 -0.844193  0.473184  1.750913  0.661052  0.725755   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.162921  0.982176  0.694896  0.105734  0.457975  2.105963   \n",
       "7996        0.232314  0.015321  1.059071 -1.028322 -0.038565  0.757480   \n",
       "7997        0.128353 -0.290156  0.802193 -0.577578  0.902422  0.855858   \n",
       "7998        0.275074  0.920687  0.443874 -2.182236  0.542683  0.256917   \n",
       "7999        0.932033 -1.188955  0.544965 -1.239705  1.630522  0.131212   \n",
       "\n",
       "parameters   z.1.184   z.2.184   z.1.185   z.2.185   z.1.186   z.2.186  \\\n",
       "draws                                                                    \n",
       "0          -0.394857  0.962960  0.691870  0.014156  0.670726  0.252591   \n",
       "1           0.197949  1.160642  0.201224 -0.426407  0.285955 -0.168967   \n",
       "2           0.230843  0.904100 -0.214649 -1.945305  0.374889 -0.119012   \n",
       "3           0.050916  0.484942  0.360076  0.270846  0.342511  1.700868   \n",
       "4           0.424379 -1.115300 -0.138423 -0.002756  0.157621  0.374635   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.302753  1.126286  0.330743 -3.052455  0.384429  0.910391   \n",
       "7996        0.214033 -0.398716 -0.202130  0.206025  0.124921 -1.145898   \n",
       "7997        0.311351  0.657669  0.234858  1.466561  0.395842  0.811860   \n",
       "7998        0.103318  1.055180  0.107601  0.283396  0.270237  0.174600   \n",
       "7999        0.657435  0.759766  0.698825  2.433834  0.372451 -1.127563   \n",
       "\n",
       "parameters   z.1.187   z.2.187   z.1.188   z.2.188   z.1.189   z.2.189  \\\n",
       "draws                                                                    \n",
       "0           0.342732 -0.480275 -0.963289 -0.705400 -0.011286  0.104584   \n",
       "1          -0.408858 -1.174512 -1.160729 -1.221132 -0.095612 -0.160734   \n",
       "2          -0.351334  0.112966 -0.461936 -1.267577 -0.985031  1.076021   \n",
       "3          -0.303349  2.201669 -0.432906  1.185999 -0.972072 -1.116622   \n",
       "4          -0.402657  0.868778 -1.306412  0.140663 -1.524950 -1.288148   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.399869  0.544735 -1.015717  0.588012 -1.299321  0.082676   \n",
       "7996       -0.419664  0.638257 -0.696088 -1.987984 -0.541385 -0.894179   \n",
       "7997       -0.014691  1.269668 -0.163332  1.198955 -0.241296 -0.253273   \n",
       "7998       -0.219063 -0.383257 -1.036883  0.421588 -0.653390 -0.723013   \n",
       "7999        0.468507  1.462701 -0.148704 -0.715995  0.454146 -0.183801   \n",
       "\n",
       "parameters   z.1.190   z.2.190   z.1.191   z.2.191   z.1.192   z.2.192  \\\n",
       "draws                                                                    \n",
       "0          -0.593233 -0.981008  0.378491 -0.175633 -0.270884  1.676750   \n",
       "1          -0.138141 -1.878979 -0.668088  0.637317 -0.003959  1.420048   \n",
       "2          -1.269692 -1.859964  0.202662  0.175564  0.118748 -0.975067   \n",
       "3          -1.152451  0.224959  0.065976  0.412230 -0.463664  0.004012   \n",
       "4          -1.287174 -0.259746 -0.622368  0.939121 -0.485930 -3.007541   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.878052  0.215041  0.809761 -0.048256 -0.299561  0.751424   \n",
       "7996       -1.244731 -0.986726  0.116398 -0.075759  0.280948 -0.320632   \n",
       "7997       -0.971378 -0.465004 -0.200239  1.947265  0.276758 -0.988564   \n",
       "7998       -0.620543 -0.214125  0.124311  0.019941 -0.207182 -0.206831   \n",
       "7999       -0.198391 -1.301124 -0.062060 -0.127658  0.207185 -1.756979   \n",
       "\n",
       "parameters   z.1.193   z.2.193   z.1.194   z.2.194   z.1.195   z.2.195  \\\n",
       "draws                                                                    \n",
       "0          -0.079560 -0.289013 -1.249484  0.244958  1.730934  1.530976   \n",
       "1          -0.014935  0.035376 -2.655963 -0.661855  1.365808  1.640728   \n",
       "2          -0.509898  0.267249 -2.003884 -0.711713  1.482148  0.659332   \n",
       "3           0.135820  0.236283 -0.402219  0.761881  1.336694  2.203182   \n",
       "4           0.030800  0.160314 -1.038253  0.272730  1.381904  1.358055   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.205243 -1.469317 -0.442236  1.273625  1.634617  1.756182   \n",
       "7996       -0.353044  0.254274 -1.404474 -0.315717  1.567673  1.526419   \n",
       "7997       -0.216303  0.406169 -0.564838  0.232358  1.042576  1.726759   \n",
       "7998       -0.659480  0.898771 -0.691873 -1.857792  1.669726  1.761148   \n",
       "7999       -0.042742 -0.129621 -0.726083 -1.581759  1.757948  1.532520   \n",
       "\n",
       "parameters   z.1.196   z.2.196   z.1.197   z.2.197   z.1.198   z.2.198  \\\n",
       "draws                                                                    \n",
       "0           3.259456 -0.090013  1.640392  0.769577  1.001403 -0.524934   \n",
       "1           2.973286  1.527735  2.599604  0.609670  0.373816  0.939341   \n",
       "2           2.320429  1.372529  1.803248  0.844227  0.430172  0.067439   \n",
       "3           3.123642  1.267467  2.235961  1.064833  1.549990  1.306227   \n",
       "4           3.323599  1.351659  1.919174  1.239821  0.613619  0.943296   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.770127  0.100487  1.237391  1.131228 -0.050678 -0.014432   \n",
       "7996        3.053079  0.792237  1.582020  0.994448  0.615992 -0.332766   \n",
       "7997        2.489394  0.980939  1.870459  0.995005  1.083828  0.085560   \n",
       "7998        3.342970 -0.434832  1.704352  1.406380  1.259622 -0.571441   \n",
       "7999        3.116335 -0.084914  2.719274 -0.002609  0.427639  0.438111   \n",
       "\n",
       "parameters   z.1.199   z.2.199   z.1.200   z.2.200   z.1.201   z.2.201  \\\n",
       "draws                                                                    \n",
       "0          -0.332415 -0.135464 -1.127972  2.307152 -0.267959 -0.661513   \n",
       "1          -0.144960 -0.145220  0.004728 -1.176126 -1.491962  0.796506   \n",
       "2          -1.123553  0.286673 -0.091308 -0.015220 -0.373115 -1.703799   \n",
       "3           0.047364 -0.375184  1.108521 -0.786399  0.216688 -0.895912   \n",
       "4           0.478014 -0.261993  1.681605 -1.424684 -0.912467 -0.396006   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.032636 -1.486096 -0.039513 -0.271569 -1.882234 -0.253267   \n",
       "7996        0.136453  0.846794 -0.156905 -0.001411 -1.179923  0.500368   \n",
       "7997       -0.364794  1.164369 -0.892238  1.442207 -0.571101  0.020865   \n",
       "7998       -0.067719  0.462158  0.473267 -0.672258 -0.885180  0.263232   \n",
       "7999       -0.814974  1.459938 -0.548870  0.475448 -0.856790 -0.843569   \n",
       "\n",
       "parameters   z.1.202   z.2.202   z.1.203   z.2.203   z.1.204   z.2.204  \\\n",
       "draws                                                                    \n",
       "0          -0.912385 -0.907534 -0.255144 -1.676469 -1.135161  0.796501   \n",
       "1          -2.444328 -0.328050  1.343301 -1.271974 -1.586865  0.263760   \n",
       "2          -1.475855  1.163295 -0.661072  0.090670 -0.996595  0.218159   \n",
       "3          -2.839768 -0.531010 -1.037511  1.212546 -0.241543 -0.413399   \n",
       "4          -0.177310 -0.492794 -1.582802  1.118340 -0.508731 -0.453288   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.650476 -0.907001 -0.484914  0.642708 -0.528811 -1.490364   \n",
       "7996       -2.293601 -0.491580 -0.753630 -0.057181 -0.910655 -0.682927   \n",
       "7997       -0.953247 -1.946072 -2.117796  0.808255 -1.710126 -0.058752   \n",
       "7998       -0.503416 -0.635334 -0.545901  1.714043 -0.582340  0.677611   \n",
       "7999       -1.099090 -0.197499 -0.813265 -0.599152 -1.289894  0.292906   \n",
       "\n",
       "parameters   z.1.205   z.2.205   z.1.206   z.2.206   z.1.207   z.2.207  \\\n",
       "draws                                                                    \n",
       "0          -1.397150  0.750070 -1.901946 -0.161131 -0.070010  0.771634   \n",
       "1          -0.615715  0.751649 -1.821769  1.759781  1.069821 -0.667240   \n",
       "2          -0.325123 -0.241869 -1.260406 -0.159336 -0.332912  1.164616   \n",
       "3          -0.252692  0.630187 -0.521892 -0.026792 -0.072190  0.876789   \n",
       "4          -0.502404 -0.527122 -0.590293 -0.411418  0.442320  0.521634   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.004965 -0.647583 -1.221881 -1.199177 -0.279149  0.044625   \n",
       "7996       -0.488964 -0.485346 -0.137074 -2.422071  0.803092 -0.337353   \n",
       "7997       -0.415447 -0.187659 -0.955788 -0.467790  0.095417 -0.467312   \n",
       "7998       -1.432580 -0.115756 -1.515664 -0.179515 -0.166178  0.451416   \n",
       "7999       -0.742077  0.998885 -2.162448  0.407606  0.697625  0.183846   \n",
       "\n",
       "parameters   z.1.208   z.2.208   z.1.209   z.2.209   z.1.210   z.2.210  \\\n",
       "draws                                                                    \n",
       "0           0.721395 -0.687563  0.625212 -0.331866  1.471524  1.067197   \n",
       "1          -0.077468  2.264576 -0.939363  0.086498  2.799483  1.179418   \n",
       "2           0.113986  0.288987 -0.237401 -1.677699  1.346649  1.564966   \n",
       "3          -0.331647  1.255788  0.753982 -0.795172  0.996092  2.316779   \n",
       "4          -0.301809  1.740962 -1.051555 -0.518726  1.660539  0.936958   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.565994 -0.745460 -0.717347 -0.416736  1.603607  1.361029   \n",
       "7996       -0.160241  1.398258 -0.303171 -0.177206  1.476771  2.246683   \n",
       "7997       -0.978177  1.551117 -1.430768  1.041120  2.123037  0.846223   \n",
       "7998        0.732734  0.197024 -0.164538 -0.323547  1.850738  0.310548   \n",
       "7999       -0.385094  1.748256 -0.271294 -0.698630  2.561905 -0.091668   \n",
       "\n",
       "parameters   z.1.211   z.2.211   z.1.212   z.2.212   z.1.213   z.2.213  \\\n",
       "draws                                                                    \n",
       "0           0.379751 -0.160306 -0.047961 -0.137530 -0.012484  0.348187   \n",
       "1          -0.579041 -0.495169  0.368723  0.132089 -0.300547 -0.965856   \n",
       "2          -1.041032 -0.658147 -0.479500  0.834507 -0.067109 -0.240953   \n",
       "3           0.949739 -1.029926 -0.569946 -0.359061 -0.392044 -0.313228   \n",
       "4           0.257436 -1.477411 -0.588826 -0.382202 -0.416234  1.008025   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.466491 -1.062280 -0.767022  0.242592 -0.489035  0.546057   \n",
       "7996        0.237326 -1.112413 -0.584382  0.830218  0.306113  0.511715   \n",
       "7997        1.005733 -2.626757 -1.239907  0.333053 -0.302188  0.455504   \n",
       "7998       -0.679769 -1.062913 -0.358207  0.323807 -0.277752 -0.203353   \n",
       "7999        0.313518 -1.635574  0.178460 -0.713147 -0.468777  0.920732   \n",
       "\n",
       "parameters   z.1.214   z.2.214   z.1.215   z.2.215   z.1.216   z.2.216  \\\n",
       "draws                                                                    \n",
       "0          -1.012746 -1.528896 -1.991741 -0.057893  0.251506  1.056235   \n",
       "1          -1.881721  1.189040 -0.172974 -1.605619 -1.249434 -1.197815   \n",
       "2          -0.398746 -0.892674 -0.882704 -0.308510 -0.262881 -0.153623   \n",
       "3          -2.214638 -1.485882 -0.107226  0.336018 -1.727922 -1.023749   \n",
       "4          -1.375485  0.909629  0.001333 -0.089157 -1.853798 -1.038188   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.266902 -0.842713  0.674500 -0.998945 -0.131972 -1.059639   \n",
       "7996       -0.968239 -0.511667 -1.760786  1.315366 -0.943056  2.496364   \n",
       "7997       -0.961842 -0.438593 -0.807869 -0.303028 -0.192681 -0.333225   \n",
       "7998       -0.726128 -0.538159 -1.165088 -1.636069  0.347768 -0.329004   \n",
       "7999       -1.469499  2.092914 -1.657286  0.888663 -0.600777  1.202361   \n",
       "\n",
       "parameters   z.1.217   z.2.217   z.1.218   z.2.218   z.1.219   z.2.219  \\\n",
       "draws                                                                    \n",
       "0          -1.503587  0.939415 -0.279350 -0.333166 -0.624511  0.825865   \n",
       "1           0.235497  0.605939  0.311934 -1.221290 -1.005650  0.467686   \n",
       "2           0.077194 -1.559162  0.348832 -0.432021 -1.041795 -0.403227   \n",
       "3          -0.709151 -0.155993 -0.194077 -0.148447 -0.619831 -0.313530   \n",
       "4          -0.164796 -1.139340  0.100946 -0.400948 -1.248121 -2.055430   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.756152  0.581819 -0.041530  0.928989 -1.017979 -0.767581   \n",
       "7996       -1.742019  0.327766 -0.371923 -0.324404 -0.486523 -0.253413   \n",
       "7997       -1.008253 -0.210258 -0.813878  0.021542 -0.515664 -2.415008   \n",
       "7998        0.083162  0.796850 -0.153530 -0.367293 -1.269914 -0.318175   \n",
       "7999       -0.982442 -1.367377  0.579348 -1.580557 -0.979499 -0.027481   \n",
       "\n",
       "parameters   z.1.220   z.2.220   z.1.221   z.2.221   z.1.222   z.2.222  \\\n",
       "draws                                                                    \n",
       "0          -0.870484  2.048743 -1.759479  0.364668  0.655261 -1.123401   \n",
       "1          -0.448532 -1.094489  0.179539 -0.233023 -1.444420  0.471709   \n",
       "2          -0.050247 -0.460290 -1.069693  0.877592 -0.381193 -0.368850   \n",
       "3          -1.329584  0.687450 -0.553795 -0.656326 -0.473457 -1.098787   \n",
       "4           0.231581 -0.771794  0.756095 -0.253487 -1.379638  0.581856   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.201373 -0.499105 -0.069359 -2.125341 -0.455634  0.589070   \n",
       "7996        0.037261  0.760083 -0.108056  0.539889 -0.263306 -0.368366   \n",
       "7997        0.368638  0.090693  0.221116 -0.311374  0.567206 -1.251229   \n",
       "7998       -0.561987  0.721104  0.771318 -0.280007 -0.734842  1.203725   \n",
       "7999       -0.074498  0.508188 -1.090371  1.228268  0.041177 -0.911200   \n",
       "\n",
       "parameters   z.1.223   z.2.223   z.1.224   z.2.224   z.1.225   z.2.225  \\\n",
       "draws                                                                    \n",
       "0           1.649176  0.764155 -0.862793 -0.442504  0.175428 -0.887106   \n",
       "1           2.469363  0.832983  0.581295  1.141798  0.773065  0.438019   \n",
       "2           1.505813  1.592643 -0.843110  1.703313 -0.042113 -1.165736   \n",
       "3           2.039641  1.327381 -0.582409  1.377688  0.362066 -1.178746   \n",
       "4           2.187511  1.895891  0.017917  0.430093  0.302575  0.348330   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.455077  1.617816 -0.567132 -1.477221 -0.282963 -1.021762   \n",
       "7996        1.475588  1.055376 -0.789983  0.838024 -0.520997  0.400584   \n",
       "7997        2.074985  2.130637 -0.053061 -0.407399  0.075314  0.556859   \n",
       "7998        1.635496  1.429582 -0.605417 -0.603124 -0.838933  1.146618   \n",
       "7999        2.527987  1.516036 -0.354244  1.512053 -0.096952  0.469165   \n",
       "\n",
       "parameters   z.1.226   z.2.226   z.1.227   z.2.227   z.1.228   z.2.228  \\\n",
       "draws                                                                    \n",
       "0          -1.410454 -0.269047 -2.524708 -1.321545 -0.326580  0.745544   \n",
       "1          -2.293732 -0.080565 -1.703107 -0.565061 -0.097318  0.214134   \n",
       "2          -1.601744 -1.666208 -2.960863 -0.516680 -0.300672 -0.568188   \n",
       "3          -1.594711 -0.034631 -1.845421 -0.468800 -1.083567  0.643403   \n",
       "4          -1.890432 -0.187185 -0.412855  0.690796 -1.680816 -1.467388   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.586082 -0.550894 -1.081480  0.648673 -0.895462 -1.673891   \n",
       "7996       -1.330011  1.256356 -2.526202 -0.746436 -1.805335 -0.223712   \n",
       "7997       -1.537894 -0.756932 -0.694657 -1.153431 -0.124652  0.927824   \n",
       "7998       -2.209169 -0.030196 -1.592760 -0.620985 -1.791198  0.507036   \n",
       "7999       -2.232217 -0.135588 -0.587575 -0.391613 -0.438010  1.418632   \n",
       "\n",
       "parameters   z.1.229   z.2.229   z.1.230   z.2.230   z.1.231   z.2.231  \\\n",
       "draws                                                                    \n",
       "0           0.466806 -0.109665 -0.571703 -1.814963 -1.455457  0.395886   \n",
       "1           1.646032 -0.393141 -0.778745 -1.511284 -2.513872 -0.379097   \n",
       "2           0.983079 -0.690330 -0.434836 -0.608055 -0.424472 -2.100685   \n",
       "3           0.573586 -0.172829 -0.757809 -1.274483 -1.888483 -0.874226   \n",
       "4           1.287025  0.983148 -1.228409 -0.416436 -1.513315 -1.700213   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.973307 -0.775476 -1.410603 -3.638368 -1.882796  1.172944   \n",
       "7996        0.627709  0.297980 -1.638036 -1.659034 -0.935066 -0.128931   \n",
       "7997        1.738789 -1.081498 -0.341102 -2.386888 -1.641152  1.276184   \n",
       "7998        0.516725  0.792697 -0.790422 -1.760003 -1.501593 -1.733025   \n",
       "7999        1.017589  0.704699 -1.700592  0.515187 -0.747152 -1.771321   \n",
       "\n",
       "parameters   z.1.232   z.2.232   z.1.233   z.2.233   z.1.234   z.2.234  \\\n",
       "draws                                                                    \n",
       "0          -1.247855 -1.368274 -0.090387 -0.547681  0.563610  0.085771   \n",
       "1          -0.138979 -0.681795 -0.718249  0.812110  0.863742 -1.033062   \n",
       "2           0.020218 -0.934597 -0.960235  0.008960  0.051111  0.378809   \n",
       "3          -0.512385 -0.164714 -0.795544 -0.580163 -0.118204  0.471488   \n",
       "4           0.179024 -0.056641 -1.682862  1.315415  0.459968 -0.860687   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.375541  0.627113 -0.326476  0.925597  0.350290 -1.334499   \n",
       "7996       -0.391013  0.439912 -0.538392 -0.168932  0.436978 -1.107113   \n",
       "7997       -0.725222  0.291262 -0.070774  0.696829  0.421438  1.195706   \n",
       "7998       -0.542215 -1.383063 -1.090096 -0.669537  0.406426  0.161907   \n",
       "7999        1.161145 -0.268552 -0.401139 -0.251150  0.603337  0.046464   \n",
       "\n",
       "parameters   z.1.235   z.2.235   z.1.236   z.2.236   z.1.237   z.2.237  \\\n",
       "draws                                                                    \n",
       "0           0.145211  0.989378 -0.444949  1.129208  0.085336  0.373794   \n",
       "1          -0.008440  1.877719 -0.732319 -1.096513  0.924446 -0.178373   \n",
       "2           0.234517 -0.389450 -1.099462  1.406926  0.206169 -0.179828   \n",
       "3           0.862001  0.872008  0.387048 -0.591753  1.250002 -0.675579   \n",
       "4           1.114685 -0.318541 -0.676480 -0.614642  1.028749 -0.129637   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.158525  0.196728 -0.741670  0.866594  0.963809 -0.469244   \n",
       "7996       -0.035451  0.351214 -1.806823  0.989469  0.344223 -0.477662   \n",
       "7997        0.818134 -0.332315 -0.800306 -0.232420  0.654312 -0.505913   \n",
       "7998        0.589573 -0.154162 -1.598715  0.783966  0.203730 -0.558706   \n",
       "7999       -0.139369 -0.014860 -1.569516 -0.548250  0.612693  1.315784   \n",
       "\n",
       "parameters   z.1.238   z.2.238   z.1.239   z.2.239   z.1.240   z.2.240  \\\n",
       "draws                                                                    \n",
       "0          -1.108464  0.683629 -0.615402  0.244323  0.408857 -0.108795   \n",
       "1           0.336057 -0.162994  0.262525  1.388979  0.007126  0.356189   \n",
       "2          -0.648036  1.410921 -0.404205  0.916267  0.091081  1.091886   \n",
       "3           0.218131 -0.124039 -0.609615  0.247457  0.781949  0.462511   \n",
       "4           0.357023  0.411200  0.290544  0.541237 -0.679540  2.052404   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.067686 -1.129254  0.535855  0.666599  0.686998  0.564275   \n",
       "7996       -0.066688  0.384417  0.145089 -0.255522  0.440796  0.101217   \n",
       "7997       -0.207640  0.702062  0.471600 -0.508543  0.092716  0.555971   \n",
       "7998       -0.220178 -0.434650 -0.137269 -0.433743  0.682797  0.409113   \n",
       "7999       -2.112829  0.278851 -0.128415  0.030782  0.214230  0.368063   \n",
       "\n",
       "parameters   z.1.241   z.2.241   z.1.242   z.2.242   z.1.243   z.2.243  \\\n",
       "draws                                                                    \n",
       "0          -0.243651  0.462552 -0.533178 -2.039531 -0.713953  1.175128   \n",
       "1           0.217826 -0.309193  0.303724 -0.264035  0.276895  0.897497   \n",
       "2           0.810037 -0.812652 -1.053037  0.297415  0.052266  0.422678   \n",
       "3          -0.586910  1.141393 -1.233994 -1.351729  0.459993 -0.367312   \n",
       "4           0.604984 -0.050366 -1.340168  1.629408  0.168874  0.014169   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.308418 -1.396716 -0.437832  0.079933  0.360537  0.292971   \n",
       "7996        0.539149 -1.155940 -0.833961  0.287103 -0.291243  1.403322   \n",
       "7997        0.450542 -0.401951 -0.843721 -0.637528 -0.087800  0.925674   \n",
       "7998       -0.097499  1.170121 -0.103542  0.215882 -0.312999 -0.706021   \n",
       "7999       -0.359224  1.637869 -1.261576  0.386654  0.549211  0.538989   \n",
       "\n",
       "parameters   z.1.244   z.2.244   z.1.245   z.2.245   z.1.246   z.2.246  \\\n",
       "draws                                                                    \n",
       "0          -0.762853 -1.074885 -1.638510 -0.322943  2.306729  1.017136   \n",
       "1           0.544454 -1.878713 -2.843090  0.195806  2.322523  0.452795   \n",
       "2          -0.620484 -0.025156 -2.799254  1.284142  1.772670  0.980446   \n",
       "3          -1.120764  1.358222 -2.305675  0.650903  2.832756  1.069020   \n",
       "4           0.182089  0.318462 -1.112054  0.294766  1.999570  1.081604   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.116028 -0.894167 -0.397535 -1.844476  1.590235  1.005100   \n",
       "7996       -1.127266 -1.200699 -2.315492 -0.236222  2.007709  1.149008   \n",
       "7997        0.838143 -1.542975 -0.438723  0.608588  1.762849  1.192745   \n",
       "7998       -1.115671  0.062866 -1.420490 -0.747259  2.034692  0.897575   \n",
       "7999       -0.444763  0.629904 -2.131197  0.736745  2.312745  0.906142   \n",
       "\n",
       "parameters   z.1.247   z.2.247   z.1.248   z.2.248   z.1.249   z.2.249  \\\n",
       "draws                                                                    \n",
       "0          -0.460609  1.093187 -1.070493  1.089439 -0.084093  1.913826   \n",
       "1           0.306323  0.600361 -0.647861 -0.531207 -0.280747 -1.104201   \n",
       "2          -0.958395  1.383803 -0.607795  0.697924 -1.020350 -0.015639   \n",
       "3          -0.357712  0.553850 -0.793237  0.178772  0.386098 -1.071301   \n",
       "4          -0.468836  1.078398 -0.179065 -0.468040 -0.259917 -2.818806   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.479105 -0.022247 -0.094020  0.192301 -0.595798 -0.719045   \n",
       "7996       -0.216890  0.025507  0.065379  0.025691 -0.637307 -1.765990   \n",
       "7997       -0.407296 -1.340445 -0.303574  0.352191 -0.437060 -0.417015   \n",
       "7998       -0.257355  1.160356 -0.767375  0.880113  0.042233 -1.248645   \n",
       "7999       -0.119511  0.451170 -0.018734  0.163278 -0.121093 -0.136882   \n",
       "\n",
       "parameters   z.1.250   z.2.250   z.1.251   z.2.251   z.1.252   z.2.252  \\\n",
       "draws                                                                    \n",
       "0           0.348161  0.237829  1.075346  0.625004  1.178419 -0.916089   \n",
       "1           0.806677 -0.793322  0.871006  0.898156  1.433423 -0.872420   \n",
       "2           0.229310  0.642308  0.950967  0.479462  0.776310 -0.130608   \n",
       "3          -0.083966  1.067161  0.810650  0.647335  0.676572  1.658786   \n",
       "4           0.613847  0.220184  0.965255  0.236702  0.179985  0.842887   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.110420  0.415970  0.192198  1.908867 -0.212232  1.695208   \n",
       "7996        0.819612 -0.673463  0.893520 -0.322952  1.084269 -0.838756   \n",
       "7997       -0.743630  1.421361  0.599395  0.737444  0.194268  0.144520   \n",
       "7998        0.645034  0.914156  1.200565 -0.211043  0.570824  0.395849   \n",
       "7999        0.903745 -0.101422  2.128245 -1.362926  1.157047 -1.761911   \n",
       "\n",
       "parameters   z.1.253   z.2.253   z.1.254   z.2.254   z.1.255   z.2.255  \\\n",
       "draws                                                                    \n",
       "0          -0.121834 -1.027177  0.562374  0.784724 -0.007590  0.840861   \n",
       "1          -0.232187 -0.083297  0.093483 -0.039666 -0.349354  0.560424   \n",
       "2          -0.704579  0.762597 -0.776734  0.065111 -0.386332  0.112796   \n",
       "3          -0.131825 -0.846245 -0.099016 -0.569132  0.168716 -0.161406   \n",
       "4          -1.162737 -0.175657 -0.856963 -0.002652 -0.256250  0.294449   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.375671 -1.039667 -0.071945 -0.259404 -0.311296  1.177409   \n",
       "7996       -1.634543 -0.205709 -0.880008 -0.212725  0.638357 -1.086961   \n",
       "7997       -1.956624 -1.339995  0.781010 -0.449250 -0.762302 -0.623648   \n",
       "7998       -1.078518 -0.839751 -0.357005  1.161223  0.024166 -0.612974   \n",
       "7999       -0.498332  0.858829 -0.334365  0.345017 -0.216210 -0.204819   \n",
       "\n",
       "parameters   z.1.256   z.2.256   z.1.257   z.2.257   z.1.258   z.2.258  \\\n",
       "draws                                                                    \n",
       "0           0.391231 -0.550165  0.681499  1.176131  1.432658  0.147938   \n",
       "1          -0.952093 -1.138840 -0.172878  0.281017  0.504794 -0.093700   \n",
       "2           0.256450 -1.307405  0.128079 -0.428751  0.590734 -0.151886   \n",
       "3           0.225184  0.497932  1.227320 -0.014663  0.828610  0.198026   \n",
       "4          -0.046434 -0.112443  0.156580  0.067023 -0.613286  0.424840   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.381267 -0.204936  0.440749  1.140490  0.325559  1.193637   \n",
       "7996       -0.581592 -0.441600 -0.252946  0.263518  0.423076 -0.316567   \n",
       "7997       -0.919502 -0.312337  0.848386  0.723560  0.761398  0.527249   \n",
       "7998       -0.097271 -0.609567 -0.158096  1.694520  0.981647  1.073253   \n",
       "7999       -0.279132 -0.302813  0.463054  0.162822  0.591432  0.051485   \n",
       "\n",
       "parameters   z.1.259   z.2.259   z.1.260   z.2.260   z.1.261   z.2.261  \\\n",
       "draws                                                                    \n",
       "0          -0.299009  0.179229  0.158094  2.042774 -0.646161  2.643519   \n",
       "1          -0.015784  0.578468  1.049017  0.615702 -0.988660  0.843067   \n",
       "2           0.412937 -0.167005  1.051520  0.750296 -0.009801  0.379676   \n",
       "3           1.236628 -0.907020  0.818787  1.075956  0.535393  1.558724   \n",
       "4           0.752702 -1.194433  0.016588  1.994057  0.840764  0.364958   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.370672  0.200354  1.304703  0.426546  0.016582 -0.532798   \n",
       "7996       -0.401965  0.813574  0.874442  0.690837  0.019112  0.573135   \n",
       "7997        0.127949 -0.626320  0.467841  1.522530  0.651665  0.044173   \n",
       "7998       -0.189001  1.510972  0.658110  1.512686  1.117440 -0.953309   \n",
       "7999        0.472255  0.023587  0.540872  1.319473 -0.767702  1.553380   \n",
       "\n",
       "parameters   z.1.262   z.2.262   z.1.263   z.2.263   z.1.264   z.2.264  \\\n",
       "draws                                                                    \n",
       "0           0.441437  0.575083 -0.424986 -0.060793  0.421211 -1.303775   \n",
       "1          -0.051253  1.755931 -0.622006  0.980958 -0.465890  0.543176   \n",
       "2          -0.423180  1.066256 -0.685271 -0.347575 -0.279267 -1.335536   \n",
       "3           0.719315 -0.451938 -0.970884  1.504297 -0.547936 -0.259178   \n",
       "4           0.413713  0.292042 -0.335081  0.484873 -0.329836  1.119952   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.213759  1.000327 -0.836702 -0.025703 -0.398938 -1.270004   \n",
       "7996        1.354777 -1.544929 -0.886890  0.450444 -1.533121  0.365734   \n",
       "7997        0.247796 -0.901564 -0.580486  1.718071 -0.733565 -0.252685   \n",
       "7998       -0.547964 -0.622197 -0.948518  0.663267  0.325001 -1.127563   \n",
       "7999        0.802153 -0.488153 -0.959591 -0.589164 -0.240999  0.707993   \n",
       "\n",
       "parameters   z.1.265   z.2.265   z.1.266   z.2.266   z.1.267   z.2.267  \\\n",
       "draws                                                                    \n",
       "0           0.058181  1.618167  1.012304  1.954381 -0.201758  1.133942   \n",
       "1           0.660120 -0.283653  0.531581  1.397366 -0.176482  1.610705   \n",
       "2           0.609899 -0.495841  0.593815  0.815143  0.946898  0.021333   \n",
       "3           0.787641  0.722499  1.073586  1.253372  1.265875 -0.696305   \n",
       "4           1.081773 -1.742862  1.042681  0.536760  0.906130 -0.273998   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.334919 -0.696158  0.990074 -0.176205  0.728910  1.382891   \n",
       "7996        0.585115 -0.533361  0.751649  0.852503  0.632852  0.321781   \n",
       "7997        0.278499 -0.401694  1.004687  0.702079  0.438185  1.347507   \n",
       "7998       -0.902593  0.672022  1.444596  0.983530 -0.104268  2.206342   \n",
       "7999        0.160263  0.116072  0.691553  1.399700  0.957316 -0.531733   \n",
       "\n",
       "parameters   z.1.268   z.2.268   z.1.269   z.2.269   z.1.270   z.2.270  \\\n",
       "draws                                                                    \n",
       "0          -0.857608  2.361891  1.373045  0.498801 -0.401383 -1.235380   \n",
       "1           0.088528 -0.175157  1.334912 -0.239708 -0.586957 -0.198358   \n",
       "2          -0.016392  0.302775  0.934820  1.870012 -0.329719  0.300999   \n",
       "3          -0.363185  0.429031  1.117184  1.201860 -0.140075 -1.063485   \n",
       "4           1.092537 -1.301619  0.908740  1.389195 -0.782242  0.122848   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.358496 -0.736983  0.443725  2.087483 -0.342266 -1.108642   \n",
       "7996        0.354586 -0.263692  1.970611  0.089999 -0.704449  1.004763   \n",
       "7997        0.141892 -1.365090  1.097420  1.298756 -0.854144 -1.929992   \n",
       "7998        0.425900  0.110014  1.735063 -0.044940 -1.054074  0.408526   \n",
       "7999       -0.359155  0.764543  1.671533 -0.417895 -0.586414  0.010057   \n",
       "\n",
       "parameters   z.1.271   z.2.271   z.1.272   z.2.272   z.1.273   z.2.273  \\\n",
       "draws                                                                    \n",
       "0           0.428421  1.323584  0.405822  0.942658 -0.138024  0.268988   \n",
       "1           1.129805 -0.245695 -0.535657  1.013168  0.875010 -1.254255   \n",
       "2           0.334733  1.278774 -1.068891 -1.265800  0.880380 -1.677525   \n",
       "3           0.170880  0.550350 -0.178869  0.055004 -0.158383  0.316424   \n",
       "4           0.807822 -0.011608 -0.739058 -1.579089  0.348236 -0.493016   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.700594  0.300006  0.165156 -1.559318 -0.073724 -1.701669   \n",
       "7996        0.660697  0.870158 -0.168570 -2.369758  0.617121 -2.885632   \n",
       "7997        0.488976 -0.209868 -1.393670  1.048011  0.674210 -2.023455   \n",
       "7998        1.056725 -0.423049 -0.341425 -2.039501  0.703974 -0.394638   \n",
       "7999        0.707935 -0.137830 -1.762182  0.192378 -0.264837  0.577119   \n",
       "\n",
       "parameters   z.1.274   z.2.274   z.1.275   z.2.275   z.1.276   z.2.276  \\\n",
       "draws                                                                    \n",
       "0          -1.314127  0.826033  2.160101  0.209759 -1.542430 -1.264669   \n",
       "1          -0.836622 -1.663900  2.822336 -0.639772 -0.086349  0.876283   \n",
       "2           1.093640 -0.385379  2.538488  0.784056 -0.267945 -0.182904   \n",
       "3           0.290799 -0.623618  2.598997  1.073300  0.630356  0.689101   \n",
       "4           0.575670 -2.703362  2.546202  0.504383  0.278097 -0.760029   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.690037  0.414104  3.115894  0.405025  0.254671  0.156077   \n",
       "7996        0.920776  0.323713  2.394321  1.554342 -0.864331  0.099196   \n",
       "7997       -0.278525  0.642006  2.293807  1.022229  1.044840 -1.635892   \n",
       "7998        0.716357 -0.519693  2.720093  0.911327 -0.827245  0.239297   \n",
       "7999        0.694032 -0.779780  2.351233  0.673321  0.031905  0.241396   \n",
       "\n",
       "parameters   z.1.277   z.2.277   z.1.278   z.2.278   z.1.279   z.2.279  \\\n",
       "draws                                                                    \n",
       "0           0.093430  0.147259  0.924504  0.067851 -0.384478 -0.264944   \n",
       "1          -1.914034  0.271241  0.291514  0.654012 -0.192508 -1.460688   \n",
       "2          -0.511911 -0.147752  0.734731 -0.000308 -1.557591  1.533074   \n",
       "3          -0.183603 -1.017696  1.019354  1.387370 -0.630696 -0.588749   \n",
       "4          -0.443575 -2.825268  1.357040  0.697337 -0.225871 -0.159475   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.203942 -0.211834  0.886861  0.129278 -0.252172 -0.055122   \n",
       "7996       -0.425443 -1.491097  0.581486  1.000219 -0.728757 -1.110799   \n",
       "7997        0.229693 -1.174964  0.786642  1.949829 -1.860060  1.155555   \n",
       "7998       -1.789863 -1.445927  0.640736  1.958144 -0.428607 -0.505283   \n",
       "7999       -1.191747 -0.043301  0.547934 -0.015136 -0.315675  0.115192   \n",
       "\n",
       "parameters   z.1.280   z.2.280   z.1.281   z.2.281   z.1.282   z.2.282  \\\n",
       "draws                                                                    \n",
       "0           0.059454  1.899268  0.800016  0.643279  1.854994  0.560486   \n",
       "1           0.317220  0.989637  0.841708 -0.070195  1.747652  0.163938   \n",
       "2          -0.068991  2.890663  0.745933  0.097765  1.422909  0.609237   \n",
       "3           0.495696  1.061598  1.526201 -1.052216  1.569018 -0.129039   \n",
       "4           0.183501  0.505265  1.094177 -1.112240  1.591243 -0.018674   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.262887  0.533767  1.771051 -0.013550  1.451406 -0.058412   \n",
       "7996        1.009554  0.449013  1.211449 -0.461054  2.098341 -0.602972   \n",
       "7997        0.442130  2.500341  1.095743  0.526430  2.001278  0.699613   \n",
       "7998        0.332040  2.017696  1.458239  0.250104  2.052971 -0.340422   \n",
       "7999        0.460418  2.061263  0.893651  0.119003  1.742773  0.715230   \n",
       "\n",
       "parameters   z.1.283   z.2.283   z.1.284   z.2.284   z.1.285   z.2.285  \\\n",
       "draws                                                                    \n",
       "0          -0.808894  0.453711 -0.421325  0.466425  0.716427  0.733540   \n",
       "1          -0.191805  0.662206 -1.128978  0.599339  1.037551  0.716601   \n",
       "2          -0.187450  0.350478 -0.193836  0.466069 -0.311532  0.002470   \n",
       "3          -0.560663 -0.151458  0.392602 -1.219229  0.246292 -1.075527   \n",
       "4          -1.651850 -0.163068  0.159345 -1.536314 -0.162778  0.502315   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.583447  0.726685  0.330361 -0.513667  0.073637 -0.690162   \n",
       "7996       -0.870070 -1.789200 -0.147982  0.219806  0.713491 -0.116881   \n",
       "7997       -0.574228  1.328853 -0.440579  0.015606  0.091197 -0.316332   \n",
       "7998       -0.670429 -0.342517  0.399839 -1.467299  0.477283  0.024499   \n",
       "7999        0.332636  0.097790 -0.316208 -0.180232  0.391625  0.831131   \n",
       "\n",
       "parameters   z.1.286   z.2.286   z.1.287   z.2.287   z.1.288   z.2.288  \\\n",
       "draws                                                                    \n",
       "0           0.279733 -0.807705 -1.196004  0.116112 -0.097709 -0.060753   \n",
       "1           0.549227  0.545540 -0.212931 -0.485441  0.374575  1.179519   \n",
       "2           1.274218 -1.105257 -0.226131 -1.284584  1.455893 -1.024499   \n",
       "3           0.637531  0.695340  0.643347 -0.232398  0.506610  0.323395   \n",
       "4           0.743246  0.422530  0.048744  0.828291  0.249841  0.763714   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.654467 -0.111805  0.142819  0.671254  0.369632  0.967312   \n",
       "7996        0.956688  0.618796  0.802726 -0.119150 -0.275146  1.384049   \n",
       "7997        0.543587  0.862026 -0.111124  0.592892  0.468751  0.295554   \n",
       "7998        0.790493  0.027193  0.651682  0.430207 -0.711643  0.821332   \n",
       "7999        0.555874  0.317654  0.012643  0.848737  0.750065 -0.025215   \n",
       "\n",
       "parameters   z.1.289   z.2.289   z.1.290   z.2.290   z.1.291   z.2.291  \\\n",
       "draws                                                                    \n",
       "0           0.224051 -2.115554 -1.622363  0.107560  0.774984  0.393429   \n",
       "1           0.734138  1.328872 -1.108271  0.820515  0.874072  0.677977   \n",
       "2           1.037440 -0.814616 -0.682827 -0.291145  1.492311 -0.383265   \n",
       "3           0.410212  0.508741 -1.738624 -0.066920  1.195792 -0.942897   \n",
       "4           1.350901  1.846830 -1.547625 -0.014038  0.967586 -0.060688   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.374435 -0.874151 -1.144225  1.019966  1.018998  1.117493   \n",
       "7996        1.442437 -0.450161 -1.955015  0.059045  1.973306 -1.849791   \n",
       "7997        0.987141 -0.090093 -1.848511  0.684543  1.348099 -0.692253   \n",
       "7998        1.152101 -0.827455 -1.646252  1.192287  1.409831 -1.150681   \n",
       "7999        0.692848  1.258413 -1.504180 -0.398196  1.009436 -0.232500   \n",
       "\n",
       "parameters   z.1.292   z.2.292   z.1.293   z.2.293   z.1.294   z.2.294  \\\n",
       "draws                                                                    \n",
       "0           0.072614 -1.813051 -1.882276  0.081769  0.084141  0.159880   \n",
       "1           0.088330  0.028556 -1.018966 -0.846479 -0.256766 -1.759974   \n",
       "2           0.804124 -0.817560 -1.787894 -0.421822  0.190112  0.600203   \n",
       "3           0.280506 -1.369278 -2.476761 -0.089866 -0.258388 -1.021006   \n",
       "4          -0.072154 -0.959703 -1.833566 -0.045371 -0.208809  0.174372   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.086630 -1.995437 -1.221640 -0.795003  0.477054  1.819049   \n",
       "7996        0.494718 -2.492603 -1.170297 -0.483610  0.146898 -0.759364   \n",
       "7997        0.253229 -1.422510 -2.037156 -0.701889 -0.300033  1.998114   \n",
       "7998        0.074427 -1.843403 -2.016044 -1.041591  0.183752  0.773143   \n",
       "7999        0.469581 -1.141193 -1.744912 -0.994475  0.213869 -0.469427   \n",
       "\n",
       "parameters   z.1.295   z.2.295   z.1.296   z.2.296   z.1.297   z.2.297  \\\n",
       "draws                                                                    \n",
       "0          -0.748036 -0.764569 -1.022217 -0.460769 -0.640573 -0.477693   \n",
       "1          -1.034167  0.206706 -0.663623 -0.122557 -0.983829  0.207802   \n",
       "2          -0.674290 -1.531854 -0.870796 -0.198345 -0.324021 -0.943876   \n",
       "3          -0.985414 -0.908527 -2.107126  0.246224 -1.462594  0.743746   \n",
       "4          -1.104280 -0.709082 -1.064152  1.055789 -0.500776  0.146946   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.504848 -0.521066 -2.085869  0.362313 -0.447498 -0.529677   \n",
       "7996       -0.336091  0.926268 -1.611962  1.832074  0.465896 -1.188417   \n",
       "7997        0.035517 -1.509244 -0.812803  0.702133 -0.564444  0.341874   \n",
       "7998       -0.606398 -0.710955 -1.961302  0.126126 -0.738659  0.137407   \n",
       "7999       -0.125585 -0.286840  0.103529 -0.028133 -0.243528  0.230339   \n",
       "\n",
       "parameters   z.1.298   z.2.298   z.1.299   z.2.299   z.1.300   z.2.300  \\\n",
       "draws                                                                    \n",
       "0          -0.387916  0.388673 -0.369864  0.084240  0.153006 -0.862092   \n",
       "1          -0.575686 -1.349441  0.060267 -1.117551  0.033058 -0.093888   \n",
       "2          -0.085068  0.724013  0.115212 -0.850596 -0.075968  0.834294   \n",
       "3          -1.582374 -0.581092 -0.275418 -0.199287 -0.565434  0.026105   \n",
       "4          -1.076277 -0.809873 -0.450995 -0.910374 -0.151399  0.038161   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.112675 -0.968909 -0.345379 -0.906018  0.320371 -0.838569   \n",
       "7996       -1.108075  0.667061  0.209503  0.549506  0.688728 -0.834518   \n",
       "7997       -0.654984  0.691311 -0.601548 -0.598587 -0.261288  1.343921   \n",
       "7998       -0.816052  0.154895 -0.305983 -0.632948 -0.228820 -1.603944   \n",
       "7999       -0.630239  0.173625  0.297307  0.109020 -1.023336  0.470630   \n",
       "\n",
       "parameters  L_Rho_d.1.1  L_Rho_d.2.1  L_Rho_d.1.2  L_Rho_d.2.2   sigma_d  \\\n",
       "draws                                                                      \n",
       "0                   1.0     0.865404          0.0     0.501076  1.174641   \n",
       "1                   1.0     0.906667          0.0     0.421847  1.114294   \n",
       "2                   1.0     0.893535          0.0     0.448993  1.156236   \n",
       "3                   1.0     0.859748          0.0     0.510719  1.094353   \n",
       "4                   1.0     0.799363          0.0     0.600848  1.043099   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "7995                1.0     0.900839          0.0     0.434153  1.206081   \n",
       "7996                1.0     0.860271          0.0     0.509838  1.090496   \n",
       "7997                1.0     0.898567          0.0     0.438836  1.108480   \n",
       "7998                1.0     0.864132          0.0     0.503265  1.055216   \n",
       "7999                1.0     0.909428          0.0     0.415861  1.097247   \n",
       "\n",
       "parameters     d.1.1     d.2.1     d.3.1     d.4.1     d.5.1     d.6.1  \\\n",
       "draws                                                                    \n",
       "0          -0.478953  0.875701  0.309198 -0.375399  0.997592  0.280467   \n",
       "1           0.036160  1.586232  0.741627 -0.276257  0.947406  0.168759   \n",
       "2          -0.552507  1.093119  1.248176  1.056411  0.915834  0.842251   \n",
       "3          -0.312019  1.809019  1.009801  1.107113  1.452863 -1.183948   \n",
       "4          -1.081659  2.269201  0.151023  0.839087  1.214566 -0.045623   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.150773  2.405000  2.109957  0.795794  1.860197  1.422438   \n",
       "7996        0.382982  2.793897  0.846967  0.132354  1.167981  0.305179   \n",
       "7997        0.113134  1.665523 -0.587537 -0.151735  1.155895  0.397038   \n",
       "7998       -0.518664  1.225518  0.668813  0.417296  1.689538 -0.159956   \n",
       "7999        0.190747  2.119945  0.494289  0.305819  1.060821 -0.487754   \n",
       "\n",
       "parameters     d.7.1     d.8.1     d.9.1    d.10.1    d.11.1    d.12.1  \\\n",
       "draws                                                                    \n",
       "0           1.030238 -1.233445  2.654795 -0.564744  0.584026 -1.401375   \n",
       "1          -0.175637 -1.270199  2.651583 -1.486119 -1.176287  0.532095   \n",
       "2           0.010028 -0.988465  2.712124 -0.589233 -0.211123 -1.628166   \n",
       "3          -1.351732 -0.632658  2.320406 -0.657594 -0.788541 -0.860385   \n",
       "4          -2.068249 -0.934238  2.315075 -0.670333 -3.209839  0.171181   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.186060 -1.208392  3.726376 -1.124753 -0.374307 -0.941007   \n",
       "7996        0.388728 -1.534211  2.310061  0.614302 -2.551058 -0.798606   \n",
       "7997       -0.488162 -0.985494  2.455298 -0.928513 -1.730851 -0.444086   \n",
       "7998        0.171020 -1.103811  2.834835 -0.382619 -0.160303 -0.503625   \n",
       "7999        0.878551 -0.882648  2.249404 -0.085522 -0.960362  1.050887   \n",
       "\n",
       "parameters    d.13.1    d.14.1    d.15.1    d.16.1    d.17.1    d.18.1  \\\n",
       "draws                                                                    \n",
       "0           0.381137  1.129046 -0.146075 -1.745127 -1.967229 -0.367542   \n",
       "1           0.645940 -0.043432 -0.624553 -0.544947 -1.709282 -0.406287   \n",
       "2           1.182411  1.335540 -0.323282 -1.722648 -1.726245 -2.050372   \n",
       "3           0.744565  1.149802  0.087778 -0.468541 -0.489200 -1.872676   \n",
       "4           0.767993  0.620708 -1.586270 -0.597569 -0.830820 -1.010600   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.069548  0.607620 -1.299383 -1.150289 -1.456446 -0.104901   \n",
       "7996        0.463448  0.882501 -1.573618 -0.851047 -1.084885 -0.810110   \n",
       "7997        0.452772 -0.091761 -1.375290  0.225321 -1.474144 -1.163356   \n",
       "7998        0.424668  1.282233 -1.616203 -0.060024 -0.768009  0.018385   \n",
       "7999        0.276515  0.545120 -1.250764 -0.429876 -0.898322 -0.839170   \n",
       "\n",
       "parameters    d.19.1    d.20.1    d.21.1    d.22.1    d.23.1    d.24.1  \\\n",
       "draws                                                                    \n",
       "0          -2.054934 -0.879806 -1.393074 -0.345328 -1.245138  2.281077   \n",
       "1          -1.897005  0.155644 -0.039408  0.465143 -0.961667  2.964271   \n",
       "2          -1.514044 -0.748433 -5.069778  0.964486 -2.466216  2.260763   \n",
       "3           0.180357  0.273141 -1.993020  0.049188 -1.010092  1.703399   \n",
       "4          -1.868653  0.467470 -0.843680  0.908044 -1.652141  2.306828   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.764054 -0.709223 -0.684062  0.626020 -0.205188  2.997497   \n",
       "7996       -2.591259  0.059844 -3.109939 -0.469837 -1.521249  2.536310   \n",
       "7997       -2.002357 -0.580123 -1.992514  0.641199 -1.010715  1.634793   \n",
       "7998       -1.074184 -0.193439 -0.562675 -0.488265 -1.680129  2.806794   \n",
       "7999       -1.578071  0.498339 -1.419257  1.159922 -1.075122  2.084774   \n",
       "\n",
       "parameters    d.25.1    d.26.1    d.27.1    d.28.1    d.29.1    d.30.1  \\\n",
       "draws                                                                    \n",
       "0           0.079562  0.063589 -2.385680 -0.079076 -2.467246  2.691009   \n",
       "1          -1.440884 -0.365272 -0.432355 -1.046878 -0.814333  2.280711   \n",
       "2          -0.141619  0.663809 -0.974260 -0.557925 -0.336950  2.287006   \n",
       "3          -1.165383 -0.112122 -0.398553 -0.726536 -1.212188  2.841629   \n",
       "4          -0.765707 -0.744988 -0.285193 -0.279578  0.222148  2.782015   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.584322  0.107091 -0.817427 -0.402662 -0.217559  3.208972   \n",
       "7996        0.186560  0.205385  0.222748 -0.603589 -0.575406  2.653175   \n",
       "7997       -1.146559 -0.272275 -0.249132  0.059248 -1.430438  2.213955   \n",
       "7998       -0.005473  0.315566 -0.649502  1.253290 -0.407769  2.883094   \n",
       "7999       -1.186197 -0.156135 -0.599706 -1.004679 -0.699753  2.458900   \n",
       "\n",
       "parameters    d.31.1    d.32.1    d.33.1    d.34.1    d.35.1    d.36.1  \\\n",
       "draws                                                                    \n",
       "0           1.175903 -0.929365 -1.170327 -1.225601 -0.434519 -1.903577   \n",
       "1           0.213543 -1.396501 -0.265699  0.154761 -0.481439 -0.329492   \n",
       "2           1.250679 -1.450120 -1.764366 -1.983956 -1.332678 -1.524334   \n",
       "3          -0.105991 -0.145868 -0.722964 -1.367744  0.030395 -1.948798   \n",
       "4          -0.061319 -1.718825 -0.389709 -0.974627 -0.765927 -0.434989   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.936535 -2.353572 -1.043239 -0.395480 -0.756785 -0.633285   \n",
       "7996        0.656274 -0.784623 -2.313053 -0.462348 -1.157040 -0.760399   \n",
       "7997        0.953743 -1.816524 -1.916159 -0.621611 -0.181570 -0.926989   \n",
       "7998        1.800483 -2.366929 -1.048119 -1.419479 -0.300554 -1.646790   \n",
       "7999        0.243475 -0.283325 -1.282677 -1.336366 -0.157892 -1.337802   \n",
       "\n",
       "parameters    d.37.1    d.38.1    d.39.1    d.40.1    d.41.1    d.42.1  \\\n",
       "draws                                                                    \n",
       "0           0.450214  0.305983  2.611876 -1.276234  1.530870 -0.456919   \n",
       "1          -0.258608  0.218621  1.822336 -0.903834  1.192110 -0.242208   \n",
       "2          -1.166429  0.632321  1.982091  0.337840  0.510165  0.565084   \n",
       "3           0.000551  0.679217  2.045087  0.103380  1.108289 -0.411600   \n",
       "4          -1.124765  0.160699  2.108156  0.421185  0.036311 -0.946611   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.619825  0.808968  2.700574  0.961883  1.883774  0.921742   \n",
       "7996       -0.733150 -0.364009  1.931041  0.282110  1.464423  0.472973   \n",
       "7997       -0.372559 -0.135151  1.861338 -0.319816  1.530980 -0.661857   \n",
       "7998       -0.097446 -0.082528  2.186205  0.367116  1.098691  0.784042   \n",
       "7999       -0.469881 -0.130940  1.537444 -0.307948  0.869933 -0.798872   \n",
       "\n",
       "parameters    d.43.1    d.44.1    d.45.1    d.46.1    d.47.1    d.48.1  \\\n",
       "draws                                                                    \n",
       "0          -1.720361  1.967160  0.652061  0.489523 -0.847354  0.350949   \n",
       "1          -1.502716  2.157794 -0.398110  1.113703 -1.930332  0.254808   \n",
       "2          -0.797448  2.108223  0.729659  0.702204 -1.599895  0.638929   \n",
       "3          -0.942090  2.187644 -0.324643  1.392549 -0.321902 -0.052057   \n",
       "4          -0.318332  2.276379  0.409820  0.620247 -0.350930  0.226575   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.448055  2.020965  0.177011  0.868984 -0.961136  0.330802   \n",
       "7996        0.375819  2.848992  0.289920  1.562910 -2.093618  0.436995   \n",
       "7997       -0.852049  2.283172  0.339733  1.165587 -1.885656  0.175949   \n",
       "7998        0.254156  2.439126  0.516438  0.749158 -0.390857  0.681974   \n",
       "7999       -0.976847  1.992207  0.189840  0.275615 -1.875514 -0.151722   \n",
       "\n",
       "parameters    d.49.1    d.50.1    d.51.1    d.52.1    d.53.1    d.54.1  \\\n",
       "draws                                                                    \n",
       "0           1.027575  1.819114  0.141461 -0.249152 -2.846906 -0.024646   \n",
       "1           0.980036  1.426851 -1.101757 -1.535853 -1.416625 -1.017160   \n",
       "2           1.293899  1.326501  0.033384 -1.767305 -2.983836  0.169207   \n",
       "3           1.136178  1.457374 -0.536954 -0.588722 -1.440589 -1.469241   \n",
       "4           0.793988  1.412545 -0.421745 -1.278911 -0.730188 -0.307353   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.564309  1.625489 -0.281779 -0.715430 -1.958948  0.447220   \n",
       "7996        1.144465  1.737741  0.672496 -0.453596 -1.644011 -0.450641   \n",
       "7997        0.669404  1.515888 -0.875939 -0.374499 -0.517681 -0.264752   \n",
       "7998        0.693667  1.283088 -0.786374 -2.190214 -0.743467 -0.632042   \n",
       "7999        0.782978  1.408595 -0.288523 -2.175964 -1.477517  0.140051   \n",
       "\n",
       "parameters    d.55.1    d.56.1    d.57.1    d.58.1    d.59.1    d.60.1  \\\n",
       "draws                                                                    \n",
       "0           0.031526 -0.121904 -0.101969  0.495524  1.268794 -0.193496   \n",
       "1          -0.139172  0.888480  0.567819  0.198222  1.233408 -0.236852   \n",
       "2           0.715439  0.020186 -0.511613 -0.351076  0.544161 -0.924069   \n",
       "3           0.638125 -0.340409 -0.064015  0.545242  0.811360  0.084726   \n",
       "4           0.670205  0.577972  0.392854  0.749485  1.301764 -0.334947   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.329269  1.169679 -0.000182  0.403721  0.537984 -0.079475   \n",
       "7996        0.106259  1.072424  0.230748  0.531996  0.961556 -0.609904   \n",
       "7997        0.307913  0.263254  0.324921  0.630999  0.118244 -0.119898   \n",
       "7998        0.489364 -0.056654 -0.545288 -0.214183 -0.076751 -1.270818   \n",
       "7999        0.660902 -0.485971  1.060990  0.365056  0.714142 -1.021666   \n",
       "\n",
       "parameters    d.61.1    d.62.1    d.63.1    d.64.1    d.65.1    d.66.1  \\\n",
       "draws                                                                    \n",
       "0           0.596334 -1.902655 -1.213691 -1.275677 -0.702973 -0.913710   \n",
       "1           0.281403 -2.990852 -1.595608  0.239334 -1.840403 -0.037261   \n",
       "2           0.436413 -1.108464 -1.061959  0.074151 -0.881981 -0.628520   \n",
       "3           0.258146 -1.781062 -1.056839 -0.975180 -1.002662 -0.159209   \n",
       "4           0.381931 -1.130474 -0.403871  0.172073 -0.827863 -1.407875   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.648462 -0.506511 -0.274696 -1.112889 -0.444293 -1.437797   \n",
       "7996        0.284160 -1.267019  0.149894  0.125739 -1.367208  0.070759   \n",
       "7997       -0.380293 -3.132735 -0.340577 -1.180606 -0.574477 -0.387386   \n",
       "7998        0.034622 -1.619122 -0.062694 -0.817776 -0.648656 -0.704587   \n",
       "7999        0.519976 -2.221756 -1.465369 -0.308276 -0.559353 -1.442894   \n",
       "\n",
       "parameters    d.67.1    d.68.1    d.69.1    d.70.1    d.71.1    d.72.1  \\\n",
       "draws                                                                    \n",
       "0           1.211168 -0.993981 -0.126219  0.700694  2.924587 -1.515894   \n",
       "1           1.688437 -1.722072  0.198778  0.154268  1.888517 -0.591863   \n",
       "2           1.793255 -1.697145  0.179526  0.419759  2.412240  0.192147   \n",
       "3           1.310240 -0.950637 -0.032809  0.632733  2.595023 -0.006785   \n",
       "4           1.479479 -0.751381  0.192190  0.611820  2.227252 -0.207259   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.970968 -0.130872  0.800040  0.999203  3.181453 -1.009423   \n",
       "7996        1.642407 -0.193618  0.505829  0.936434  2.355306 -0.726254   \n",
       "7997        1.579124 -1.325174 -0.537937 -0.174390  2.161263  0.270691   \n",
       "7998       -0.009421 -0.248973 -0.463548  0.520329  1.894742 -0.401323   \n",
       "7999        1.977017 -0.409804  0.034371  0.378690  2.421183 -0.960381   \n",
       "\n",
       "parameters    d.73.1    d.74.1    d.75.1    d.76.1    d.77.1    d.78.1  \\\n",
       "draws                                                                    \n",
       "0          -1.199134 -2.119498 -0.160644  0.412693  0.907245 -0.989104   \n",
       "1          -1.653421 -2.173859 -0.999959  0.232455  0.116273 -0.129550   \n",
       "2          -1.541924 -0.510223  0.309486  0.836373 -0.580318  0.878997   \n",
       "3          -1.031726 -0.345705  0.965294  0.078679 -0.528294  1.018327   \n",
       "4          -0.783734  0.086940  0.213626 -0.211474 -0.809175  0.923111   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.192768 -0.843526 -0.047717 -1.389858  0.076108  0.417925   \n",
       "7996       -1.130202  0.429852 -0.169420 -0.689256 -0.063951  1.064980   \n",
       "7997       -1.435147 -1.072983 -0.019166 -0.446204  0.684194 -0.087465   \n",
       "7998        0.255256 -1.234262  0.842017 -0.431646  1.201227  1.043972   \n",
       "7999       -1.830275 -1.773434  0.469418  0.374265 -1.017841  0.712897   \n",
       "\n",
       "parameters    d.79.1    d.80.1    d.81.1    d.82.1    d.83.1    d.84.1  \\\n",
       "draws                                                                    \n",
       "0           0.862596  1.711437  2.566690  0.338527 -0.618698 -0.410202   \n",
       "1          -0.279536  0.320817  1.363799 -0.156892 -0.181080 -0.422468   \n",
       "2          -0.392311  1.099507  1.510316  0.179438  0.339868 -0.494070   \n",
       "3           0.801014  0.615615  2.035532  0.295132 -1.341565 -0.121134   \n",
       "4          -1.115564 -1.007413  1.371989 -0.406133 -1.616687 -0.843546   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.194227  0.079506  1.761204 -0.196529 -0.345359  0.167509   \n",
       "7996        0.195184  0.867728  1.758366 -0.753328  1.191124 -1.259730   \n",
       "7997        0.200902  0.137542  1.658322 -0.327585 -1.354566 -0.111411   \n",
       "7998        0.272823  0.407852  1.738688 -0.590641  0.118572 -0.149504   \n",
       "7999       -0.238653  0.376397  1.395878 -0.079229 -0.361021 -0.519781   \n",
       "\n",
       "parameters    d.85.1    d.86.1    d.87.1    d.88.1    d.89.1    d.90.1  \\\n",
       "draws                                                                    \n",
       "0          -1.505585 -0.721272 -0.242957  0.575543  0.059661  0.026040   \n",
       "1          -1.141496 -0.922077 -0.832344  0.749481 -0.594651 -1.088730   \n",
       "2          -1.386567 -0.255034 -0.481221  0.861784 -1.056121  1.176251   \n",
       "3          -0.853633 -0.522866 -0.266665  0.227051  0.250623 -0.362570   \n",
       "4          -1.097504 -0.936119 -1.316315 -0.220954 -1.015166 -0.493313   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.856075 -0.480276 -0.595143  1.359228  0.095918 -0.774653   \n",
       "7996       -0.560915 -0.242180 -2.075988  1.090943  0.152430 -0.650759   \n",
       "7997       -0.204307 -0.297183 -1.012435  0.705592 -0.494073 -1.521313   \n",
       "7998       -0.990389 -1.078538 -1.069169  0.657082  0.181892  0.633836   \n",
       "7999       -1.053717 -0.577861 -2.114499  0.310240 -0.695740 -1.763496   \n",
       "\n",
       "parameters    d.91.1    d.92.1    d.93.1    d.94.1    d.95.1    d.96.1  \\\n",
       "draws                                                                    \n",
       "0           2.303049 -0.198721 -1.491252 -0.936074  1.674106  0.162555   \n",
       "1           2.088345 -0.804637 -2.091817  0.113743 -0.817788 -0.081172   \n",
       "2           1.566095  0.863699 -0.965147 -0.431092  0.457807  0.129229   \n",
       "3           2.455514 -0.225581  0.613545 -0.144236  0.364741 -0.102219   \n",
       "4           1.516462  0.140041 -2.245375 -1.140552 -0.511464  0.119794   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.507355  0.987333 -3.513256 -1.201888  0.915774 -0.283312   \n",
       "7996        2.324136  1.548459 -0.446293 -1.847411  0.770710  0.741687   \n",
       "7997        2.169706 -0.762580 -1.255663  0.182622 -0.084911  0.025825   \n",
       "7998        2.732229  0.561286 -0.833354 -0.979673  1.528543  0.741344   \n",
       "7999        2.302353 -0.656003  0.627323 -0.803159  0.791286 -0.329510   \n",
       "\n",
       "parameters    d.97.1    d.98.1    d.99.1   d.100.1   d.101.1   d.102.1  \\\n",
       "draws                                                                    \n",
       "0           1.216787 -0.503069  0.067878  0.553822  0.540015 -1.078441   \n",
       "1           0.599339  1.318755 -1.219822  1.338196  1.025870 -0.620058   \n",
       "2           0.950087  0.847818 -0.786880  0.545882  0.457627 -0.829904   \n",
       "3           1.498351  1.582455 -0.073093  0.693403  0.545517 -0.011568   \n",
       "4           0.276529  1.395175 -0.422910  0.712210  0.914355  0.213758   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.438410  0.162633 -1.017552  0.395656 -0.076950 -1.455438   \n",
       "7996        0.946724  0.360378 -0.236966 -0.107962  0.488973  0.566057   \n",
       "7997        0.789448  0.608318 -0.666498  0.402503  0.239672 -1.476874   \n",
       "7998        0.857304  0.220634 -0.746295  0.804680  1.623617 -0.414383   \n",
       "7999        0.526725  1.647985  0.072359  1.076517  0.973352  0.948523   \n",
       "\n",
       "parameters   d.103.1   d.104.1   d.105.1   d.106.1   d.107.1   d.108.1  \\\n",
       "draws                                                                    \n",
       "0          -1.314059  0.524216 -0.032583 -1.136863 -0.587115  0.010742   \n",
       "1          -0.898224 -0.814701  0.905694 -1.946671 -0.597867  0.665153   \n",
       "2          -1.519984 -0.567840  0.264372 -1.564901  0.044441 -0.154304   \n",
       "3           0.382596  0.024713  0.342891 -0.493010 -0.767378 -0.264932   \n",
       "4          -0.845495 -1.340684  0.285876 -0.268386  0.051360  0.193268   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.510636 -1.598739  1.097092 -0.129344  0.893002  0.668402   \n",
       "7996       -1.032053 -0.807309  0.535039 -0.678845  1.174765  0.031669   \n",
       "7997       -0.300973 -0.557870 -0.772040 -1.864760 -0.579207 -0.503510   \n",
       "7998        0.240548 -0.255935  0.547045  0.162978  0.450820  0.006540   \n",
       "7999       -0.175001  0.412381 -0.748610 -1.670426 -0.178335 -0.107888   \n",
       "\n",
       "parameters   d.109.1   d.110.1   d.111.1   d.112.1   d.113.1   d.114.1  \\\n",
       "draws                                                                    \n",
       "0          -0.818755  0.975165 -0.339449 -2.002079 -1.388657  0.422492   \n",
       "1          -0.901654  0.837224 -1.687155 -1.246215 -1.893740  0.114825   \n",
       "2          -1.500347  0.228832  0.105274 -2.187093 -0.559223 -0.177537   \n",
       "3          -1.244099  0.659503 -1.116438 -2.777419 -1.382864 -0.079664   \n",
       "4          -0.528402  0.091640 -0.727814 -0.260704 -1.568531 -0.006826   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.576933  0.587953 -0.423664 -2.433777 -0.656909  0.377759   \n",
       "7996       -2.031427  1.029462  1.450317 -0.877966 -1.077413 -0.802605   \n",
       "7997       -0.841610  0.066041  0.568250 -0.933050 -2.951564  0.969420   \n",
       "7998       -1.437635  0.322734  1.045192 -0.524167  0.073819  0.866922   \n",
       "7999       -2.250536  0.518664 -0.925782 -1.677294 -1.981252  1.006651   \n",
       "\n",
       "parameters   d.115.1   d.116.1   d.117.1   d.118.1   d.119.1   d.120.1  \\\n",
       "draws                                                                    \n",
       "0           0.324657 -1.931504  0.157918  1.357651 -0.589241  0.017949   \n",
       "1           1.523676 -0.851205  0.552432  0.946415 -0.151866 -1.243608   \n",
       "2           0.327030 -0.820642 -0.291321  1.889391 -0.066803 -1.088594   \n",
       "3           1.218063 -0.018562  0.290459  2.328414 -1.140065 -0.421382   \n",
       "4           1.414921 -0.289243 -0.641822  2.248282 -0.030657 -0.826884   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.385636 -2.035265 -0.328600  0.909439 -2.173843 -1.034031   \n",
       "7996        0.994865 -0.027329 -0.683601  1.392678 -0.299415 -0.552950   \n",
       "7997        1.106014 -1.327055  0.446654  2.308175 -0.126596 -0.547142   \n",
       "7998        1.359804 -0.012718 -0.060325  2.155535 -0.954969  0.153444   \n",
       "7999        0.464541 -0.454912  0.642984  1.792409  0.418054  0.313152   \n",
       "\n",
       "parameters   d.121.1   d.122.1   d.123.1   d.124.1   d.125.1   d.126.1  \\\n",
       "draws                                                                    \n",
       "0           0.239429 -2.185894 -0.201618 -1.495156 -0.562587 -0.785242   \n",
       "1          -0.142913 -2.598751 -1.766244 -2.920091 -1.245414  0.297457   \n",
       "2          -0.117302 -0.975938 -1.058514 -1.044736  0.294860  0.286825   \n",
       "3           0.542544  0.729046 -0.255848 -1.597689 -1.438327 -1.070850   \n",
       "4           0.196169 -0.602268 -1.304021 -1.033125 -1.897310 -0.268622   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.667850 -0.482389 -1.581094 -0.831508  1.381166 -1.574602   \n",
       "7996        1.236387 -0.001824 -1.117671 -1.682583 -0.491625 -1.474163   \n",
       "7997        0.042876 -0.528881 -0.966956 -1.801886 -1.237144  0.162307   \n",
       "7998       -0.022238 -1.268257  0.156284 -0.587983 -0.474885 -0.013344   \n",
       "7999        0.264337 -2.565504 -0.440364 -2.821323 -2.445911 -0.375651   \n",
       "\n",
       "parameters   d.127.1   d.128.1   d.129.1   d.130.1   d.131.1   d.132.1  \\\n",
       "draws                                                                    \n",
       "0           1.245005 -0.380004  1.197054  0.161175  0.458448 -1.159786   \n",
       "1           2.609680 -1.337790  1.372915 -0.688273  0.412058 -0.882433   \n",
       "2           1.979262 -1.533290  0.059103 -0.434304  0.031434 -1.045420   \n",
       "3           1.295693 -0.322848  0.467980 -1.630519  0.362299 -1.829727   \n",
       "4           2.634350 -0.747357 -0.008694 -1.800606 -0.780709 -0.339714   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.155435 -0.826005  0.547146 -1.230535  0.466566 -0.639817   \n",
       "7996        1.453544 -0.924569 -0.848374  0.031307  1.367690 -1.373294   \n",
       "7997        1.422988  0.126056  1.123466 -1.931522  0.442197  0.208029   \n",
       "7998        1.422140  0.143838 -0.177975 -0.710480  0.683557  0.302737   \n",
       "7999        2.094750 -1.029611  0.378026 -1.573110 -0.432541 -1.042428   \n",
       "\n",
       "parameters   d.133.1   d.134.1   d.135.1   d.136.1   d.137.1   d.138.1  \\\n",
       "draws                                                                    \n",
       "0          -0.035512 -1.003396  0.772364 -0.548882  0.209936  1.031726   \n",
       "1           0.080083 -0.809116  0.248100  0.789920  0.925712  1.338971   \n",
       "2           1.196577  0.216979  1.070848 -0.005644  1.607073  2.092888   \n",
       "3          -0.049750 -0.948838 -0.786981 -0.098447  0.556278  1.432921   \n",
       "4           0.772595 -0.237113  1.031412  0.188912  1.624425  2.257859   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.725380 -0.620772  1.156983 -0.819543 -0.082317  1.225233   \n",
       "7996        1.315286  0.178725  0.291625 -0.178477  0.553915  2.103769   \n",
       "7997       -0.309055 -0.386201  0.180048 -0.340591  0.664161  0.877617   \n",
       "7998        0.865585 -0.483163  0.675506 -0.353412  1.458548  1.177698   \n",
       "7999        0.968903 -1.409014  0.277124 -0.165702  0.116091  0.759943   \n",
       "\n",
       "parameters   d.139.1   d.140.1   d.141.1   d.142.1   d.143.1   d.144.1  \\\n",
       "draws                                                                    \n",
       "0          -0.167143 -0.622752 -0.909620 -0.081484  0.241565 -0.215075   \n",
       "1          -0.148212 -1.534339 -1.723457 -0.144874 -0.289824 -0.089475   \n",
       "2          -0.215351  0.100726 -1.324219  0.444431  1.085978 -1.381500   \n",
       "3          -0.125289  0.254067 -0.899182 -0.643624  0.129099 -2.020672   \n",
       "4           0.065757 -0.905659 -0.918080 -1.541176 -0.062834 -1.364488   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.333338  0.240900 -1.935874  0.148305  1.094999 -0.855543   \n",
       "7996        0.812782 -0.277859  0.280159  1.272471  0.718325 -0.582883   \n",
       "7997        0.500820 -0.391463 -1.059139 -0.213613  0.545138 -0.160716   \n",
       "7998       -0.103841 -0.369460 -1.343062 -0.118076  0.043328 -0.171552   \n",
       "7999        0.340009 -1.005010 -0.469970 -0.242151 -0.316939 -0.483466   \n",
       "\n",
       "parameters   d.145.1   d.146.1   d.147.1   d.148.1   d.149.1   d.150.1  \\\n",
       "draws                                                                    \n",
       "0          -1.296413  1.359324  0.601503  0.176105 -1.890656  0.678792   \n",
       "1           0.263668  0.251302  0.010866  0.949476 -2.114139 -0.093563   \n",
       "2           1.012517  2.350982 -0.009922  0.288151 -0.437877 -0.816865   \n",
       "3          -0.758809  0.801428 -0.057348  0.840487 -1.006796  1.294628   \n",
       "4          -0.723209  1.596336  0.501579  1.302688 -0.361060 -0.885080   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.398542  2.056795  0.645930  0.502006 -0.143065 -0.301165   \n",
       "7996        0.990603  1.612328  1.201221  0.155815 -2.209327 -0.094851   \n",
       "7997       -0.837258  0.971079  0.735667  0.118522 -0.731558 -0.481913   \n",
       "7998        0.676045  1.204198 -0.066749  0.908615 -0.122003 -0.813889   \n",
       "7999        0.173800  0.901185  0.589583  0.706371 -0.552739  0.006962   \n",
       "\n",
       "parameters   d.151.1   d.152.1   d.153.1   d.154.1   d.155.1   d.156.1  \\\n",
       "draws                                                                    \n",
       "0           0.408745 -0.689631  1.010307 -0.321389  0.145731  1.179719   \n",
       "1           0.236635 -0.339564  0.629605 -0.597281 -0.281912  0.755649   \n",
       "2          -0.130795  0.382010  0.480523 -0.333326 -1.509889 -0.363752   \n",
       "3           1.128410 -0.211495  0.999872 -0.278235 -0.410908  0.995537   \n",
       "4           0.044162 -0.226745  0.128436 -0.049336  0.595034  0.904893   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.421267  0.138832  0.880904 -0.677348  0.176504  0.645967   \n",
       "7996        0.210379 -0.502091  0.403970  0.229298  0.109760 -0.311358   \n",
       "7997        0.256125  0.946468  0.437167 -1.415321 -0.103277 -0.423315   \n",
       "7998        0.471795 -0.043892  1.187021 -0.678595  0.596846  1.096448   \n",
       "7999        0.049002 -0.568267  0.103754 -0.596777  0.006751  1.356391   \n",
       "\n",
       "parameters   d.157.1   d.158.1   d.159.1   d.160.1   d.161.1   d.162.1  \\\n",
       "draws                                                                    \n",
       "0          -0.845296  0.763039  0.257182 -1.757898  0.660822  0.058109   \n",
       "1          -0.932646  0.819742  0.290737 -0.495966  1.343845  0.911953   \n",
       "2          -1.534615  1.098974 -0.261890 -0.327641  1.264328 -0.119976   \n",
       "3          -0.264455  1.318431 -0.922838 -1.752446  0.629697 -0.624935   \n",
       "4          -0.548383  0.090426 -0.250371  0.099825  1.243207 -0.147216   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.650823  0.200482  0.237994 -0.032162  0.745519 -0.629411   \n",
       "7996       -0.589125  0.960823 -0.158633 -0.247523  1.165572 -0.775340   \n",
       "7997        0.569938  0.728599  0.023767  0.218820  1.188785 -0.413051   \n",
       "7998        0.320294  1.128116 -0.983991 -0.390432  0.923404 -1.232998   \n",
       "7999       -0.189115  0.906584  0.702386 -1.542083  1.376450  0.328814   \n",
       "\n",
       "parameters   d.163.1   d.164.1   d.165.1   d.166.1   d.167.1   d.168.1  \\\n",
       "draws                                                                    \n",
       "0           0.023939 -1.306130 -2.557735 -1.231920 -2.341358 -0.463872   \n",
       "1          -0.118395 -0.019211 -1.662367 -2.346640 -0.295903 -1.278936   \n",
       "2           0.071012 -0.771844 -1.386235 -2.488547 -1.446859 -0.488957   \n",
       "3           0.520414 -0.105977 -0.992316 -1.391645 -2.504333 -0.999463   \n",
       "4           0.087626  0.630759 -1.422585 -1.573122 -0.020957 -1.316480   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.143689 -1.604109 -2.672071 -1.086073 -1.153193 -1.244856   \n",
       "7996       -0.350347 -0.792202 -3.145142 -0.804351 -0.163392 -1.845676   \n",
       "7997        0.460598  0.229156 -1.920618 -2.082923 -1.555346 -0.590349   \n",
       "7998       -0.197379 -0.618883 -1.004036 -1.202681 -0.973561 -0.468977   \n",
       "7999       -0.115663  0.829889 -1.198023 -1.925958 -0.917333 -1.472541   \n",
       "\n",
       "parameters   d.169.1   d.170.1   d.171.1   d.172.1   d.173.1   d.174.1  \\\n",
       "draws                                                                    \n",
       "0          -0.412691  1.074902  1.008635  1.192221  1.022275  1.008169   \n",
       "1          -0.153024  0.702929  0.927489  1.195554  1.015693  1.608341   \n",
       "2          -0.940930  0.405601  1.051519  1.041658  1.018902  0.506642   \n",
       "3          -0.575555  0.558319  1.367056  0.888250  0.949284  1.216221   \n",
       "4          -1.133579  0.597113  1.120850  1.159328  0.221806  1.046757   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.808230 -0.343819  0.696333  0.605657  1.485467  0.958307   \n",
       "7996       -2.816580  0.543281  1.241159  1.155876  0.653630  1.152445   \n",
       "7997       -0.970830  0.337632  1.197161  0.972086  1.469203  1.549587   \n",
       "7998       -1.241278  0.803284  1.308516  1.278371  1.078464  2.057256   \n",
       "7999       -0.238393  1.234683  0.286341  0.661014  0.634444  0.702852   \n",
       "\n",
       "parameters   d.175.1   d.176.1   d.177.1   d.178.1   d.179.1   d.180.1  \\\n",
       "draws                                                                    \n",
       "0           0.306036  0.551369 -0.074231 -1.520120  3.469684 -0.842662   \n",
       "1           1.490528  0.451293 -0.589528 -0.129233  3.578741 -1.166891   \n",
       "2           1.435671  0.316009  0.214401  0.023223  3.310587 -2.143929   \n",
       "3           0.129446  0.245468 -0.739372 -1.073689  3.333682 -0.915415   \n",
       "4           1.080555  0.306489  0.212663  0.452331  3.334772 -2.161473   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.364136  1.615932 -1.589324  0.124813  3.476538 -1.651713   \n",
       "7996        0.840993  1.462625  0.523895  0.796499  3.792176 -0.895917   \n",
       "7997        0.331526  0.952342 -0.386842 -0.726148  3.570082 -0.918804   \n",
       "7998        1.175071  1.031219 -0.263922  0.062317  3.695788 -1.703160   \n",
       "7999        1.040686  0.233462  0.029680 -1.196232  3.358056 -1.148794   \n",
       "\n",
       "parameters   d.181.1   d.182.1   d.183.1   d.184.1   d.185.1   d.186.1  \\\n",
       "draws                                                                    \n",
       "0           0.435872  1.016459  0.008909 -0.463815  0.812699  0.787862   \n",
       "1           0.330915  0.893020  1.047929  0.220574  0.224222  0.318638   \n",
       "2           0.024113  0.550791  0.819687  0.266909 -0.248185  0.433461   \n",
       "3           0.881610  0.713859  0.188777  0.055720  0.394050  0.374828   \n",
       "4           0.345970  0.493578  0.689542  0.442669 -0.144389  0.164414   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.196496  0.838101  0.552354  0.365145  0.398903  0.463653   \n",
       "7996        0.253338  1.154912 -0.042055  0.233402 -0.220422  0.136225   \n",
       "7997        0.142277  0.889214  1.000316  0.345126  0.260336  0.438783   \n",
       "7998        0.290263  0.468383  0.572648  0.109023  0.113542  0.285158   \n",
       "7999        1.022671  0.597961  1.789085  0.721369  0.766783  0.408671   \n",
       "\n",
       "parameters   d.187.1   d.188.1   d.189.1   d.190.1   d.191.1   d.192.1  \\\n",
       "draws                                                                    \n",
       "0           0.402586 -1.131518 -0.013257 -0.696836  0.444591 -0.318191   \n",
       "1          -0.455588 -1.293394 -0.106540 -0.153930 -0.744447 -0.004412   \n",
       "2          -0.406225 -0.534107 -1.138927 -1.468063  0.234325  0.137300   \n",
       "3          -0.331970 -0.473752 -1.063790 -1.261188  0.072201 -0.507412   \n",
       "4          -0.420011 -1.362716 -1.590674 -1.342650 -0.649191 -0.506873   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.482275 -1.225037 -1.567086 -1.059002  0.976637 -0.361295   \n",
       "7996       -0.457642 -0.759081 -0.590379 -1.357375  0.126931  0.306373   \n",
       "7997       -0.016285 -0.181050 -0.267472 -1.076753 -0.221961  0.306781   \n",
       "7998       -0.231159 -1.094136 -0.689468 -0.654807  0.131175 -0.218622   \n",
       "7999        0.514068 -0.163165  0.498311 -0.217684 -0.068095  0.227333   \n",
       "\n",
       "parameters   d.193.1   d.194.1   d.195.1   d.196.1   d.197.1   d.198.1  \\\n",
       "draws                                                                    \n",
       "0          -0.093454 -1.467694  2.033226  3.828689  1.926871  1.176288   \n",
       "1          -0.016642 -2.959525  1.521912  3.313116  2.896724  0.416541   \n",
       "2          -0.589562 -2.316962  1.713713  2.682963  2.084980  0.497381   \n",
       "3           0.148635 -0.440169  1.462816  3.418368  2.446931  1.696236   \n",
       "4           0.032127 -1.083001  1.441462  3.466843  2.001889  0.640065   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.247540 -0.533372  1.971480  3.340997  1.492394 -0.061122   \n",
       "7996       -0.384993 -1.531574  1.709542  3.329371  1.725187  0.671737   \n",
       "7997       -0.239767 -0.626111  1.155674  2.759443  2.073366  1.201401   \n",
       "7998       -0.695894 -0.730076  1.761922  3.527557  1.798460  1.329174   \n",
       "7999       -0.046898 -0.796693  1.928903  3.419389  2.983715  0.469226   \n",
       "\n",
       "parameters   d.199.1   d.200.1   d.201.1   d.202.1   d.203.1   d.204.1  \\\n",
       "draws                                                                    \n",
       "0          -0.390468 -1.324961 -0.314756 -1.071725 -0.299702 -1.333406   \n",
       "1          -0.161528  0.005268 -1.662484 -2.723701  1.496833 -1.768235   \n",
       "2          -1.299091 -0.105574 -0.431409 -1.706436 -0.764355 -1.152298   \n",
       "3           0.051833  1.213113  0.237133 -3.107710 -1.135404 -0.264333   \n",
       "4           0.498616  1.754080 -0.951793 -0.184952 -1.651019 -0.530657   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.039361 -0.047655 -2.270126 -0.784527 -0.584845 -0.637789   \n",
       "7996        0.148802 -0.171104 -1.286702 -2.501164 -0.821831 -0.993066   \n",
       "7997       -0.404367 -0.989027 -0.633053 -1.056655 -2.347534 -1.895640   \n",
       "7998       -0.071458  0.499399 -0.934057 -0.531213 -0.576044 -0.614495   \n",
       "7999       -0.894228 -0.602246 -0.940110 -1.205974 -0.892352 -1.415333   \n",
       "\n",
       "parameters   d.205.1   d.206.1   d.207.1   d.208.1   d.209.1   d.210.1  \\\n",
       "draws                                                                    \n",
       "0          -1.641149 -2.234103 -0.082236  0.847379  0.734399  1.728512   \n",
       "1          -0.686088 -2.029987  1.192096 -0.086323 -1.046727  3.119448   \n",
       "2          -0.375918 -1.457326 -0.384925  0.131795 -0.274492  1.557043   \n",
       "3          -0.276535 -0.571135 -0.079002 -0.362939  0.825123  1.090077   \n",
       "4          -0.524057 -0.615734  0.461384 -0.314817 -1.096875  1.732107   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.005988 -1.473687 -0.336676  0.682635 -0.865179  1.934080   \n",
       "7996       -0.533214 -0.149479  0.875769 -0.174742 -0.330607  1.610413   \n",
       "7997       -0.460514 -1.059471  0.105768 -1.084289 -1.585977  2.353343   \n",
       "7998       -1.511682 -1.599353 -0.175354  0.773193 -0.173623  1.952929   \n",
       "7999       -0.814242 -2.372739  0.765467 -0.422543 -0.297676  2.811042   \n",
       "\n",
       "parameters   d.211.1   d.212.1   d.213.1   d.214.1   d.215.1   d.216.1  \\\n",
       "draws                                                                    \n",
       "0           0.446070 -0.056337 -0.014664 -1.189612 -2.339580  0.295429   \n",
       "1          -0.645222  0.410866 -0.334898 -2.096791 -0.192744 -1.392237   \n",
       "2          -1.203678 -0.554415 -0.077594 -0.461044 -1.020614 -0.303952   \n",
       "3           1.039350 -0.623722 -0.429034 -2.423597 -0.117343 -1.890957   \n",
       "4           0.268532 -0.614204 -0.434174 -1.434767  0.001390 -1.933695   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.562626 -0.925091 -0.589816 -1.527986  0.813502 -0.159169   \n",
       "7996        0.258803 -0.637267  0.333815 -1.055861 -1.920131 -1.028400   \n",
       "7997        1.114835 -1.374411 -0.334970 -1.066182 -0.895507 -0.213583   \n",
       "7998       -0.717303 -0.377986 -0.293089 -0.766222 -1.229420  0.366970   \n",
       "7999        0.344006  0.195814 -0.514364 -1.612403 -1.818452 -0.659200   \n",
       "\n",
       "parameters   d.217.1   d.218.1   d.219.1   d.220.1   d.221.1   d.222.1  \\\n",
       "draws                                                                    \n",
       "0          -1.766174 -0.328136 -0.733575 -1.022506 -2.066756  0.769696   \n",
       "1           0.262413  0.347586 -1.120590 -0.499797  0.200059 -1.609509   \n",
       "2           0.089255  0.403331 -1.204560 -0.058098 -1.236817 -0.440749   \n",
       "3          -0.776062 -0.212388 -0.678314 -1.455035 -0.606048 -0.518129   \n",
       "4          -0.171898  0.105296 -1.301914  0.241562  0.788681 -1.439099   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.911981 -0.050088 -1.227765 -0.242872 -0.083652 -0.549532   \n",
       "7996       -1.899665 -0.405581 -0.530552  0.040633 -0.117834 -0.287134   \n",
       "7997       -1.117628 -0.902167 -0.571603  0.408628  0.245102  0.628736   \n",
       "7998        0.087754 -0.162007 -1.340034 -0.593018  0.813908 -0.775417   \n",
       "7999       -1.077981  0.635688 -1.074753 -0.081743 -1.196406  0.045182   \n",
       "\n",
       "parameters   d.223.1   d.224.1   d.225.1   d.226.1   d.227.1   d.228.1  \\\n",
       "draws                                                                    \n",
       "0           1.937188 -1.013471  0.206065 -1.656777 -2.965625 -0.383614   \n",
       "1           2.751597  0.647734  0.861422 -2.555892 -1.897763 -0.108441   \n",
       "2           1.741074 -0.974834 -0.048693 -1.851994 -3.423455 -0.347648   \n",
       "3           2.232087 -0.637361  0.396228 -1.745177 -2.019543 -1.185806   \n",
       "4           2.281790  0.018689  0.315615 -1.971908 -0.430648 -1.753258   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.754941 -0.684007 -0.341277 -1.912943 -1.304353 -1.080000   \n",
       "7996        1.609124 -0.861474 -0.568146 -1.450373 -2.754814 -1.968711   \n",
       "7997        2.300079 -0.058817  0.083484 -1.704724 -0.770013 -0.138175   \n",
       "7998        1.725802 -0.638846 -0.885256 -2.331151 -1.680706 -1.890101   \n",
       "7999        2.773826 -0.388693 -0.106381 -2.449294 -0.644714 -0.480606   \n",
       "\n",
       "parameters   d.229.1   d.230.1   d.231.1   d.232.1   d.233.1   d.234.1  \\\n",
       "draws                                                                    \n",
       "0           0.548329 -0.671545 -1.709639 -1.465781 -0.106172  0.662039   \n",
       "1           1.834164 -0.867751 -2.801194 -0.154864 -0.800341  0.962462   \n",
       "2           1.136671 -0.502773 -0.490789  0.023376 -1.110258  0.059096   \n",
       "3           0.627706 -0.829310 -2.066668 -0.560730 -0.870606 -0.129357   \n",
       "4           1.342495 -1.281352 -1.578537  0.186740 -1.755392  0.479792   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.173887 -1.701301 -2.270804 -0.452933 -0.393757  0.422478   \n",
       "7996        0.684514 -1.786272 -1.019687 -0.426398 -0.587114  0.476523   \n",
       "7997        1.927412 -0.378105 -1.819184 -0.803894 -0.078451  0.467156   \n",
       "7998        0.545256 -0.834067 -1.584506 -0.572154 -1.150287  0.428867   \n",
       "7999        1.116546 -1.865969 -0.819810  1.274063 -0.440149  0.662010   \n",
       "\n",
       "parameters   d.235.1   d.236.1   d.237.1   d.238.1   d.239.1   d.240.1  \\\n",
       "draws                                                                    \n",
       "0           0.170571 -0.522655  0.100239 -1.302047 -0.722876  0.480261   \n",
       "1          -0.009404 -0.816019  1.030105  0.374466  0.292530  0.007940   \n",
       "2           0.271157 -1.271237  0.238380 -0.749283 -0.467356  0.105311   \n",
       "3           0.943334  0.423567  1.367944  0.238712 -0.667134  0.855728   \n",
       "4           1.162727 -0.705636  1.073087  0.372411  0.303066 -0.708828   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.191194 -0.894515  1.162432 -1.287716  0.646284  0.828576   \n",
       "7996       -0.038659 -1.970334  0.375374 -0.072723  0.158219  0.480686   \n",
       "7997        0.906885 -0.887123  0.725291 -0.230165  0.522759  0.102774   \n",
       "7998        0.622127 -1.686991  0.214979 -0.232335 -0.144848  0.720499   \n",
       "7999       -0.152922 -1.722147  0.672275 -2.318295 -0.140903  0.235063   \n",
       "\n",
       "parameters   d.241.1   d.242.1   d.243.1   d.244.1   d.245.1   d.246.1  \\\n",
       "draws                                                                    \n",
       "0          -0.286202 -0.626293 -0.838638 -0.896078 -1.924661  2.709577   \n",
       "1           0.242722  0.338438  0.308543  0.606682 -3.168040  2.587975   \n",
       "2           0.936594 -1.217559  0.060432 -0.717425 -3.236597  2.049624   \n",
       "3          -0.642287 -1.350425  0.503394 -1.226511 -2.523222  3.100036   \n",
       "4           0.631059 -1.397928  0.176152  0.189937 -1.159983  2.085750   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.578059 -0.528061  0.434836 -0.139940 -0.479459  1.917953   \n",
       "7996        0.587940 -0.909432 -0.317599 -1.229279 -2.525036  2.189399   \n",
       "7997        0.499417 -0.935247 -0.097325  0.929064 -0.486316  1.954082   \n",
       "7998       -0.102883 -0.109260 -0.330281 -1.177274 -1.498925  2.147040   \n",
       "7999       -0.394157 -1.384261  0.602620 -0.488015 -2.338450  2.537653   \n",
       "\n",
       "parameters   d.247.1   d.248.1   d.249.1   d.250.1   d.251.1   d.252.1  \\\n",
       "draws                                                                    \n",
       "0          -0.541050 -1.257444 -0.098779  0.408964  1.263144  1.384219   \n",
       "1           0.341334 -0.721908 -0.312835  0.898876  0.970557  1.597255   \n",
       "2          -1.108130 -0.702754 -1.179765  0.265136  1.099541  0.897597   \n",
       "3          -0.391463 -0.868081  0.422528 -0.091888  0.887138  0.740408   \n",
       "4          -0.489042 -0.186783 -0.271120  0.640304  1.006856  0.187742   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.577839 -0.113396 -0.718580  0.133175  0.231806 -0.255969   \n",
       "7996       -0.236518  0.071296 -0.694981  0.893783  0.974381  1.182391   \n",
       "7997       -0.451479 -0.336505 -0.484472 -0.824298  0.664417  0.215342   \n",
       "7998       -0.271565 -0.809746  0.044565  0.680650  1.266855  0.602343   \n",
       "7999       -0.131133 -0.020555 -0.132869  0.991631  2.335211  1.269566   \n",
       "\n",
       "parameters   d.253.1   d.254.1   d.255.1   d.256.1   d.257.1   d.258.1  \\\n",
       "draws                                                                    \n",
       "0          -0.143112  0.660587 -0.008916  0.459556  0.800517  1.682858   \n",
       "1          -0.258725  0.104167 -0.389283 -1.060911 -0.192637  0.562489   \n",
       "2          -0.814659 -0.898088 -0.446690  0.296517  0.148090  0.683028   \n",
       "3          -0.144263 -0.108359  0.184635  0.246431  1.343121  0.906792   \n",
       "4          -1.212850 -0.893897 -0.267294 -0.048435  0.163329 -0.639718   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.453090 -0.086771 -0.375448 -0.459839  0.531579  0.392651   \n",
       "7996       -1.782464 -0.959645  0.696126 -0.634224 -0.275836  0.461363   \n",
       "7997       -2.168878  0.865734 -0.844997 -1.019249  0.940418  0.843995   \n",
       "7998       -1.138070 -0.376717  0.025500 -0.102642 -0.166825  1.035850   \n",
       "7999       -0.546794 -0.366881 -0.237236 -0.306277  0.508084  0.648947   \n",
       "\n",
       "parameters   d.259.1   d.260.1   d.261.1   d.262.1   d.263.1   d.264.1  \\\n",
       "draws                                                                    \n",
       "0          -0.351228  0.185703 -0.759007  0.518530 -0.499206  0.494772   \n",
       "1          -0.017588  1.168913 -1.101658 -0.057111 -0.693098 -0.519139   \n",
       "2           0.477453  1.215805 -0.011332 -0.489295 -0.792334 -0.322898   \n",
       "3           1.353308  0.896042  0.585909  0.787184 -1.062490 -0.599636   \n",
       "4           0.785143  0.017303  0.877000  0.431544 -0.349522 -0.344051   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.447061  1.573578  0.020000  0.257810 -1.009131 -0.481152   \n",
       "7996       -0.438341  0.953575  0.020841  1.477379 -0.967150 -1.671863   \n",
       "7997        0.141829  0.518592  0.722358  0.274676 -0.643457 -0.813142   \n",
       "7998       -0.199437  0.694448  1.179141 -0.578221 -1.000892  0.342946   \n",
       "7999        0.518181  0.593471 -0.842359  0.880160 -1.052908 -0.264436   \n",
       "\n",
       "parameters   d.265.1   d.266.1   d.267.1   d.268.1   d.269.1   d.270.1  \\\n",
       "draws                                                                    \n",
       "0           0.068342  1.189093 -0.236993 -1.007381  1.612834 -0.471481   \n",
       "1           0.735568  0.592338 -0.196653  0.098647  1.487484 -0.654043   \n",
       "2           0.705187  0.686590  1.094837 -0.018953  1.080872 -0.381233   \n",
       "3           0.861957  1.174883  1.385314 -0.397453  1.222594 -0.153292   \n",
       "4           1.128396  1.087620  0.945183  1.139624  0.947906 -0.815955   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.610021  1.194109  0.879124  1.638457  0.535169 -0.412800   \n",
       "7996        0.638065  0.819670  0.690123  0.386674  2.148944 -0.768200   \n",
       "7997        0.308710  1.113675  0.485719  0.157284  1.216468 -0.946802   \n",
       "7998       -0.952431  1.524361 -0.110026  0.449416  1.830866 -1.112276   \n",
       "7999        0.175848  0.758804  1.050412 -0.394082  1.834085 -0.643441   \n",
       "\n",
       "parameters   d.271.1   d.272.1   d.273.1   d.274.1   d.275.1   d.276.1  \\\n",
       "draws                                                                    \n",
       "0           0.503241  0.476695 -0.162129 -1.543627  2.537342 -1.811801   \n",
       "1           1.258935 -0.596879  0.975019 -0.932243  3.144913 -0.096218   \n",
       "2           0.387030 -1.235889  1.017926  1.264505  2.935089 -0.309807   \n",
       "3           0.187003 -0.195746 -0.173327  0.318237  2.844221  0.689832   \n",
       "4           0.842638 -0.770910  0.363245  0.600480  2.655940  0.290083   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.844973  0.199191 -0.088917  0.832241  3.758020  0.307153   \n",
       "7996        0.720488 -0.183825  0.672968  1.004103  2.610999 -0.942549   \n",
       "7997        0.542020 -1.544855  0.747348 -0.308739  2.542639  1.158184   \n",
       "7998        1.115073 -0.360277  0.742845  0.755912  2.870287 -0.872922   \n",
       "7999        0.776780 -1.933549 -0.290592  0.761524  2.579884  0.035007   \n",
       "\n",
       "parameters   d.277.1   d.278.1   d.279.1   d.280.1   d.281.1   d.282.1  \\\n",
       "draws                                                                    \n",
       "0           0.109747  1.085960 -0.451623  0.069837  0.939732  2.178951   \n",
       "1          -2.132798  0.324833 -0.214510  0.353476  0.937910  1.947399   \n",
       "2          -0.591890  0.849522 -1.800942 -0.079769  0.862475  1.645217   \n",
       "3          -0.200927  1.115533 -0.690205  0.542467  1.670203  1.717060   \n",
       "4          -0.462693  1.415527 -0.235606  0.191409  1.141335  1.659823   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.245970  1.069626 -0.304140  1.523145  2.136030  1.750513   \n",
       "7996       -0.463944  0.634108 -0.794707  1.100915  1.321081  2.288233   \n",
       "7997        0.254610  0.871976 -2.061838  0.490092  1.214609  2.218377   \n",
       "7998       -1.888692  0.676115 -0.452273  0.350374  1.538758  2.166328   \n",
       "7999       -1.307640  0.601219 -0.346374  0.505192  0.980556  1.912252   \n",
       "\n",
       "parameters   d.283.1   d.284.1   d.285.1   d.286.1   d.287.1   d.288.1  \\\n",
       "draws                                                                    \n",
       "0          -0.950160 -0.494906  0.841544  0.328586 -1.404875 -0.114773   \n",
       "1          -0.213727 -1.258014  1.156138  0.612000 -0.237267  0.417387   \n",
       "2          -0.216736 -0.224120 -0.360205  1.473297 -0.261461  1.683355   \n",
       "3          -0.613563  0.429645  0.269531  0.697685  0.704049  0.554411   \n",
       "4          -1.723043  0.166212 -0.169794  0.775279  0.050845  0.260609   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.703684  0.398442  0.088812  1.995421  0.172252  0.445806   \n",
       "7996       -0.948808 -0.161374  0.778059  1.043264  0.875370 -0.300045   \n",
       "7997       -0.636521 -0.488372  0.101090  0.602555 -0.123178  0.519601   \n",
       "7998       -0.707447  0.421916  0.503637  0.834142  0.687666 -0.750938   \n",
       "7999        0.364983 -0.346958  0.429709  0.609931  0.013872  0.823007   \n",
       "\n",
       "parameters   d.289.1   d.290.1   d.291.1   d.292.1   d.293.1   d.294.1  \\\n",
       "draws                                                                    \n",
       "0           0.263179 -1.905694  0.910328  0.085295 -2.210998  0.098835   \n",
       "1           0.818045 -1.234940  0.973974  0.098426 -1.135428 -0.286113   \n",
       "2           1.199525 -0.789509  1.725463  0.929757 -2.067227  0.219814   \n",
       "3           0.448917 -1.902668  1.308618  0.306972 -2.710452 -0.282768   \n",
       "4           1.409123 -1.614327  1.009288 -0.075264 -1.912591 -0.217808   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.657680 -1.380028  1.228994  1.310563 -1.473397  0.575366   \n",
       "7996        1.572972 -2.131937  2.151883  0.539488 -1.276205  0.160191   \n",
       "7997        1.094225 -2.049037  1.494340  0.280699 -2.258147 -0.332580   \n",
       "7998        1.215715 -1.737152  1.487677  0.078537 -2.127363  0.193898   \n",
       "7999        0.760226 -1.650457  1.107601  0.515247 -1.914599  0.234667   \n",
       "\n",
       "parameters   d.295.1   d.296.1   d.297.1   d.298.1   d.299.1   d.300.1  \\\n",
       "draws                                                                    \n",
       "0          -0.878673 -1.200737 -0.752444 -0.455662 -0.434457  0.179727   \n",
       "1          -1.152367 -0.739472 -1.096275 -0.641484  0.067155  0.036837   \n",
       "2          -0.779638 -1.006846 -0.374644 -0.098359  0.133213 -0.087837   \n",
       "3          -1.078391 -2.305940 -1.600594 -1.731676 -0.301404 -0.618785   \n",
       "4          -1.151873 -1.110016 -0.522359 -1.122663 -0.470433 -0.157924   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.608887 -2.515727 -0.539719 -0.135895 -0.416555  0.386393   \n",
       "7996       -0.366506 -1.757839  0.508058 -1.208352  0.228462  0.751055   \n",
       "7997        0.039370 -0.900976 -0.625674 -0.726037 -0.666804 -0.289633   \n",
       "7998       -0.639881 -2.069597 -0.779445 -0.861112 -0.322879 -0.241454   \n",
       "7999       -0.137798  0.113597 -0.267210 -0.691528  0.326220 -1.122852   \n",
       "\n",
       "parameters     d.1.2     d.2.2     d.3.2     d.4.2     d.5.2     d.6.2  \\\n",
       "draws                                                                    \n",
       "0          -0.549773  1.659944  0.205286 -0.088823  0.673942  0.520768   \n",
       "1          -0.061053  1.941167  1.667916  0.389213  0.969648 -0.576702   \n",
       "2          -0.364778  1.608919  1.525883  0.313317  0.523179  1.511563   \n",
       "3          -0.041467  1.388373  1.433303  0.777011  0.140366 -0.864691   \n",
       "4          -1.077255  1.995448  0.941120  0.411349  0.978842 -0.496642   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.867638  2.497003  2.317963  0.588795  2.048123  0.654592   \n",
       "7996        0.572795  1.306354  1.080702  0.398558  0.619434  0.447119   \n",
       "7997       -0.096377  0.990157 -0.668491 -0.542688  1.207000  0.038647   \n",
       "7998        0.379653  0.856802  1.408728  0.728642  1.258806 -0.242389   \n",
       "7999       -0.203091  1.366514  1.158265 -0.006361  0.585584  0.162737   \n",
       "\n",
       "parameters     d.7.2     d.8.2     d.9.2    d.10.2    d.11.2    d.12.2  \\\n",
       "draws                                                                    \n",
       "0           1.252245 -1.068320  3.040357 -0.073958 -0.632624 -0.754639   \n",
       "1          -0.532595 -1.163938  2.736374 -1.174436 -0.287530  1.262836   \n",
       "2          -0.225942 -1.178596  2.565667 -0.629778  0.154570 -0.841172   \n",
       "3           0.008045 -0.912220  2.515892 -0.855892 -1.174183 -0.383733   \n",
       "4          -1.913870 -1.315482  2.474361 -1.572775 -1.606590 -0.424166   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.522593 -0.333932  3.291314 -0.762360 -0.518113  0.112524   \n",
       "7996        0.637355 -1.452765  2.108005  0.662153 -2.409504 -0.443226   \n",
       "7997        0.630129 -0.834764  2.096825 -0.538901 -1.015333 -0.578503   \n",
       "7998       -0.018701 -0.361177  2.654069 -0.873063 -1.093638 -0.988992   \n",
       "7999        1.028918 -1.695007  2.594973 -0.633020 -0.851499  0.413211   \n",
       "\n",
       "parameters    d.13.2    d.14.2    d.15.2    d.16.2    d.17.2    d.18.2  \\\n",
       "draws                                                                    \n",
       "0           1.134353  1.157441 -0.415262 -1.623028 -1.258167 -0.523906   \n",
       "1           1.749995 -0.480566 -0.033837 -0.337356 -1.800091 -0.643410   \n",
       "2           1.572048  1.043762 -0.486572 -1.270145 -2.289787 -1.567739   \n",
       "3           1.413228  0.852916 -0.254989 -0.439240 -1.172149 -1.299892   \n",
       "4           1.146642 -0.918600 -1.095451 -0.809045 -1.755196 -0.318788   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.582081 -0.243944 -1.898263 -0.916908 -1.615048  0.608734   \n",
       "7996        0.969157 -0.387937 -1.198934 -0.068395 -1.479488 -0.593188   \n",
       "7997        1.063981 -0.669704 -1.594806 -0.220824 -0.855632 -0.812043   \n",
       "7998        1.162585  0.818562 -0.607212 -0.304055 -1.433244  0.422877   \n",
       "7999        0.835971 -0.414981 -0.657887 -0.764855 -0.968778 -0.342691   \n",
       "\n",
       "parameters    d.19.2    d.20.2    d.21.2    d.22.2    d.23.2    d.24.2  \\\n",
       "draws                                                                    \n",
       "0          -3.199509 -0.152576 -1.256645  0.845815 -0.839132  1.728583   \n",
       "1          -2.195859  0.524999 -0.234425  0.642395 -1.216641  1.848761   \n",
       "2          -1.256507 -0.081146 -5.011274  0.749544 -2.409873  0.702500   \n",
       "3          -0.547645  0.068234 -1.260249  0.654034 -0.423167  1.378487   \n",
       "4          -1.881025  0.180544 -1.566990  0.666360 -1.705021  0.999321   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -2.784957 -0.310580 -0.609623  1.085464 -0.423747  2.339907   \n",
       "7996       -3.172834  0.018830 -1.853542  0.248706 -2.441202  1.163136   \n",
       "7997       -2.154108 -0.399936 -2.143558  0.321479 -1.462092  0.581245   \n",
       "7998       -1.232539 -0.448591 -0.770559  0.181931 -1.302640  1.655238   \n",
       "7999       -1.123472  0.170851 -1.580643  1.223423 -0.586693  1.405382   \n",
       "\n",
       "parameters    d.25.2    d.26.2    d.27.2    d.28.2    d.29.2    d.30.2  \\\n",
       "draws                                                                    \n",
       "0          -0.589931  0.485515 -2.092345 -0.441458 -1.694587  2.518677   \n",
       "1          -1.360257 -0.618715  0.041912 -1.264020 -0.698487  2.177768   \n",
       "2          -0.602056  0.373513  0.236222 -1.235387 -0.068023  2.051218   \n",
       "3          -1.153424  0.563668  0.231357 -0.500062 -0.926818  2.623153   \n",
       "4           0.193252 -1.125800 -0.210065 -0.021363  0.153166  2.219626   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.126940  0.526940 -0.483808 -0.118178  0.130625  3.239778   \n",
       "7996       -0.424218  0.751630  0.664554 -0.877137  0.504029  2.608101   \n",
       "7997       -0.814900  0.433272 -0.501363 -0.462125 -0.569657  2.380143   \n",
       "7998        0.483701  0.109703  0.308891  1.391742  0.137471  2.966948   \n",
       "7999       -0.854327 -0.312905 -0.422181 -1.550313 -0.572648  2.281767   \n",
       "\n",
       "parameters    d.31.2    d.32.2    d.33.2    d.34.2    d.35.2    d.36.2  \\\n",
       "draws                                                                    \n",
       "0           0.050051 -1.131460 -0.865983 -2.242773 -0.526945 -2.264971   \n",
       "1           0.473847 -0.954612 -0.822599  0.547439 -0.776341 -0.162330   \n",
       "2           0.888196 -1.312616 -1.707940 -1.402620 -1.391959 -1.906361   \n",
       "3          -0.533925 -0.553560 -0.958643  0.005105 -0.428116 -1.606346   \n",
       "4           0.380430 -1.266216 -0.689489  0.074422 -0.740634  0.073070   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.446435 -2.000875 -1.359139 -0.135077 -0.795243 -0.977312   \n",
       "7996        1.083754 -0.816106 -1.932788 -0.478533 -1.174703 -0.030312   \n",
       "7997        0.451636 -1.832772 -1.710702 -0.481763 -0.725228 -0.774272   \n",
       "7998        1.358300 -1.811734  0.097662 -1.260567 -0.069011 -1.425748   \n",
       "7999        0.882474 -0.864399 -1.746750 -1.517191 -0.334249 -1.377539   \n",
       "\n",
       "parameters    d.37.2    d.38.2    d.39.2    d.40.2    d.41.2    d.42.2  \\\n",
       "draws                                                                    \n",
       "0           0.451280  0.418215  2.031159 -1.379071  1.122927 -0.226003   \n",
       "1          -0.738258  0.079002  1.488589 -0.735296  1.609600  0.521764   \n",
       "2          -1.691047 -0.362632  1.056187  0.500989  1.011676  0.513328   \n",
       "3          -0.307749  0.804638  1.459078 -0.203143  1.378065 -0.354104   \n",
       "4          -1.466129 -0.203739  2.331496  0.723769  0.892493  0.190457   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.104910  1.216258  1.925100  0.147900  2.084423  0.956260   \n",
       "7996       -1.001199  0.412378  1.823739  0.020476  2.031963  0.365182   \n",
       "7997       -0.742986  0.267798  1.092192 -0.048647  1.522675 -0.794466   \n",
       "7998        0.782916 -0.158470  2.081414 -0.462487  1.350835  1.186132   \n",
       "7999       -0.160590  0.101108  2.021060  0.486820  1.442174 -0.132640   \n",
       "\n",
       "parameters    d.43.2    d.44.2    d.45.2    d.46.2    d.47.2    d.48.2  \\\n",
       "draws                                                                    \n",
       "0          -2.509897  2.304508  0.445570  1.021010 -1.450153  0.242376   \n",
       "1          -1.114174  2.272394 -0.661581  0.464034 -2.463141 -0.192697   \n",
       "2          -0.590390  2.426959  0.041570  0.576326 -1.383124 -0.738434   \n",
       "3          -1.600053  2.236578 -0.865636  0.662507 -0.137847 -0.431881   \n",
       "4           0.186374  2.178373  0.636959  0.194633  0.118961 -0.167677   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.198140  2.322518 -0.098558  1.468308 -0.486408 -0.083068   \n",
       "7996        0.159904  2.869365  0.145624  0.593512 -2.469313  0.002097   \n",
       "7997       -0.832172  2.418513 -0.002717  0.997660 -2.181480  0.544427   \n",
       "7998       -0.000287  2.892001  0.031959  0.545154 -0.352180  0.396108   \n",
       "7999       -1.073283  2.249209 -0.375563 -0.498221 -1.671510 -0.243033   \n",
       "\n",
       "parameters    d.49.2    d.50.2    d.51.2    d.52.2    d.53.2    d.54.2  \\\n",
       "draws                                                                    \n",
       "0           0.834981  1.671488 -0.342870 -0.153526 -1.709953 -0.073791   \n",
       "1           1.265006  1.637538 -1.243249 -1.388345 -1.991110 -0.251722   \n",
       "2           2.014749  1.537673  0.419088 -1.528418 -2.965370 -0.314553   \n",
       "3           0.880899  2.161585 -1.049529 -0.267008 -1.858983 -0.767006   \n",
       "4           0.635154  1.909486 -0.320237 -1.372088 -1.509946  0.147425   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.011507  1.924402  0.003137 -0.837520 -0.572303  0.337962   \n",
       "7996        1.025667  1.770326  0.382675 -1.033772 -1.866355 -0.008323   \n",
       "7997        0.705277  1.712302 -0.692670  0.006931 -0.181342  0.244735   \n",
       "7998        0.607451  1.696803 -1.100853 -2.338184 -1.155497  0.407080   \n",
       "7999        1.305472  1.454247 -0.750841 -1.952990 -2.626248  0.938906   \n",
       "\n",
       "parameters    d.55.2    d.56.2    d.57.2    d.58.2    d.59.2    d.60.2  \\\n",
       "draws                                                                    \n",
       "0           0.194541 -0.610058 -0.069607  0.004859  1.843607 -0.778443   \n",
       "1           0.820847  1.408630 -0.089937  0.094179  1.309253 -0.368686   \n",
       "2           0.600408 -0.234514 -0.332368 -0.581848 -0.245961 -1.209480   \n",
       "3          -0.417913 -0.353847 -0.970043  0.479652  1.547971 -0.403366   \n",
       "4           0.433623  0.369757 -0.612333  0.822510  1.470245  0.273960   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.071187  1.690042 -0.332293  0.243604  1.591646 -1.002984   \n",
       "7996       -0.023561  0.686887 -0.407988  0.611471  1.433167 -0.207820   \n",
       "7997        0.316406  0.682650  0.601528 -0.076965  1.303674 -0.275480   \n",
       "7998        0.036882 -0.645513 -0.895448 -0.272235  0.580800 -0.962142   \n",
       "7999        1.064354 -0.869613  0.520799  0.560490  0.933798 -0.002614   \n",
       "\n",
       "parameters    d.61.2    d.62.2    d.63.2    d.64.2    d.65.2    d.66.2  \\\n",
       "draws                                                                    \n",
       "0           0.573837 -1.452957 -2.043586 -1.243371 -1.231457 -0.847257   \n",
       "1           0.313688 -2.988467 -2.249053 -0.310629 -1.294447  0.493878   \n",
       "2           0.651966 -0.739420 -1.775488 -0.771131 -0.893785 -0.094902   \n",
       "3           0.406378 -0.691514 -0.938161 -0.909334 -1.421630  0.366591   \n",
       "4           0.825582 -1.463795  0.019583 -0.414006 -1.238549 -0.730656   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.426982  0.189514 -0.027883 -0.664231 -0.542474 -0.997227   \n",
       "7996        1.133761 -0.656600 -0.729101 -0.993561 -0.816158 -0.759818   \n",
       "7997       -0.224306 -3.021560 -0.316375 -1.812170 -1.399482 -0.690235   \n",
       "7998        0.214557 -1.254312 -0.342507 -1.243187 -0.772811 -0.328504   \n",
       "7999        1.094662 -2.628002 -2.133445 -1.173548 -0.527974 -2.184086   \n",
       "\n",
       "parameters    d.67.2    d.68.2    d.69.2    d.70.2    d.71.2    d.72.2  \\\n",
       "draws                                                                    \n",
       "0           1.700662 -1.591544  0.540250  1.206184  2.155288 -0.881434   \n",
       "1           2.041244 -2.328988 -0.758306  1.074864  1.544826 -0.536788   \n",
       "2           2.111888 -2.016509  0.049680 -0.194395  2.198106  0.426496   \n",
       "3           1.600454 -0.558606 -0.423601  1.079119  2.141309 -0.796653   \n",
       "4           1.642916 -0.207779 -1.260039  0.926034  1.535006 -0.469058   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.106505 -0.808882  0.215036  1.016699  1.974719 -1.465513   \n",
       "7996        2.273229  0.012036  0.221849  1.697521  1.529452 -1.865273   \n",
       "7997        1.972575 -1.110901 -0.437143  0.747419  1.577340  0.396693   \n",
       "7998        0.178469 -1.114676 -0.357569  1.569685  1.394886 -0.496901   \n",
       "7999        2.314295 -0.044535  0.426907  1.276087  2.041356 -0.580856   \n",
       "\n",
       "parameters    d.73.2    d.74.2    d.75.2    d.76.2    d.77.2    d.78.2  \\\n",
       "draws                                                                    \n",
       "0          -1.979262 -1.131675 -0.059214  0.188151  0.168931  0.770779   \n",
       "1          -1.047699 -2.175849 -0.841033  0.418474  0.656621  0.225106   \n",
       "2          -2.033557 -0.565892  0.241965 -0.659793  0.189951  0.389631   \n",
       "3          -1.205870 -0.655096  0.140854 -0.864112  0.146486  0.423738   \n",
       "4          -0.263767 -1.022944 -0.330201 -0.777267  0.495756  0.599326   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.605051 -1.078684 -0.240947 -1.797558 -0.066982  0.642976   \n",
       "7996       -0.994079  0.964742 -0.065709 -0.747230  0.560049  0.865027   \n",
       "7997       -1.558119 -1.265593  0.235670 -1.032503  0.534532  0.851731   \n",
       "7998       -0.277345 -1.733904  0.387629 -0.252365  0.883467  0.396047   \n",
       "7999       -1.524300 -1.832469  0.361346 -0.510415 -0.739994  0.741897   \n",
       "\n",
       "parameters    d.79.2    d.80.2    d.81.2    d.82.2    d.83.2    d.84.2  \\\n",
       "draws                                                                    \n",
       "0           0.798052  1.574913  2.636296 -0.588122  0.063725  0.586565   \n",
       "1          -0.287726  0.834005  1.842159 -0.317446  0.048699  0.054294   \n",
       "2           0.442904 -0.109351  1.504604 -0.183342 -0.190953 -0.663065   \n",
       "3           0.457416  0.384942  2.122979 -0.814370 -1.643274 -1.155211   \n",
       "4           0.036934 -0.624992  1.910831 -0.536340 -1.555291 -1.388737   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.590408  0.497715  2.131639 -0.321352  0.165624  0.571824   \n",
       "7996        0.271875 -0.059266  2.158119 -0.650199  1.087680 -0.900721   \n",
       "7997       -0.159740 -0.452116  1.883062 -1.312784 -1.303237 -0.648713   \n",
       "7998        0.854566 -0.010155  2.172472 -0.271898  0.461900 -0.082696   \n",
       "7999        0.207209  0.372514  1.688991 -0.058066 -0.598264 -0.255620   \n",
       "\n",
       "parameters    d.85.2    d.86.2    d.87.2    d.88.2    d.89.2    d.90.2  \\\n",
       "draws                                                                    \n",
       "0          -2.171017 -0.849017 -0.634851  0.769110  0.364261  0.615412   \n",
       "1          -0.951299 -1.480662 -1.622520 -0.082109 -0.608555 -0.934286   \n",
       "2          -0.791255  0.169196 -0.656104  0.793585 -1.156464  0.888753   \n",
       "3          -0.916929 -0.860115  0.415502 -0.087669 -0.243177 -0.492062   \n",
       "4          -0.734118 -1.335301 -0.742745  0.241108 -2.285619 -1.703257   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.157328 -0.228136 -1.693766  0.980970 -0.857211 -1.092012   \n",
       "7996       -0.778715 -0.198539 -1.870493  1.026767  0.005037 -0.318284   \n",
       "7997       -0.986807 -1.213012 -0.609747  0.413537 -0.778495 -0.911193   \n",
       "7998       -1.084661 -0.768776 -0.577243  0.075295 -0.425470 -0.221454   \n",
       "7999       -0.876752 -0.768212 -1.400823  0.636386 -0.156903 -1.455888   \n",
       "\n",
       "parameters    d.91.2    d.92.2    d.93.2    d.94.2    d.95.2    d.96.2  \\\n",
       "draws                                                                    \n",
       "0           2.759990  0.235333 -1.917690  0.185871  0.729079  0.624729   \n",
       "1           3.344405 -0.220055 -2.133894  0.201654  0.260088 -0.321333   \n",
       "2           2.505736  0.809516 -0.299119 -0.269930  0.245396 -0.034337   \n",
       "3           2.479289 -0.251501 -0.477305 -0.289557  0.404947 -0.156275   \n",
       "4           2.406761  0.693531 -1.219720 -2.186469  0.206730  0.396434   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.712574  0.460772 -3.041883 -1.357169  0.678533 -0.430885   \n",
       "7996        2.474171  1.862045 -0.378896 -1.051060  0.194005  0.819300   \n",
       "7997        2.444710 -0.243546 -2.007294 -0.508414  0.362903  0.197385   \n",
       "7998        3.038567 -0.014987 -1.000803 -0.908763  1.141257  0.881157   \n",
       "7999        2.664730  0.114984  0.495348 -0.727089  0.470822 -0.063742   \n",
       "\n",
       "parameters    d.97.2    d.98.2    d.99.2   d.100.2   d.101.2   d.102.2  \\\n",
       "draws                                                                    \n",
       "0           1.397623  0.972696 -0.573830  0.872325  0.814499 -0.876818   \n",
       "1           0.981599  1.319900 -0.904057  0.561052  1.012550 -0.384813   \n",
       "2           1.077155  0.587455 -1.264229  0.035904  0.405700 -1.088148   \n",
       "3           0.627674  0.782390 -0.124779  1.138594  1.362796  0.025888   \n",
       "4           0.773678  0.766135  0.019931  0.344842  0.581571  0.246829   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.561432  0.377032 -0.456671  0.375580  0.766604 -0.213509   \n",
       "7996        2.044768  1.085268 -0.109828 -0.782651  1.258919  0.363205   \n",
       "7997        1.717920  1.151295 -0.854115  0.655910  0.503145 -1.589895   \n",
       "7998        1.301769  0.531111 -0.556883 -0.046752  1.100571  0.225031   \n",
       "7999        1.517542  1.441675 -0.406812  0.710195  0.496591  0.186350   \n",
       "\n",
       "parameters   d.103.2   d.104.2   d.105.2   d.106.2   d.107.2   d.108.2  \\\n",
       "draws                                                                    \n",
       "0          -1.158053  0.901152  0.104327 -1.185266  0.028245  0.501512   \n",
       "1          -0.831868 -0.616652 -0.065111 -1.701120 -0.195199  0.494392   \n",
       "2          -1.725981 -0.459666 -0.279853 -1.113187  0.325578  0.456590   \n",
       "3           0.556024  0.362843 -0.151986 -1.407888 -0.475213  0.234022   \n",
       "4          -1.274155 -1.781746 -0.283705 -1.055850 -0.255025  0.454014   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.601295 -0.848659 -0.136543 -0.920087  0.381922  0.349931   \n",
       "7996       -1.358838 -0.950119 -0.624081 -0.881394  0.800182  0.126781   \n",
       "7997       -0.767036 -0.628567 -0.992081 -1.238032 -0.414063  0.096794   \n",
       "7998       -0.020343 -0.452774  0.217775  0.014881  0.514403 -0.031223   \n",
       "7999       -0.582011 -0.550010 -0.925803 -1.670551  0.549442  0.583078   \n",
       "\n",
       "parameters   d.109.2   d.110.2   d.111.2   d.112.2   d.113.2   d.114.2  \\\n",
       "draws                                                                    \n",
       "0          -0.826979 -0.484411 -1.392443 -2.027127 -2.419008  0.891120   \n",
       "1          -0.821257  0.250390 -1.994981 -0.457766 -1.889423  0.538076   \n",
       "2          -1.895779 -0.420479  0.414671 -1.970949 -1.365360  0.689748   \n",
       "3          -1.487771  0.538155 -1.581122 -2.204580 -1.129102  0.693692   \n",
       "4          -0.460979  0.647283  0.242282 -0.345305 -0.664734  0.463897   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.011542  0.202610 -0.466574 -2.041902 -0.496363  1.042316   \n",
       "7996       -1.420866  1.120321  0.766081 -1.414625 -1.005716  0.712070   \n",
       "7997       -0.047765  0.259382  0.627366 -1.220467 -2.864618  0.473441   \n",
       "7998       -0.438408  0.243332  0.855018 -0.662348 -1.311637  1.118934   \n",
       "7999       -2.052521  0.282998 -0.849072 -2.347939 -2.227451  0.957984   \n",
       "\n",
       "parameters   d.115.2   d.116.2   d.117.2   d.118.2   d.119.2   d.120.2  \\\n",
       "draws                                                                    \n",
       "0           0.902224 -1.534668  0.071720  2.125181  0.444977  0.829271   \n",
       "1           1.584238 -0.865543  0.486495  1.859150  0.367981 -0.741168   \n",
       "2           0.520732 -1.348000 -0.218094  1.360800 -0.582414 -0.635292   \n",
       "3           1.455942  0.050325 -0.381196  2.290702 -0.033701 -1.097867   \n",
       "4           1.195348 -0.579877 -0.186671  1.843797 -0.364136 -1.249263   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.404857 -1.593709 -0.116089  1.728275 -1.909610 -0.650960   \n",
       "7996        1.515050 -0.292567 -0.880612  1.620766 -0.408044 -0.188442   \n",
       "7997        1.010430 -0.967070  0.431183  2.150943  0.128237 -0.088388   \n",
       "7998        1.619262 -0.233100  0.318896  2.175789 -0.662665  0.379576   \n",
       "7999        0.976598 -1.024141  0.651960  1.424898  0.214859  0.583195   \n",
       "\n",
       "parameters   d.121.2   d.122.2   d.123.2   d.124.2   d.125.2   d.126.2  \\\n",
       "draws                                                                    \n",
       "0           0.498280 -2.217583  0.149562 -1.739366 -0.700133 -0.536904   \n",
       "1          -0.312366 -1.602764 -2.128115 -3.136659 -0.668109 -0.530141   \n",
       "2          -0.201325 -0.974176 -0.822967 -1.546810 -1.012310 -0.350520   \n",
       "3          -0.199315  0.151029 -0.965072 -1.626675 -0.737451 -1.198711   \n",
       "4           0.514800 -0.568542 -1.070019 -1.498215 -0.934520 -1.295658   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.947501 -1.300341 -1.109327 -0.737327  0.527147 -1.412024   \n",
       "7996        0.703844  0.126359 -0.737960 -1.232666 -0.413096 -1.568170   \n",
       "7997        0.331423 -0.666064 -0.466363 -2.056667 -0.756405 -0.552871   \n",
       "7998        0.266500 -1.273795 -0.967866 -0.744889  0.317764  0.052293   \n",
       "7999       -0.521198 -2.176597 -1.066422 -3.179731 -1.589218 -1.066860   \n",
       "\n",
       "parameters   d.127.2   d.128.2   d.129.2   d.130.2   d.131.2   d.132.2  \\\n",
       "draws                                                                    \n",
       "0           1.685650 -0.965166  0.534942  0.131648  0.772165 -0.251955   \n",
       "1           1.916003 -0.905756  0.165666 -0.512481  0.620156 -0.434398   \n",
       "2           1.733075 -1.482966 -0.097708  0.468820  0.921853 -0.353141   \n",
       "3           1.369650 -1.320638 -0.178111 -1.604276 -0.024628 -1.164171   \n",
       "4           1.673780 -0.691264 -0.071252 -1.397232 -0.320283 -0.634016   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.024745 -0.867578  0.321822 -1.240001  0.578598 -1.034443   \n",
       "7996        1.997037 -0.750763 -1.009542  0.283616  1.497113 -0.390785   \n",
       "7997        1.811963  0.033560  0.401168 -0.665909  0.769560 -1.130200   \n",
       "7998        1.352271  0.163264 -1.025436 -0.331808  1.614888  0.076428   \n",
       "7999        2.000307 -0.855088  0.122763 -1.966257  0.112275 -0.943196   \n",
       "\n",
       "parameters   d.133.2   d.134.2   d.135.2   d.136.2   d.137.2   d.138.2  \\\n",
       "draws                                                                    \n",
       "0          -1.203110 -0.270931  0.308548 -0.971057  1.286603  1.028479   \n",
       "1          -0.125748 -0.433512  0.219186 -0.012957  1.961079  0.630240   \n",
       "2           0.855872  0.910540  0.374883 -0.307956  1.452923  1.208596   \n",
       "3          -0.367747 -0.588743  0.032290  0.216875  0.929240  1.306337   \n",
       "4           2.113779 -0.047233  0.606973 -0.375252  0.979778  1.109684   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.136397 -0.797087  0.305660 -0.504389  0.425315  0.776376   \n",
       "7996        0.390243  1.226924  0.705743 -0.523277  0.427049  1.994738   \n",
       "7997       -0.885456  0.205154  0.449947 -0.462782  1.068344  1.227803   \n",
       "7998        0.556701  0.901914  0.348914 -1.721968  1.400576  0.515078   \n",
       "7999        0.888617 -1.310420  0.440986 -0.832827  0.037639  0.302465   \n",
       "\n",
       "parameters   d.139.2   d.140.2   d.141.2   d.142.2   d.143.2   d.144.2  \\\n",
       "draws                                                                    \n",
       "0          -0.319157 -0.675549 -1.448762 -0.201693  0.544469 -0.409019   \n",
       "1           0.236783 -1.036200 -1.904449  0.728275  0.217311 -0.539903   \n",
       "2          -0.123460  0.177124 -1.253447  0.487351  1.127023 -0.437936   \n",
       "3          -0.022692  0.474577 -1.346977  0.213500  0.422193 -0.723892   \n",
       "4           0.355278 -1.062198 -0.925620 -0.655785  0.602764 -1.194188   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.420396 -0.083177 -2.033573  0.522294  1.122542 -0.566058   \n",
       "7996        0.011029  0.156425 -0.038532  1.232709  1.797695 -1.310509   \n",
       "7997       -0.241841 -0.095055 -1.045202 -0.016834  0.540644 -0.399775   \n",
       "7998        0.363892 -0.087531 -1.237460  0.433759  1.557273 -0.822598   \n",
       "7999        0.250897 -0.590912 -0.448874  0.043299  0.023526 -0.469981   \n",
       "\n",
       "parameters   d.145.2   d.146.2   d.147.2   d.148.2   d.149.2   d.150.2  \\\n",
       "draws                                                                    \n",
       "0          -0.475749  1.286180  1.467181  0.712206 -1.522892  0.274069   \n",
       "1           0.254554  0.121272 -0.196726  1.326284 -1.717327 -0.418766   \n",
       "2           0.322642  1.851944  0.468717  0.281103 -0.747660 -1.440229   \n",
       "3           0.145597  0.420691 -0.061876  0.124820 -0.755186  0.340293   \n",
       "4          -0.417409  1.024592  0.002323  0.933128 -1.407486 -0.536895   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.482305  1.832744  1.469187 -0.040361 -0.324278 -0.730243   \n",
       "7996        0.743365  1.470108  0.690028 -0.101309 -1.584427  0.089441   \n",
       "7997       -0.076919  0.957211  1.135551  0.671821 -1.093172 -0.903629   \n",
       "7998       -0.090792  1.406213 -0.206822  1.117272 -0.587932 -0.755018   \n",
       "7999        0.533730  0.933376  0.190090  0.944822 -0.240741  0.112141   \n",
       "\n",
       "parameters   d.151.2   d.152.2   d.153.2   d.154.2   d.155.2   d.156.2  \\\n",
       "draws                                                                    \n",
       "0          -0.064592 -0.704005  1.158432 -0.538718  0.718904  1.542056   \n",
       "1           0.875707 -0.533835  1.214761 -0.014235 -0.020398  1.228133   \n",
       "2          -0.582532 -1.041456  0.528289 -1.113614 -1.604985  0.410432   \n",
       "3           0.700933 -0.811333  1.016883 -0.285441  0.082713  0.760238   \n",
       "4          -0.096199 -0.891068  0.923379 -0.593660 -0.725371  1.719332   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.789079 -0.716367  0.701772 -0.255326 -0.393352  1.192755   \n",
       "7996        0.332539 -0.672748  0.304657  0.242268 -0.498435  0.974144   \n",
       "7997        0.518734  0.400544  0.493768 -1.285202 -0.207447  0.304319   \n",
       "7998        0.273241 -0.390826  1.062657 -0.664119 -0.250758  1.082510   \n",
       "7999       -0.256173 -0.141466  0.436221 -0.855547  0.263996  1.553899   \n",
       "\n",
       "parameters   d.157.2   d.158.2   d.159.2   d.160.2   d.161.2   d.162.2  \\\n",
       "draws                                                                    \n",
       "0          -0.282974  1.625056  0.764848 -0.967903  0.343737  0.335851   \n",
       "1          -0.630038  1.023471  0.233753 -0.446556  0.622241  0.567681   \n",
       "2          -1.174740  0.621560  0.184275 -0.512109  0.478356 -0.077871   \n",
       "3           0.408371  0.824966 -0.053113 -1.661701  0.003384  0.067356   \n",
       "4          -0.930009  0.698971  0.925840 -0.792566  1.131312  0.345582   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.483635  0.744872  0.700571 -0.770126  0.544596 -0.292172   \n",
       "7996       -0.138297  0.855552  0.019076 -1.107074  1.374147  0.056577   \n",
       "7997       -0.169084  0.724919  0.324934 -0.792374  0.350685 -0.693004   \n",
       "7998        0.388175  1.424376 -0.005761 -0.967037  0.540612 -0.550632   \n",
       "7999        0.394995  0.886407  0.715805 -0.986045  1.101694  0.245380   \n",
       "\n",
       "parameters   d.163.2   d.164.2   d.165.2   d.166.2   d.167.2   d.168.2  \\\n",
       "draws                                                                    \n",
       "0          -0.888741 -1.083211 -2.482604 -1.566305 -2.765838 -1.423123   \n",
       "1           0.247804  0.168492 -2.227211 -2.285791 -0.229820 -0.999006   \n",
       "2           0.025188 -0.694211 -1.623864 -2.182725 -0.812769 -0.678495   \n",
       "3           0.241603 -0.341178 -1.682661 -1.593771 -2.801984 -0.249685   \n",
       "4           0.335430  1.205531 -1.470317 -0.966938 -0.016824  0.000601   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.547082 -0.857410 -3.624099 -1.063880 -0.926626 -1.274943   \n",
       "7996       -0.861870 -0.197714 -2.194602 -0.799662  0.445435 -1.577665   \n",
       "7997        0.731830 -0.279054 -2.090296 -0.737854 -1.307197 -0.178043   \n",
       "7998       -0.642900  0.123557 -1.029898 -1.469545 -1.089267  0.137719   \n",
       "7999        0.522098  0.360770 -0.600633 -1.699228 -1.244922 -0.969734   \n",
       "\n",
       "parameters   d.169.2   d.170.2   d.171.2   d.172.2   d.173.2   d.174.2  \\\n",
       "draws                                                                    \n",
       "0          -0.515561  0.705060  1.104969  0.943062  1.214606  1.540100   \n",
       "1          -0.222203 -0.058653  0.816776  1.065903  0.873870  1.195579   \n",
       "2          -0.725284  0.318695  1.338188  1.023823  0.592029  0.473331   \n",
       "3          -1.072054  0.261871  1.318973  1.124013  1.274171 -0.239723   \n",
       "4          -0.774624 -0.193286  0.894797  1.273448  0.150215  0.313529   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -1.332040 -0.742028  0.294205  0.281023  1.286825  0.381482   \n",
       "7996       -2.120222  1.038871  1.309408  1.121732  0.619259  0.615866   \n",
       "7997        0.059895  0.268465  1.227153  1.179970  0.657738  0.507997   \n",
       "7998       -0.127648  0.610036  1.386465  1.191618  0.837197  1.414060   \n",
       "7999       -0.505642  1.403915  0.521016  0.583177  0.667918  0.666286   \n",
       "\n",
       "parameters   d.175.2   d.176.2   d.177.2   d.178.2   d.179.2   d.180.2  \\\n",
       "draws                                                                    \n",
       "0           1.260473  0.586064 -0.221391 -1.429163  2.778557 -1.307140   \n",
       "1           1.832619  0.588293 -0.140352 -0.518000  2.992880 -1.891376   \n",
       "2           1.819037  1.151643  0.635531 -0.035871  3.172655 -1.647880   \n",
       "3           1.611977  0.722854 -0.540485 -0.842954  2.697070 -1.563581   \n",
       "4           1.629638  1.147445  0.705181 -0.356471  3.419476 -1.160626   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.440165  1.234699 -0.920676 -0.709399  3.313163 -1.694287   \n",
       "7996        1.494315  1.014587 -0.159738  0.056722  2.786219 -1.648797   \n",
       "7997        1.300510  0.744733  0.137255 -0.288246  3.178910 -1.016994   \n",
       "7998        2.084938  1.004954 -0.320494 -0.264041  3.219583 -2.723561   \n",
       "7999        1.390074  1.094701 -0.286147 -0.802538  2.988857 -0.922426   \n",
       "\n",
       "parameters   d.181.2   d.182.2   d.183.2   d.184.2   d.185.2   d.186.2  \\\n",
       "draws                                                                    \n",
       "0           1.131804 -0.912495  0.407278  0.165395  0.711644  0.830489   \n",
       "1          -0.232077  0.828834  1.734091  0.745560  0.002858  0.209474   \n",
       "2           0.568607  0.186810  0.742029  0.707849 -1.231651  0.325528   \n",
       "3           0.423657  1.159921  1.513039  0.318943  0.490161  1.272885   \n",
       "4          -0.252537  1.491922  1.006057 -0.345155 -0.117146  0.366227   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.691302  0.810359  1.600314  0.918687 -1.238990  0.894379   \n",
       "7996        0.226457  0.421815  0.384962 -0.020888 -0.075077 -0.519901   \n",
       "7997       -0.013298  0.518061  1.315176  0.630037  0.947325  0.789198   \n",
       "7998        0.739760 -0.754138  0.631280  0.654567  0.248614  0.339136   \n",
       "7999        0.387522 -0.021878  1.686917  1.002716  1.807899 -0.142853   \n",
       "\n",
       "parameters   d.187.2   d.188.2   d.189.2   d.190.2   d.191.2   d.192.2  \\\n",
       "draws                                                                    \n",
       "0           0.065718 -1.394407  0.050084 -1.180450  0.281375  0.711544   \n",
       "1          -0.965160 -1.746685 -0.172151 -1.022799 -0.375388  0.663510   \n",
       "2          -0.304331 -1.135296 -0.459064 -2.277352  0.300520 -0.383516   \n",
       "3           0.945118  0.255556 -1.538679 -0.958572  0.292473 -0.434004   \n",
       "4           0.208760 -1.001146 -2.078865 -1.236059  0.069649 -2.290134   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.719688 -0.795664 -1.368401 -0.841390  0.854525  0.067995   \n",
       "7996       -0.038840 -1.758287 -1.005028 -1.716306  0.067075  0.085300   \n",
       "7997        0.602985  0.420535 -0.363544 -1.193731  0.747783 -0.205215   \n",
       "7998       -0.403282 -0.721593 -0.979750 -0.679552  0.123943 -0.298757   \n",
       "7999        1.134942 -0.475097  0.369309 -0.791673 -0.120178 -0.594971   \n",
       "\n",
       "parameters   d.193.2   d.194.2   d.195.2   d.196.2   d.197.2   d.198.2  \\\n",
       "draws                                                                    \n",
       "0          -0.250984 -1.125969  2.660668  3.260381  2.120481  0.708997   \n",
       "1           0.001541 -2.994416  2.151111  3.722023  2.912947  0.819212   \n",
       "2          -0.388054 -2.439767  1.873550  3.109859  2.301276  0.479438   \n",
       "3           0.259849  0.047386  2.489027  3.647330  2.698886  2.188395   \n",
       "4           0.126157 -0.694779  2.003405  3.618411  2.377286  1.102849   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.546375  0.186418  2.695565  3.062319  1.936745 -0.062617   \n",
       "7996       -0.189828 -1.493099  2.319321  3.304625  2.037017  0.392865   \n",
       "7997       -0.017870 -0.449574  1.878417  2.956714  2.347069  1.121160   \n",
       "7998       -0.124049 -1.617468  2.457797  2.817357  2.300969  0.845116   \n",
       "7999       -0.101797 -1.446295  2.453492  3.070942  2.712284  0.626638   \n",
       "\n",
       "parameters   d.199.2   d.200.2   d.201.2   d.202.2   d.203.2   d.204.2  \\\n",
       "draws                                                                    \n",
       "0          -0.417644  0.211326 -0.661747 -1.461634 -1.246105 -0.685126   \n",
       "1          -0.214714 -0.548075 -1.132913 -2.623694  0.759224 -1.479217   \n",
       "2          -1.011960 -0.102235 -1.269992 -0.920845 -0.635908 -0.916363   \n",
       "3          -0.165130  0.603447 -0.296857 -2.968631 -0.298460 -0.458311   \n",
       "4           0.234373  0.509235 -1.009023 -0.456700 -0.618851 -0.708283   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.742697 -0.185129 -2.177635 -1.181660 -0.190314 -1.354935   \n",
       "7996        0.598807 -0.147980 -0.828719 -2.424984 -0.738788 -1.233997   \n",
       "7997        0.203047 -0.187159 -0.558691 -1.896125 -1.716248 -1.731939   \n",
       "7998        0.183681  0.074542 -0.667359 -0.796434  0.412470 -0.171157   \n",
       "7999       -0.147062 -0.330751 -1.239885 -1.186865 -1.084925 -1.153490   \n",
       "\n",
       "parameters   d.205.2   d.206.2   d.207.2   d.208.2   d.209.2   d.210.2  \\\n",
       "draws                                                                    \n",
       "0          -0.978777 -2.028239  0.383003  0.328637  0.440221  2.123995   \n",
       "1          -0.268732 -1.013318  0.767190  0.986224 -0.908374  3.382700   \n",
       "2          -0.461461 -1.384890  0.260657  0.267789 -1.116232  2.203712   \n",
       "3           0.114466 -0.506006  0.422122  0.389833  0.264970  2.232056   \n",
       "4          -0.749282 -0.750049  0.695744  0.839485 -1.201910  1.971815   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.344484 -1.955473 -0.279924  0.224604 -0.997600  2.454962   \n",
       "7996       -0.728549 -1.475206  0.565838  0.627073 -0.382933  2.634494   \n",
       "7997       -0.505088 -1.179558 -0.132280 -0.219779 -0.918663  2.526274   \n",
       "7998       -1.367766 -1.477385  0.088197  0.772771 -0.321854  1.852506   \n",
       "7999       -0.284701 -1.971844  0.780027  0.413461 -0.589502  2.514612   \n",
       "\n",
       "parameters   d.211.2   d.212.2   d.213.2   d.214.2   d.215.2   d.216.2  \\\n",
       "draws                                                                    \n",
       "0           0.291677 -0.129702  0.192246 -1.929378 -2.058755  0.877348   \n",
       "1          -0.817762  0.434608 -0.757652 -1.342170 -0.929494 -1.825342   \n",
       "2          -1.417201 -0.062162 -0.194422 -0.875384 -1.072115 -0.351344   \n",
       "3           0.317945 -0.736926 -0.543927 -2.914152  0.086918 -2.197926   \n",
       "4          -0.711305 -0.730514  0.284711 -0.576796 -0.054767 -2.196403   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.049400 -0.706331 -0.245401 -1.817734  0.209763 -0.698237   \n",
       "7996       -0.395835 -0.086640  0.571673 -1.192801 -0.920520  0.503218   \n",
       "7997       -0.276009 -1.072990 -0.079417 -1.171386 -0.952078 -0.354013   \n",
       "7998       -1.184308 -0.154671 -0.361259 -0.947908 -1.931221  0.142392   \n",
       "7999       -0.433468 -0.147332 -0.047645 -0.511363 -1.248252 -0.050855   \n",
       "\n",
       "parameters   d.217.2   d.218.2   d.219.2   d.220.2   d.221.2   d.222.2  \\\n",
       "draws                                                                    \n",
       "0          -0.975529 -0.480067 -0.148748  0.320977 -1.573940  0.004883   \n",
       "1           0.522749 -0.258936 -0.796161 -0.967626  0.071852 -1.237557   \n",
       "2          -0.729674  0.136110 -1.285649 -0.290868 -0.649544 -0.585311   \n",
       "3          -0.754403 -0.265569 -0.758413 -0.866742 -0.887874 -1.059580   \n",
       "4          -0.851484 -0.167122 -2.328930 -0.290622  0.471571 -0.785688   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.516894  0.441319 -1.507942 -0.480132 -1.188236 -0.186589   \n",
       "7996       -1.451996 -0.529270 -0.597310  0.457543  0.198796 -0.451816   \n",
       "7997       -1.106541 -0.800179 -1.688383  0.411297  0.068776 -0.043688   \n",
       "7998        0.499001 -0.335048 -1.326935 -0.129501  0.554625 -0.030821   \n",
       "7999       -1.604284 -0.143100 -0.989950  0.157548 -0.527584 -0.374693   \n",
       "\n",
       "parameters   d.223.2   d.224.2   d.225.2   d.226.2   d.227.2   d.228.2  \\\n",
       "draws                                                                    \n",
       "0           2.126219 -1.137512 -0.343807 -1.592137 -3.344302  0.106834   \n",
       "1           2.886336  1.123994  0.986919 -2.355214 -1.986252  0.002337   \n",
       "2           2.382519  0.013212 -0.648691 -2.519820 -3.327208 -0.605606   \n",
       "3           2.660915  0.222031 -0.318154 -1.519767 -1.998313 -0.659891   \n",
       "4           3.012218  0.284497  0.470605 -1.693588  0.088708 -2.321166   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        2.428046 -1.389688 -0.842454 -2.011715 -0.835351 -1.849395   \n",
       "7996        1.971045 -0.275179 -0.266044 -0.549209 -2.784886 -1.818003   \n",
       "7997        3.103205 -0.251027  0.345895 -1.900012 -1.252985  0.327173   \n",
       "7998        2.250505 -0.872338 -0.156063 -2.030459 -1.782128 -1.364034   \n",
       "7999        3.214366  0.336465  0.117335 -2.289326 -0.765015  0.210249   \n",
       "\n",
       "parameters   d.229.2   d.230.2   d.231.2   d.232.2   d.233.2   d.234.2  \\\n",
       "draws                                                                    \n",
       "0           0.409979 -1.649416 -1.246516 -2.073836 -0.414237  0.623414   \n",
       "1           1.478176 -1.497158 -2.717949 -0.460896 -0.343902  0.387031   \n",
       "2           0.657276 -0.764912 -1.529091 -0.464301 -0.987403  0.249460   \n",
       "3           0.443073 -1.425315 -2.265424 -0.574146 -1.072758  0.152303   \n",
       "4           1.689323 -1.285264 -2.327423  0.113773 -0.578767 -0.155903   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.651426 -3.437734 -1.431448 -0.079648  0.129953 -0.318190   \n",
       "7996        0.754537 -2.459061 -0.948889 -0.122237 -0.599000 -0.205590   \n",
       "7997        1.205824 -1.500833 -1.013870 -0.580671  0.268473  1.001412   \n",
       "7998        0.892138 -1.655399 -2.289551 -1.228897 -1.349560  0.456579   \n",
       "7999        1.336974 -1.461884 -1.553816  1.036128 -0.514884  0.623252   \n",
       "\n",
       "parameters   d.235.2   d.236.2   d.237.2   d.238.2   d.239.2   d.240.2  \\\n",
       "draws                                                                    \n",
       "0           0.729944  0.212326  0.306756 -0.724423 -0.481775  0.351584   \n",
       "1           0.874117 -1.255285  0.850116  0.262899  0.918133  0.174630   \n",
       "2           0.040108 -0.405501  0.119645  0.062958  0.058074  0.660944   \n",
       "3           1.298401  0.033426  0.798501  0.135906 -0.435261  0.994211   \n",
       "4           0.729797 -0.949282  0.776537  0.555408  0.581477  0.719721   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.275246 -0.352045  0.801457 -1.751329  0.931245  1.041881   \n",
       "7996        0.162009 -1.144899  0.057355  0.151165 -0.005953  0.469794   \n",
       "7997        0.653245 -0.910198  0.405626  0.134694  0.222358  0.362797   \n",
       "7998        0.455732 -1.041456 -0.110932 -0.431590 -0.355509  0.839867   \n",
       "7999       -0.145852 -1.816336  1.211782 -1.981082 -0.114095  0.381721   \n",
       "\n",
       "parameters   d.241.2   d.242.2   d.243.2   d.244.2   d.245.2   d.246.2  \\\n",
       "draws                                                                    \n",
       "0           0.024571 -1.742430 -0.034099 -1.408129 -1.855687  2.943547   \n",
       "1           0.074729  0.182737  0.701624 -0.333052 -2.780317  2.559273   \n",
       "2           0.414998 -0.933531  0.273428 -0.654104 -2.225361  2.340402   \n",
       "3           0.085728 -1.916516  0.227499 -0.295370 -1.805540  3.262731   \n",
       "4           0.472878 -0.096230  0.149690  0.351422 -0.742504  2.345160   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.690224 -0.433844  0.545124 -0.594270 -1.397727  2.254061   \n",
       "7996       -0.136887 -0.622735  0.506993 -1.725073 -2.303547  2.522296   \n",
       "7997        0.253234 -1.150502  0.362833  0.084260 -0.140945  2.336074   \n",
       "7998        0.532492  0.020230 -0.660341 -0.983935 -1.692103  2.331987   \n",
       "7999        0.388906 -1.082455  0.793981 -0.156388 -1.790473  2.721288   \n",
       "\n",
       "parameters   d.247.2   d.248.2   d.249.2   d.250.2   d.251.2   d.252.2  \\\n",
       "draws                                                                    \n",
       "0           0.175205 -0.446971  1.040963  0.493902  1.460997  0.658713   \n",
       "1           0.591683 -0.904230 -0.802679  0.442071  1.302161  1.038088   \n",
       "2          -0.271763 -0.265614 -1.062281  0.570357  1.231388  0.734230   \n",
       "3          -0.027009 -0.646414 -0.235491  0.517444  1.124515  1.563672   \n",
       "4           0.284957 -0.442649 -1.983393  0.649834  0.953195  0.678349   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.532189 -0.001458 -1.023834  0.337781  1.208348  0.657064   \n",
       "7996       -0.189288  0.075617 -1.579720  0.394466  0.658677  0.550848   \n",
       "7997       -1.057732 -0.131052 -0.638184 -0.049279  0.955746  0.263799   \n",
       "7998        0.381542 -0.232341 -0.624587  1.073637  0.982656  0.730721   \n",
       "7999        0.086614  0.055811 -0.183295  0.855538  1.501800  0.350615   \n",
       "\n",
       "parameters   d.253.2   d.254.2   d.255.2   d.256.2   d.257.2   d.258.2  \\\n",
       "draws                                                                    \n",
       "0          -0.728429  1.033550  0.487201  0.073883  1.385021  1.543426   \n",
       "1          -0.273732  0.075800 -0.089517 -1.497218 -0.042562  0.465946   \n",
       "2          -0.332030 -0.768671 -0.340577 -0.413781 -0.090259  0.531459   \n",
       "3          -0.597002 -0.411254  0.068529  0.490166  1.146550  0.890290   \n",
       "4          -1.079600 -0.716211 -0.029120 -0.109190  0.172565 -0.245101   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.952555 -0.213997  0.278301 -0.521551  1.076055  0.978732   \n",
       "7996       -1.647770 -0.943824 -0.005468 -0.791123 -0.090784  0.220893   \n",
       "7997       -2.600711  0.559386 -1.062654 -1.067797  1.196998  1.014862   \n",
       "7998       -1.429395  0.291138 -0.303486 -0.412409  0.755721  1.465066   \n",
       "7999       -0.105384 -0.176219 -0.309209 -0.416712  0.536362  0.613664   \n",
       "\n",
       "parameters   d.259.2   d.260.2   d.261.2   d.262.2   d.263.2   d.264.2  \\\n",
       "draws                                                                    \n",
       "0          -0.198463  1.363052  0.899085  0.787222 -0.467796 -0.339204   \n",
       "1           0.255969  1.349233 -0.602544  0.773614 -0.167299 -0.215360   \n",
       "2           0.339921  1.475874  0.186980  0.116336 -0.888419 -0.981854   \n",
       "3           0.656563  1.371729  1.374916  0.424188 -0.072711 -0.660392   \n",
       "4          -0.120989  1.263595  0.929777  0.527996  0.024496  0.426901   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.507640  1.640890 -0.260969  0.756040 -0.922523 -1.098445   \n",
       "7996        0.075235  1.204422  0.336578  0.412002 -0.581575 -1.234915   \n",
       "7997       -0.177225  1.206611  0.670574 -0.191743  0.257551 -0.853580   \n",
       "7998        0.630066  1.403412  0.512676 -0.830079 -0.512672 -0.302445   \n",
       "7999        0.482011  1.141798 -0.057254  0.577697 -1.226381  0.082574   \n",
       "\n",
       "parameters   d.265.2   d.266.2   d.267.2   d.268.2   d.269.2   d.270.2  \\\n",
       "draws                                                                    \n",
       "0           1.011570  2.179362  0.462325  0.518380  1.689338 -1.135146   \n",
       "1           0.533581  1.193901  0.578831  0.007105  1.235976 -0.686240   \n",
       "2           0.372697  1.036668  0.989350  0.140248  1.936599 -0.184384   \n",
       "3           1.144875  1.710621  0.801851 -0.101921  1.722850 -0.726182   \n",
       "4          -0.190330  1.205815  0.583818  0.095191  1.628391 -0.575251   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.085845  0.983436  1.516064  1.090084  1.575156 -0.952378   \n",
       "7996        0.252373  1.179109  0.772595  0.186038  1.898711 -0.102235   \n",
       "7997        0.081996  1.342232  1.091934 -0.522706  1.724846 -1.789593   \n",
       "7998       -0.466146  1.839556  1.076609  0.446778  1.558245 -0.744205   \n",
       "7999        0.212885  1.328764  0.712643 -0.009526  1.477282 -0.580575   \n",
       "\n",
       "parameters   d.271.2   d.272.2   d.273.2   d.274.2   d.275.2   d.276.2  \\\n",
       "draws                                                                    \n",
       "0           1.214546  0.967366  0.018015 -0.849670  2.319285 -2.312302   \n",
       "1           1.025943 -0.064920  0.294441 -1.627370  2.550657  0.324669   \n",
       "2           1.009690 -1.761441  0.038679  0.929813  3.029642 -0.371777   \n",
       "3           0.468370 -0.137550  0.027834 -0.074941  3.045187  0.978225   \n",
       "4           0.666299 -1.605922 -0.018630 -1.214314  2.439180 -0.244463   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.918275 -0.637056 -0.971134  0.966550  3.597453  0.358422   \n",
       "7996        1.103602 -1.475669 -1.025408  1.043777  3.110343 -0.755696   \n",
       "7997        0.384953 -0.878360 -0.312750  0.034876  2.781986  0.244941   \n",
       "7998        0.738909 -1.394410  0.432342  0.377223  2.964271 -0.627241   \n",
       "7999        0.643533 -1.670641 -0.000932  0.336736  2.653457  0.141986   \n",
       "\n",
       "parameters   d.277.2   d.278.2   d.279.2   d.280.2   d.281.2   d.282.2  \\\n",
       "draws                                                                    \n",
       "0           0.181650  0.979730 -0.546778  1.178315  1.191871  2.215565   \n",
       "1          -1.806238  0.601941 -0.881103  0.785675  0.817376  1.842704   \n",
       "2          -0.605579  0.758918 -0.813322  1.429388  0.821405  1.786340   \n",
       "3          -0.741544  1.734488 -0.922457  1.059719  0.847862  1.404117   \n",
       "4          -2.140579  1.568572 -0.288285  0.469678  0.215252  1.315098   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        0.110659  1.031254 -0.302844  1.651601  1.917125  1.546345   \n",
       "7996       -1.228132  1.101603 -1.301240  1.196725  0.880152  1.633261   \n",
       "7997       -0.342767  1.732006 -1.290590  1.656650  1.347485  2.333681   \n",
       "7998       -2.399944  1.624132 -0.659156  1.374274  1.462509  1.691212   \n",
       "7999       -1.208963  0.539859 -0.262439  1.399995  0.946046  2.065417   \n",
       "\n",
       "parameters   d.283.2   d.284.2   d.285.2   d.286.2   d.287.2   d.288.2  \\\n",
       "draws                                                                    \n",
       "0          -0.555225 -0.153763  1.160025 -0.191043 -1.147442 -0.135083   \n",
       "1           0.117498 -0.858874  1.385079  0.811318 -0.443309  0.932877   \n",
       "2          -0.011713  0.041697 -0.320574  0.742657 -0.900506  0.972276   \n",
       "3          -0.612160 -0.312050 -0.369391  0.988463  0.475415  0.657401   \n",
       "4          -1.479540 -0.830012  0.179096  0.884547  0.559770  0.686974   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.253397  0.089964 -0.281379  1.739010  0.506656  0.908107   \n",
       "7996       -1.810984 -0.016619  0.604358  1.241526  0.686810  0.511378   \n",
       "7997        0.074453 -0.431244 -0.063041  0.960761  0.177723  0.610666   \n",
       "7998       -0.793223 -0.414623  0.448220  0.735249  0.822697 -0.212738   \n",
       "7999        0.376548 -0.397774  0.770037  0.699635  0.399896  0.736960   \n",
       "\n",
       "parameters   d.289.2   d.290.2   d.291.2   d.292.2   d.293.2   d.294.2  \\\n",
       "draws                                                                    \n",
       "0          -1.017425 -1.585886  1.019367 -0.993318 -1.865278  0.179635   \n",
       "1           1.366346 -0.733987  1.201761  0.102663 -1.427353 -1.086705   \n",
       "2           0.648917 -0.856599  1.342793  0.406341 -2.066126  0.508002   \n",
       "3           0.670294 -1.673217  0.598089 -0.501381 -2.380531 -0.813756   \n",
       "4           2.283891 -1.299231  0.768752 -0.661651 -1.557291 -0.064821   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995        1.035577 -0.709105  1.692271  0.135749 -1.743576  1.470809   \n",
       "7996        1.102903 -1.801215  0.822762 -0.921722 -1.366757 -0.284381   \n",
       "7997        0.939410 -1.508207  1.006024 -0.439741 -2.370524  0.673120   \n",
       "7998        0.611116 -0.867961  0.674476 -0.911079 -2.391463  0.578134   \n",
       "7999        1.265587 -1.682670  0.901193 -0.052149 -2.194972 -0.000788   \n",
       "\n",
       "parameters   d.295.2   d.296.2   d.297.2   d.298.2   d.299.2   d.300.2  \\\n",
       "draws                                                                    \n",
       "0          -1.210420 -1.310323 -0.932329 -0.165565 -0.326398 -0.351877   \n",
       "1          -0.947648 -0.728064 -0.896277 -1.215933 -0.464430 -0.010734   \n",
       "2          -1.491883 -1.002621 -0.824764  0.287979 -0.322550  0.354632   \n",
       "3          -1.434926 -1.844910 -0.960422 -1.813581 -0.370514 -0.517408   \n",
       "4          -1.365178 -0.225597 -0.325457 -1.404999 -0.946618 -0.102321   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "7995       -0.821352 -2.076550 -0.763551 -0.629763 -0.849662 -0.091016   \n",
       "7996        0.199689 -0.493627 -0.223664 -0.668640  0.502052  0.182139   \n",
       "7997       -0.698782 -0.468041 -0.395909 -0.316111 -0.890346  0.393484   \n",
       "7998       -0.930497 -1.721426 -0.600573 -0.661857 -0.615139 -1.060428   \n",
       "7999       -0.256203  0.090471 -0.137904 -0.549669  0.346420 -0.806404   \n",
       "\n",
       "parameters  Rho_d.1.1  Rho_d.2.1  Rho_d.1.2  Rho_d.2.2  \n",
       "draws                                                   \n",
       "0                 1.0   0.865404   0.865404        1.0  \n",
       "1                 1.0   0.906667   0.906667        1.0  \n",
       "2                 1.0   0.893535   0.893535        1.0  \n",
       "3                 1.0   0.859748   0.859748        1.0  \n",
       "4                 1.0   0.799363   0.799363        1.0  \n",
       "...               ...        ...        ...        ...  \n",
       "7995              1.0   0.900839   0.900839        1.0  \n",
       "7996              1.0   0.860271   0.860271        1.0  \n",
       "7997              1.0   0.898567   0.898567        1.0  \n",
       "7998              1.0   0.864132   0.864132        1.0  \n",
       "7999              1.0   0.909428   0.909428        1.0  \n",
       "\n",
       "[8000 rows x 1273 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": az.summary(trace,round_to='none')['mean'],\n",
    "        \"pystan\": [df['a'].mean(),df['gr.1.1'].mean(),\n",
    "                   df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),   \n",
    "                   df['sigma'].mean(),                \n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),                   \n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha[0]',\n",
       " 'sigma_gr[0]',\n",
       " 'Rho_gr[0, 0]',\n",
       " 'Rho_gr[0, 1]',\n",
       " 'Rho_gr[1, 0]',\n",
       " 'Rho_gr[1, 1]',\n",
       " 'gr[0, 0]',\n",
       " 'gr[0, 1]',\n",
       " 'gr[1, 0]',\n",
       " 'gr[1, 1]',\n",
       " 'gr[2, 0]',\n",
       " 'gr[2, 1]',\n",
       " 'gr[3, 0]',\n",
       " 'gr[3, 1]',\n",
       " 'gr[4, 0]',\n",
       " 'gr[4, 1]',\n",
       " 'gr[5, 0]',\n",
       " 'gr[5, 1]',\n",
       " 'gr[6, 0]',\n",
       " 'gr[6, 1]',\n",
       " 'gr[7, 0]',\n",
       " 'gr[7, 1]',\n",
       " 'gr[8, 0]',\n",
       " 'gr[8, 1]',\n",
       " 'gr[9, 0]',\n",
       " 'gr[9, 1]',\n",
       " 'gr[10, 0]',\n",
       " 'gr[10, 1]',\n",
       " 'gr[11, 0]',\n",
       " 'gr[11, 1]',\n",
       " 'gr[12, 0]',\n",
       " 'gr[12, 1]',\n",
       " 'gr[13, 0]',\n",
       " 'gr[13, 1]',\n",
       " 'gr[14, 0]',\n",
       " 'gr[14, 1]',\n",
       " 'gr[15, 0]',\n",
       " 'gr[15, 1]',\n",
       " 'gr[16, 0]',\n",
       " 'gr[16, 1]',\n",
       " 'gr[17, 0]',\n",
       " 'gr[17, 1]',\n",
       " 'gr[18, 0]',\n",
       " 'gr[18, 1]',\n",
       " 'gr[19, 0]',\n",
       " 'gr[19, 1]',\n",
       " 'gr[20, 0]',\n",
       " 'gr[20, 1]',\n",
       " 'gr[21, 0]',\n",
       " 'gr[21, 1]',\n",
       " 'gr[22, 0]',\n",
       " 'gr[22, 1]',\n",
       " 'gr[23, 0]',\n",
       " 'gr[23, 1]',\n",
       " 'gr[24, 0]',\n",
       " 'gr[24, 1]',\n",
       " 'sigma_d[0]',\n",
       " 'L_Rho_d[0, 0]',\n",
       " 'L_Rho_d[0, 1]',\n",
       " 'L_Rho_d[1, 0]',\n",
       " 'L_Rho_d[1, 1]',\n",
       " 'd[0, 0]',\n",
       " 'd[0, 1]',\n",
       " 'd[1, 0]',\n",
       " 'd[1, 1]',\n",
       " 'd[2, 0]',\n",
       " 'd[2, 1]',\n",
       " 'd[3, 0]',\n",
       " 'd[3, 1]',\n",
       " 'd[4, 0]',\n",
       " 'd[4, 1]',\n",
       " 'd[5, 0]',\n",
       " 'd[5, 1]',\n",
       " 'd[6, 0]',\n",
       " 'd[6, 1]',\n",
       " 'd[7, 0]',\n",
       " 'd[7, 1]',\n",
       " 'd[8, 0]',\n",
       " 'd[8, 1]',\n",
       " 'd[9, 0]',\n",
       " 'd[9, 1]',\n",
       " 'd[10, 0]',\n",
       " 'd[10, 1]',\n",
       " 'd[11, 0]',\n",
       " 'd[11, 1]',\n",
       " 'd[12, 0]',\n",
       " 'd[12, 1]',\n",
       " 'd[13, 0]',\n",
       " 'd[13, 1]',\n",
       " 'd[14, 0]',\n",
       " 'd[14, 1]',\n",
       " 'd[15, 0]',\n",
       " 'd[15, 1]',\n",
       " 'd[16, 0]',\n",
       " 'd[16, 1]',\n",
       " 'd[17, 0]',\n",
       " 'd[17, 1]',\n",
       " 'd[18, 0]',\n",
       " 'd[18, 1]',\n",
       " 'd[19, 0]',\n",
       " 'd[19, 1]',\n",
       " 'd[20, 0]',\n",
       " 'd[20, 1]',\n",
       " 'd[21, 0]',\n",
       " 'd[21, 1]',\n",
       " 'd[22, 0]',\n",
       " 'd[22, 1]',\n",
       " 'd[23, 0]',\n",
       " 'd[23, 1]',\n",
       " 'd[24, 0]',\n",
       " 'd[24, 1]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(az.summary(trace,round_to='none')['mean'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tfp\": az.summary(trace,round_to='none')['mean'],\n",
    "        \"pystan\": [df['a'].mean(),df['b'].mean(),\n",
    "                   df['sigma_cafe.1'].mean(),\n",
    "                   df['sigma_cafe.2'].mean(),   \n",
    "                   df['sigma'].mean(),                \n",
    "                   df['Rho.1.1'].mean(),df['Rho.2.1'].mean(),\n",
    "                   df['Rho.1.2'].mean(),df['Rho.2.2'].mean(),                   \n",
    "                   df['a_cafe.1'].mean(), df['b_cafe.1'].mean(),\n",
    "                   df['a_cafe.2'].mean(), df['b_cafe.2'].mean(),\n",
    "                   df['a_cafe.3'].mean(), df['b_cafe.3'].mean(),\n",
    "                   df['a_cafe.4'].mean(), df['b_cafe.4'].mean(),\n",
    "                   df['a_cafe.5'].mean(), df['b_cafe.5'].mean(),\n",
    "                   df['a_cafe.6'].mean(), df['b_cafe.6'].mean(),\n",
    "                   df['a_cafe.7'].mean(), df['b_cafe.7'].mean(),\n",
    "                   df['a_cafe.8'].mean(), df['b_cafe.8'].mean(),\n",
    "                   df['a_cafe.9'].mean(), df['b_cafe.9'].mean(),\n",
    "                   df['a_cafe.10'].mean(), df['b_cafe.10'].mean(),\n",
    "                   df['a_cafe.11'].mean(), df['b_cafe.11'].mean(),\n",
    "                   df['a_cafe.12'].mean(), df['b_cafe.12'].mean(),\n",
    "                   df['a_cafe.13'].mean(), df['b_cafe.13'].mean(),\n",
    "                   df['a_cafe.14'].mean(), df['b_cafe.14'].mean(),\n",
    "                   df['a_cafe.15'].mean(), df['b_cafe.15'].mean(),\n",
    "                   df['a_cafe.16'].mean(), df['b_cafe.16'].mean(),\n",
    "                   df['a_cafe.17'].mean(), df['b_cafe.17'].mean(),\n",
    "                   df['a_cafe.18'].mean(), df['b_cafe.18'].mean(),\n",
    "                   df['a_cafe.19'].mean(), df['b_cafe.19'].mean(),\n",
    "                   df['a_cafe.20'].mean(), df['b_cafe.20'].mean(),\n",
    "                   ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRAND\n",
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['N_networktypes', 'N_id', 'N_responses', 'N_periods', 'N_individual_predictors', 'N_dyadic_predictors', 'outcomes', 'flows', 'individual_predictors', 'dyadic_predictors', 'N_block_predictors', 'N_groups_per_block_type', 'block_predictors', 'outcome_mode', 'exposure'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import jax.numpy as jnp\n",
    "with open('STRAND.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_networktypes: \n",
      "1\n",
      "N_id : \n",
      "100\n",
      "N_responses : \n",
      "1\n",
      "N_periods : \n",
      "0\n",
      "N_periods : \n",
      "0\n",
      "N_individual_predictors : \n",
      "1\n",
      "N_dyadic_predictors : \n",
      "2\n",
      "flows : \n",
      "0\n",
      "individual_predictors : \n",
      "[0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
      "N_block_predictors : \n",
      "0\n",
      "N_groups_per_block_type : \n",
      "1\n",
      "outcome_mode : \n",
      "2\n",
      "block_predictors : \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "outcome_mode : \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"N_networktypes: \")\n",
    "print(data['N_networktypes'])\n",
    "print(\"N_id : \")\n",
    "print(data['N_id'])\n",
    "print(\"N_responses : \")\n",
    "print(data['N_responses'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_periods : \")\n",
    "print(data['N_periods'])\n",
    "print(\"N_individual_predictors : \" )\n",
    "print(data['N_individual_predictors'])\n",
    "print(\"N_dyadic_predictors : \")\n",
    "print(data['N_dyadic_predictors'])\n",
    "print(\"flows : \")\n",
    "print(data['flows'])\n",
    "data['individual_predictors'] = jnp.array(data['individual_predictors']['Mass'])\n",
    "print(\"individual_predictors : \")\n",
    "print(data['individual_predictors'])\n",
    "print(\"N_block_predictors : \")\n",
    "print(data['N_block_predictors'])\n",
    "print(\"N_groups_per_block_type : \")\n",
    "print(data['N_groups_per_block_type'])\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )\n",
    "data['block_predictors'] = jnp.array(data['block_predictors'])\n",
    "print(\"block_predictors : \")\n",
    "print(data['block_predictors'] )\n",
    "print(\"outcome_mode : \")\n",
    "print(data['outcome_mode'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0,  0,  0, ...,  1,  9, 19],\n",
       "       [ 1,  0,  0, ...,  0,  0,  2],\n",
       "       [ 0,  0,  0, ...,  0,  3, 11],\n",
       "       ...,\n",
       "       [ 4,  0,  0, ...,  0,  1,  0],\n",
       "       [ 3,  0,  0, ...,  0,  0,  9],\n",
       "       [10,  6,  3, ...,  0, 11,  0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outcomes'] = jnp.array(data['outcomes']).reshape(data['N_id'],data['N_id'])\n",
    "data['outcomes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.        ,  0.08778227, -0.1032394 , ...,  0.08142215,\n",
       "        -0.1223947 , -0.1078428 ],\n",
       "       [ 0.08778227,  1.        , -0.1504998 , ...,  0.06893802,\n",
       "        -0.1820744 , -0.00592948],\n",
       "       [-0.1032394 , -0.1504998 ,  1.        , ..., -0.1213151 ,\n",
       "         0.1459238 ,  0.1074177 ],\n",
       "       ...,\n",
       "       [ 0.08142215,  0.06893802, -0.1213151 , ...,  1.        ,\n",
       "        -0.1211644 , -0.03577805],\n",
       "       [-0.1223947 , -0.1820744 ,  0.1459238 , ..., -0.1211644 ,\n",
       "         1.        ,  0.03175739],\n",
       "       [-0.1078428 , -0.00592948,  0.1074177 , ..., -0.03577805,\n",
       "         0.03175739,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kinship = jnp.array(data['dyadic_predictors']['Kinship']).reshape(data['N_id'],data['N_id'])\n",
    "Kinship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dominant = jnp.array(data['dyadic_predictors']['Dominant']).reshape(data['N_id'],data['N_id'])\n",
    "Dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[14, 16, 16, ...,  8, 19, 21],\n",
       "       [13, 11, 16, ..., 15, 21, 26],\n",
       "       [14, 17, 13, ..., 17, 18, 14],\n",
       "       ...,\n",
       "       [22, 18, 15, ..., 14,  6, 13],\n",
       "       [15, 17, 11, ...,  6, 15, 20],\n",
       "       [10, 14, 19, ..., 16, 14, 15]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exposure = jnp.array(data['exposure']).reshape(data['N_id'],data['N_id'])\n",
    "exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "#### Specific functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_to_mat: \n",
      "[[ 0  1  1  1  1  1  1  1  1  1]\n",
      " [ 2  0  2  2  2  2  2  2  2  2]\n",
      " [ 3  3  0  3  3  3  3  3  3  3]\n",
      " [ 4  4  4  0  4  4  4  4  4  4]\n",
      " [ 5  5  5  5  0  5  5  5  5  5]\n",
      " [ 6  6  6  6  6  0  6  6  6  6]\n",
      " [ 7  7  7  7  7  7  0  7  7  7]\n",
      " [ 8  8  8  8  8  8  8  0  8  8]\n",
      " [ 9  9  9  9  9  9  9  9  0  9]\n",
      " [10 10 10 10 10 10 10 10 10  0]]\n",
      "get_upper_tri: \n",
      "[2 3 6]\n",
      "get_lower_tri: \n",
      "[4 7 8]\n",
      "On function for upper,  lower and both triangles: \n",
      "Upper triangle elements (excluding diagonal): [2 3 6]\n",
      "Lower triangle elements (excluding diagonal): [4 7 8]\n",
      "Both triangle elements (excluding diagonal): [[4 2]\n",
      " [7 3]\n",
      " [8 6]]\n",
      "Dot product betwee matrix and 2x2 cov mat\n",
      "[[-1.7161117   3.8507886   2.6675742  -1.2665142  -2.5273845   1.5500902\n",
      "  -0.56202716 -0.19732404 -1.3603567   0.8664815 ]\n",
      " [-4.0113864  -1.0849247   0.08289722  4.2800307  -0.29872686  1.4720303\n",
      "  -3.766257   -2.42005    -4.7452354   2.517879  ]\n",
      " [-2.399936    2.1465735   0.24681942  1.4653203  -0.04389387 -1.331646\n",
      "  -0.42534143 -3.0043676   1.5274246  -2.8574097 ]\n",
      " [ 2.1985683  -5.28951    -0.97243196  0.52319175 -2.375515    0.44109926\n",
      "  -0.97210443 -3.6193433   2.5031362  -1.6038274 ]\n",
      " [ 2.032421   -0.4514307   0.21383949  3.0827558   1.507783    2.882153\n",
      "  -0.765796   -2.905682   -1.852034    1.2984148 ]\n",
      " [-0.6211288  -0.20698328  3.1470568   0.01483868 -2.5300467  -0.33965978\n",
      "  -1.9962643   5.4495344   0.4039624  -0.548226  ]\n",
      " [ 1.0118315   4.703859    0.18517043  2.2761464   1.2174578   3.4529765\n",
      "   0.39946204 -0.43596604 -0.44351754  4.5684686 ]\n",
      " [-0.5720065   2.2101119   3.3897924   2.550859    2.1159594  -4.299001\n",
      "   0.38712546  1.5366088  -3.8165128  -2.9029126 ]\n",
      " [ 2.3046231   3.365604   -1.0326629  -2.1595194   0.8815888  -0.29888955\n",
      "  -0.03953517  3.1525686  -0.88793373 -0.55513495]\n",
      " [-2.4216936  -3.8494189   0.59663135  0.83933854  0.09861036 -0.68377066\n",
      "  -3.796394    5.007627    1.9496675  -0.19646278]]\n",
      "sr_to_dr_shape:\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [5 4]\n",
      " [7 2]\n",
      " [7 4]\n",
      " [7 6]]\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jaxr\n",
    "@jit\n",
    "def batch_matrix_vector_multiplication(A, v):\n",
    "    \"\"\"\n",
    "    Perform matrix-vector multiplication for each row of the array v.\n",
    "\n",
    "    Parameters:\n",
    "    A (jax.numpy.ndarray): A 2x2 matrix.\n",
    "    v (jax.numpy.ndarray): An array of shape (n, 2) where each row is a 2-vector.\n",
    "\n",
    "    Returns:\n",
    "    jax.numpy.ndarray: An array of shape (n, 2) where each row is the result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "    # Define a function that performs the matrix-vector multiplication\n",
    "    def matvec(A, v):\n",
    "        return jnp.dot(A, v)\n",
    "    \n",
    "    # Vectorize the function using jax.vmap\n",
    "    vmap_matvec = jax.vmap(lambda v: matvec(A, v))\n",
    "    \n",
    "    # Apply the vectorized function to the array of vectors\n",
    "    result = vmap_matvec(v)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def transform_matrix(X):\n",
    "    Y = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if i != j:\n",
    "                Y.append(jnp.array([X[i, j], X[j, i]]))\n",
    "    return jnp.concatenate(Y).reshape(-1, 2)\n",
    "\n",
    "# vec_to_mat ------------------------------------------------------------------\n",
    "@jit\n",
    "def vec_to_mat(vec):\n",
    "    # Repeat the array to fill a 10x10 matrix\n",
    "    m = jnp.transpose(jnp.tile(vec, (vec.shape[0] , 1)))\n",
    "    m = jnp.where(jnp.eye(m.shape[0], dtype=bool), 0, m)\n",
    "    return m\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "print(\"vec_to_mat: \")\n",
    "v = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(vec_to_mat(v))\n",
    "\n",
    "\n",
    "# Triangles ------------------------------------------------------------------\n",
    "def upper_tri(array, diag=1):\n",
    "    \"\"\"Extracts the upper triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "    \"\"\"\n",
    "    upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "    upper_triangle_elements = array[upper_triangle_indices]\n",
    "    return upper_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_upper_tri = jit(upper_tri, static_argnums=(1,))\n",
    "\n",
    "\n",
    "def lower_tri(array, diag=-1):\n",
    "    \"\"\"Extracts the lower triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=0 includes the diagonal, diag=-1 excludes it.\n",
    "    \"\"\"\n",
    "    lower_triangle_indices = jnp.tril_indices(array.shape[0], k=diag)\n",
    "    lower_triangle_elements = array[lower_triangle_indices]\n",
    "    return lower_triangle_elements\n",
    "# JIT compile the function with static_argnums\n",
    "get_lower_tri = jit(lower_tri, static_argnums=(1,))\n",
    "\n",
    "\n",
    "def get_tri(array, type='upper', diag=0):\n",
    "    \"\"\"Extracts the upper, lower, or both triangle elements of a 2D JAX array.\n",
    "\n",
    "    Args:\n",
    "        array (2D array): A JAX 2D array.\n",
    "        type (str): A string indicating which part of the triangle to extract.\n",
    "                    It can be 'upper', 'lower', or 'both'.\n",
    "        diag (int): Integer indicating if diagonal must be kept or not.\n",
    "                    diag=1 excludes the diagonal, diag=0 includes it.\n",
    "\n",
    "    Returns:\n",
    "        If argument type is 'upper', 'lower', it return a 1D JAX array containing the requested triangle elements.\n",
    "        If argument type is 'both', it return a 2D JAX array containing the the first column the lower triangle and in the second ecolumn the upper triangle\n",
    "    \"\"\"\n",
    "    if type == 'upper':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        triangle_elements = array[upper_triangle_indices]\n",
    "    elif type == 'lower':\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        triangle_elements = array[lower_triangle_indices]\n",
    "    elif type == 'both':\n",
    "        upper_triangle_indices = jnp.triu_indices(array.shape[0], k=diag)\n",
    "        lower_triangle_indices = jnp.tril_indices(array.shape[0], k=-diag)\n",
    "        upper_triangle_elements = array[upper_triangle_indices]\n",
    "        lower_triangle_elements = array[lower_triangle_indices]\n",
    "        triangle_elements = jnp.stack((lower_triangle_elements, upper_triangle_elements), axis = 1)\n",
    "    else:\n",
    "        raise ValueError(\"type must be 'upper', 'lower', or 'both'\")\n",
    "\n",
    "    return triangle_elements\n",
    "\n",
    "## Example ------------------------------------------------------------------\n",
    "array = jnp.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "print(\"get_upper_tri: \")\n",
    "result1 = get_upper_tri(array, 1)\n",
    "print(result1)\n",
    "\n",
    "print(\"get_lower_tri: \")\n",
    "result2 = get_lower_tri(array, -1)  # Change diag to -1 to exclude the diagonal\n",
    "print(result2)\n",
    "\n",
    "# JIT compile the function with static_argnums\n",
    "get_triangle = jit(get_tri, static_argnames=('type', 'diag'))\n",
    "\n",
    "print(\"On function for upper,  lower and both triangles: \")\n",
    "# Test the function\n",
    "result_upper = get_triangle(array, 'upper', 1)\n",
    "print(\"Upper triangle elements (excluding diagonal):\", result_upper)\n",
    "\n",
    "result_lower = get_triangle(array, 'lower', 1)\n",
    "print(\"Lower triangle elements (excluding diagonal):\", result_lower)\n",
    "\n",
    "result_both = get_triangle(array, 'both', 1)\n",
    "print(\"Both triangle elements (excluding diagonal):\", result_both)\n",
    "\n",
    "\n",
    "# Dot product betwee matrix and 2x2 cov mat-----------------------------\n",
    "# Seed for reproducibility\n",
    "seed = 0\n",
    "key = jaxr.PRNGKey(seed)\n",
    "\n",
    "# Define shapes\n",
    "shape_M = (10, 10)\n",
    "shape_diag = (2, 2)\n",
    "\n",
    "# Generate random matrices\n",
    "sr_raw_M = jaxr.normal(key, shape_M)  # Random matrix with shape (10, 10)\n",
    "diag = jaxr.normal(key, shape_diag)   # Random matrix with shape (2, 2)\n",
    "\n",
    "# Initialize the result matrix with zeros\n",
    "result = jnp.zeros(shape_M)\n",
    "\n",
    "# Compute the result matrix\n",
    "@jit\n",
    "def dot_mat_cov(mat, cov):\n",
    "    \"\"\"dot productbetween [sr_raw_M[i,j],sr_raw_M[j,i]] and diag for each combinations of i and j. where M is a 2x2 matrix of shape 10x10 and diag a 2x2x matrix of 2x2. The return object should be a matrix of shape equal to M.\n",
    "\n",
    "    Args:\n",
    "        mat (2d jax array): _description_\n",
    "        cov (2d jax array): _description_\n",
    "    \"\"\"\n",
    "    def compute_ij(i, j):\n",
    "        # Create the 2x2 tensor from sr_raw_M for indices (i, j)\n",
    "        tensor_2 = jnp.array([[mat[i, j], mat[j, i]]])\n",
    "        \n",
    "        # Perform the dot product with cov\n",
    "        return jnp.einsum('ij,ij->',tensor_2 , cov)\n",
    "    \n",
    "    # Create a result matrix with the same shape as sr_raw_M\n",
    "    result_matrix = jnp.zeros_like(mat)\n",
    "    \n",
    "    # Vectorized computation using broadcasting\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            result_matrix = result_matrix.at[i, j].set(compute_ij(i, j))\n",
    "    \n",
    "    return result_matrix\n",
    "\n",
    "# Compute the result matrix\n",
    "result_matrix = dot_mat_cov(sr_raw_M, diag)\n",
    "\n",
    "# Display the resulting matrix\n",
    "print(\"Dot product betwee matrix and 2x2 cov mat\")\n",
    "print(result_matrix)\n",
    "\n",
    "\n",
    "# sr_to_dr_shape-----------------------------\n",
    "@jit\n",
    "def sr_to_dr_shape(sr):      \n",
    "    # Extract columns\n",
    "    sr1 = array[:, 0] # i to j value\n",
    "    sr2 = array[:, 1] # j to i value\n",
    "\n",
    "    # Create a grid of indices\n",
    "    N = sr.shape[0]\n",
    "    i_indices, j_indices = jnp.tril_indices(N, -1)  # Indices for upper triangle, excluding diagonal\n",
    "\n",
    "    # Generate combinations\n",
    "    return jnp.stack([sr1[i_indices], sr2[j_indices]], axis=-1)\n",
    "\n",
    "\n",
    "array = jnp.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "print(\"sr_to_dr_shape:\")\n",
    "print(sr_to_dr_shape(array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litteral transcriptioon of STRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dom = get_triangle(Dominant, 'both', 1)\n",
    "result_dom.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.08778227,  0.08778227],\n",
       "       [-0.1032394 , -0.1032394 ],\n",
       "       [-0.1504998 , -0.1107113 ],\n",
       "       ...,\n",
       "       [-0.07871823, -0.1211644 ],\n",
       "       [-0.03577805, -0.03577805],\n",
       "       [ 0.03175739,  0.03175739]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_kin = get_triangle(Kinship, 'both', 1)\n",
    "result_kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_id = data['individual_predictors'].shape[0]\n",
    "(N_id*(N_id-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 dyadic effects\n",
    "result_dom = get_triangle(Dominant, 'both', 1)\n",
    "dyad_effects = Normal(0, 1).sample([],seed = init_key)\n",
    "terms2 = jnp.dot(dyad_effects,jnp.column_stack([result_kin[:,1], result_dom[:,1]])) # Is this correct?\n",
    "terms2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:69: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "(100,)\n",
      "(100,)\n",
      "(4950, 2)\n",
      "(100, 2)\n",
      "(2,)\n",
      "(2, 2)\n",
      "(4950, 2)\n",
      "()\n",
      "(2, 2)\n",
      "(4950, 2)\n"
     ]
    }
   ],
   "source": [
    "# Litteral transcription of STRAND\n",
    "N_id = data['individual_predictors'].shape[0]\n",
    "focal_individual_predictors = data['individual_predictors']\n",
    "target_individual_predictors = data['individual_predictors']\n",
    "\n",
    "\n",
    "focal_effects = Normal(0, 1).sample([],seed = init_key)\n",
    "target_effects = Normal(0, 1).sample([], seed = init_key)\n",
    "sr_raw = Normal(0, 1).sample([N_id,2], seed = init_key)\n",
    "sr_sigma = Exponential(1).sample(2,seed = init_key) \n",
    "sr_L = LKJ(2, 2).sample(seed = init_key)\n",
    "\n",
    "X = batch_matrix_vector_multiplication(sr_L @ jnp.diag(sr_sigma), sr_raw) # Mat mul between lkj of cov and sr_raw\n",
    "terms = jnp.stack([jnp.dot(focal_effects, focal_individual_predictors), jnp.dot(target_effects, target_individual_predictors)], axis = 1)\n",
    "sr = X + terms\n",
    "sr = sr_to_dr_shape(sr) # To compute the log probability, we need to reshape `sr` and `outcomes` to fit `dr`. A matrix approach should be possible or convert `sr` and `dr` to matrices.\n",
    "\n",
    "\n",
    "# Get both triangles for dyadic characteristics\n",
    "result_kin = get_triangle(Kinship, 'both', 1)\n",
    "result_kin.shape\n",
    "\n",
    "\n",
    "dyad_effects =Normal(0, 1).sample([],seed = init_key)   # 2D array of dim N_id*N_id of a normal distribution of mean 0 and #sd 1\n",
    "terms2 = jnp.dot(dyad_effects, result_kin)\n",
    "\n",
    "dr_raw = Normal(0, 1).sample([terms2.shape[0],2],seed = init_key)  # 2D array of dim N_id*2 of a normal distribution of mean 0 and sd 1\n",
    "dr_sigma = Exponential(1).sample([],seed = init_key)   # Vector of length 2 of an exponential distribution for a rate of 1\n",
    "dr_L = LKJ(2, 2).sample(seed = init_key)  # 2D array of dim 2*2 of a lkj distribution of concentration of 2\n",
    "X2 = batch_matrix_vector_multiplication(dr_L, dr_raw) * jnp.repeat(dr_sigma,2)\n",
    "dr = X2 + terms2\n",
    "\n",
    "y = Independent(Poisson(sr + dr)).sample(seed = init_key)\n",
    "print(focal_effects.shape)\n",
    "print(target_effects.shape)\n",
    "print(focal_individual_predictors.shape)\n",
    "print(target_individual_predictors.shape)\n",
    "print(sr.shape)\n",
    "print(sr_raw.shape)\n",
    "print(sr_sigma.shape)\n",
    "print(sr_L.shape)\n",
    "print(dr_raw.shape)\n",
    "print(dr_sigma.shape)\n",
    "print(dr_L.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Litteral transcription of STRAND\n",
    "N_id = data['individual_predictors'].shape[0]\n",
    "focal_individual_predictors = data['individual_predictors']\n",
    "target_individual_predictors = data['individual_predictors']\n",
    "\n",
    "\n",
    "focal_effects = Normal(0, 1).sample([],seed = init_key)\n",
    "target_effects = Normal(0, 1).sample([], seed = init_key)\n",
    "sr_raw = Normal(0, 1).sample([N_id,2], seed = init_key)\n",
    "sr_sigma = Exponential(1).sample(2,seed = init_key) \n",
    "sr_L = LKJ(2, 2).sample(seed = init_key)\n",
    "\n",
    "X = batch_matrix_vector_multiplication(sr_L @ jnp.diag(sr_sigma), sr_raw) # Mat mul between lkj of cov and sr_raw\n",
    "terms = jnp.stack([focal_effects*focal_individual_predictors,target_effects*target_individual_predictors], axis = 1)\n",
    "sr = X + terms\n",
    "sr = sr_to_dr_shape(sr) # To compute the log probability, we need to reshape `sr` and `outcomes` to fit `dr`. A matrix approach should be possible or convert `sr` and `dr` to matrices.\n",
    "\n",
    "\n",
    "\n",
    "# Get both triangles for dyadic characteristics\n",
    "result_kin = get_triangle(Kinship, 'both', 1)\n",
    "result_kin.shape\n",
    "\n",
    "\n",
    "dyad_effects =Normal(0, 1).sample([],seed = init_key)   # 2D array of dim N_id*N_id of a normal distribution of mean 0 and #sd 1\n",
    "terms2 = jnp.dot(dyad_effects, result_kin)\n",
    "\n",
    "dr_raw = Normal(0, 1).sample([terms2.shape[0],2],seed = init_key)  # 2D array of dim N_id*2 of a normal distribution of mean 0 and sd 1\n",
    "dr_sigma = Exponential(1).sample([],seed = init_key)   # Vector of length 2 of an exponential distribution for a rate of 1\n",
    "dr_L = LKJ(2, 2).sample(seed = init_key)  # 2D array of dim 2*2 of a lkj distribution of concentration of 2\n",
    "X2 = batch_matrix_vector_multiplication(dr_L, dr_raw) * jnp.repeat(dr_sigma,2)\n",
    "dr = X2 + terms2\n",
    "\n",
    "y = Independent(Poisson(sr + dr)).sample(seed = init_key)\n",
    "print(\"focal_effects\")\n",
    "print(focal_effects.shape)\n",
    "print(\"target_effects\")\n",
    "print(target_effects.shape)\n",
    "print(\"focal_individual_predictors\")\n",
    "print(focal_individual_predictors.shape)\n",
    "print(\"target_individual_predictors\")\n",
    "print(target_individual_predictors.shape)\n",
    "print(\"sr\")\n",
    "print(sr.shape)\n",
    "print(\"sr_raw\")\n",
    "print(sr_raw.shape)\n",
    "print(\"sr_sigma\")\n",
    "print(sr_sigma.shape)\n",
    "print(\"sr_L\")\n",
    "print(sr_L.shape)\n",
    "print(\"dr_raw\")\n",
    "print(dr_raw.shape)\n",
    "print(\"dr_sigma\")\n",
    "print(dr_sigma.shape)\n",
    "print(\"dr_L\")\n",
    "print(dr_L.shape)\n",
    "print(\"y\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_outcomes = get_triangle(data['outcomes'], 'both', 1)\n",
    "result_outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sr\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    focal_effects = yield normal(1, 0, 1)\n",
    "    target_effects = yield normal(1, 0, 1)\n",
    "    #sr_raw = yield normal([N_id,2], 0, 1)\n",
    "    #sr_sigma = yield exponential([2], 1)\n",
    "    #sr_L = yield lkj((), 2, 2)    \n",
    "\n",
    "    #X = batch_matrix_vector_multiplication(sr_L @ jnp.diag(sr_sigma), sr_raw)\n",
    "    terms = jnp.stack([jnp.dot(focal_effects, focal_individual_predictors), jnp.dot(target_effects, target_individual_predictors)], axis = 1)\n",
    "    sr = terms\n",
    "    sr = sr_to_dr_shape(sr) # To compute the log probability, we need to reshape `sr` and `outcomes` to fit `dr`. A matrix approach should be possible or convert `sr` and `dr` to matrices.\n",
    "    sr = sr.astype(jnp.float32)\n",
    "    #print(sr.shape)\n",
    "    # Get both triangles for dyadic characteristics\n",
    "    #result_kin = get_triangle(Kinship, 'both', 1)\n",
    "    #result_kin.shape\n",
    "#\n",
    "    #dr_raw = yield normal([terms2.shape[0],2], 0, 1)  # 2D array of dim N_id*2 of a normal distribution of mean 0 and sd 1\n",
    "    #dr_sigma = yield exponential([], 1)  # Vector of length 2 of an exponential distribution for a rate of 1\n",
    "    #dr_L = yield lkj((), 2, 2)  # 2D array of dim 2*2 of a lkj distribution of concentration of 2\n",
    "    #X2 = batch_matrix_vector_multiplication(dr_L, dr_raw) * jnp.repeat(dr_sigma,2)\n",
    "    #dr = X2 + terms2\n",
    "\n",
    "\n",
    "    y = yield Independent(Poisson(log_rate = sr), reinterpreted_batch_ndims= -1)\n",
    "    print(focal_effects.shape)\n",
    "    print(target_effects.shape)\n",
    "    print(focal_individual_predictors.shape)\n",
    "    print(target_individual_predictors.shape)\n",
    "    print(sr.shape)\n",
    "    #print(sr_raw.shape)\n",
    "    #print(sr_sigma.shape)\n",
    "    #print(sr_L.shape)\n",
    "    #print(dr_raw.shape)\n",
    "    #print(dr_sigma.shape)\n",
    "    #print(dr_L.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "\n",
    "posterior, sample_stats = NUTS(model, obs = result_outcomes, n_chains = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 2)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m tensor \u001b[38;5;241m=\u001b[39m JointDistributionCoroutine(model)\n\u001b[0;32m      5\u001b[0m infos \u001b[38;5;241m=\u001b[39m get_distributions(model)\n\u001b[1;32m----> 6\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mlist\u001b[39m(init_params)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[1;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:956\u001b[0m, in \u001b[0;36mJointDistribution._call_sample_n\u001b[1;34m(self, sample_shape, seed, value, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 956\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\internal\\distribution_util.py:1350\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:693\u001b[0m, in \u001b[0;36mJointDistribution._sample_n\u001b[1;34m(self, sample_shape, seed, value)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;129m@distribution_util\u001b[39m\u001b[38;5;241m.\u001b[39mAppendDocstring(kwargs_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    685\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother dependent (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownstream\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) distribution-making functions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[1;32m--> 693\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m   might_have_batch_dims \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    696\u001b[0m       distribution_util\u001b[38;5;241m.\u001b[39mshape_may_be_nontrivial(sample_shape)\n\u001b[0;32m    697\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:361\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcallable_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\internal\\callable_util.py:55\u001b[0m, in \u001b[0;36mget_output_spec\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_tensor_spec\u001b[39m(t):\n\u001b[0;32m     58\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensorSpec):\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:362\u001b[0m, in \u001b[0;36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cached_static_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     flat_list_of_static_attributes \u001b[38;5;241m=\u001b[39m callable_util\u001b[38;5;241m.\u001b[39mget_output_spec(\n\u001b[1;32m--> 362\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes \u001b[38;5;241m=\u001b[39m StaticDistributionAttributes(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_list_of_static_attributes))\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_static_attributes\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\joint_distribution.py:1047\u001b[0m, in \u001b[0;36mJointDistribution._execute_model\u001b[1;34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m==\u001b[39m stop_index:\n\u001b[0;32m   1046\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[154], line 27\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m tmp \u001b[38;5;241m=\u001b[39m sr_raw\u001b[38;5;241m.\u001b[39mastype(jnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 27\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mIndependent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPoisson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreinterpreted_batch_ndims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\distribution.py:342\u001b[0m, in \u001b[0;36m_DistributionMeta.__new__.<locals>.wrapped_init\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to have things set in `self` before `__init__` is\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# called, here is the place to do it.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m \u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to override things set in `self` by subclass\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# `__init__`, here is the place to do it.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m   \u001b[38;5;66;03m# We prefer subclasses will set `parameters = dict(locals())` because\u001b[39;00m\n\u001b[0;32m    347\u001b[0m   \u001b[38;5;66;03m# this has nearly zero overhead. However, failing to do this, we will\u001b[39;00m\n\u001b[0;32m    348\u001b[0m   \u001b[38;5;66;03m# resolve the input arguments dynamically and only when needed.\u001b[39;00m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\substrates\\jax\\distributions\\independent.py:161\u001b[0m, in \u001b[0;36m_Independent.__init__\u001b[1;34m(self, distribution, reinterpreted_batch_ndims, validate_args, experimental_use_kahan_sum, name)\u001b[0m\n\u001b[0;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinterpreted_batch_ndims \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(\n\u001b[0;32m    155\u001b[0m       reinterpreted_batch_ndims,\n\u001b[0;32m    156\u001b[0m       dtype_hint\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32,\n\u001b[0;32m    157\u001b[0m       as_shape_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreinterpreted_batch_ndims\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    159\u001b[0m   static_val \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mget_static_value(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinterpreted_batch_ndims)\n\u001b[0;32m    160\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_static_reinterpreted_batch_ndims \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 161\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m static_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstatic_val\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28msuper\u001b[39m(_Independent, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    164\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    165\u001b[0m     reparameterization_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mreparameterization_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    169\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "    init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "    init_key = jnp.array(init_key)\n",
    "\n",
    "    tensor = JointDistributionCoroutine(model)\n",
    "    infos = get_distributions(model)\n",
    "    init_params = tensor.sample(seed = init_key)\n",
    "    \n",
    "list(init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    _, bijectors = initialise(infos, init_params)\n",
    "    init_params = list(init_params)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:69: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "(100, 2)\n",
      "(2,)\n",
      "(2, 2)\n",
      "(4950, 2)\n",
      "()\n",
      "(2, 2)\n",
      "(4950, 2)\n"
     ]
    }
   ],
   "source": [
    "t = tensor.sample(seed = init_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'focal_effects': {'distribution': 'normal', 'shape': ()},\n",
       " 'target_effects': {'distribution': 'normal', 'shape': ()},\n",
       " 'sr_raw': {'distribution': 'normal', 'shape': (100, 2)},\n",
       " 'sr_sigma': {'distribution': 'exponential', 'shape': (2,)},\n",
       " 'sr_L': {'distribution': 'lkj', 'shape': 2},\n",
       " 'dr_raw': {'distribution': 'normal', 'shape': (4950, 2)},\n",
       " 'dr_sigma': {'distribution': 'exponential', 'shape': ()},\n",
       " 'dr_L': {'distribution': 'lkj', 'shape': 2}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "(100, 2)\n",
      "(2,)\n",
      "(2, 2)\n",
      "(4950, 2)\n",
      "()\n",
      "(2, 2)\n",
      "(4950, 2)\n"
     ]
    }
   ],
   "source": [
    "for a in t:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix approach for STRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both triangles for nodes characteristics\n",
    "## Convert vector of individuals characteristic to a matrix\n",
    "char_focal = vec_to_mat(data['individual_predictors'])\n",
    "focal_individual_predictors = char_focal\n",
    "target_individual_predictors = jnp.transpose(char_focal)\n",
    "N_id = data['outcomes'].shape[0]# Get Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m sr_sigma \u001b[38;5;241m=\u001b[39m Exponential(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m2\u001b[39m,seed \u001b[38;5;241m=\u001b[39m init_key) \n\u001b[0;32m     19\u001b[0m diag \u001b[38;5;241m=\u001b[39m sr_L \u001b[38;5;241m@\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdiag(sr_sigma) \u001b[38;5;66;03m# diag_pre_multiply(sr_sigma, sr_L)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdot_mat_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr_raw_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:332\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 332\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[0;32m    335\u001b[0m   pgle_profiler \u001b[38;5;241m=\u001b[39m _read_pgle_profiler(jaxpr)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:180\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[1;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_pjit_helper\u001b[39m(fun, jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 180\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args_flat:\n\u001b[0;32m    183\u001b[0m     dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:736\u001b[0m, in \u001b[0;36m_infer_params\u001b[1;34m(fun, ji, args, kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m entry \u001b[38;5;241m=\u001b[39m _infer_params_cached(\n\u001b[0;32m    734\u001b[0m     fun, ji, signature, avals, pjit_mesh, resource_env)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpjit_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 736\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_params_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mji\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpjit_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_avals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mattrs_tracked:\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;66;03m# If there are attrs_tracked, don't use the cache.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p, p\u001b[38;5;241m.\u001b[39mconsts \u001b[38;5;241m+\u001b[39m args_flat\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:633\u001b[0m, in \u001b[0;36m_infer_params_impl\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    627\u001b[0m in_shardings_flat, in_layouts_flat \u001b[38;5;241m=\u001b[39m _process_in_axis_resources(\n\u001b[0;32m    628\u001b[0m     in_shardings_treedef, in_shardings_leaves,\n\u001b[0;32m    629\u001b[0m     ji\u001b[38;5;241m.\u001b[39min_layouts_treedef, ji\u001b[38;5;241m.\u001b[39min_layouts_leaves,\n\u001b[0;32m    630\u001b[0m     in_avals, in_tree, dbg, device_or_backend_set, have_kwargs)\n\u001b[0;32m    632\u001b[0m attr_token \u001b[38;5;241m=\u001b[39m _attr_token(flat_fun, in_type)\n\u001b[1;32m--> 633\u001b[0m jaxpr, consts, out_avals, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_create_pjit_jaxpr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHashableFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIgnoreKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mji\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m _attr_update(flat_fun, in_type, attr_token, attrs_tracked)\n\u001b[0;32m    639\u001b[0m out_shardings_flat, out_layouts_flat \u001b[38;5;241m=\u001b[39m _check_and_canonicalize_out_shardings(\n\u001b[0;32m    640\u001b[0m     out_shardings_treedef, out_shardings_leaves, ji\u001b[38;5;241m.\u001b[39mout_layouts_treedef,\n\u001b[0;32m    641\u001b[0m     ji\u001b[38;5;241m.\u001b[39mout_layouts_leaves, HashableFunction(out_tree, closure\u001b[38;5;241m=\u001b[39m()),\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(out_avals), jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mdebug_info, device_or_backend_set)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\linear_util.py:352\u001b[0m, in \u001b[0;36mcache.<locals>.memoized_fun\u001b[1;34m(fun, *args)\u001b[0m\n\u001b[0;32m    350\u001b[0m   fun\u001b[38;5;241m.\u001b[39mpopulate_stores(stores)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m explain \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mexplain_cache_misses\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m    354\u001b[0m     explain(fun\u001b[38;5;241m.\u001b[39mf, cache \u001b[38;5;129;01mis\u001b[39;00m new_cache, cache, key)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:1277\u001b[0m, in \u001b[0;36m_create_pjit_jaxpr\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     attrs_tracked \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1276\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1277\u001b[0m     jaxpr, global_out_avals, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpe_debug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# assert attr_data is sentinel or attr_data matches attrs_tracked\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# TODO(dougalm,mattjj): enable debug info with attrs_tracked\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdynamic_shapes\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs_tracked:\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\interpreters\\partial_eval.py:2355\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[1;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(DynamicJaxprTrace, dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[0;32m   2354\u001b[0m   main\u001b[38;5;241m.\u001b[39mjaxpr_stack \u001b[38;5;241m=\u001b[39m ()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m   jaxpr, out_avals, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_to_subjaxpr_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_avals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2357\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun\n\u001b[0;32m   2358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jaxpr, out_avals, consts, attrs_tracked\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\interpreters\\partial_eval.py:2378\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[1;34m(fun, main, in_avals, keep_inputs, debug_info)\u001b[0m\n\u001b[0;32m   2376\u001b[0m in_tracers \u001b[38;5;241m=\u001b[39m _input_type_to_tracers(trace\u001b[38;5;241m.\u001b[39mnew_arg, in_avals)\n\u001b[0;32m   2377\u001b[0m in_tracers_ \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t, keep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(in_tracers, keep_inputs) \u001b[38;5;28;01mif\u001b[39;00m keep]\n\u001b[1;32m-> 2378\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2379\u001b[0m out_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mfull_raise, ans)\n\u001b[0;32m   2380\u001b[0m jaxpr, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mto_jaxpr(trace, out_tracers)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\linear_util.py:193\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    198\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[1;32mIn[15], line 177\u001b[0m, in \u001b[0;36mdot_mat_cov\u001b[1;34m(mat, cov)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m--> 177\u001b[0m         result_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mresult_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_ij\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_matrix\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:500\u001b[0m, in \u001b[0;36m_IndexUpdateRef.set\u001b[1;34m(self, values, indices_are_sorted, unique_indices, mode)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, values, \u001b[38;5;241m*\u001b[39m, indices_are_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Pure equivalent of ``x[idx] = y``.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m  Returns the value of ``x`` that would result from the NumPy-style\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m  See :mod:`jax.ops` for details.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scatter_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\ops\\scatter.py:76\u001b[0m, in \u001b[0;36m_scatter_update\u001b[1;34m(x, idx, y, scatter_op, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# XLA gathers and scatters are very similar in structure; the scatter logic\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# is more or less a transpose of the gather equivalent.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39m_split_index_for_jit(idx, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_scatter_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatter_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnormalize_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\ops\\scatter.py:113\u001b[0m, in \u001b[0;36m_scatter_impl\u001b[1;34m(x, y, scatter_op, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[0;32m    111\u001b[0m y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(y, \u001b[38;5;28mtuple\u001b[39m(indexer\u001b[38;5;241m.\u001b[39mslice_shape))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Collapse any `None`/`jnp.newaxis` dimensions.\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39mreversed_y_dims:\n\u001b[0;32m    115\u001b[0m   y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mrev(y, indexer\u001b[38;5;241m.\u001b[39mreversed_y_dims)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:1671\u001b[0m, in \u001b[0;36msqueeze\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove one or more length-1 axes from array\u001b[39;00m\n\u001b[0;32m   1616\u001b[0m \n\u001b[0;32m   1617\u001b[0m \u001b[38;5;124;03mJAX implementation of :func:`numpy.sqeeze`, implemented via :func:`jax.lax.squeeze`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;124;03m  Array([0, 1, 2], dtype=int32)\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqueeze\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[1;32m-> 1671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_squeeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ensure_index_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:332\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 332\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[0;32m    335\u001b[0m   pgle_profiler \u001b[38;5;241m=\u001b[39m _read_pgle_profiler(jaxpr)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:180\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[1;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_pjit_helper\u001b[39m(fun, jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 180\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args_flat:\n\u001b[0;32m    183\u001b[0m     dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:733\u001b[0m, in \u001b[0;36m_infer_params\u001b[1;34m(fun, ji, args, kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m _infer_params_impl(fun, ji, pjit_mesh, resource_env, args,\n\u001b[0;32m    730\u001b[0m                                     kwargs, in_avals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    731\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m p, p\u001b[38;5;241m.\u001b[39mconsts \u001b[38;5;241m+\u001b[39m args_flat\n\u001b[1;32m--> 733\u001b[0m entry \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_params_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mji\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpjit_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpjit_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m _infer_params_impl(\n\u001b[0;32m    737\u001b[0m       fun, ji, pjit_mesh, resource_env, args, kwargs, in_avals\u001b[38;5;241m=\u001b[39mavals)\n",
      "File \u001b[1;32mg:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\jax\\_src\\pjit.py:172\u001b[0m, in \u001b[0;36mPjitInfo.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m use_resource_env: \u001b[38;5;28mbool\u001b[39m  \u001b[38;5;66;03m# False for jit, True for pjit\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Hash and compare PjitInfo by identity when used as a cache key.\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    173\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is the equivalent of :  dot_product(focal_effects,  to_vector(focal_individual_predictors[i]));\n",
    "## Priors\n",
    "focal_effects = Normal(0, 1).sample([],seed = init_key)\n",
    "target_effects = Normal(0, 1).sample([], seed = init_key)\n",
    "\n",
    "sr_focal_char = jnp.dot(focal_effects, focal_individual_predictors) #  dot_product(focal_effects,  to_vector(focal_individual_predictors[i]))\n",
    "sr_target_char = jnp.dot(target_effects, target_individual_predictors) #  dot_product(target_effects,  to_vector(target_individual_predictors[i]))\n",
    "\n",
    "# This is the equivalent of :  diag_pre_multiply(sr_sigma, sr_L) * sr_raw[i]\n",
    "## Priors\n",
    "### sr_raw\n",
    "sr_raw = Normal(0, 1).sample([N_id], seed = init_key)\n",
    "sr_raw_M = vec_to_mat(sr_raw)\n",
    "\n",
    "### sr_L and sr_sigma\n",
    "sr_L = LKJ(2, 2).sample(seed = init_key)\n",
    "sr_sigma = Exponential(1).sample(2,seed = init_key) \n",
    "\n",
    "diag = sr_L @ jnp.diag(sr_sigma) # diag_pre_multiply(sr_sigma, sr_L)\n",
    "\n",
    "dot_mat_cov(sr_raw_M, diag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: We need the dot product between `[sr_raw_M[i,j],sr_raw_M[j,i]]` and `diag` for each combinations of `i` and `j`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(mu_l\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m Independent(Normal(mu_l, sigma), reinterpreted_batch_ndims\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m---> 14\u001b[0m posterior, sample_stats \u001b[38;5;241m=\u001b[39m NUTStrans(model, obs \u001b[38;5;241m=\u001b[39m \u001b[43mY2\u001b[49m, n_chains \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y2' is not defined"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    means = yield normal(NY, 0, 1)\n",
    "    print(means.shape)\n",
    "    offset = yield normal((NV,1), 0, 1)\n",
    "    print(offset.shape)\n",
    "    sigma = yield exponential(1, 1)    \n",
    "    print(sigma.shape)\n",
    "    tmp1 = jnp.tile(jnp.squeeze(offset), (NY, 1))\n",
    "    print(tmp1.shape)\n",
    "    mu_l = jnp.transpose(jnp.transpose(tmp1) + offset )\n",
    "    print(mu_l.shape)\n",
    "    y = yield Independent(Normal(mu_l, sigma), reinterpreted_batch_ndims= [8])\n",
    "    \n",
    "posterior, sample_stats = NUTStrans(model, obs = Y2, n_chains = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "g:\\OneDrive\\Travail\\Max Planck\\Projects\\BI\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\random_generators.py:284: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionCoroutine 'JointDistributionCoroutine' batch_shape=StructTuple(\n",
       "  var0=[],\n",
       "  var1=[],\n",
       "  var2=[],\n",
       "  var3=[],\n",
       "  var4=[],\n",
       "  var5=[],\n",
       "  var6=[],\n",
       "  var7=[]\n",
       ") event_shape=StructTuple(\n",
       "  var0=[],\n",
       "  var1=[],\n",
       "  var2=[100, 2],\n",
       "  var3=[2],\n",
       "  var4=[2, 2],\n",
       "  var5=[4950, 2],\n",
       "  var6=[],\n",
       "  var7=[2, 2]\n",
       ") dtype=StructTuple(\n",
       "  var0=float32,\n",
       "  var1=float32,\n",
       "  var2=float32,\n",
       "  var3=float32,\n",
       "  var4=float32,\n",
       "  var5=float32,\n",
       "  var6=float32,\n",
       "  var7=float32\n",
       ")>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    init_key, key = random.split(random.PRNGKey(int(seed)))\n",
    "    init_key = jnp.array(init_key)\n",
    "\n",
    "    tensor = JointDistributionCoroutine(model)\n",
    "    tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lattent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NY, NV), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[k,i] = means[k] + offsets[i]\n",
    "\n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    means = yield normal(NY, 0, 1)\n",
    "    print(means.shape)\n",
    "    offset = yield normal((NV,1), 0, 1)\n",
    "    print(offset.shape)\n",
    "    sigma = yield exponential(1, 1)    \n",
    "    print(sigma.shape)\n",
    "    tmp1 = jnp.tile(jnp.squeeze(offset), (NY, 1))\n",
    "    print(tmp1.shape)\n",
    "    mu_l = jnp.transpose(jnp.transpose(tmp1) + offset )\n",
    "    print(mu_l.shape)\n",
    "    y = yield Independent(Normal(mu_l, sigma), reinterpreted_batch_ndims= [8])\n",
    "    \n",
    "posterior, sample_stats = NUTStrans(model, obs = Y2, n_chains = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(NY, NV, Y2):\n",
    "    means = normal('means', [NY], 0, 1)\n",
    "    offset = normal('offset', [NV], 0, 1)    \n",
    "    sigma = exponential('sigma', [NV], 1 )    \n",
    "\n",
    "    #tmp = jnp.transpose(jnp.tile(means, (1, 8)))\n",
    "    tmp1 = jnp.tile(jnp.squeeze(offset), (NY, 1))\n",
    "    #tmp = jnp.tile(means, (NV, 1)).reshape(NV,NY)\n",
    "    print(means.shape)\n",
    "    print(offset.shape)\n",
    "    print(sigma.shape)\n",
    "    print(tmp1.shape)       \n",
    "    mu_l = offset + tmp1\n",
    "    print(mu_l.shape)\n",
    "    print('ok')\n",
    "\n",
    "\n",
    "    sample('Y', Normal(mu_l, sigma), obs=Y2)\n",
    "\n",
    "dat = dict(\n",
    "    NY = NY,\n",
    "    NV = NV, \n",
    "    Y2 = Y2\n",
    ")\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Distance matrix \n",
    "L = jnp.arange(1,11)\n",
    "m = jnp.abs(L[:, None] - L[None, :])\n",
    "\n",
    "# Kernel\n",
    "@jit\n",
    "def sq_exp_kernel(m, sq_alpha=0.5, sq_rho=0.1, delta=0):\n",
    "    \"\"\"Squared Exponential Kernel.\n",
    "\n",
    "    The SE kernel is a widely used kernel in Gaussian processes (GPs) and support vector machines (SVMs). It has some desirable properties, such as universality and infinite differentiability. This function computes the covariance matrix using the squared exponential kernel.\n",
    "\n",
    "    Args:\n",
    "        m (array): Input array representing the distances between data points.\n",
    "        sq_alpha (float, optional): Scale parameter of the squared exponential kernel. Defaults to 0.5.\n",
    "        sq_rho (float, optional): Length-scale parameter of the squared exponential kernel. Defaults to 0.1.\n",
    "        delta (int, optional): Delta value to be added to the diagonal of the covariance matrix. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - K (array): The covariance matrix computed using the squared exponential kernel.\n",
    "            - cov (array): A masked covariance matrix with the upper triangular part set to zero.\n",
    "    \"\"\"\n",
    "    # Get the number of data points\n",
    "    N = m.shape[0]\n",
    "    \n",
    "    # Compute the kernel matrix using the squared exponential kernel\n",
    "    K = sq_alpha * jnp.exp(-sq_rho *  jnp.square(m))\n",
    "    \n",
    "    # Set the diagonal elements of the kernel matrix\n",
    "    K = K.at[jnp.diag_indices(N)].set(sq_alpha + delta)\n",
    "    \n",
    "    # Create a mask for the upper triangular part of the covariance matrix\n",
    "    mask = jnp.triu(jnp.ones_like(K, dtype=bool))\n",
    "    \n",
    "    # Apply the mask to set the upper triangular part of the covariance matrix to zero\n",
    "    cov = jnp.where(mask, K, 0)\n",
    "    \n",
    "    return K, cov\n",
    "\n",
    "\n",
    "r = sq_exp_kernel(m, 1, 4)\n",
    "Z = Normal(0,1).sample(10, seed = init_key)\n",
    "a = r[1] @ jnp.transpose(r[1]) @ Z\n",
    "\n",
    "\n",
    "# Set up subplots\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Plot the first subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Z)\n",
    "plt.title(\"PreProcessed Via GP\")\n",
    "plt.ylim(-15, 15)\n",
    "\n",
    "\n",
    "# Plot the second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(a)\n",
    "plt.title(\"Processed Via GP\")\n",
    "plt.ylim(-15, 15)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def periodic_kernel(m, sigma=1, length_scale=1.0, period=1.0):\n",
    "    \"\"\"Periodic Kernel.\n",
    "\n",
    "    The periodic kernel is often used in Gaussian processes (GPs) for modeling functions with periodic behavior.\n",
    "\n",
    "    Args:\n",
    "        m (array): Input array representing the absolute distances between data points.\n",
    "        sigma (float, optional): Scale parameter of the kernel. Defaults to 1.0.\n",
    "        length_scale (float, optional): Length scale parameter of the kernel. Defaults to 1.0.\n",
    "        period (float, optional): Period parameter of the kernel. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        array: The covariance matrix computed using the periodic kernel.\n",
    "    \"\"\"    \n",
    "    # Compute the kernel matrix using the squared exponential kernel\n",
    "    return sigma**2 * jnp.exp(-2*jnp.sin(jnp.pi * m / period)**2 / length_scale**2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def local_periodic_kernel(m, sigma=1, length_scale=1.0, period=1.0):\n",
    "    \"\"\"Locally Periodic Kernel\n",
    "\n",
    "    A SE kernel times a periodic results in functions which are periodic, but which can slowly vary over time.\n",
    "\n",
    "    Args:\n",
    "        m (array): Input array representing the absolute distances between data points.\n",
    "        sigma (float, optional): Scale parameter of the kernel. Defaults to 1.0.\n",
    "        length_scale (float, optional): Length scale parameter of the kernel. Defaults to 1.0.\n",
    "        period (float, optional): Period parameter of the kernel. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        array: The covariance matrix computed using the periodic kernel.\n",
    "    \"\"\"    \n",
    "    # Compute the kernel matrix using the squared exponential kernel\n",
    "    return sigma**2 * jnp.exp(-2*jnp.sin(jnp.pi * m / period)**2 / length_scale**2)  * jnp.exp(-(m**2/ 2*length_scale**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnable Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dgompertz(x, eta, b):\n",
    "    \"\"\"This function calculates the probability density function (PDF) of the Gompertz distribution.\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "        eta (_type_): _description_\n",
    "        b (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return b * eta * jnp.exp(eta + b * x - eta * jnp.exp(b * x))\n",
    "\n",
    "def cgompertz(x, eta, b):\n",
    "    \"\"\"This function calculates the cumulative distribution function (CDF) of the Gompertz distribution.\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "        eta (_type_): _description_\n",
    "        b (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return 1 - jnp.exp(-eta * (jnp.exp(b * x) - 1))\n",
    "\n",
    "def qgompertz(p, eta, b):\n",
    "    \"\"\"This function calculates the quantile function (inverse CDF) of the Gompertz distribution.\n",
    "\n",
    "    Args:\n",
    "        p (_type_): _description_\n",
    "        eta (_type_): _description_\n",
    "        b (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return jnp.log(-jnp.log(1 - p) / eta + 1) / b\n",
    "\n",
    "def rgompertz(key, n, eta, b):\n",
    "    \"\"\"This function generates random samples from the Gompertz distribution.\n",
    "\n",
    "    Args:\n",
    "        key (_type_): _description_\n",
    "        n (_type_): _description_\n",
    "        eta (_type_): _description_\n",
    "        b (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    u = random.uniform(key, shape=(n,))\n",
    "    return jnp.log(-jnp.log(1 - u) / eta + 1) / b\n",
    "\n",
    "# Example usage:\n",
    "key = random.PRNGKey(0)  # Random key for reproducibility\n",
    "eta = 1.3\n",
    "b = 0.5\n",
    "n = 100\n",
    "\n",
    "x = rgompertz(key, n, eta, b)\n",
    "\n",
    "# Plot the CDF of the Gompertz distribution\n",
    "x_values = jnp.linspace(0, 15, 400)\n",
    "y_values = cgompertz(x_values, eta, b)\n",
    "plt.plot(x_values, y_values, label='Gompertz CDF')\n",
    "\n",
    "# Add points representing the empirical CDF based on the generated samples\n",
    "for i in range(1, 16):\n",
    "    empirical_cdf = jnp.mean(x <= i)\n",
    "    plt.scatter(i, empirical_cdf, color='red')\n",
    "\n",
    "# Display the plot\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Gompertz CDF and Empirical CDF')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a dictionary with the length of x and x itself\n",
    "dl = {'n': len(x), 'x': x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgompertz(key, n, eta, b):\n",
    "    u = random.uniform(key, shape=(n,))\n",
    "    return jnp.log(-jnp.log(1 - u) / eta + 1) / b\n",
    "\n",
    "def model():\n",
    "    eta  = yield lognormal(1,0,1)\n",
    "    b = yield lognormal(1,0,1)\n",
    "    tmp = rgompertz(key, n, eta, b)\n",
    "    print(tmp.shape)\n",
    "    y = yield Independent(Normal(tmp, 1), reinterpreted_batch_ndims=1)\n",
    "\n",
    "def target_log_prob(*params):\n",
    "    eta, b = params\n",
    "    return jnp.log(b) + jnp.log(eta) + eta + b * x - eta * jnp.exp(b * x)   \n",
    "\n",
    "init_key, key = random.split(random.PRNGKey(int(0)))\n",
    "init_key = jnp.array(init_key)\n",
    "tensor = JointDistributionCoroutine(model)\n",
    "infos = get_distributions(model)\n",
    "init_params = tensor.sample(seed = init_key)\n",
    "init_params = list(init_params)[:-1]\n",
    "_, bijectors = initialise(infos, init_params)\n",
    "\n",
    "names = infos.keys()\n",
    "def trace_fn(_, pkr):\n",
    "    return (\n",
    "        pkr.inner_results.inner_results.target_log_prob,\n",
    "        pkr.inner_results.inner_results.leapfrogs_taken,\n",
    "        pkr.inner_results.inner_results.has_divergence,\n",
    "        pkr.inner_results.inner_results.energy,\n",
    "        pkr.inner_results.inner_results.log_accept_ratio\n",
    "    )\n",
    "\n",
    "@jit\n",
    "def run_chain(key):\n",
    "    inner_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob,\n",
    "        step_size= 1e-3\n",
    "    )\n",
    "    kernel = tensorflow_probability.substrates.jax.mcmc.TransformedTransitionKernel(\n",
    "            inner_kernel=inner_kernel,\n",
    "            bijector=bijectors\n",
    "    )\n",
    "    \n",
    "    hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "        kernel,\n",
    "        target_accept_prob=.8,\n",
    "        num_adaptation_steps=int(0.8*500),\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "              inner_results=pkr.inner_results._replace(step_size=new_step_size)\n",
    "          ),\n",
    "        step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,\n",
    "    )\n",
    "    \n",
    "    return tfp.mcmc.sample_chain(num_results = 500,\n",
    "                                 num_steps_between_results = 0,\n",
    "                                 current_state= init_params,\n",
    "                                 kernel=hmc,\n",
    "                                 trace_fn=trace_fn,\n",
    "                                 num_burnin_steps=0.8,\n",
    "                                 parallel_iterations = 10,\n",
    "                                 seed=key)\n",
    "\n",
    "start = tm.time()  \n",
    "rng_keys = jax.random.split(random.PRNGKey(0), 1)\n",
    "result =  jax.pmap(run_chain)(rng_keys)\n",
    "end = tm.time()    \n",
    "print(f\"HonnorMode took: {end - start:.4f} seconds\")\n",
    "posterior, sample_stats = result\n",
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posterior, sample_stats = NUTStrans(model, obs =  x, target_log_prob_fn= logProb)\n",
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2121884511.py, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 43\u001b[0;36m\u001b[0m\n\u001b[0;31m    return dict(\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "from tensorflow_probability.python.bijectors import sigmoid as sigmoid_bijector\n",
    "from tensorflow_probability.python.distributions import distribution\n",
    "from tensorflow_probability.python.distributions import kullback_leibler\n",
    "from tensorflow_probability.python.internal import assert_util\n",
    "from tensorflow_probability.python.internal import distribution_util\n",
    "from tensorflow_probability.python.internal import dtype_util\n",
    "from tensorflow_probability.python.internal import parameter_properties\n",
    "from tensorflow_probability.python.internal import prefer_static as ps\n",
    "from tensorflow_probability.python.internal import reparameterization\n",
    "from tensorflow_probability.python.internal import samplers\n",
    "from tensorflow_probability.python.internal import tensor_util\n",
    "\n",
    "\n",
    "class Gompertz(\n",
    "    distribution.DiscreteDistributionMixin,\n",
    "    distribution.AutoCompositeTensorDistribution):\n",
    "\n",
    "  def __init__(self,\n",
    "               eta=None,\n",
    "               b=None,\n",
    "               dtype=tf.float32,\n",
    "               validate_args=False,\n",
    "               allow_nan_stats=True,\n",
    "               name='Gompertz'):\n",
    "    parameters = dict(locals())\n",
    "\n",
    "    with tf.name_scope(name) as name:\n",
    "      self.eta = tensor_util.convert_nonref_to_tensor(\n",
    "          eta, dtype_hint=tf.float32, name='probs')\n",
    "      self.b = tensor_util.convert_nonref_to_tensor(\n",
    "          b, dtype_hint=tf.float32, name='logits')\n",
    "    super(Gompertz, self).__init__(\n",
    "        dtype=dtype,\n",
    "        reparameterization_type=reparameterization.NOT_REPARAMETERIZED,\n",
    "        validate_args=validate_args,\n",
    "        allow_nan_stats=allow_nan_stats,\n",
    "        parameters=parameters,\n",
    "        name=name)\n",
    "\n",
    "  @classmethod\n",
    "  def _parameter_properties(cls, dtype, num_classes=None):\n",
    "    return dict(\n",
    "        eta=parameter_properties.ParameterProperties(),\n",
    "        b=parameter_properties.ParameterProperties()\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "    \"\"\"Input argument `eta`.\"\"\"\n",
    "    return self.eta\n",
    "\n",
    "  @property\n",
    "  def b(self):\n",
    "    \"\"\"Input argument `b`.\"\"\"\n",
    "    return self.b\n",
    "\n",
    "  def _event_shape_tensor(self):\n",
    "    return tf.constant([], dtype=tf.float32)\n",
    "\n",
    "  def _event_shape(self):\n",
    "    return tf.TensorShape([])\n",
    "\n",
    "  def _sample_n(self, n, seed=None):\n",
    "    probs = self._probs_parameter_no_checks()\n",
    "    new_shape = ps.concat([[n], ps.shape(probs)], 0)\n",
    "    uniform = samplers.uniform(new_shape, seed=seed, dtype=probs.dtype)\n",
    "    sample = tf.less(uniform, probs)\n",
    "    return tf.cast(sample, self.dtype)\n",
    "\n",
    "  def _log_prob(self, event):\n",
    "    log_probs0, log_probs1 = self._outcome_log_probs()\n",
    "    event = tf.cast(event, log_probs0.dtype)\n",
    "    return (tf.math.multiply_no_nan(log_probs0, 1 - event) +\n",
    "            tf.math.multiply_no_nan(log_probs1, event))\n",
    "\n",
    "  def _outcome_log_probs(self):\n",
    "\n",
    "    return -tf.math.softplus(s), -tf.math.softplus(-s)\n",
    "\n",
    "  def _cdf(self, event):\n",
    "    prob = self._probs_parameter_no_checks()\n",
    "    return tf.where(event < 0, 0.0, tf.where(event < 1, 1.0 - prob, 1.0))\n",
    "\n",
    "  def _entropy(self):\n",
    "    probs0, probs1, log_probs0, log_probs1 = _probs_and_log_probs(\n",
    "        probs=self._probs, logits=self._logits, return_log_probs=True)\n",
    "    return -1. * (\n",
    "        tf.math.multiply_no_nan(log_probs0, probs0) +\n",
    "        tf.math.multiply_no_nan(log_probs1, probs1))\n",
    "\n",
    "  def _mean(self):\n",
    "    return self._probs_parameter_no_checks()\n",
    "\n",
    "  def _variance(self):\n",
    "    probs0, probs1 = _probs_and_log_probs(\n",
    "        probs=self._probs, logits=self._logits, return_log_probs=False)\n",
    "    return probs0 * probs1\n",
    "\n",
    "  def _mode(self):\n",
    "    \"\"\"Returns `1` if `prob > 0.5` and `0` otherwise.\"\"\"\n",
    "    return tf.cast(self._probs_parameter_no_checks() > 0.5, self.dtype)\n",
    "\n",
    "  def logits_parameter(self, name=None):\n",
    "    \"\"\"Logits computed from non-`None` input arg (`probs` or `logits`).\"\"\"\n",
    "    with self._name_and_control_scope(name or 'logits_parameter'):\n",
    "      return self._logits_parameter_no_checks()\n",
    "\n",
    "  def _logits_parameter_no_checks(self):\n",
    "    if self._logits is None:\n",
    "      probs = tf.convert_to_tensor(self._probs)\n",
    "      return tf.math.log(probs) - tf.math.log1p(-probs)\n",
    "    return tensor_util.identity_as_tensor(self._logits)\n",
    "\n",
    "  def probs_parameter(self, name=None):\n",
    "    \"\"\"Probs computed from non-`None` input arg (`probs` or `logits`).\"\"\"\n",
    "    with self._name_and_control_scope(name or 'probs_parameter'):\n",
    "      return self._probs_parameter_no_checks()\n",
    "\n",
    "  def _probs_parameter_no_checks(self):\n",
    "    if self._logits is None:\n",
    "      return tensor_util.identity_as_tensor(self._probs)\n",
    "    return tf.math.sigmoid(self._logits)\n",
    "\n",
    "  def _default_event_space_bijector(self):\n",
    "    return\n",
    "\n",
    "  @classmethod\n",
    "  def _maximum_likelihood_parameters(cls, value):\n",
    "    return {'probs': tf.reduce_mean(value, axis=0)}\n",
    "\n",
    "  def _parameter_control_dependencies(self, is_init):\n",
    "    return maybe_assert_bernoulli_param_correctness(is_init, self.validate_args, self._probs, self._logits)\n",
    "\n",
    "  def _sample_control_dependencies(self, x):\n",
    "    assertions = []\n",
    "    if not self.validate_args:\n",
    "      return assertions\n",
    "    assertions.extend(distribution_util.assert_nonnegative_integer_form(x))\n",
    "    assertions.append(\n",
    "        assert_util.assert_less_equal(\n",
    "            x, tf.ones([], dtype=x.dtype),\n",
    "            message='Sample must be less than or equal to `1`.'))\n",
    "    return assertions\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gompertz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGompertz\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Gompertz' is not defined"
     ]
    }
   ],
   "source": [
    "Gompertz(1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sample: [-0.5500158  -0.77412045 -1.132883  ]\n",
      "Samples: [2.28469634e+00 2.33874202e+00 1.87490487e+00 2.41405869e+00\n",
      " 1.39808154e+00 4.43970442e-01 7.01626301e-01 5.32675162e-02\n",
      " 4.98693138e-01 2.58231688e+00 1.25846529e+00 9.91220355e-01\n",
      " 1.12735081e+00 9.59754407e-01 2.11598545e-01 2.73563838e+00\n",
      " 1.04305756e+00 2.71856976e+00 2.38767847e-01 1.35787833e+00\n",
      " 6.37294590e-01 1.06195137e-01 1.73686653e-01 1.51281029e-01\n",
      " 8.44262540e-01 2.18797612e+00 2.19362402e+00 8.11356783e-01\n",
      " 2.25915432e+00 1.79151487e+00 9.84604597e-01 4.83774036e-01\n",
      " 1.02526411e-01 1.20222557e+00 1.17362328e-01 1.03268266e+00\n",
      " 3.29465294e+00 9.54857826e-01 1.25356066e+00 7.08465874e-01\n",
      " 7.78900445e-01 1.47081865e-02 4.09788758e-01 8.94750893e-01\n",
      " 9.56156015e-01 1.45893216e-01 1.82427382e+00 3.17324996e-01\n",
      " 1.44575536e-01 1.94167301e-01 1.44673383e+00 1.12765384e+00\n",
      " 1.27260220e+00 8.57538730e-03 3.76007468e-01 1.42078650e+00\n",
      " 5.81966519e-01 1.09778738e+00 1.17388129e+00 1.16678071e+00\n",
      " 6.32805586e-01 2.80893147e-01 1.79411337e-01 1.15107310e+00\n",
      " 8.34145963e-01 6.62693322e-01 2.50335515e-01 1.51402390e+00\n",
      " 3.03143591e-01 1.71181238e+00 1.50946915e+00 1.33479387e-01\n",
      " 6.34941012e-02 2.43843007e+00 2.49084949e+00 1.64776236e-01\n",
      " 3.28109153e-02 1.56580877e+00 8.53027463e-01 2.30294853e-01\n",
      " 5.25834799e-01 1.46227866e-01 1.17934525e+00 1.14565635e+00\n",
      " 8.18578184e-01 8.31155479e-01 7.68513799e-01 1.16758794e-01\n",
      " 9.46263909e-01 4.74745780e-01 4.06673908e-01 6.54262662e-01\n",
      " 1.49272692e+00 1.86676100e-01 3.41682732e-01 1.66354465e+00\n",
      " 2.92172611e-01 1.97587416e-01 2.10582352e+00 1.36363685e+00\n",
      " 6.91969573e-01 7.15453684e-01 1.05129874e+00 6.32502735e-01\n",
      " 9.84996557e-01 2.30803967e+00 2.17140388e+00 1.75701785e+00\n",
      " 6.09963238e-01 2.50981760e+00 8.48282874e-01 1.25242794e+00\n",
      " 1.88237607e+00 3.11678433e+00 5.67258775e-01 2.59250820e-01\n",
      " 1.89316481e-01 2.66430140e+00 1.45370972e+00 1.49243927e+00\n",
      " 4.66553211e-01 7.77367890e-01 1.60013044e+00 5.70425510e-01\n",
      " 6.50412977e-01 2.62291098e+00 1.76922095e+00 5.92893898e-01\n",
      " 2.22320127e+00 1.93494916e+00 8.84222269e-01 1.45753515e+00\n",
      " 1.03039694e+00 5.24353206e-01 3.53613794e-01 4.58725631e-01\n",
      " 5.69103599e-01 1.20833099e+00 8.80589366e-01 1.44493476e-01\n",
      " 2.39101708e-01 1.37348402e+00 4.73664254e-01 8.08244169e-01\n",
      " 1.10961246e+00 1.74573928e-01 2.43753225e-01 2.60122716e-01\n",
      " 7.62675852e-02 1.04987133e+00 1.15842378e+00 1.32988822e+00\n",
      " 7.09284782e-01 2.00871870e-01 1.78359199e+00 1.64202452e-02\n",
      " 1.41303742e+00 1.01525569e+00 1.27185190e+00 2.29578304e+00\n",
      " 1.12202096e+00 1.10590863e+00 2.03748751e+00 1.89657822e-01\n",
      " 1.65980577e+00 8.14229131e-01 5.38596928e-01 2.65523648e+00\n",
      " 2.60101974e-01 1.38251424e+00 3.30223858e-01 1.63722429e-02\n",
      " 1.40472782e+00 1.50880903e-01 1.77976847e+00 2.24269852e-01\n",
      " 2.42202163e-01 2.65101552e-01 1.68995559e+00 2.05409145e+00\n",
      " 2.77802963e-02 2.70200312e-01 1.56272069e-01 1.22314894e+00\n",
      " 7.31115818e-01 5.65098464e-01 6.90537214e-01 1.48849940e+00\n",
      " 1.86850405e+00 1.61656284e+00 1.52852046e+00 8.74135137e-01\n",
      " 7.15363503e-01 8.02761018e-02 1.01825428e+00 1.72256589e-01\n",
      " 1.06170714e+00 1.39614153e+00 6.82879612e-03 2.06346011e+00\n",
      " 4.03783530e-01 1.98559567e-01 9.20980513e-01 8.24127078e-01\n",
      " 2.47198582e-01 1.51322663e+00 8.25571358e-01 6.18345998e-02\n",
      " 4.21507686e-01 4.09213305e-01 6.78997397e-01 1.73752999e+00\n",
      " 2.71700416e-02 1.41217232e-01 9.46908772e-01 2.25248292e-01\n",
      " 1.54399562e+00 1.43256877e-02 7.42794216e-01 1.62299478e+00\n",
      " 4.34249118e-02 1.44318908e-01 1.47347867e+00 4.48055387e-01\n",
      " 1.53241944e+00 4.80381668e-01 3.35484058e-01 1.04088604e+00\n",
      " 3.04465085e-01 1.06931373e-01 1.66713819e-01 1.54036379e+00\n",
      " 7.76874423e-02 6.74740136e-01 2.20955801e+00 8.07235122e-01\n",
      " 2.23791316e-01 2.09774780e+00 2.33976409e-01 7.23200202e-01\n",
      " 1.67828918e-01 5.92332959e-01 5.46322584e-01 1.00673687e+00\n",
      " 4.72962171e-01 8.85900021e-01 1.13728356e+00 1.51971221e+00\n",
      " 4.04306382e-01 1.34220138e-01 5.14088571e-01 1.42012227e+00\n",
      " 1.42964065e+00 1.75261423e-02 1.44246173e+00 1.21758914e+00\n",
      " 1.25477219e+00 1.38648939e+00 1.51945210e+00 1.01750720e+00\n",
      " 2.95362186e+00 1.82825494e+00 2.32683039e+00 6.72772408e-01\n",
      " 1.02519011e+00 1.83869362e-01 2.30351593e-02 4.37122107e-01\n",
      " 1.24875653e+00 9.36787367e-01 1.99754119e+00 4.37510848e-01\n",
      " 1.50746465e-01 6.74384117e-01 5.03951199e-02 5.17416775e-01\n",
      " 1.49818256e-01 1.17803597e+00 1.29766250e+00 1.44752294e-01\n",
      " 3.28219354e-01 5.70496678e-01 2.44557810e+00 6.43678844e-01\n",
      " 1.31882870e+00 3.12453240e-01 1.22074172e-01 4.06457931e-01\n",
      " 3.49786133e-01 1.47604692e+00 9.54480410e-01 1.09424248e-01\n",
      " 2.67811656e+00 2.19568059e-01 2.32143268e-01 1.97745466e+00\n",
      " 1.54054165e-01 1.52113020e+00 2.51698673e-01 9.37961340e-01\n",
      " 2.04694700e+00 3.14167500e+00 1.65818584e+00 1.78861725e+00\n",
      " 5.90978444e-01 4.77358192e-01 5.58290064e-01 3.43007535e-01\n",
      " 2.60763168e-01 1.77485657e+00 1.16184548e-01 8.61720681e-01\n",
      " 2.00887829e-01 2.75817704e+00 1.13056147e+00 1.83132634e-01\n",
      " 3.86631429e-01 8.86240959e-01 1.14869487e+00 6.84627518e-02\n",
      " 1.55253482e+00 7.34383285e-01 5.70510507e-01 9.59128141e-01\n",
      " 1.22776735e+00 4.30688709e-02 2.69581135e-02 2.21721411e+00\n",
      " 5.47422143e-03 3.49557936e-01 2.13995361e+00 6.03513122e-01\n",
      " 1.12785220e+00 2.17449737e+00 6.42941535e-01 4.91547287e-01\n",
      " 4.80770886e-01 6.34998679e-01 1.05642068e+00 2.46439075e+00\n",
      " 2.55059659e-01 2.30641198e+00 2.96050757e-01 8.45167875e-01\n",
      " 2.61103213e-01 1.18933451e+00 1.80596352e+00 3.09437966e+00\n",
      " 2.44726822e-01 1.22580278e+00 2.30148900e-02 1.23033725e-01\n",
      " 1.65600091e-01 2.73996019e+00 9.73594189e-01 1.37039506e+00\n",
      " 2.16410589e+00 8.63953352e-01 9.19641495e-01 1.61534703e+00\n",
      " 6.23782158e-01 1.68251252e+00 1.09067070e+00 8.65942426e-03\n",
      " 4.55039829e-01 2.14704424e-01 7.60814369e-01 1.74340451e+00\n",
      " 1.05673701e-01 7.07873344e-01 4.58456844e-01 4.27836776e-01\n",
      " 1.55188763e+00 2.33739689e-01 1.84947848e+00 2.60140300e+00\n",
      " 1.25184989e+00 1.23379993e+00 3.20303380e-01 1.36744571e+00\n",
      " 3.53159636e-01 2.13700444e-01 4.64260310e-01 7.33470976e-01\n",
      " 1.70804039e-01 1.02566791e+00 6.19956970e-01 9.76126552e-01\n",
      " 1.47752833e+00 1.95645586e-01 1.46437621e+00 2.45763135e+00\n",
      " 2.41320938e-01 1.34432280e+00 4.15034890e-01 5.69640577e-01\n",
      " 9.68636751e-01 1.61656886e-01 5.60586393e-01 9.12279665e-01\n",
      " 1.98135357e-02 1.11522913e+00 1.04095507e+00 7.12079823e-01\n",
      " 2.51586616e-01 1.48214489e-01 6.81628346e-01 8.05050135e-01\n",
      " 6.92017317e-01 7.83281028e-02 1.79307371e-01 1.96896279e+00\n",
      " 2.07457995e+00 8.92613113e-01 1.86984849e+00 5.32746911e-01\n",
      " 2.72431877e-02 1.54605877e+00 6.75713599e-01 9.64013398e-01\n",
      " 8.84697974e-01 2.25300598e+00 1.80011958e-01 3.03069639e+00\n",
      " 2.11075366e-01 7.84244955e-01 7.14254320e-01 1.65072632e+00\n",
      " 8.30512464e-01 9.66987669e-01 6.28221452e-01 1.02223921e+00\n",
      " 4.53158140e-01 9.01294947e-01 3.94942999e-01 5.61876297e-01\n",
      " 2.49157691e+00 5.81069067e-02 9.99654889e-01 3.21543932e-01\n",
      " 9.35379446e-01 8.41474652e-01 8.41360271e-01 2.57299840e-01\n",
      " 7.21804127e-02 2.09153700e+00 1.51066566e+00 5.81087172e-01\n",
      " 7.70000279e-01 1.40174317e+00 7.97077790e-02 1.98796809e-01\n",
      " 8.21623743e-01 6.59592271e-01 1.34813106e+00 8.30641866e-01\n",
      " 2.47260857e+00 1.09361327e+00 1.17373013e+00 1.03193450e+00\n",
      " 7.28924036e-01 1.45293963e+00 2.53755164e+00 3.62016678e-01\n",
      " 1.19164371e+00 2.02141929e+00 4.46384758e-01 1.59633622e-01\n",
      " 2.90606081e-01 5.44173658e-01 1.97545695e+00 1.29036796e+00\n",
      " 1.54067412e-01 2.64706492e+00 1.24831808e+00 5.41631915e-02\n",
      " 3.68540734e-01 1.30934834e+00 8.38163972e-01 9.62472737e-01\n",
      " 2.06769562e+00 2.29246545e+00 1.57709575e+00 1.62196171e+00\n",
      " 6.01419330e-01 3.95167261e-01 2.32097626e+00 5.39041996e-01\n",
      " 1.05989957e+00 9.75071192e-02 1.17737758e+00 5.33089697e-01\n",
      " 9.03579593e-01 1.07513142e+00 1.13466501e+00 5.87450683e-01\n",
      " 4.03820157e-01 1.22469807e+00 1.14971268e+00 7.17180133e-01\n",
      " 9.21734691e-01 8.87693390e-02 1.02361870e+00 3.79356593e-01\n",
      " 9.91981268e-01 2.11843705e+00 9.63382542e-01 1.34290719e+00\n",
      " 1.93856514e+00 1.25592709e+00 1.79440796e+00 1.27491403e+00\n",
      " 8.90937913e-03 1.44963467e+00 8.46393585e-01 1.50792050e+00\n",
      " 1.45965970e+00 3.59643072e-01 6.96165979e-01 4.78729159e-02\n",
      " 1.49915183e+00 1.74022698e+00 1.98701572e+00 2.36846924e+00\n",
      " 4.62919265e-01 9.91691709e-01 5.89780509e-01 7.39735663e-01\n",
      " 2.00939155e+00 1.21955669e+00 3.03467247e-03 1.10846853e+00\n",
      " 4.09056515e-01 5.84889412e-01 9.64759439e-02 2.37119055e+00\n",
      " 9.23157334e-01 3.85830492e-01 2.70051384e+00 3.31081331e-01\n",
      " 1.08732235e+00 3.29117686e-01 7.98107743e-01 2.05941772e+00\n",
      " 1.00716281e+00 6.26431644e-01 8.26394200e-01 2.53463566e-01\n",
      " 5.25476396e-01 6.16769195e-01 1.38559663e+00 7.31236935e-01\n",
      " 6.50490105e-01 5.85459583e-02 3.52277011e-01 6.82673395e-01\n",
      " 1.40590978e+00 2.65608490e-01 1.98846459e-01 2.05452561e-01\n",
      " 8.39730084e-01 2.00186706e+00 1.60057098e-01 1.05873585e+00\n",
      " 3.37762795e-02 4.73566800e-01 1.37524113e-01 1.55323017e+00\n",
      " 1.58552849e+00 1.98491240e+00 7.35564411e-01 5.40738583e-01\n",
      " 1.35049367e+00 1.97618082e-01 1.26095009e+00 1.50396717e+00\n",
      " 2.63505244e+00 4.52426411e-02 1.13257933e+00 1.22403526e+00\n",
      " 9.88743246e-01 1.42922854e+00 7.15322316e-01 8.12194049e-01\n",
      " 2.74974561e+00 9.93722796e-01 5.26671171e-01 9.30163503e-01\n",
      " 5.41301966e-01 5.64776719e-01 7.03137755e-01 1.30890322e+00\n",
      " 1.77370384e-01 4.78569120e-01 2.37229854e-01 7.63603926e-01\n",
      " 2.64142007e-01 2.22504449e+00 2.04889446e-01 4.30159718e-01\n",
      " 1.27986872e+00 8.90960395e-01 1.01255544e-01 1.26078999e+00\n",
      " 6.36319757e-01 2.57926971e-01 8.12736928e-01 3.72607380e-01\n",
      " 3.16768527e-01 9.31991100e-01 2.62152529e+00 2.72209954e+00\n",
      " 8.93698931e-01 6.90580249e-01 6.28800094e-01 7.21647501e-01\n",
      " 8.48097384e-01 2.30029416e+00 1.20663774e+00 1.10038185e+00\n",
      " 1.23910427e+00 1.85827816e+00 9.94298577e-01 1.29481339e+00\n",
      " 2.02176619e+00 6.45895958e-01 1.80391479e+00 2.35387802e+00\n",
      " 2.85889053e+00 3.51594597e-01 5.25371552e-01 2.69955128e-01\n",
      " 7.99070060e-01 1.48936677e+00 7.94302344e-01 2.27962589e+00\n",
      " 2.88371563e-01 1.11571884e+00 8.03378463e-01 1.48524582e+00\n",
      " 8.13867271e-01 1.67953655e-01 1.62521195e+00 1.33034086e+00\n",
      " 2.52732849e+00 3.18856798e-02 3.00976157e-01 6.86194152e-02\n",
      " 1.81428123e+00 1.01972806e+00 8.42976093e-01 1.83739471e+00\n",
      " 8.57050002e-01 1.07259500e+00 1.00501323e+00 1.37392902e+00\n",
      " 3.56739946e-02 4.04371440e-01 1.73273042e-01 9.35709476e-01\n",
      " 3.69764626e-01 6.33100748e-01 1.93662715e+00 1.62258029e-01\n",
      " 1.88704395e+00 3.85578454e-01 1.05325484e+00 2.07708344e-01\n",
      " 1.40683699e+00 9.38762188e-01 1.78139472e+00 3.18200409e-01\n",
      " 1.20450568e+00 1.13629580e+00 1.13372557e-01 5.17904282e-01\n",
      " 4.71980810e-01 7.71499991e-01 1.49203753e+00 2.90833735e+00\n",
      " 1.35914236e-01 1.06245697e+00 4.73861426e-01 6.35085464e-01\n",
      " 1.08010793e+00 1.35577410e-01 1.46798384e+00 6.44610763e-01\n",
      " 1.66230583e+00 7.24914312e-01 1.26488948e+00 2.00361347e+00\n",
      " 3.12560916e-01 7.08797276e-01 6.47106171e-01 1.95930982e+00\n",
      " 2.17546314e-01 8.74882042e-01 2.93563753e-01 3.11443716e-01\n",
      " 2.03820086e+00 1.14024329e+00 9.52451229e-01 1.12117338e+00\n",
      " 1.29267609e+00 1.75394928e+00 6.25910521e-01 9.54417586e-01\n",
      " 9.40436244e-01 8.14082980e-01 8.60986471e-01 4.11199093e+00\n",
      " 2.91469991e-01 1.32436693e-01 5.32186747e-01 1.36572266e+00\n",
      " 2.25059971e-01 3.22422773e-01 8.42532277e-01 1.38789070e+00\n",
      " 1.24115777e+00 1.58020067e+00 5.72248638e-01 1.24838281e+00\n",
      " 7.14046776e-01 3.38506609e-01 1.89018026e-01 1.23165995e-01\n",
      " 1.55621624e+00 1.21156566e-01 1.34441423e+00 1.57042289e+00\n",
      " 1.90135562e+00 2.04390541e-01 2.54313469e+00 3.32338452e-01\n",
      " 2.65168786e-01 1.66679323e+00 1.91813922e+00 5.38100779e-01\n",
      " 5.96393704e-01 2.65913916e+00 1.51088881e+00 2.02426434e-01\n",
      " 2.25765753e+00 1.30972183e+00 2.99624234e-01 1.15899217e+00\n",
      " 1.11760490e-01 7.59102225e-01 2.47098073e-01 1.18605033e-01\n",
      " 1.37103140e+00 2.08063769e+00 6.61056221e-01 1.04731166e+00\n",
      " 6.47901833e-01 1.71203232e+00 6.86841965e-01 2.45486379e+00\n",
      " 2.16943383e-01 7.76465774e-01 3.10661465e-01 1.26729280e-01\n",
      " 1.62397945e+00 5.80564857e-01 7.82416344e-01 4.20959741e-01\n",
      " 7.95787513e-01 7.07709849e-01 3.27028245e-01 6.22405291e-01\n",
      " 2.34762454e+00 2.18056035e+00 4.24693823e-01 1.01222754e+00\n",
      " 2.48806739e+00 7.35946670e-02 2.75390148e+00 3.23049307e-01\n",
      " 9.92977023e-02 1.68204033e+00 1.41034055e+00 2.03558588e+00\n",
      " 5.93004040e-02 1.09334087e+00 1.29289222e+00 2.38595396e-01\n",
      " 2.09061432e+00 2.00463128e+00 2.00436521e+00 7.14979470e-01\n",
      " 6.47765756e-01 4.45922017e-01 1.16527152e+00 2.17178488e+00\n",
      " 1.16922557e+00 2.14473200e+00 1.10504138e+00 6.63201809e-01\n",
      " 2.55055040e-01 9.65495482e-02 8.64494085e-01 1.08491862e+00\n",
      " 1.20714974e+00 2.76253391e-02 5.60100496e-01 4.42234069e-01\n",
      " 8.73182118e-01 1.07192826e+00 2.61082292e-01 1.22351778e+00\n",
      " 1.38616872e+00 6.93622455e-02 1.03990003e-01 4.66037691e-01\n",
      " 4.66903448e-01 2.30965987e-01 7.31276751e-01 1.95581555e+00\n",
      " 3.01739424e-01 1.33090168e-01 2.69364893e-01 3.84260505e-01\n",
      " 2.43643045e-01 9.06407773e-01 7.74467170e-01 2.09301639e+00\n",
      " 2.06436920e+00 1.74756742e+00 7.17589498e-01 9.56817269e-01\n",
      " 1.59884501e+00 1.30449426e+00 9.56141233e-01 5.91651142e-01\n",
      " 1.30002642e+00 1.27363813e+00 1.33918810e+00 2.10350513e-01\n",
      " 1.34108412e+00 9.39181447e-01 1.49912322e+00 2.95176005e+00\n",
      " 1.39870334e+00 7.26501644e-01 2.31348062e+00 1.25980914e+00\n",
      " 4.80110496e-01 1.54828501e+00 8.83381844e-01 2.78782439e+00\n",
      " 8.67595732e-01 6.13754153e-01 9.91736889e-01 1.20722401e+00\n",
      " 1.98507380e+00 1.16102970e+00 1.10897183e+00 3.13624573e+00\n",
      " 2.85425425e-01 1.60289013e+00 1.28162932e+00 1.24494791e+00\n",
      " 1.38897336e+00 6.51127219e-01 2.32220793e+00 1.39248419e+00\n",
      " 1.83955476e-01 5.10735273e-01 1.91619992e-01 5.37220478e-01\n",
      " 5.34615852e-02 4.24107045e-01 1.67190397e+00 1.08693922e+00\n",
      " 1.02469969e+00 3.23423147e-01 6.63186982e-02 5.98498404e-01\n",
      " 1.00010777e+00 1.73640454e+00 2.63942289e+00 6.97729826e-01\n",
      " 1.57683587e+00 1.52119458e+00 7.83293247e-01 1.19398904e+00\n",
      " 2.11694643e-01 2.45485708e-01 1.51119161e+00 1.65319633e+00\n",
      " 8.44149470e-01 2.29877487e-01 1.85482454e+00 4.93118942e-01\n",
      " 1.69322833e-01 5.64558506e-01 1.57445037e+00 3.94175127e-02\n",
      " 3.17234874e-01 2.37524807e-01 7.97749877e-01 5.67309439e-01\n",
      " 3.56461644e-01 3.88614208e-01 1.84465492e+00 1.87443733e+00\n",
      " 2.43579939e-01 3.21976972e+00 5.66767156e-01 2.89427853e+00\n",
      " 1.15540314e+00 2.36782169e+00 1.53057039e-01 7.88301349e-01\n",
      " 9.28017259e-01 1.96162975e+00 2.26007383e-02 1.73299694e+00\n",
      " 2.33197227e-01 5.38314223e-01 6.75447106e-01 3.91876072e-01\n",
      " 5.59066534e-01 2.34330463e+00 1.33891499e+00 2.40426445e+00\n",
      " 1.16073862e-01 1.56586266e+00 7.60284290e-02 5.42711437e-01\n",
      " 4.51739073e-01 1.37368691e+00 7.17328414e-02 6.01211369e-01\n",
      " 2.57793069e+00 1.23799253e+00 8.75174820e-01 9.00373340e-01\n",
      " 7.09949255e-01 6.64650917e-01 5.31698823e-01 2.16613516e-01\n",
      " 1.18794680e+00 1.78707933e+00 1.94475865e+00 1.56366438e-01\n",
      " 5.47314048e-01 4.38898534e-01 1.32382500e+00 1.49828613e+00\n",
      " 1.33721554e+00 4.67643477e-02 5.44845223e-01 3.64151597e-01\n",
      " 4.12856668e-01 1.67701975e-01 1.01054721e-01 1.25721931e+00\n",
      " 7.64179006e-02 1.66419566e+00 2.08074236e+00 3.16133112e-01\n",
      " 1.50069594e+00 4.43767428e-01 3.64860483e-02 1.03611600e+00\n",
      " 2.66175365e+00 9.60100770e-01 6.63777530e-01 8.26422572e-01\n",
      " 1.30544901e-01 9.87628102e-01 1.26194596e-01 7.55949736e-01\n",
      " 2.39017200e+00 9.14226592e-01 1.20036578e+00 1.31817985e+00\n",
      " 1.66494000e+00 7.49546289e-01 5.71555793e-01 1.66886246e+00\n",
      " 1.32381463e+00 1.79130360e-01 9.05281156e-02 6.23508453e-01\n",
      " 1.05872130e+00 2.62394637e-01 1.91950822e+00 1.79457223e+00\n",
      " 1.41883388e-01 1.37996697e+00 5.48268378e-01 1.54154390e-01\n",
      " 1.42905638e-01 1.10623133e+00 3.99710894e-01 2.09078297e-01]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_30880/518415903.py\", line 73, in train_step  *\n        optimizer.apply_gradients(zip(gradients, [eta, b]))\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 335, in apply\n        grads, trainable_variables = self._filter_empty_gradients(\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 662, in _filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable.\")\n\n    ValueError: No gradients provided for any variable.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 78\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: NLL = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnll\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eta = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meta\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, b = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file04kt0xqi.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(gompertz_dist)\u001b[38;5;241m.\u001b[39mlog_prob, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(nll), [ag__\u001b[38;5;241m.\u001b[39mld(eta), ag__\u001b[38;5;241m.\u001b[39mld(b)]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:282\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    281\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:335\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    328\u001b[0m grads, trainable_variables \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overwrite_variables_directly_with_gradients(\n\u001b[1;32m    330\u001b[0m         grads, trainable_variables\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Filter empty gradients.\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(grads)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:662\u001b[0m, in \u001b[0;36mBaseOptimizer._filter_empty_gradients\u001b[0;34m(self, grads, vars)\u001b[0m\n\u001b[1;32m    659\u001b[0m         missing_grad_vars\u001b[38;5;241m.\u001b[39mappend(v\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered_grads:\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_grad_vars:\n\u001b[1;32m    664\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients do not exist for variables \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(missing_grad_vars))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when minimizing the loss.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m If using `model.compile()`, did you forget to provide a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`loss` argument?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    669\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_30880/518415903.py\", line 73, in train_step  *\n        optimizer.apply_gradients(zip(gradients, [eta, b]))\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 335, in apply\n        grads, trainable_variables = self._filter_empty_gradients(\n    File \"/home/sosa/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 662, in _filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable.\")\n\n    ValueError: No gradients provided for any variable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "class Gompertz(tfd.Distribution):\n",
    "    def __init__(self, eta, b, validate_args=False, allow_nan_stats=True, name=\"Gompertz\"):\n",
    "        parameters = dict(locals())\n",
    "        with tf.name_scope(name) as name:\n",
    "            self.eta = tf.convert_to_tensor(eta, dtype=tf.float32, name=\"eta\")\n",
    "            self.b = tf.convert_to_tensor(b, dtype=tf.float32, name=\"b\")\n",
    "            super(Gompertz, self).__init__(\n",
    "                dtype=self.eta.dtype,\n",
    "                reparameterization_type=tfd.FULLY_REPARAMETERIZED,\n",
    "                validate_args=validate_args,\n",
    "                allow_nan_stats=allow_nan_stats,\n",
    "                parameters=parameters,\n",
    "                name=name)\n",
    "\n",
    "    def _batch_shape_tensor(self):\n",
    "        return tf.broadcast_dynamic_shape(tf.shape(self.eta), tf.shape(self.b))\n",
    "\n",
    "    def _batch_shape(self):\n",
    "        return tf.broadcast_static_shape(self.eta.shape, self.b.shape)\n",
    "\n",
    "    def _event_shape_tensor(self):\n",
    "        return tf.constant([], dtype=tf.int32)\n",
    "\n",
    "    def _event_shape(self):\n",
    "        return tf.TensorShape([])\n",
    "\n",
    "    def _log_prob(self, x):\n",
    "        eta = self.eta\n",
    "        b = self.b\n",
    "        return tf.math.log(b) + tf.math.log(eta) + eta + b * x - eta * tf.math.exp(b * x)\n",
    "\n",
    "    def _cdf(self, x):\n",
    "        eta = self.eta\n",
    "        b = self.b\n",
    "        return 1. - tf.math.exp(-eta * (tf.math.exp(b * x) - 1.))\n",
    "\n",
    "    def _sample_n(self, n, seed=None):\n",
    "        eta = self.eta\n",
    "        b = self.b\n",
    "        u = tf.random.uniform(shape=[n], seed=seed, dtype=self.dtype)\n",
    "        return tf.math.log(-tf.math.log(1. - u) / eta + 1.) / b\n",
    "\n",
    "# Define learnable parameters\n",
    "eta = tf.Variable(1.3, dtype=tf.float32, name='eta')\n",
    "b = tf.Variable(0.5, dtype=tf.float32, name='b')\n",
    "\n",
    "# Create an instance of the Gompertz distribution with learnable parameters\n",
    "gompertz_dist = Gompertz(eta=eta, b=b)\n",
    "\n",
    "# Example: computing the log probability of a sample\n",
    "sample = tf.constant([0.5, 1.0, 1.5], dtype=tf.float32)\n",
    "log_prob = gompertz_dist.log_prob(sample)\n",
    "print(\"Log probability of sample:\", log_prob.numpy())\n",
    "\n",
    "# Example: drawing samples from the distribution\n",
    "samples = gompertz_dist.sample(1000)\n",
    "print(\"Samples:\", samples.numpy())\n",
    "\n",
    "# Example: fitting the distribution to data\n",
    "data = samples  # In practice, you would use your dataset here\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        nll = -tf.reduce_mean(gompertz_dist.log_prob(data))  # Negative log likelihood\n",
    "    gradients = tape.gradient(nll, [eta, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [eta, b]))\n",
    "    return nll\n",
    "\n",
    "# Training loop\n",
    "for step in range(1000):\n",
    "    nll = train_step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}: NLL = {nll.numpy()}, eta = {eta.numpy()}, b = {b.numpy()}\")\n",
    "\n",
    "print(f\"Fitted eta: {eta.numpy()}, Fitted b: {b.numpy()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
