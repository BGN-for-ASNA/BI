{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n",
      "[-1.1842843]\n",
      "<function Mgaussian.gaussian_process at 0x7f14340636d0>\n",
      "<PjitFunction of <function factors.random_centered at 0x7f14340612d0>>\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "from main import *\n",
    "from functools import partial\n",
    "import time as tm\n",
    "# Bi modules\n",
    "bi = bi(platform='cpu')\n",
    "print(bi.dist.normal(0,1, sample = True, shape=(1,), seed = 1))\n",
    "bi.net.mat_to_edgl(jnp.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8],\n",
    "                              [9, 10, 11, 12],\n",
    "                              [13, 14, 15, 16]]))\n",
    "print(bi.gaussian_process)\n",
    "print(bi.random_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Continuous variable: Model (model 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1217.66it/s, 31 steps of size 9.58e-02. acc. prob=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 2.0677 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]    114.52      1.79    114.60    111.92    117.51    162.96      1.00\n",
      "      b[0]      0.89      0.04      0.89      0.83      0.95    163.36      1.00\n",
      "      s[0]      5.14      0.22      5.11      4.79      5.45    152.53      1.01\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/Howell1.csv', sep=';') \n",
    "m.df = m.df[m.df.age > 18]\n",
    "#m.scale(['weight'])\n",
    "# TODO: use jax arrays with hugging face package\n",
    "m.data_to_model(['weight', 'height'])\n",
    "#m.list = dict(height =  jnp.array(m.df.height), weight =  jnp.array(m.df.weight))\n",
    " # define model ------------------------------------------------\n",
    "def model(height, weight):\n",
    "    s = dist.uniform( 0, 50, name = 's',shape = [1])\n",
    "    a = dist.normal( 178, 20, name = 'a',shape= [1])\n",
    "    b = dist.normal(  0, 1, name = 'b',shape= [1])   \n",
    "    lk(\"y\", Normal(a + b * weight , s), obs=height)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable: Model (model 5.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1108.24it/s, 1023 steps of size 1.13e-03. acc. prob=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.3190 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.00      0.03      0.00     -0.04      0.04     43.50      1.02\n",
      "      s[0]      0.16      0.02      0.16      0.13      0.20     14.04      1.02\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/milk.csv', sep=';') \n",
    "m.index([\"clade\"])\n",
    "m.scale(['kcal_per_g'])\n",
    "\n",
    "def model(kcal_per_g, index_clade):\n",
    "    s = bi.dist.exponential( 1, shape = [1], name = 's')\n",
    "    a = bi.dist.normal(0, 0.5, shape=[1], name = 'a')\n",
    "    m = a[index_clade]\n",
    "    lk(\"y\", Normal(m, s), obs=kcal_per_g)\n",
    "\n",
    "\n",
    "m.data_to_model(['kcal_per_g', \"index_clade\"])\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kcal_per_g': Array([-0.15172414, -0.13172413, -0.18172413, -0.16172414, -0.04172414,\n",
       "        -0.17172414, -0.08172414,  0.24827586,  0.26827586,  0.27827585,\n",
       "         0.15827586, -0.18172413,  0.06827586,  0.06827586,  0.08827586,\n",
       "         0.03827586,  0.07827586,  0.32827586,  0.14827587,  0.19827586,\n",
       "        -0.16172414, -0.02172414, -0.13172413, -0.10172414, -0.15172414,\n",
       "        -0.11172414, -0.16172414, -0.09172413,  0.06827586], dtype=float32),\n",
       " 'index_clade': Array([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.data_on_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1216.16it/s, 3 steps of size 8.21e-01. acc. prob=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.4961 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         a      0.51      0.23      0.51      0.17      0.87    569.19      1.00\n",
      "        bs     -0.03      0.24     -0.02     -0.48      0.31    606.63      1.00\n",
      "        bw      0.03      0.27      0.03     -0.40      0.44    432.09      1.00\n",
      "       bws     -0.00      0.26      0.00     -0.43      0.40    494.42      1.00\n",
      "     sigma     53.18      3.78     52.99     47.04     58.66    828.84      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/tulips.csv', sep=';') \n",
    "m.scale(['blooms', 'water', 'shade'])\n",
    "m.data_to_model(['blooms', 'water', 'shade'])\n",
    "\n",
    " # define model ------------------------------------------------\n",
    "def model(blooms,shade, water):\n",
    "    sigma = dist.exponential(1, name = 'sigma')\n",
    "    bws = dist.normal(0, 0.25, name = 'bws')\n",
    "    bs = dist.normal(0, 0.25, name = 'bs')\n",
    "    bw = dist.normal(0, 0.25, name = 'bw')\n",
    "    a = dist.normal(0.5, 0.25, name = 'a')\n",
    "    mu = a + bw*water + bs*shade + bws*water*shade\n",
    "    lk(\"y\", Normal(mu, sigma), obs=blooms)\n",
    "\n",
    "# Run sampler ------------------------------------------------ \n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial (model 11.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('../data/chimpanzees.csv', sep = ';')\n",
    "d[\"treatment\"] = 1 + d.prosoc_left + 2 * d.condition\n",
    "d[\"side\"] = d.prosoc_left  # right 0, left 1\n",
    "d[\"cond\"] = d.condition  # no partner 0, partner 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1655.01it/s, 1 steps of size 9.55e-01. acc. prob=0.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.0934 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         x      0.33      0.08      0.33      0.19      0.47    206.41      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " # setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/chimpanzees.csv', sep=';') \n",
    "m.df['treatment'] =  1 + m.df.prosoc_left + 2 * m.df.condition\n",
    "m.df[\"side\"] = m.df.prosoc_left  # right 0, left 1\n",
    "m.df[\"cond\"] = m.df.condition  # no partner 0, partner 1\n",
    "m.data_to_model(['pulled_left', ])\n",
    "\n",
    "def model(pulled_left):\n",
    "    a = dist.normal( 0, 10)\n",
    "    lk(\"y\", Binomial(logits=a), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model, init_strategy = numpyro.infer.initialization.init_to_mean()) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices (model 11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:03<00:00, 297.75it/s, 1023 steps of size 6.48e-04. acc. prob=0.80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 4.3662 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.46      1.30      0.36     -1.82      2.12      5.02      1.39\n",
      "      a[1]      0.07      0.26      0.08     -0.31      0.52      6.16      1.36\n",
      "      a[2]      3.73      0.45      3.71      3.02      4.40     22.51      1.03\n",
      "      a[3]     -0.11      0.20     -0.12     -0.41      0.22     17.17      1.00\n",
      "      a[4]     -0.01      0.21     -0.03     -0.32      0.31      6.31      1.00\n",
      "      a[5]      0.10      0.15      0.12     -0.15      0.33     26.70      1.01\n",
      "      a[6]      1.69      0.18      1.67      1.41      1.99     11.01      1.00\n",
      "      b[0]      0.22      0.46      0.17     -0.44      0.97      8.12      1.18\n",
      "      b[1]     -0.62      0.24     -0.63     -0.97     -0.22      6.81      1.11\n",
      "      b[2]     -0.08      0.24     -0.11     -0.48      0.23     11.00      1.00\n",
      "      b[3]     -0.51      0.19     -0.52     -0.80     -0.21      8.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "m.data('../data/chimpanzees.csv', sep=';') \n",
    "m.df['treatment'] =  1 + m.df.prosoc_left + 2 * m.df.condition\n",
    "m.data_to_model(['actor', 'treatment', 'pulled_left'])\n",
    "m.data_on_model['n_actor'] = len(jnp.unique(jnp.array(m.df[\"actor\"]))) # adding additional information on the dictionary\n",
    "m.data_on_model['n_treatment'] = len(jnp.unique(jnp.array(m.df[\"treatment\"])))\n",
    "def model(n_actor, n_treatment, actor, treatment, pulled_left):\n",
    "    a = dist.normal(0, 1.5, shape = [n_actor], name='a')\n",
    "    b = dist.normal(0, 0.5, shape = [n_treatment], name='b')\n",
    "    p = a[actor] + b[treatment]\n",
    "    lk(\"y\", Binomial(1, logits=p), obs=pulled_left)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson (model 11.10) PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 15:19:45.678611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1154.11it/s, 511 steps of size 1.04e-03. acc. prob=0.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2232 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      3.49      0.06      3.49      3.40      3.57     15.07      1.07\n",
      "      b[0]      0.34      0.05      0.34      0.26      0.41     14.80      1.03\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/Kline.csv', sep=';') \n",
    "m.df[\"P\"] = m.df.population.apply(math.log).pipe(lambda x: (x - x.mean()) / x.std())\n",
    "m.df[\"cid\"] = (m.df.contact == \"high\").astype(int)\n",
    "m.data_to_model(['total_tools', 'P', 'cid'])\n",
    "def model(cid, P, total_tools):\n",
    "    a = dist.normal(3, 0.5, shape= [1], name='a')\n",
    "    b = dist.normal(0, 0.2, shape=[1], name='b')\n",
    "    l = jnp.exp(a[cid] + b[cid]*P)\n",
    "    lk(\"y\", Poisson(l), obs=total_tools)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (model 11.12) (PB estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:339: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:290: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:291: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/.local/lib/python3.10/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "init_key, sample_key = random.split(random.PRNGKey(int(r.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "num_days = 30\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 4\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, 30), np.repeat(7, 4)])\n",
    "monastery = np.concatenate([np.repeat(0, 30), np.repeat(1, 4)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1493.57it/s, 3 steps of size 8.06e-01. acc. prob=0.90]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.1340 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.28      0.20      1.27      0.96      1.59    400.94      1.00\n",
      "      b[0]     -0.03      0.64     -0.03     -0.94      1.04    401.81      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data_on_model = dict(\n",
    "    log_days = jnp.array(d.log_days.values),\n",
    "    monastery = jnp.array(d.monastery.values),\n",
    "    output = jnp.array(d.y.values)\n",
    ")\n",
    "\n",
    "def model(log_days, monastery, output):\n",
    "    a = dist.normal(0, 1, shape=[1], name = 'a')\n",
    "    b = dist.normal(0, 1, shape=[1], name = 'b')\n",
    "    l = log_days + a +  b * monastery\n",
    "    lk(\"y\", Poisson(rate = l), obs=output)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial (model 11.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # scores for each career, based on income\n",
    "\n",
    "# next line converts scores to probabilities\n",
    "p = jnp.array(tf.nn.softmax(score))\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = tfd.Categorical(probs=p).sample(seed = init_key, sample_shape = N)\n",
    "result = [income[index] for index in career]\n",
    "data = {'career': career, 'income': result}\n",
    "d = pd.DataFrame(data)\n",
    "career = jnp.array(d.career.values)\n",
    "career_income = jnp.array(d.income.values)\n",
    "income = jnp.array(income)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 965.26it/s, 11 steps of size 1.06e-01. acc. prob=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.8327 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      0.82      0.76      0.76     -0.26      2.07    190.41      1.01\n",
      "      a[1]     -0.99      0.76     -1.07     -2.39      0.03    188.60      1.00\n",
      "      b[0]      0.31      0.29      0.23      0.00      0.66    115.59      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "m.data_on_model = dict(\n",
    "    income = income,\n",
    "    career = career\n",
    ")\n",
    "\n",
    "def model(income, career):\n",
    "    a = dist.normal(0, 1, shape= [2], name = 'a')\n",
    "    b = dist.halfnormal(0.5, shape=[1], name = 'b')\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = a[0] + b * income[0]\n",
    "    p = jax.nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    lk(\"y\", Categorical(probs =  p[career]), obs=career)\n",
    "\n",
    "# Run sampler ------------------------------------------------ \n",
    "m.run(model)  \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (model m12.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 879.91it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9900 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/UCBadmit.csv', sep=';') \n",
    "m.df[\"gid\"] = (m.df[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.df[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.df[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.df[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data_on_model = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential(1, shape=[1], name = 'phi')\n",
    "    alpha = dist.normal( 0., 1.5, shape=[2], name = 'alpha')\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Negative-binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 846.78it/s, 3 steps of size 6.20e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.2618 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  alpha[0]     -0.40      0.43     -0.38     -1.09      0.30    288.51      1.01\n",
      "  alpha[1]     -0.34      0.43     -0.35     -0.96      0.37    437.26      1.00\n",
      "    phi[0]      0.98      0.75      0.83      0.00      1.96    270.05      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/UCBadmit.csv', sep=';') \n",
    "m.df[\"gid\"] = (m.df[\"applicant.gender\"] != \"male\").astype(int)\n",
    "gid = jnp.array(m.df[\"gid\"].astype('int32').values)\n",
    "applications = jnp.array(m.df[\"applications\"].astype('float32').values)\n",
    "admit = jnp.array(m.df[\"admit\"].astype('float32').values)\n",
    "\n",
    "m.data_on_model = dict(\n",
    "    gid = gid,\n",
    "    applications = applications,\n",
    "    admit =  admit\n",
    ")\n",
    "\n",
    "def model(gid, applications, admit):\n",
    "    phi = dist.exponential(1, shape=[1], name = 'phi')\n",
    "    alpha = dist.normal(0., 1.5, shape=[2], name = 'alpha')\n",
    "    theta = phi + 2\n",
    "    pbar = jax.nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    lk(\"y\", BetaBinomial(total_count = applications, concentration1 = concentration1, concentration0 = concentration0), obs=admit)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1303.32it/s, 15 steps of size 5.52e-01. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.1922 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "        al      0.12      0.08      0.12     -0.02      0.24    196.44      1.00\n",
      "        ap     -1.35      0.32     -1.33     -1.82     -0.86    266.48      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "from jax.scipy.special import expit\n",
    "r.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "\n",
    "m.data_on_model = dict(\n",
    "    y = jnp.array(y)\n",
    ")\n",
    "\n",
    "def model(y):\n",
    "    al = dist.normal( 1, 0.5, [1] , name = 'al')\n",
    "    ap = dist.normal( -1.5, 1, [1], name = 'ap')\n",
    "    p = expit(ap)\n",
    "    lambda_ = jnp.exp(al)\n",
    "    lk(\"y\", ZeroInflatedPoisson(p, lambda_), obs=y)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. OrderedLogistic (Todo: PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpyro.distributions as dist\n",
    "## setup platform------------------------------------------------\n",
    "#m = bi()\n",
    "## import data ------------------------------------------------\n",
    "#m.data('../data/Trolley.csv', sep=';') \n",
    "#d = m.df\n",
    "## discrete proportion of each response value\n",
    "#pr_k = d.response.value_counts().sort_index().values / d.shape[0]\n",
    "## cumsum converts to cumulative proportions\n",
    "#cum_pr_k = jnp.cumsum(pr_k, -1)\n",
    "#logit = lambda x: jnp.log(x / (1 - x))  # convenience function\n",
    "#lco = logit(cum_pr_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TransformedDistribution.__init__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Run sampler ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     16\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[0;32m---> 17\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     18\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BI/bi/honnor/main.py:168\u001b[0m, in \u001b[0;36mbi.run\u001b[0;34m(self, model, potential_fn, kinetic_fn, step_size, inverse_mass_matrix, adapt_step_size, adapt_mass_matrix, dense_mass, target_accept_prob, trajectory_length, max_tree_depth, init_strategy, find_heuristic_step_size, forward_mode_differentiation, regularize_mass_matrix, num_warmup, num_samples, num_chains, thinning, postprocess_fn, chain_method, progress_bar, jit_model_args)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m MCMC(NUTS(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    145\u001b[0m                         potential_fn\u001b[38;5;241m=\u001b[39mpotential_fn,\n\u001b[1;32m    146\u001b[0m                         kinetic_fn\u001b[38;5;241m=\u001b[39mkinetic_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m                         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    166\u001b[0m                         jit_model_args\u001b[38;5;241m=\u001b[39mjit_model_args)\n\u001b[1;32m    167\u001b[0m start \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()  \n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_on_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m end \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()    \n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBI took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:644\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m map_args \u001b[38;5;241m=\u001b[39m (rng_key, init_state, init_params)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 644\u001b[0m     states_flat, last_state \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     states \u001b[38;5;241m=\u001b[39m tree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[jnp\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], states_flat)\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/mcmc.py:426\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Check if _sample_fn is None, then we need to initialize the sampler.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sample_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 426\u001b[0m     new_init_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     init_state \u001b[38;5;241m=\u001b[39m new_init_state \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m init_state\n\u001b[1;32m    434\u001b[0m sample_fn, postprocess_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cached_fns()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:743\u001b[0m, in \u001b[0;36mHMC.init\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# vectorized\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     rng_key, rng_key_init_model \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mswapaxes(\n\u001b[1;32m    741\u001b[0m         vmap(random\u001b[38;5;241m.\u001b[39msplit)(rng_key), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    742\u001b[0m     )\n\u001b[0;32m--> 743\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_key_init_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn \u001b[38;5;129;01mand\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid value of `init_params` must be provided with\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `potential_fn`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/hmc.py:687\u001b[0m, in \u001b[0;36mHMC._init_state\u001b[0;34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         (\n\u001b[1;32m    683\u001b[0m             new_init_params,\n\u001b[1;32m    684\u001b[0m             potential_fn,\n\u001b[1;32m    685\u001b[0m             postprocess_fn,\n\u001b[1;32m    686\u001b[0m             model_trace,\n\u001b[0;32m--> 687\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforward_mode_differentiation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_mode_differentiation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m             init_params \u001b[38;5;241m=\u001b[39m new_init_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/util.py:656\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[1;32m    646\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[1;32m    647\u001b[0m substituted_model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[1;32m    648\u001b[0m     seed(model, rng_key \u001b[38;5;28;01mif\u001b[39;00m is_prng_key(rng_key) \u001b[38;5;28;01melse\u001b[39;00m rng_key[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    649\u001b[0m     substitute_fn\u001b[38;5;241m=\u001b[39minit_strategy,\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    651\u001b[0m (\n\u001b[1;32m    652\u001b[0m     inv_transforms,\n\u001b[1;32m    653\u001b[0m     replay_model,\n\u001b[1;32m    654\u001b[0m     has_enumerate_support,\n\u001b[1;32m    655\u001b[0m     model_trace,\n\u001b[0;32m--> 656\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstituted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# substitute param sites from model_trace to model so\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# we don't need to generate again parameters of `numpyro.module`\u001b[39;00m\n\u001b[1;32m    659\u001b[0m model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[1;32m    660\u001b[0m     model,\n\u001b[1;32m    661\u001b[0m     data\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     },\n\u001b[1;32m    666\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/infer/util.py:450\u001b[0m, in \u001b[0;36m_get_model_transforms\u001b[0;34m(model, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_transforms\u001b[39m(model, model_args\u001b[38;5;241m=\u001b[39m(), model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    449\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[0;32m--> 450\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     inv_transforms \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# model code may need to be replayed in the presence of deterministic sites\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/handlers.py:171\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(response):\n\u001b[1;32m      7\u001b[0m     cutpoints \u001b[38;5;241m=\u001b[39m numpyro\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m      8\u001b[0m         \n\u001b[0;32m----> 9\u001b[0m         \u001b[43mdistnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformedDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcutpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdistnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOrderedTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     numpyro\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist\u001b[38;5;241m.\u001b[39mOrderedLogistic(\u001b[38;5;241m0\u001b[39m, cutpoints), obs\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpyro/distributions/distribution.py:99\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformedDistribution.__init__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "#import numpyro.distributions as distnp\n",
    "#from numpyro.distributions.transforms import OrderedTransform\n",
    "## setup platform------------------------------------------------\n",
    "#m = bi()\n",
    "#m.data_on_model = dict(response = jnp.array(d.response.values - 1))\n",
    "#def model(response):\n",
    "#    cutpoints = numpyro.sample(\n",
    "#        \n",
    "#        distnp.TransformedDistribution(\"cutpoints\",\n",
    "#            distnp.Normal(0, 1.5), OrderedTransform()\n",
    "#        ),\n",
    "#    )\n",
    "#    numpyro.sample(\"R\", dist.OrderedLogistic(0, cutpoints), obs=response)\n",
    "#\n",
    "## Run sampler ------------------------------------------------\n",
    "#start = tm.time()    \n",
    "#m.run(model) \n",
    "#end = tm.time()    \n",
    "#print(f\"BI took: {end - start:.4f} seconds\")\n",
    "#\n",
    "## Diagnostic ------------------------------------------------\n",
    "#m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying interceps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:00<00:00, 1119.98it/s, 15 steps of size 1.06e-01. acc. prob=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.8454 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "  a_bar[0]      0.83      0.90      0.92     -0.12      2.42     28.91      1.08\n",
      "  alpha[0]      0.83      0.07      0.84      0.72      0.92    152.28      1.01\n",
      "  alpha[1]      0.80      1.55      0.89     -1.53      3.38     82.40      1.03\n",
      "  alpha[2]      0.82      1.86      0.90     -1.22      3.84     89.87      1.03\n",
      "  alpha[3]      0.83      1.53      0.90     -1.36      3.15    109.65      1.01\n",
      "  alpha[4]      0.84      1.78      0.89     -2.14      3.17    108.21      1.02\n",
      "  alpha[5]      0.87      1.54      0.98     -1.71      3.08     67.36      1.03\n",
      "  alpha[6]      0.77      1.78      0.85     -1.66      3.43     85.76      1.02\n",
      "  alpha[7]      0.90      1.52      1.05     -1.68      2.92     73.27      1.05\n",
      "  alpha[8]      0.79      1.57      0.89     -1.19      3.30     76.00      1.04\n",
      "  alpha[9]      0.83      1.51      0.87     -1.21      2.83     75.38      1.02\n",
      " alpha[10]      0.79      1.71      0.96     -1.14      3.65     82.64      1.03\n",
      " alpha[11]      0.82      1.57      0.91     -1.17      3.07     84.09      1.02\n",
      " alpha[12]      0.85      1.73      0.90     -1.58      3.60     74.53      1.04\n",
      " alpha[13]      0.79      1.68      0.86     -1.60      3.24    163.52      1.02\n",
      " alpha[14]      0.85      1.58      0.94     -0.94      3.83     89.79      1.02\n",
      " alpha[15]      0.87      1.63      0.89     -1.28      3.15    102.49      1.01\n",
      " alpha[16]      0.84      1.59      0.96     -1.42      3.11     76.68      1.03\n",
      " alpha[17]      0.91      1.70      0.91     -1.63      3.38     89.86      1.02\n",
      " alpha[18]      0.88      1.62      0.99     -1.49      3.20     79.28      1.03\n",
      " alpha[19]      0.85      1.60      0.91     -1.43      3.48     79.63      1.03\n",
      " alpha[20]      0.87      1.70      0.96     -1.08      3.32     98.30      1.02\n",
      " alpha[21]      0.80      1.60      0.89     -1.63      3.33     91.41      1.02\n",
      " alpha[22]      0.88      1.52      0.94     -1.27      3.35     88.01      1.03\n",
      " alpha[23]      0.87      1.60      0.95     -1.06      3.59    133.47      1.01\n",
      " alpha[24]      0.76      1.80      0.93     -0.87      3.87     95.39      1.03\n",
      " alpha[25]      0.81      1.74      0.91     -1.85      3.51     82.99      1.02\n",
      " alpha[26]      0.86      1.76      0.90     -1.31      3.65     66.97      1.02\n",
      " alpha[27]      0.77      1.67      0.93     -2.01      3.29     82.09      1.03\n",
      " alpha[28]      0.83      1.62      0.92     -0.63      3.88     83.88      1.02\n",
      " alpha[29]      0.70      1.89      0.91     -1.41      3.62     85.67      1.05\n",
      " alpha[30]      0.82      1.49      0.90     -1.02      3.21     82.11      1.02\n",
      " alpha[31]      0.85      1.41      0.94     -0.88      2.74     74.49      1.03\n",
      " alpha[32]      0.80      1.60      0.88     -1.55      3.14     93.61      1.02\n",
      " alpha[33]      0.92      1.67      0.94     -1.64      3.46     95.65      1.00\n",
      " alpha[34]      0.86      1.67      0.92     -1.48      3.25     62.73      1.02\n",
      " alpha[35]      0.79      1.73      0.93     -1.72      3.39    106.68      1.03\n",
      " alpha[36]      0.88      1.47      1.00     -0.94      3.26     68.86      1.04\n",
      " alpha[37]      0.85      1.72      0.92     -2.14      3.07    106.00      1.02\n",
      " alpha[38]      0.87      1.47      0.89     -1.24      3.12     77.45      1.03\n",
      " alpha[39]      0.75      1.86      0.96     -1.97      3.44     85.08      1.03\n",
      " alpha[40]      0.78      1.87      1.03     -1.32      3.91     84.61      1.02\n",
      " alpha[41]      0.72      1.93      0.84     -1.27      4.30    109.55      1.02\n",
      " alpha[42]      0.84      1.79      0.94     -1.24      3.23     90.72      1.02\n",
      " alpha[43]      0.86      1.54      0.97     -1.45      3.30     89.63      1.02\n",
      " alpha[44]      0.92      1.66      1.09     -1.12      3.76    111.30      1.01\n",
      " alpha[45]      0.89      1.70      0.93     -1.15      3.43    229.84      1.01\n",
      " alpha[46]      0.90      1.52      0.91     -1.55      2.76     85.47      1.01\n",
      " alpha[47]      0.77      1.82      0.87     -1.34      3.97     87.19      1.03\n",
      "  sigma[0]      1.11      0.87      0.85      0.29      2.14     11.96      1.11\n",
      "\n",
      "Number of divergences: 3\n"
     ]
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi()\n",
    "# import data ------------------------------------------------\n",
    "m.data('../data/reedfrogs.csv', sep=';') \n",
    "m.df[\"tank\"] = np.arange(m.df.shape[0])\n",
    "tank = jnp.array(m.df[\"tank\"].astype('int32').values)\n",
    "density = jnp.array(m.df[\"density\"].astype('float32').values)\n",
    "surv = jnp.array(m.df[\"surv\"].astype('int32').values)\n",
    "m.data_on_model = dict(\n",
    "    tank = tank,\n",
    "    surv = surv\n",
    ")\n",
    "\n",
    "def model(tank, surv):\n",
    "    sigma = dist.exponential( 1, shape = [1], name = 'sigma')\n",
    "    a_bar = dist.normal( 0., 1.5, shape= [1], name = 'a_bar')\n",
    "    alpha = dist.normal( a_bar, sigma, shape= [48], name = 'alpha')\n",
    "    p = jnp.squeeze(alpha[tank])[0]\n",
    "    lk(\"y\", Binomial(total_count = density, logits = p), obs=surv)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Varying effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dd\n",
    "a = 3.5  # average morning wait time\n",
    "b = -1  # average difference afternoon wait time\n",
    "sigma_a = 1  # std dev in intercepts\n",
    "sigma_b = 0.5  # std dev in slopes\n",
    "rho = -0.7  # correlation between intercepts and slopes\n",
    "Mu = jnp.array([a, b])\n",
    "cov_ab = sigma_a * sigma_b * rho\n",
    "Sigma = jnp.array([[sigma_a**2, cov_ab], [cov_ab, sigma_b**2]])\n",
    "jnp.array([1, 2, 3, 4]).reshape(2, 2).T\n",
    "sigmas = jnp.array([sigma_a, sigma_b])  # standard deviations\n",
    "Rho = jnp.array([[1, rho], [rho, 1]])  # correlation matrix\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "Sigma = jnp.diag(sigmas) @ Rho @ jnp.diag(sigmas)\n",
    "\n",
    "N_cafes = 20\n",
    "seed = random.PRNGKey(5)  # used to replicate example\n",
    "vary_effects = bi.dist.multivariatenormal(Mu, Sigma, shape=(N_cafes,), sample = True)\n",
    "a_cafe = vary_effects[:, 0]\n",
    "b_cafe = vary_effects[:, 1]\n",
    "\n",
    "seed = random.PRNGKey(22)\n",
    "N_visits = 10\n",
    "afternoon = jnp.tile(jnp.arange(2), N_visits * N_cafes // 2)\n",
    "cafe_id = jnp.repeat(jnp.arange(N_cafes), N_visits)\n",
    "mu = a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n",
    "sigma = 0.5  # std dev within cafes\n",
    "wait = dist.normal(mu, sigma, sample = True)\n",
    "d = pd.DataFrame(dict(cafe=cafe_id, afternoon=afternoon, wait=wait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 565.81it/s, 127 steps of size 3.13e-02. acc. prob=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 3.9591 seconds\n",
      "\n",
      "                   mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "     Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "     Rho[0,1]     -0.47      0.34     -0.53     -0.98     -0.04    116.23      1.01\n",
      "     Rho[1,0]     -0.47      0.34     -0.53     -0.98     -0.04    116.23      1.01\n",
      "     Rho[1,1]      1.00      0.00      1.00      1.00      1.00    363.54      1.00\n",
      "            a      3.51      0.17      3.52      3.21      3.76    225.61      1.03\n",
      "  a_cafe[0,0]      3.22      0.18      3.22      2.92      3.47    512.84      1.00\n",
      "  a_cafe[0,1]     -0.84      0.15     -0.82     -1.07     -0.61    324.48      1.01\n",
      "  a_cafe[1,0]      4.36      0.19      4.34      4.09      4.70    372.76      1.00\n",
      "  a_cafe[1,1]     -0.98      0.18     -0.96     -1.27     -0.71    157.51      1.01\n",
      "  a_cafe[2,0]      3.71      0.19      3.71      3.43      4.01    406.81      1.00\n",
      "  a_cafe[2,1]     -0.86      0.17     -0.88     -1.14     -0.60    324.84      1.00\n",
      "  a_cafe[3,0]      2.65      0.20      2.65      2.36      2.96    345.97      1.00\n",
      "  a_cafe[3,1]     -0.72      0.18     -0.74     -1.03     -0.44     82.97      1.00\n",
      "  a_cafe[4,0]      3.48      0.19      3.49      3.17      3.75    538.24      1.00\n",
      "  a_cafe[4,1]     -0.84      0.15     -0.84     -1.10     -0.62    180.17      1.02\n",
      "  a_cafe[5,0]      2.65      0.19      2.65      2.33      2.92    329.67      1.02\n",
      "  a_cafe[5,1]     -0.79      0.17     -0.78     -1.04     -0.51    140.45      1.03\n",
      "  a_cafe[6,0]      3.75      0.20      3.75      3.43      4.09    410.41      1.00\n",
      "  a_cafe[6,1]     -0.82      0.16     -0.82     -1.09     -0.59    194.86      1.00\n",
      "  a_cafe[7,0]      3.40      0.19      3.42      3.11      3.69    508.91      1.00\n",
      "  a_cafe[7,1]     -0.81      0.16     -0.82     -1.03     -0.53    182.72      1.01\n",
      "  a_cafe[8,0]      3.17      0.16      3.16      2.93      3.44    797.87      1.00\n",
      "  a_cafe[8,1]     -0.86      0.13     -0.86     -1.08     -0.67    285.96      1.01\n",
      "  a_cafe[9,0]      2.94      0.19      2.94      2.68      3.27    415.49      1.00\n",
      "  a_cafe[9,1]     -0.84      0.15     -0.84     -1.09     -0.61    177.24      1.03\n",
      " a_cafe[10,0]      3.88      0.18      3.88      3.61      4.17    404.64      1.01\n",
      " a_cafe[10,1]     -0.91      0.14     -0.91     -1.15     -0.69    188.57      1.02\n",
      " a_cafe[11,0]      3.29      0.19      3.29      2.99      3.58    498.10      1.00\n",
      " a_cafe[11,1]     -0.82      0.16     -0.83     -1.07     -0.57    286.03      1.01\n",
      " a_cafe[12,0]      2.79      0.19      2.78      2.50      3.10    411.62      1.00\n",
      " a_cafe[12,1]     -0.81      0.16     -0.81     -1.06     -0.55    209.87      1.03\n",
      " a_cafe[13,0]      3.18      0.18      3.18      2.91      3.47    113.75      1.01\n",
      " a_cafe[13,1]     -0.73      0.18     -0.76     -0.96     -0.40     61.70      1.01\n",
      " a_cafe[14,0]      3.31      0.19      3.31      3.03      3.62    513.47      1.00\n",
      " a_cafe[14,1]     -0.82      0.15     -0.83     -1.05     -0.58    237.12      1.00\n",
      " a_cafe[15,0]      4.54      0.19      4.54      4.21      4.78    403.62      1.00\n",
      " a_cafe[15,1]     -0.99      0.18     -0.96     -1.24     -0.71    154.22      1.00\n",
      " a_cafe[16,0]      5.37      0.21      5.36      5.05      5.70    204.41      1.00\n",
      " a_cafe[16,1]     -1.08      0.23     -1.05     -1.42     -0.71     90.72      1.00\n",
      " a_cafe[17,0]      4.26      0.21      4.26      3.90      4.56    148.03      1.00\n",
      " a_cafe[17,1]     -1.08      0.24     -1.04     -1.44     -0.74     57.15      1.01\n",
      " a_cafe[18,0]      2.32      0.19      2.33      2.01      2.60    424.89      1.00\n",
      " a_cafe[18,1]     -0.71      0.18     -0.71     -0.98     -0.42     86.91      1.01\n",
      " a_cafe[19,0]      3.56      0.18      3.56      3.30      3.86    494.25      1.00\n",
      " a_cafe[19,1]     -0.93      0.16     -0.91     -1.20     -0.72    116.45      1.03\n",
      "            b     -0.87      0.09     -0.86     -1.00     -0.73    110.24      1.05\n",
      "     sigma[0]      0.52      0.03      0.52      0.48      0.56    313.92      1.00\n",
      "sigma_cafe[0]      0.78      0.14      0.76      0.58      1.00    308.86      1.00\n",
      "sigma_cafe[1]      0.17      0.10      0.17      0.01      0.29     24.26      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi()\n",
    "m.data_on_model = dict(\n",
    "    cafe = cafe_id, \n",
    "    wait = wait, \n",
    "    N_cafes = N_cafes\n",
    ")\n",
    "def model(cafe, wait, N_cafes):\n",
    "    a = dist.normal(5, 2, name = 'a')\n",
    "    b = dist.normal(-1, 0.5, name = 'b')\n",
    "    sigma_cafe = dist.exponential(1, shape=[2], name = 'sigma_cafe')\n",
    "    sigma = dist.exponential( 1, shape=[1], name = 'sigma')\n",
    "    Rho = dist.lkj(2, 2, name = 'Rho')\n",
    "    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "    a_cafe_b_cafe = dist.multivariatenormal(jnp.stack([a, b]), cov, shape = [N_cafes], name = 'a_cafe')    \n",
    "\n",
    "    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "    lk(\"y\", Normal(mu, sigma), obs=wait)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "m.run(model) \n",
    "\n",
    "# Diagnostic ------------------------------------------------\n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:39<00:00, 25.49it/s, 31 steps of size 1.32e-01. acc. prob=0.90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 39.7222 seconds\n",
      "BI took: 39.7995 seconds\n",
      "\n",
      "                         mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "           Rho[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "           Rho[0,1]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,0]     -0.48      0.33     -0.53     -0.96     -0.04    115.42      1.00\n",
      "           Rho[1,1]      1.00      0.00      1.00      1.00      1.00     61.24      1.00\n",
      "                  a      3.50      0.18      3.50      3.23      3.79    514.91      1.00\n",
      " a_cafe,b_cafe[0,0]      3.21      0.18      3.21      2.94      3.49    363.81      1.00\n",
      " a_cafe,b_cafe[0,1]     -0.83      0.15     -0.84     -1.05     -0.60    249.04      1.00\n",
      " a_cafe,b_cafe[1,0]      4.35      0.18      4.35      4.08      4.66    352.42      1.00\n",
      " a_cafe,b_cafe[1,1]     -0.97      0.17     -0.96     -1.20     -0.68    272.80      1.00\n",
      " a_cafe,b_cafe[2,0]      3.71      0.19      3.71      3.36      3.99    568.49      1.00\n",
      " a_cafe,b_cafe[2,1]     -0.85      0.16     -0.86     -1.08     -0.58    216.11      1.01\n",
      " a_cafe,b_cafe[3,0]      2.64      0.20      2.64      2.37      2.97    487.59      1.00\n",
      " a_cafe,b_cafe[3,1]     -0.70      0.18     -0.72     -0.98     -0.43    102.60      1.01\n",
      " a_cafe,b_cafe[4,0]      3.48      0.19      3.49      3.20      3.75    534.61      1.00\n",
      " a_cafe,b_cafe[4,1]     -0.84      0.15     -0.84     -1.05     -0.58    265.62      1.00\n",
      " a_cafe,b_cafe[5,0]      2.65      0.18      2.64      2.39      2.96    534.49      1.00\n",
      " a_cafe,b_cafe[5,1]     -0.79      0.17     -0.80     -1.01     -0.49    200.19      1.00\n",
      " a_cafe,b_cafe[6,0]      3.75      0.18      3.76      3.47      4.05    781.58      1.00\n",
      " a_cafe,b_cafe[6,1]     -0.82      0.16     -0.84     -1.06     -0.55    171.69      1.00\n",
      " a_cafe,b_cafe[7,0]      3.41      0.19      3.41      3.14      3.70    437.90      1.01\n",
      " a_cafe,b_cafe[7,1]     -0.81      0.15     -0.82     -1.04     -0.57    209.64      1.02\n",
      " a_cafe,b_cafe[8,0]      3.15      0.17      3.15      2.86      3.37    555.12      1.00\n",
      " a_cafe,b_cafe[8,1]     -0.87      0.14     -0.86     -1.10     -0.67    213.95      1.00\n",
      " a_cafe,b_cafe[9,0]      2.94      0.19      2.94      2.68      3.25    514.75      1.00\n",
      " a_cafe,b_cafe[9,1]     -0.85      0.17     -0.85     -1.09     -0.57    308.92      1.00\n",
      "a_cafe,b_cafe[10,0]      3.89      0.18      3.88      3.59      4.16    570.16      1.00\n",
      "a_cafe,b_cafe[10,1]     -0.92      0.15     -0.91     -1.14     -0.69    283.55      1.00\n",
      "a_cafe,b_cafe[11,0]      3.31      0.20      3.30      2.99      3.60    501.42      1.00\n",
      "a_cafe,b_cafe[11,1]     -0.84      0.17     -0.84     -1.08     -0.53    328.56      1.00\n",
      "a_cafe,b_cafe[12,0]      2.79      0.18      2.80      2.51      3.08    661.61      1.00\n",
      "a_cafe,b_cafe[12,1]     -0.82      0.16     -0.82     -1.06     -0.58    300.02      1.00\n",
      "a_cafe,b_cafe[13,0]      3.18      0.19      3.17      2.93      3.53    243.63      1.01\n",
      "a_cafe,b_cafe[13,1]     -0.73      0.19     -0.75     -0.99     -0.40     96.66      1.03\n",
      "a_cafe,b_cafe[14,0]      3.33      0.18      3.32      3.07      3.66    523.19      1.00\n",
      "a_cafe,b_cafe[14,1]     -0.83      0.15     -0.85     -1.05     -0.58    319.39      1.00\n",
      "a_cafe,b_cafe[15,0]      4.54      0.18      4.54      4.25      4.83    401.77      1.00\n",
      "a_cafe,b_cafe[15,1]     -0.98      0.17     -0.98     -1.23     -0.73    280.91      1.00\n",
      "a_cafe,b_cafe[16,0]      5.36      0.21      5.35      5.04      5.70    437.80      1.00\n",
      "a_cafe,b_cafe[16,1]     -1.08      0.23     -1.08     -1.45     -0.76    244.11      1.00\n",
      "a_cafe,b_cafe[17,0]      4.24      0.19      4.24      3.90      4.52    163.09      1.00\n",
      "a_cafe,b_cafe[17,1]     -1.09      0.21     -1.06     -1.41     -0.77     82.77      1.00\n",
      "a_cafe,b_cafe[18,0]      2.32      0.19      2.32      2.02      2.62    426.39      1.00\n",
      "a_cafe,b_cafe[18,1]     -0.72      0.18     -0.75     -0.96     -0.42    155.20      1.02\n",
      "a_cafe,b_cafe[19,0]      3.57      0.18      3.57      3.31      3.89    688.04      1.00\n",
      "a_cafe,b_cafe[19,1]     -0.93      0.17     -0.91     -1.21     -0.68    234.35      1.00\n",
      "                  b     -0.86      0.08     -0.86     -0.99     -0.75    174.01      1.00\n",
      "           sigma[0]      0.52      0.03      0.52      0.48      0.57    596.32      1.00\n",
      "      sigma_cafe[0]      0.77      0.13      0.76      0.58      1.00    566.72      1.00\n",
      "      sigma_cafe[1]      0.18      0.09      0.17      0.03      0.30     44.31      1.02\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "## import data ------------------------------------------------\n",
    "#m = bi()\n",
    "#m.data = dict(\n",
    "#    cafe = cafe_id, \n",
    "#    wait = wait, \n",
    "#    N_cafes = N_cafes\n",
    "#)\n",
    "#def model(cafe, wait, N_cafes):\n",
    "#    a = numpyro.sample(\"a\", dd.Normal(5, 2))\n",
    "#    b = numpyro.sample(\"b\", dd.Normal(-1, 0.5))\n",
    "#    sigma_cafe = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([2]))\n",
    "#    sigma = numpyro.sample(\"sigma_cafe\",dd.Exponential(1).expand([1]))\n",
    "#    Rho = numpyro.sample(\"Rho\", dd.LKJ(2, 2))\n",
    "#    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n",
    "#    a_cafe_b_cafe = numpyro.sample(\n",
    "#        \"a_cafe,b_cafe\", dd.MultivariateNormal(jnp.stack([a, b]), cov).expand([N_cafes])\n",
    "#    )\n",
    "#    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n",
    "#    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n",
    "#    lk(\"y\", dd.Normal(mu, sigma), obs=wait)\n",
    "#\n",
    "## Run sampler ------------------------------------------------\n",
    "#start = tm.time()    \n",
    "#m.run(model) \n",
    "#end = tm.time()    \n",
    "#print(f\"BI took: {end - start:.4f} seconds\")\n",
    "#\n",
    "## Diagnostic ------------------------------------------------\n",
    "#m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_4314cm3u/model_4xoavcff.stan', line 20, column 4: It\n",
      "    is suggested to reparameterize your model to replace lkj_corr with\n",
      "    lkj_corr_cholesky, the Cholesky factor variant. lkj_corr tends to run\n",
      "    slower, consume more memory, and has higher risk of numerical errors.\n",
      "Warning: The parameter b_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter a_cafe has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.012288 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 122.88 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_lpdf: Correlation matrix is not positive definite. (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 20, column 4 to column 24)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = 1.06425e+30, but Covariance matrix[2,1] = 1.06425e+30 (in '/tmp/httpstan_6u0srrts/model_4xoavcff.stan', line 30, column 8 to column 67)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 1715.6098 seconds\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "import httpstan.models\n",
    "import httpstan.cache\n",
    "import numpy as np\n",
    "#try:\n",
    "#  httpstan.cache.delete_model_directory(httpstan.models.calculate_model_name(stan_code)) # Delete  model in cache\n",
    "#except:\n",
    "#  pass\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data{\n",
    "    int len;\n",
    "    int N_cafes;\n",
    "    vector[len] wait;\n",
    "    array[len] int afternoon;\n",
    "    array[len] int cafe;\n",
    "}\n",
    "parameters{\n",
    "    vector[N_cafes] b_cafe;\n",
    "    vector[N_cafes] a_cafe;\n",
    "    real a;\n",
    "    real b;\n",
    "    vector<lower=0>[2] sigma_cafe;\n",
    "    real<lower=0> sigma;\n",
    "    corr_matrix[2] Rho;\n",
    "}\n",
    "model{\n",
    "    vector[len] mu;\n",
    "    Rho ~ lkj_corr( 2 );\n",
    "    sigma ~ exponential( 1 );\n",
    "    sigma_cafe ~ exponential( 1 );\n",
    "    b ~ normal( -1 , 0.5 );    \n",
    "    a ~ normal( 5 , 2 );\n",
    "    {\n",
    "        array[N_cafes] vector[2] YY;\n",
    "        vector[2] MU;\n",
    "        MU = [ a , b ]';\n",
    "        for ( j in 1:N_cafes ) YY[j] = [ a_cafe[j] , b_cafe[j] ]';\n",
    "        YY ~ multi_normal( MU , quad_form_diag(Rho , sigma_cafe) );\n",
    "    }\n",
    "    for ( i in 1:len ) {\n",
    "        mu[i] = a_cafe[cafe[i]] + b_cafe[cafe[i]] * afternoon[i];        \n",
    "    }\n",
    "    \n",
    "    wait ~ normal( mu , sigma );\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "data = {\n",
    "    'wait' : d['wait'].values.astype(float),\n",
    "    'afternoon' : d['afternoon'].values.astype(int),\n",
    "    'cafe' : d['cafe'].values.astype(int)+1,\n",
    "    'N_cafes' : N_cafes,\n",
    "    'len' : len(d['wait'].values)\n",
    "}\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = data)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500)\n",
    "end = tm.time()    \n",
    "df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Multiple random effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:04<00:00, 248.22it/s, 63 steps of size 9.02e-02. acc. prob=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 8.0283 seconds\n",
      "\n",
      "                  mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "L_Rho_d[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      "L_Rho_d[0,1]      0.00      0.00      0.00      0.00      0.00       nan       nan\n",
      "L_Rho_d[1,0]      0.88      0.04      0.88      0.82      0.93     53.74      1.02\n",
      "L_Rho_d[1,1]      0.47      0.07      0.48      0.36      0.57     54.94      1.02\n",
      " Rho_gr[0,0]      1.00      0.00      1.00      1.00      1.00       nan       nan\n",
      " Rho_gr[0,1]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,0]     -0.39      0.20     -0.41     -0.71     -0.08    203.92      1.00\n",
      " Rho_gr[1,1]      1.00      0.00      1.00      1.00      1.00    435.00      1.00\n",
      "           a      0.53      0.17      0.52      0.27      0.79    153.88      1.00\n",
      "     gr[0,0]     -0.49      0.28     -0.48     -0.91     -0.03    252.20      1.01\n",
      "     gr[0,1]      0.21      0.22      0.21     -0.15      0.55    631.29      1.00\n",
      "     gr[1,0]      0.18      0.27      0.20     -0.25      0.62    235.24      1.00\n",
      "     gr[1,1]     -0.13      0.22     -0.13     -0.47      0.20    571.67      1.00\n",
      "     gr[2,0]      1.12      0.26      1.13      0.64      1.48    210.39      1.00\n",
      "     gr[2,1]     -0.33      0.23     -0.33     -0.71      0.04    406.51      1.00\n",
      "     gr[3,0]     -0.72      0.30     -0.72     -1.17     -0.26    256.68      1.00\n",
      "     gr[3,1]      0.34      0.24      0.34     -0.04      0.69    524.76      1.00\n",
      "     gr[4,0]     -0.46      0.27     -0.46     -0.88     -0.07    311.94      1.00\n",
      "     gr[4,1]      0.39      0.22      0.38      0.05      0.73    240.70      1.00\n",
      "     gr[5,0]     -0.96      0.32     -0.96     -1.41     -0.40    315.16      1.00\n",
      "     gr[5,1]      0.56      0.24      0.55      0.21      0.94    353.90      1.00\n",
      "     gr[6,0]     -0.56      0.32     -0.56     -1.05     -0.07    333.21      1.00\n",
      "     gr[6,1]      0.15      0.22      0.15     -0.22      0.49    490.87      1.00\n",
      "     gr[7,0]     -0.73      0.28     -0.73     -1.19     -0.31    233.56      1.00\n",
      "     gr[7,1]      0.25      0.21      0.25     -0.10      0.54    440.49      1.00\n",
      "     gr[8,0]      0.23      0.25      0.23     -0.18      0.61    272.17      1.00\n",
      "     gr[8,1]     -0.26      0.22     -0.26     -0.66      0.05    461.30      1.00\n",
      "     gr[9,0]      1.37      0.26      1.35      0.97      1.78    212.37      1.01\n",
      "     gr[9,1]     -0.43      0.24     -0.43     -0.83     -0.07    479.45      1.00\n",
      "    gr[10,0]     -0.93      0.32     -0.92     -1.47     -0.48    261.43      1.00\n",
      "    gr[10,1]      0.38      0.23      0.38      0.06      0.76    436.37      1.00\n",
      "    gr[11,0]     -0.70      0.31     -0.70     -1.23     -0.25    302.94      1.00\n",
      "    gr[11,1]     -0.09      0.23     -0.08     -0.45      0.29    673.00      1.00\n",
      "    gr[12,0]      0.98      0.27      0.99      0.56      1.42    228.46      1.01\n",
      "    gr[12,1]     -0.25      0.22     -0.25     -0.61      0.07    362.00      1.00\n",
      "    gr[13,0]      0.24      0.30      0.24     -0.15      0.79    200.18      1.00\n",
      "    gr[13,1]      0.24      0.23      0.24     -0.14      0.58    281.45      1.00\n",
      "    gr[14,0]     -0.74      0.30     -0.75     -1.23     -0.31    270.41      1.00\n",
      "    gr[14,1]      0.59      0.23      0.58      0.25      0.98    316.93      1.00\n",
      "    gr[15,0]      0.03      0.27      0.02     -0.36      0.48    239.98      1.00\n",
      "    gr[15,1]      0.47      0.24      0.44      0.15      0.89    238.07      1.00\n",
      "    gr[16,0]      0.57      0.27      0.55      0.17      1.05    167.80      1.00\n",
      "    gr[16,1]      0.19      0.22      0.18     -0.15      0.53    332.53      1.00\n",
      "    gr[17,0]     -0.31      0.31     -0.31     -0.84      0.16    270.13      1.00\n",
      "    gr[17,1]     -0.61      0.28     -0.60     -0.99     -0.08    453.87      1.00\n",
      "    gr[18,0]      0.09      0.29      0.07     -0.41      0.54    257.63      1.00\n",
      "    gr[18,1]      0.02      0.21      0.02     -0.31      0.35    431.74      1.00\n",
      "    gr[19,0]      0.90      0.27      0.88      0.53      1.37    243.69      1.00\n",
      "    gr[19,1]     -0.42      0.23     -0.42     -0.78     -0.04    503.12      1.00\n",
      "    gr[20,0]      1.42      0.25      1.40      1.03      1.85    205.85      1.00\n",
      "    gr[20,1]     -0.37      0.22     -0.37     -0.73      0.01    389.14      1.00\n",
      "    gr[21,0]      0.26      0.28      0.27     -0.20      0.67    237.98      1.00\n",
      "    gr[21,1]     -0.33      0.23     -0.34     -0.70      0.05    334.85      1.00\n",
      "    gr[22,0]      1.13      0.27      1.12      0.73      1.57    226.02      1.00\n",
      "    gr[22,1]     -0.57      0.22     -0.56     -0.92     -0.21    411.56      1.00\n",
      "    gr[23,0]     -0.24      0.28     -0.23     -0.64      0.27    322.79      1.00\n",
      "    gr[23,1]     -0.19      0.22     -0.19     -0.53      0.18    245.26      1.01\n",
      "    gr[24,0]     -1.07      0.33     -1.08     -1.55     -0.55    374.00      1.00\n",
      "    gr[24,1]      0.18      0.23      0.19     -0.20      0.52    360.96      1.00\n",
      "       sigma      1.10      0.05      1.10      1.02      1.18    340.08      1.01\n",
      " sigma_gr[0]      0.83      0.14      0.81      0.63      1.05    412.62      1.00\n",
      " sigma_gr[1]      0.43      0.09      0.43      0.29      0.56    255.29      1.00\n",
      "      z[0,0]     -0.17      0.59     -0.21     -1.05      0.76    634.46      1.00\n",
      "      z[0,1]      1.59      0.41      1.59      1.01      2.27    620.52      1.00\n",
      "      z[0,2]      0.56      0.45      0.58     -0.14      1.22    645.43      1.00\n",
      "      z[0,3]      0.57      0.44      0.56     -0.09      1.25    410.03      1.00\n",
      "      z[0,4]      1.11      0.42      1.11      0.47      1.81    519.89      1.00\n",
      "      z[0,5]      0.11      0.53      0.13     -0.59      1.12   1137.88      1.00\n",
      "      z[0,6]      0.03      0.56      0.02     -0.77      0.96   1519.90      1.00\n",
      "      z[0,7]     -0.82      0.65     -0.80     -1.85      0.16    740.06      1.00\n",
      "      z[0,8]      2.31      0.37      2.30      1.69      2.86    603.31      1.00\n",
      "      z[0,9]     -0.55      0.65     -0.51     -1.43      0.54   1341.70      1.00\n",
      "     z[0,10]     -1.00      0.73     -0.96     -2.08      0.17    790.39      1.00\n",
      "     z[0,11]     -0.28      0.58     -0.26     -1.08      0.74    756.81      1.00\n",
      "     z[0,12]      0.50      0.47      0.51     -0.31      1.18    709.48      1.01\n",
      "     z[0,13]      0.66      0.45      0.67      0.05      1.41    655.68      1.00\n",
      "     z[0,14]     -0.90      0.67     -0.86     -2.06      0.06    654.51      1.00\n",
      "     z[0,15]     -0.40      0.54     -0.38     -1.24      0.45    736.60      1.00\n",
      "     z[0,16]     -0.96      0.73     -0.95     -2.17      0.07    889.27      1.00\n",
      "     z[0,17]     -0.54      0.60     -0.53     -1.46      0.46   1240.12      1.00\n",
      "     z[0,18]     -1.36      0.58     -1.38     -2.36     -0.53    512.19      1.00\n",
      "     z[0,19]     -0.41      0.56     -0.42     -1.23      0.49    790.24      1.00\n",
      "     z[0,20]     -1.15      0.75     -1.12     -2.24      0.13   1020.15      1.00\n",
      "     z[0,21]      0.24      0.52      0.24     -0.51      1.08    534.78      1.00\n",
      "     z[0,22]     -1.04      0.73     -1.00     -2.13      0.14   1238.56      1.00\n",
      "     z[0,23]      2.08      0.36      2.10      1.39      2.54    458.14      1.00\n",
      "     z[0,24]     -0.40      0.56     -0.39     -1.18      0.55    817.79      1.00\n",
      "     z[0,25]     -0.25      0.49     -0.21     -1.10      0.47    871.11      1.00\n",
      "     z[0,26]     -0.97      0.56     -0.94     -1.73      0.02    957.89      1.00\n",
      "     z[0,27]     -0.33      0.54     -0.29     -1.10      0.55    643.73      1.00\n",
      "     z[0,28]     -0.85      0.67     -0.80     -1.94      0.25    802.36      1.00\n",
      "     z[0,29]      2.50      0.29      2.48      2.06      2.96    350.11      1.00\n",
      "     z[0,30]      0.80      0.39      0.79      0.17      1.40    612.99      1.00\n",
      "     z[0,31]     -1.21      0.65     -1.16     -2.18     -0.12    733.72      1.00\n",
      "     z[0,32]     -0.81      0.59     -0.78     -1.75      0.05    861.18      1.00\n",
      "     z[0,33]     -1.12      0.69     -1.11     -2.14     -0.04    537.52      1.00\n",
      "     z[0,34]     -0.52      0.56     -0.52     -1.40      0.36    702.57      1.00\n",
      "     z[0,35]     -0.94      0.63     -0.91     -1.82      0.13    819.48      1.00\n",
      "     z[0,36]     -0.65      0.61     -0.62     -1.55      0.34    512.48      1.00\n",
      "     z[0,37]      0.09      0.41      0.10     -0.55      0.69    435.42      1.00\n",
      "     z[0,38]      1.88      0.31      1.90      1.35      2.35    423.23      1.00\n",
      "     z[0,39]     -0.20      0.62     -0.19     -1.20      0.74    902.43      1.00\n",
      "     z[0,40]      0.99      0.36      0.99      0.42      1.57    769.30      1.00\n",
      "     z[0,41]     -0.31      0.52     -0.31     -1.14      0.50    591.50      1.00\n",
      "     z[0,42]     -0.49      0.54     -0.50     -1.40      0.32    656.80      1.00\n",
      "     z[0,43]      2.02      0.34      2.01      1.50      2.57    397.03      1.00\n",
      "     z[0,44]      0.19      0.52      0.21     -0.55      1.09    804.65      1.00\n",
      "     z[0,45]      0.71      0.45      0.72     -0.00      1.38    608.11      1.00\n",
      "     z[0,46]     -0.71      0.64     -0.67     -1.78      0.25    730.98      1.00\n",
      "     z[0,47]      0.52      0.34      0.52     -0.01      1.03    389.15      1.00\n",
      "     z[0,48]      0.93      0.32      0.92      0.47      1.45    376.19      1.00\n",
      "     z[0,49]      1.50      0.28      1.50      1.11      2.02    289.02      1.00\n",
      "     z[0,50]     -0.12      0.44     -0.11     -0.84      0.58    619.12      1.00\n",
      "     z[0,51]     -0.71      0.46     -0.68     -1.35      0.06    530.12      1.00\n",
      "     z[0,52]     -1.48      0.64     -1.43     -2.50     -0.53    811.14      1.00\n",
      "     z[0,53]     -0.11      0.45     -0.10     -0.81      0.58    477.71      1.00\n",
      "     z[0,54]      0.26      0.36      0.27     -0.22      0.90    353.65      1.00\n",
      "     z[0,55]      0.19      0.40      0.20     -0.43      0.75    574.87      1.00\n",
      "     z[0,56]      0.25      0.41      0.28     -0.45      0.85    456.88      1.00\n",
      "     z[0,57]      0.46      0.35      0.45     -0.08      0.98    467.26      1.01\n",
      "     z[0,58]      0.79      0.33      0.78      0.27      1.32    326.67      1.00\n",
      "     z[0,59]     -0.44      0.40     -0.42     -1.14      0.17    528.47      1.00\n",
      "     z[0,60]      0.42      0.33      0.44     -0.16      0.90    350.05      1.00\n",
      "     z[0,61]     -1.30      0.71     -1.28     -2.47     -0.22    806.36      1.00\n",
      "     z[0,62]     -0.45      0.47     -0.42     -1.25      0.29    745.56      1.00\n",
      "     z[0,63]     -0.35      0.48     -0.35     -1.12      0.41    612.22      1.00\n",
      "     z[0,64]     -0.80      0.53     -0.76     -1.54      0.01    517.87      1.01\n",
      "     z[0,65]     -0.53      0.55     -0.49     -1.35      0.38    872.99      1.00\n",
      "     z[0,66]      1.36      0.35      1.36      0.78      1.87    412.75      1.00\n",
      "     z[0,67]     -0.75      0.49     -0.75     -1.32      0.13    718.89      1.00\n",
      "     z[0,68]      0.21      0.38      0.22     -0.36      0.84    533.37      1.00\n",
      "     z[0,69]      0.60      0.48      0.61     -0.16      1.37    591.38      1.00\n",
      "     z[0,70]      2.14      0.35      2.16      1.61      2.69    433.51      1.00\n",
      "     z[0,71]     -0.60      0.68     -0.55     -1.73      0.41    868.17      1.00\n",
      "     z[0,72]     -1.08      0.75     -1.05     -2.26      0.07    761.69      1.00\n",
      "     z[0,73]     -0.82      0.65     -0.76     -1.78      0.22    898.74      1.00\n",
      "     z[0,74]     -0.05      0.55     -0.06     -0.84      0.86    850.49      1.00\n",
      "     z[0,75]     -0.12      0.62     -0.09     -0.98      0.94    410.24      1.00\n",
      "     z[0,76]      0.37      0.56      0.38     -0.55      1.19    619.05      1.00\n",
      "     z[0,77]      0.30      0.55      0.31     -0.61      1.11    648.78      1.00\n",
      "     z[0,78]     -0.04      0.57     -0.00     -0.94      0.81    634.05      1.00\n",
      "     z[0,79]      0.14      0.59      0.17     -0.70      1.08    616.42      1.00\n",
      "     z[0,80]      1.47      0.39      1.47      0.83      2.08    542.98      1.00\n",
      "     z[0,81]     -0.24      0.56     -0.25     -1.00      0.65    577.46      1.00\n",
      "     z[0,82]     -0.54      0.66     -0.52     -1.67      0.42   1290.45      1.00\n",
      "     z[0,83]     -0.58      0.66     -0.53     -1.63      0.42   1047.78      1.00\n",
      "     z[0,84]     -0.85      0.66     -0.84     -1.91      0.16    921.49      1.00\n",
      "     z[0,85]     -0.66      0.59     -0.64     -1.52      0.39    874.25      1.00\n",
      "     z[0,86]     -0.55      0.68     -0.56     -1.55      0.60   1276.49      1.00\n",
      "     z[0,87]      0.41      0.47      0.42     -0.36      1.11    702.88      1.00\n",
      "     z[0,88]     -0.51      0.68     -0.46     -1.68      0.61    792.95      1.00\n",
      "     z[0,89]     -0.08      0.64     -0.06     -1.01      0.92   1083.74      1.00\n",
      "     z[0,90]      1.82      0.38      1.83      1.22      2.42    390.53      1.00\n",
      "     z[0,91]      0.12      0.54      0.16     -0.62      1.06    724.75      1.00\n",
      "     z[0,92]     -1.05      0.75     -1.01     -2.31     -0.00   1129.76      1.00\n",
      "     z[0,93]     -0.66      0.66     -0.61     -1.81      0.35    587.81      1.00\n",
      "     z[0,94]      0.58      0.48      0.58     -0.13      1.41    771.92      1.00\n",
      "     z[0,95]      0.07      0.54      0.07     -0.80      0.90    966.07      1.00\n",
      "     z[0,96]      0.52      0.50      0.51     -0.38      1.27    770.78      1.00\n",
      "     z[0,97]      0.74      0.45      0.75      0.07      1.51    455.98      1.00\n",
      "     z[0,98]     -0.40      0.57     -0.36     -1.36      0.46    608.50      1.00\n",
      "     z[0,99]      0.44      0.48      0.43     -0.36      1.20    497.35      1.00\n",
      "    z[0,100]      0.55      0.45      0.56     -0.15      1.29    528.00      1.00\n",
      "    z[0,101]     -0.34      0.57     -0.30     -1.24      0.53    851.20      1.00\n",
      "    z[0,102]     -1.01      0.83     -0.94     -2.27      0.27    971.05      1.00\n",
      "    z[0,103]     -0.49      0.66     -0.45     -1.54      0.46    711.43      1.00\n",
      "    z[0,104]      0.22      0.55      0.22     -0.68      1.06    400.30      1.00\n",
      "    z[0,105]     -0.66      0.58     -0.66     -1.60      0.23    826.71      1.00\n",
      "    z[0,106]      0.19      0.53      0.22     -0.67      0.98    716.75      1.00\n",
      "    z[0,107]     -0.00      0.51      0.01     -0.78      0.81    863.90      1.00\n",
      "    z[0,108]     -0.74      0.65     -0.69     -1.80      0.22   1386.78      1.00\n",
      "    z[0,109]      0.42      0.50      0.47     -0.34      1.18    970.45      1.00\n",
      "    z[0,110]     -0.37      0.67     -0.34     -1.29      0.86    669.88      1.00\n",
      "    z[0,111]     -1.01      0.80     -0.97     -2.30      0.29    923.15      1.00\n",
      "    z[0,112]     -1.21      0.73     -1.15     -2.27     -0.00    916.09      1.00\n",
      "    z[0,113]      0.49      0.45      0.50     -0.19      1.20    548.90      1.00\n",
      "    z[0,114]      0.83      0.49      0.83     -0.06      1.51    540.14      1.00\n",
      "    z[0,115]     -0.52      0.66     -0.47     -1.65      0.44   1124.47      1.00\n",
      "    z[0,116]     -0.10      0.57     -0.11     -1.09      0.69    786.89      1.00\n",
      "    z[0,117]      1.53      0.45      1.53      0.79      2.18    487.80      1.00\n",
      "    z[0,118]     -0.39      0.62     -0.37     -1.35      0.55    821.07      1.00\n",
      "    z[0,119]     -0.65      0.67     -0.59     -1.77      0.31    592.30      1.00\n",
      "    z[0,120]     -0.26      0.60     -0.23     -1.15      0.74    557.28      1.00\n",
      "    z[0,121]     -1.04      0.83     -0.99     -2.43      0.19   1635.89      1.00\n",
      "    z[0,122]     -0.59      0.64     -0.57     -1.63      0.40    783.15      1.00\n",
      "    z[0,123]     -1.17      0.64     -1.16     -2.19     -0.16    816.31      1.00\n",
      "    z[0,124]     -0.62      0.62     -0.62     -1.65      0.30    889.83      1.00\n",
      "    z[0,125]     -0.70      0.67     -0.71     -1.72      0.40    788.14      1.00\n",
      "    z[0,126]      1.69      0.41      1.69      0.93      2.24    896.64      1.00\n",
      "    z[0,127]     -1.09      0.75     -1.02     -2.16      0.12    656.49      1.00\n",
      "    z[0,128]      0.31      0.59      0.31     -0.68      1.18   1170.97      1.00\n",
      "    z[0,129]     -0.60      0.63     -0.57     -1.68      0.31   1060.75      1.00\n",
      "    z[0,130]      0.06      0.54      0.10     -0.74      0.91    647.01      1.00\n",
      "    z[0,131]     -0.67      0.61     -0.66     -1.71      0.18    471.98      1.00\n",
      "    z[0,132]      0.51      0.48      0.54     -0.17      1.37    813.64      1.00\n",
      "    z[0,133]     -0.21      0.58     -0.22     -1.10      0.71    994.70      1.00\n",
      "    z[0,134]      0.57      0.49      0.61     -0.25      1.27    594.30      1.00\n",
      "    z[0,135]     -0.12      0.55     -0.15     -0.85      0.86    563.03      1.00\n",
      "    z[0,136]      0.59      0.47      0.62     -0.11      1.34    599.37      1.00\n",
      "    z[0,137]      1.17      0.39      1.18      0.61      1.89    540.88      1.00\n",
      "    z[0,138]      0.17      0.54      0.20     -0.74      0.94    600.46      1.00\n",
      "    z[0,139]     -0.50      0.66     -0.45     -1.44      0.47   1113.30      1.00\n",
      "    z[0,140]     -1.14      0.68     -1.13     -2.22     -0.04   1172.11      1.00\n",
      "    z[0,141]      0.03      0.52      0.02     -0.83      0.83    644.73      1.00\n",
      "    z[0,142]      0.28      0.50      0.32     -0.52      1.05    768.58      1.00\n",
      "    z[0,143]     -0.76      0.71     -0.77     -1.87      0.32   1141.37      1.00\n",
      "    z[0,144]     -0.12      0.53     -0.12     -1.03      0.67    812.73      1.00\n",
      "    z[0,145]      1.05      0.44      1.04      0.37      1.73    437.59      1.01\n",
      "    z[0,146]      0.41      0.53      0.46     -0.40      1.28    618.34      1.00\n",
      "    z[0,147]      0.61      0.52      0.61     -0.27      1.39    589.82      1.00\n",
      "    z[0,148]     -0.68      0.60     -0.64     -1.64      0.25    647.19      1.00\n",
      "    z[0,149]     -0.07      0.61     -0.05     -1.05      0.83    849.63      1.00\n",
      "    z[0,150]      0.03      0.64      0.04     -0.93      1.05    775.99      1.00\n",
      "    z[0,151]     -0.33      0.58     -0.30     -1.19      0.59    636.23      1.00\n",
      "    z[0,152]      0.63      0.45      0.62     -0.01      1.39    568.32      1.00\n",
      "    z[0,153]     -0.59      0.67     -0.56     -1.66      0.43    546.03      1.00\n",
      "    z[0,154]      0.02      0.55      0.06     -0.71      0.95    475.82      1.00\n",
      "    z[0,155]      0.85      0.44      0.86      0.18      1.59    701.34      1.00\n",
      "    z[0,156]     -0.20      0.64     -0.19     -1.38      0.69    830.18      1.00\n",
      "    z[0,157]      0.67      0.48      0.68     -0.01      1.50    809.46      1.00\n",
      "    z[0,158]      0.26      0.54      0.27     -0.60      1.07    959.02      1.00\n",
      "    z[0,159]     -0.72      0.64     -0.72     -1.77      0.18    821.02      1.00\n",
      "    z[0,160]      1.10      0.46      1.10      0.40      1.84    527.33      1.01\n",
      "    z[0,161]     -0.19      0.53     -0.20     -1.02      0.61   1105.28      1.00\n",
      "    z[0,162]      0.06      0.59      0.09     -0.94      0.95    775.66      1.00\n",
      "    z[0,163]     -0.16      0.62     -0.11     -1.01      0.92    625.16      1.00\n",
      "    z[0,164]     -1.49      0.73     -1.49     -2.59     -0.34    874.07      1.00\n",
      "    z[0,165]     -1.26      0.69     -1.22     -2.28     -0.17    889.81      1.00\n",
      "    z[0,166]     -0.64      0.64     -0.63     -1.56      0.39    497.15      1.00\n",
      "    z[0,167]     -0.63      0.54     -0.59     -1.47      0.26    410.23      1.00\n",
      "    z[0,168]     -0.67      0.61     -0.62     -1.59      0.30    818.60      1.00\n",
      "    z[0,169]      0.56      0.40      0.57     -0.04      1.17    459.27      1.00\n",
      "    z[0,170]      0.84      0.36      0.85      0.28      1.40    424.70      1.00\n",
      "    z[0,171]      1.19      0.35      1.20      0.71      1.83    444.47      1.00\n",
      "    z[0,172]      0.79      0.49      0.84      0.12      1.68    751.80      1.00\n",
      "    z[0,173]      1.05      0.36      1.04      0.51      1.67    503.59      1.00\n",
      "    z[0,174]      1.02      0.40      1.03      0.36      1.58    699.47      1.00\n",
      "    z[0,175]      0.66      0.41      0.67     -0.00      1.27    935.70      1.00\n",
      "    z[0,176]     -0.05      0.53     -0.03     -0.97      0.70    595.79      1.00\n",
      "    z[0,177]     -0.43      0.56     -0.42     -1.24      0.47    713.89      1.00\n",
      "    z[0,178]      3.35      0.31      3.34      2.91      3.88    321.11      1.01\n",
      "    z[0,179]     -1.16      0.70     -1.15     -2.27     -0.13   1030.45      1.00\n",
      "    z[0,180]      0.39      0.34      0.37     -0.17      0.91    396.79      1.00\n",
      "    z[0,181]      0.70      0.37      0.72      0.09      1.25    409.37      1.00\n",
      "    z[0,182]      0.68      0.36      0.68      0.11      1.24    375.00      1.01\n",
      "    z[0,183]      0.37      0.35      0.37     -0.20      0.90    319.08      1.01\n",
      "    z[0,184]      0.24      0.34      0.24     -0.26      0.82    395.43      1.00\n",
      "    z[0,185]      0.33      0.33      0.35     -0.27      0.82    374.30      1.00\n",
      "    z[0,186]      0.06      0.38      0.08     -0.52      0.65    277.64      1.02\n",
      "    z[0,187]     -0.61      0.52     -0.58     -1.49      0.14    671.37      1.00\n",
      "    z[0,188]     -0.58      0.46     -0.55     -1.31      0.16    622.67      1.00\n",
      "    z[0,189]     -0.63      0.51     -0.60     -1.43      0.21    600.92      1.00\n",
      "    z[0,190]      0.14      0.38      0.13     -0.42      0.82    493.54      1.00\n",
      "    z[0,191]      0.05      0.44      0.07     -0.77      0.62    552.97      1.00\n",
      "    z[0,192]     -0.06      0.46     -0.04     -0.74      0.67    610.33      1.00\n",
      "    z[0,193]     -0.88      0.59     -0.86     -1.75      0.07    608.99      1.00\n",
      "    z[0,194]      1.65      0.29      1.66      1.20      2.12    270.15      1.00\n",
      "    z[0,195]      3.15      0.37      3.13      2.51      3.68    521.79      1.00\n",
      "    z[0,196]      2.12      0.41      2.12      1.49      2.80    597.32      1.00\n",
      "    z[0,197]      0.78      0.47      0.77      0.09      1.62    514.96      1.00\n",
      "    z[0,198]     -0.26      0.64     -0.25     -1.08      0.84    966.59      1.00\n",
      "    z[0,199]     -0.05      0.54     -0.07     -0.86      0.85    582.51      1.00\n",
      "    z[0,200]     -0.76      0.62     -0.73     -1.73      0.22    726.35      1.00\n",
      "    z[0,201]     -0.99      0.82     -1.00     -2.49      0.21    838.98      1.00\n",
      "    z[0,202]     -0.81      0.68     -0.79     -1.83      0.33    618.75      1.00\n",
      "    z[0,203]     -0.83      0.63     -0.82     -1.79      0.17    581.28      1.00\n",
      "    z[0,204]     -0.52      0.56     -0.53     -1.44      0.37    987.87      1.00\n",
      "    z[0,205]     -1.13      0.78     -1.16     -2.28      0.14    914.81      1.00\n",
      "    z[0,206]      0.19      0.54      0.19     -0.72      1.00    625.47      1.01\n",
      "    z[0,207]      0.09      0.56      0.12     -0.83      0.96    558.69      1.00\n",
      "    z[0,208]     -0.34      0.71     -0.34     -1.46      0.72    936.21      1.00\n",
      "    z[0,209]      1.95      0.39      1.95      1.33      2.55    736.58      1.00\n",
      "    z[0,210]      0.11      0.57      0.12     -0.82      1.04    976.36      1.00\n",
      "    z[0,211]     -0.53      0.63     -0.48     -1.49      0.54   1868.17      1.00\n",
      "    z[0,212]     -0.50      0.58     -0.50     -1.33      0.46   1108.42      1.00\n",
      "    z[0,213]     -1.24      0.78     -1.21     -2.38      0.10   1002.83      1.00\n",
      "    z[0,214]     -0.85      0.77     -0.83     -2.09      0.34   1131.52      1.00\n",
      "    z[0,215]     -0.67      0.64     -0.66     -1.63      0.40    852.69      1.00\n",
      "    z[0,216]     -0.91      0.68     -0.89     -2.00      0.17   1007.51      1.00\n",
      "    z[0,217]      0.01      0.54      0.05     -0.85      0.87    649.16      1.00\n",
      "    z[0,218]     -1.06      0.80     -1.02     -2.24      0.28    876.30      1.00\n",
      "    z[0,219]     -0.21      0.56     -0.23     -1.14      0.57    611.49      1.00\n",
      "    z[0,220]     -0.53      0.71     -0.48     -1.71      0.43    726.45      1.00\n",
      "    z[0,221]     -0.36      0.66     -0.35     -1.42      0.68    701.02      1.00\n",
      "    z[0,222]      1.98      0.30      2.00      1.55      2.47    363.57      1.00\n",
      "    z[0,223]     -0.42      0.44     -0.40     -1.18      0.23    757.96      1.00\n",
      "    z[0,224]     -0.00      0.38     -0.02     -0.54      0.63    250.71      1.00\n",
      "    z[0,225]     -1.71      0.63     -1.68     -2.78     -0.82    470.91      1.00\n",
      "    z[0,226]     -1.28      0.72     -1.24     -2.39     -0.05    865.41      1.00\n",
      "    z[0,227]     -0.85      0.59     -0.83     -1.86      0.02    611.60      1.00\n",
      "    z[0,228]      0.99      0.36      0.99      0.48      1.59    394.74      1.00\n",
      "    z[0,229]     -0.91      0.55     -0.89     -1.74      0.01    938.58      1.00\n",
      "    z[0,230]     -1.42      0.67     -1.37     -2.39     -0.41    898.47      1.00\n",
      "    z[0,231]     -0.43      0.57     -0.40     -1.28      0.52    898.61      1.00\n",
      "    z[0,232]     -0.54      0.56     -0.50     -1.47      0.25    754.87      1.00\n",
      "    z[0,233]      0.51      0.38      0.52     -0.11      1.04    470.55      1.00\n",
      "    z[0,234]      0.32      0.43      0.34     -0.29      1.04    546.42      1.00\n",
      "    z[0,235]     -0.93      0.53     -0.87     -1.78     -0.18    542.63      1.01\n",
      "    z[0,236]      0.46      0.44      0.49     -0.25      1.16    542.44      1.00\n",
      "    z[0,237]     -0.45      0.58     -0.44     -1.27      0.55    811.08      1.00\n",
      "    z[0,238]     -0.06      0.47     -0.05     -0.85      0.64    335.08      1.00\n",
      "    z[0,239]      0.43      0.45      0.42     -0.28      1.12    636.78      1.00\n",
      "    z[0,240]      0.21      0.45      0.24     -0.47      0.91    711.48      1.00\n",
      "    z[0,241]     -0.98      0.62     -0.96     -2.00     -0.05    807.30      1.00\n",
      "    z[0,242]      0.11      0.50      0.12     -0.63      0.96    667.13      1.00\n",
      "    z[0,243]     -0.48      0.56     -0.42     -1.36      0.39    571.87      1.00\n",
      "    z[0,244]     -1.24      0.65     -1.23     -2.20     -0.23    753.54      1.00\n",
      "    z[0,245]      1.90      0.37      1.90      1.38      2.53    323.03      1.00\n",
      "    z[0,246]     -0.20      0.53     -0.13     -1.22      0.47    572.12      1.00\n",
      "    z[0,247]     -0.35      0.67     -0.33     -1.29      0.84    707.25      1.00\n",
      "    z[0,248]     -0.49      0.60     -0.49     -1.41      0.47    801.34      1.00\n",
      "    z[0,249]      0.38      0.53      0.35     -0.41      1.22    768.09      1.00\n",
      "    z[0,250]      0.96      0.46      0.98      0.33      1.68    706.51      1.00\n",
      "    z[0,251]      0.68      0.48      0.67     -0.10      1.47    590.42      1.00\n",
      "    z[0,252]     -0.90      0.62     -0.90     -1.86      0.14    842.54      1.00\n",
      "    z[0,253]     -0.23      0.62     -0.21     -1.17      0.85    855.32      1.00\n",
      "    z[0,254]     -0.28      0.65     -0.30     -1.39      0.63    731.80      1.00\n",
      "    z[0,255]     -0.32      0.52     -0.31     -1.21      0.38    824.24      1.00\n",
      "    z[0,256]      0.10      0.53      0.11     -0.70      1.01    889.76      1.00\n",
      "    z[0,257]      0.46      0.45      0.47     -0.26      1.16    632.18      1.00\n",
      "    z[0,258]      0.21      0.46      0.23     -0.52      0.96    613.23      1.00\n",
      "    z[0,259]      0.72      0.44      0.71      0.04      1.40    532.79      1.00\n",
      "    z[0,260]     -0.06      0.48     -0.03     -0.76      0.75    957.00      1.00\n",
      "    z[0,261]     -0.01      0.53      0.00     -0.82      0.89    640.34      1.00\n",
      "    z[0,262]     -0.58      0.56     -0.55     -1.42      0.25    738.04      1.00\n",
      "    z[0,263]     -0.12      0.53     -0.10     -0.91      0.72    516.45      1.00\n",
      "    z[0,264]      0.51      0.47      0.52     -0.24      1.27    608.18      1.00\n",
      "    z[0,265]      0.89      0.36      0.88      0.31      1.45    533.97      1.00\n",
      "    z[0,266]      0.71      0.37      0.73      0.12      1.28    578.76      1.00\n",
      "    z[0,267]      0.12      0.43      0.13     -0.55      0.81    540.68      1.00\n",
      "    z[0,268]      1.25      0.35      1.25      0.73      1.86    359.43      1.00\n",
      "    z[0,269]     -0.56      0.52     -0.54     -1.34      0.28    537.63      1.00\n",
      "    z[0,270]      0.65      0.40      0.66      0.05      1.29    717.62      1.00\n",
      "    z[0,271]     -0.37      0.51     -0.30     -1.18      0.42    479.27      1.00\n",
      "    z[0,272]      0.37      0.59      0.38     -0.61      1.26    998.14      1.00\n",
      "    z[0,273]      0.05      0.57      0.05     -0.95      0.88    411.31      1.00\n",
      "    z[0,274]      2.49      0.37      2.51      1.88      3.01    458.86      1.00\n",
      "    z[0,275]     -0.17      0.69     -0.11     -1.26      0.94    605.58      1.00\n",
      "    z[0,276]     -0.82      0.70     -0.84     -1.76      0.51    942.16      1.00\n",
      "    z[0,277]      1.01      0.43      1.01      0.21      1.60    399.46      1.01\n",
      "    z[0,278]     -0.43      0.70     -0.40     -1.74      0.52    703.05      1.00\n",
      "    z[0,279]      0.52      0.48      0.54     -0.24      1.25    837.36      1.00\n",
      "    z[0,280]      0.94      0.40      0.96      0.33      1.57    557.48      1.00\n",
      "    z[0,281]      1.71      0.37      1.71      1.14      2.28    390.09      1.00\n",
      "    z[0,282]     -0.69      0.59     -0.67     -1.58      0.21    681.78      1.00\n",
      "    z[0,283]     -0.02      0.55      0.03     -0.86      0.81   1050.93      1.00\n",
      "    z[0,284]      0.30      0.48      0.33     -0.51      1.05    576.71      1.00\n",
      "    z[0,285]      0.91      0.36      0.91      0.40      1.50    419.41      1.00\n",
      "    z[0,286]     -0.01      0.44      0.01     -0.68      0.67    588.96      1.00\n",
      "    z[0,287]      0.35      0.44      0.35     -0.41      0.99    506.43      1.00\n",
      "    z[0,288]      1.13      0.32      1.10      0.62      1.63    475.75      1.00\n",
      "    z[0,289]     -1.52      0.72     -1.46     -2.64     -0.41    829.40      1.00\n",
      "    z[0,290]      1.10      0.34      1.12      0.55      1.62    354.55      1.00\n",
      "    z[0,291]      0.42      0.39      0.44     -0.26      0.99    675.68      1.00\n",
      "    z[0,292]     -1.62      0.64     -1.59     -2.50     -0.49    670.25      1.00\n",
      "    z[0,293]      0.06      0.36      0.07     -0.59      0.55    453.66      1.00\n",
      "    z[0,294]     -0.61      0.61     -0.54     -1.60      0.29    695.27      1.00\n",
      "    z[0,295]     -0.76      0.69     -0.69     -1.71      0.47    858.41      1.00\n",
      "    z[0,296]     -0.41      0.60     -0.39     -1.31      0.52    766.99      1.00\n",
      "    z[0,297]     -0.71      0.52     -0.72     -1.46      0.21    688.42      1.00\n",
      "    z[0,298]     -0.44      0.46     -0.43     -1.10      0.32    575.33      1.00\n",
      "    z[0,299]     -0.11      0.59     -0.09     -1.09      0.75    649.17      1.00\n",
      "      z[1,0]      0.48      0.93      0.45     -0.96      1.81   1179.23      1.00\n",
      "      z[1,1]      0.05      0.68      0.04     -1.10      1.01   1315.97      1.00\n",
      "      z[1,2]      0.92      0.82      0.95     -0.31      2.24    845.90      1.00\n",
      "      z[1,3]     -0.18      0.86     -0.20     -1.53      1.18   1015.42      1.00\n",
      "      z[1,4]     -0.19      0.83     -0.16     -1.53      1.12   1125.25      1.00\n",
      "      z[1,5]     -0.21      0.90     -0.22     -1.44      1.40    725.40      1.00\n",
      "      z[1,6]      0.32      0.87      0.31     -0.84      1.85   1021.15      1.00\n",
      "      z[1,7]     -0.18      0.95     -0.16     -1.61      1.36   1355.13      1.00\n",
      "      z[1,8]      0.67      0.62      0.68     -0.38      1.60    901.72      1.00\n",
      "      z[1,9]     -0.27      0.89     -0.32     -1.71      1.06   1780.82      1.00\n",
      "     z[1,10]     -0.24      0.97     -0.27     -1.57      1.29   1212.74      1.00\n",
      "     z[1,11]      0.26      0.85      0.25     -1.00      1.56    697.54      1.00\n",
      "     z[1,12]      1.17      0.78      1.19      0.07      2.60   1265.76      1.00\n",
      "     z[1,13]     -0.69      0.86     -0.70     -1.95      0.72    934.22      1.00\n",
      "     z[1,14]     -0.07      0.88     -0.08     -1.38      1.40   1115.40      1.00\n",
      "     z[1,15]      0.35      0.83      0.35     -0.98      1.61   1002.01      1.00\n",
      "     z[1,16]     -0.29      0.89     -0.24     -1.75      1.11   1059.24      1.00\n",
      "     z[1,17]      0.11      0.86      0.11     -1.13      1.57    721.41      1.00\n",
      "     z[1,18]     -0.65      0.90     -0.62     -1.93      0.82    906.81      1.00\n",
      "     z[1,19]      0.17      0.91      0.15     -1.26      1.51   1311.56      1.00\n",
      "     z[1,20]     -0.49      0.98     -0.47     -1.81      1.13    959.11      1.00\n",
      "     z[1,21]      0.64      0.90      0.60     -0.74      1.99    762.35      1.00\n",
      "     z[1,22]     -0.30      1.04     -0.30     -2.09      1.29   1009.67      1.00\n",
      "     z[1,23]     -0.89      0.79     -0.88     -2.13      0.29    832.07      1.00\n",
      "     z[1,24]     -0.18      0.89     -0.16     -1.57      1.15   2097.97      1.00\n",
      "     z[1,25]      0.14      0.85      0.12     -1.33      1.33   1122.71      1.00\n",
      "     z[1,26]      0.25      0.99      0.30     -1.26      1.75   1700.64      1.00\n",
      "     z[1,27]     -0.22      0.93     -0.21     -1.58      1.30    825.07      1.00\n",
      "     z[1,28]      0.19      0.92      0.20     -0.99      1.79   1489.28      1.00\n",
      "     z[1,29]      0.26      0.72      0.27     -0.89      1.28   1023.20      1.00\n",
      "     z[1,30]     -0.09      0.81     -0.09     -1.31      1.18    854.20      1.00\n",
      "     z[1,31]     -0.45      0.94     -0.44     -1.87      1.12    762.36      1.00\n",
      "     z[1,32]     -0.18      0.89     -0.18     -1.63      1.27   1554.03      1.00\n",
      "     z[1,33]     -0.14      0.91     -0.15     -1.41      1.48    996.62      1.00\n",
      "     z[1,34]     -0.25      0.79     -0.18     -1.58      0.87   1426.69      1.00\n",
      "     z[1,35]     -0.42      0.95     -0.38     -1.99      0.94   1037.27      1.00\n",
      "     z[1,36]     -0.26      0.92     -0.20     -1.73      1.09   1006.10      1.00\n",
      "     z[1,37]     -0.01      0.78     -0.02     -1.34      1.13    811.88      1.00\n",
      "     z[1,38]     -0.08      0.62     -0.08     -1.19      0.82   1327.69      1.00\n",
      "     z[1,39]     -0.01      0.90     -0.02     -1.39      1.28   1116.29      1.00\n",
      "     z[1,40]      0.88      0.83      0.88     -0.38      2.16   1015.54      1.00\n",
      "     z[1,41]      0.53      0.85      0.56     -0.80      1.96    807.14      1.00\n",
      "     z[1,42]     -0.32      0.83     -0.26     -1.60      1.00   1371.08      1.00\n",
      "     z[1,43]      1.00      0.63      1.03      0.11      2.14    503.99      1.01\n",
      "     z[1,44]     -0.17      0.81     -0.19     -1.42      1.07    869.92      1.00\n",
      "     z[1,45]     -0.20      0.89     -0.18     -1.75      0.99   1194.30      1.00\n",
      "     z[1,46]     -0.19      0.88     -0.20     -1.74      1.04   1369.59      1.00\n",
      "     z[1,47]     -0.45      0.99     -0.44     -1.94      1.14   1118.05      1.00\n",
      "     z[1,48]     -0.03      0.76     -0.05     -1.11      1.21    785.52      1.00\n",
      "     z[1,49]      0.54      0.85      0.57     -0.70      1.88    902.79      1.01\n",
      "     z[1,50]     -0.35      0.95     -0.34     -1.82      1.12   1096.67      1.00\n",
      "     z[1,51]     -0.20      0.96     -0.20     -1.71      1.14   1512.09      1.00\n",
      "     z[1,52]     -0.23      0.97     -0.24     -1.74      1.25    816.80      1.00\n",
      "     z[1,53]      0.68      0.80      0.63     -0.53      2.08    948.94      1.00\n",
      "     z[1,54]      0.14      0.89      0.17     -1.33      1.53    963.43      1.00\n",
      "     z[1,55]     -0.40      0.92     -0.38     -1.94      0.96   1856.25      1.00\n",
      "     z[1,56]     -0.67      0.88     -0.64     -2.03      0.75   1433.28      1.00\n",
      "     z[1,57]     -0.19      0.84     -0.16     -1.53      1.22    998.35      1.00\n",
      "     z[1,58]      0.94      0.82      0.97     -0.29      2.28    559.85      1.00\n",
      "     z[1,59]      0.01      0.92      0.02     -1.40      1.43   1209.23      1.00\n",
      "     z[1,60]      0.42      0.72      0.41     -0.74      1.57   1459.65      1.00\n",
      "     z[1,61]     -0.19      0.97     -0.16     -1.75      1.42    878.27      1.00\n",
      "     z[1,62]     -0.42      0.90     -0.42     -1.74      1.09   1497.51      1.00\n",
      "     z[1,63]     -0.43      0.82     -0.43     -1.77      0.80    784.83      1.00\n",
      "     z[1,64]     -0.56      0.87     -0.53     -2.01      0.72    771.69      1.00\n",
      "     z[1,65]     -0.05      0.87     -0.02     -1.26      1.47    947.38      1.00\n",
      "     z[1,66]      0.98      0.64      0.96     -0.17      1.90    908.91      1.01\n",
      "     z[1,67]     -0.29      0.93     -0.30     -1.82      1.17   2854.89      1.00\n",
      "     z[1,68]     -0.30      1.03     -0.34     -2.06      1.20    961.27      1.00\n",
      "     z[1,69]      1.29      0.79      1.24      0.14      2.62   1089.39      1.00\n",
      "     z[1,70]     -0.69      0.72     -0.69     -1.87      0.38    976.75      1.00\n",
      "     z[1,71]      0.07      0.99      0.09     -1.41      1.73   1240.68      1.00\n",
      "     z[1,72]     -0.26      0.91     -0.24     -1.51      1.29   1568.77      1.00\n",
      "     z[1,73]     -0.23      0.92     -0.24     -1.48      1.46   1061.82      1.00\n",
      "     z[1,74]     -0.23      0.89     -0.20     -1.56      1.27   1271.39      1.00\n",
      "     z[1,75]     -0.44      0.91     -0.41     -1.96      0.88   1250.05      1.00\n",
      "     z[1,76]      0.39      0.91      0.38     -1.06      1.80   1139.97      1.00\n",
      "     z[1,77]      0.25      0.80      0.21     -0.93      1.60    813.34      1.00\n",
      "     z[1,78]      0.66      0.89      0.70     -0.80      1.86   1136.88      1.00\n",
      "     z[1,79]      0.13      1.01      0.12     -1.45      1.79    921.57      1.00\n",
      "     z[1,80]      0.79      0.74      0.75     -0.30      2.08   1767.00      1.00\n",
      "     z[1,81]     -0.18      0.81     -0.18     -1.62      0.97   1385.07      1.00\n",
      "     z[1,82]     -0.09      0.86     -0.16     -1.36      1.35    942.63      1.00\n",
      "     z[1,83]      0.06      0.88      0.10     -1.43      1.42    863.34      1.00\n",
      "     z[1,84]     -0.30      0.89     -0.32     -1.77      1.16    782.39      1.00\n",
      "     z[1,85]     -0.15      0.93     -0.19     -1.44      1.43    895.78      1.00\n",
      "     z[1,86]     -0.03      0.90     -0.02     -1.64      1.22   1327.11      1.00\n",
      "     z[1,87]      0.14      0.82      0.12     -1.04      1.47    899.56      1.00\n",
      "     z[1,88]     -0.57      0.93     -0.57     -2.28      0.82    677.92      1.00\n",
      "     z[1,89]     -0.03      0.92     -0.02     -1.36      1.36   1652.08      1.00\n",
      "     z[1,90]      1.69      0.69      1.69      0.46      2.65    769.02      1.00\n",
      "     z[1,91]      0.38      0.91      0.37     -1.12      1.72   1421.08      1.00\n",
      "     z[1,92]     -0.26      0.99     -0.28     -1.75      1.23   1112.67      1.00\n",
      "     z[1,93]     -0.02      0.89      0.01     -1.52      1.27    703.39      1.00\n",
      "     z[1,94]     -0.04      0.83     -0.05     -1.30      1.26   1592.68      1.00\n",
      "     z[1,95]      0.61      0.85      0.66     -0.70      1.95   1493.87      1.00\n",
      "     z[1,96]      0.78      0.87      0.80     -0.53      2.13    886.70      1.00\n",
      "     z[1,97]      0.48      0.77      0.50     -0.74      1.64    655.08      1.00\n",
      "     z[1,98]     -0.16      0.87     -0.15     -1.65      1.19   1487.88      1.00\n",
      "     z[1,99]     -0.02      0.84     -0.01     -1.30      1.33   1900.81      1.00\n",
      "    z[1,100]      0.47      0.73      0.46     -0.71      1.55   1161.21      1.00\n",
      "    z[1,101]     -0.15      0.92     -0.19     -1.53      1.25   1091.10      1.00\n",
      "    z[1,102]     -0.41      0.99     -0.42     -1.78      1.26   1680.23      1.00\n",
      "    z[1,103]     -0.37      1.04     -0.45     -2.03      1.30   1873.72      1.00\n",
      "    z[1,104]     -0.96      0.85     -0.98     -2.17      0.47    799.58      1.00\n",
      "    z[1,105]     -0.65      0.85     -0.66     -1.95      0.62    835.60      1.00\n",
      "    z[1,106]      0.16      0.85      0.18     -1.22      1.44   1276.39      1.00\n",
      "    z[1,107]      0.45      0.82      0.44     -0.73      1.88   1345.00      1.00\n",
      "    z[1,108]     -0.12      0.99     -0.10     -1.90      1.22   1071.95      1.00\n",
      "    z[1,109]     -0.24      0.84     -0.24     -1.48      1.10   1371.93      1.00\n",
      "    z[1,110]      0.16      0.96      0.20     -1.22      1.84   1356.36      1.00\n",
      "    z[1,111]     -0.29      0.95     -0.29     -1.77      1.24   1722.37      1.00\n",
      "    z[1,112]     -0.59      0.94     -0.62     -2.14      0.78   1826.95      1.00\n",
      "    z[1,113]      0.73      0.73      0.76     -0.41      1.86    917.86      1.00\n",
      "    z[1,114]      0.29      0.82      0.27     -1.07      1.46   1012.90      1.00\n",
      "    z[1,115]     -0.06      0.93     -0.10     -1.63      1.31   1018.82      1.00\n",
      "    z[1,116]      0.24      0.88      0.23     -1.09      1.70   1285.20      1.00\n",
      "    z[1,117]      0.65      0.74      0.66     -0.64      1.74    895.20      1.00\n",
      "    z[1,118]      0.37      0.90      0.38     -1.07      1.74   2977.97      1.00\n",
      "    z[1,119]      0.09      0.87      0.11     -1.21      1.44   1298.33      1.00\n",
      "    z[1,120]      0.34      0.93      0.36     -1.02      1.84   1049.97      1.00\n",
      "    z[1,121]     -0.43      0.94     -0.43     -1.83      1.19   1200.26      1.00\n",
      "    z[1,122]     -0.04      0.89     -0.07     -1.52      1.25    799.84      1.00\n",
      "    z[1,123]     -0.56      0.87     -0.60     -1.87      0.83   1018.20      1.00\n",
      "    z[1,124]     -0.18      0.92     -0.20     -1.50      1.50   1429.93      1.00\n",
      "    z[1,125]     -0.82      0.92     -0.80     -2.23      0.63    803.25      1.00\n",
      "    z[1,126]      0.09      0.77      0.05     -1.08      1.32    858.53      1.00\n",
      "    z[1,127]     -0.46      0.97     -0.44     -1.90      1.11    755.30      1.00\n",
      "    z[1,128]     -0.21      0.96     -0.20     -1.79      1.16   1407.34      1.00\n",
      "    z[1,129]      0.17      0.93      0.19     -1.26      1.61   1019.42      1.00\n",
      "    z[1,130]      0.61      0.76      0.63     -0.51      1.85   1252.22      1.00\n",
      "    z[1,131]     -0.17      0.91     -0.17     -1.64      1.16    818.11      1.00\n",
      "    z[1,132]      0.17      0.83      0.15     -1.26      1.40   1124.08      1.00\n",
      "    z[1,133]      0.44      0.84      0.43     -0.84      1.71   1242.94      1.00\n",
      "    z[1,134]     -0.58      0.76     -0.58     -1.73      0.66    688.39      1.00\n",
      "    z[1,135]     -0.51      0.85     -0.54     -1.90      0.68   1731.88      1.00\n",
      "    z[1,136]      0.73      0.84      0.74     -0.66      1.89    880.16      1.00\n",
      "    z[1,137]     -0.54      0.77     -0.54     -1.93      0.53   1010.52      1.00\n",
      "    z[1,138]     -0.14      0.86     -0.10     -1.31      1.33    850.29      1.00\n",
      "    z[1,139]     -0.02      0.88     -0.00     -1.47      1.34   1094.61      1.00\n",
      "    z[1,140]     -0.39      0.93     -0.44     -1.64      1.14   1852.65      1.00\n",
      "    z[1,141]      0.50      0.84      0.56     -0.71      1.92    849.62      1.00\n",
      "    z[1,142]      0.83      0.84      0.83     -0.39      2.28   1057.57      1.00\n",
      "    z[1,143]     -0.14      0.94     -0.12     -1.57      1.31    882.73      1.00\n",
      "    z[1,144]      0.24      0.85      0.27     -1.14      1.57   1030.59      1.00\n",
      "    z[1,145]     -0.11      0.80     -0.13     -1.25      1.21   1489.05      1.00\n",
      "    z[1,146]      0.29      0.87      0.28     -0.92      1.73   1111.02      1.00\n",
      "    z[1,147]     -0.09      0.86     -0.07     -1.54      1.16   1260.78      1.00\n",
      "    z[1,148]     -0.18      0.96     -0.16     -1.62      1.42   1078.06      1.00\n",
      "    z[1,149]     -0.40      0.97     -0.44     -2.08      1.10    901.00      1.00\n",
      "    z[1,150]     -0.53      0.93     -0.57     -2.03      0.97    862.60      1.00\n",
      "    z[1,151]     -0.43      0.86     -0.43     -1.75      0.95    922.43      1.00\n",
      "    z[1,152]      0.51      0.78      0.47     -0.85      1.66    933.06      1.00\n",
      "    z[1,153]     -0.31      0.90     -0.29     -1.78      1.00   1462.70      1.00\n",
      "    z[1,154]     -0.21      0.78     -0.19     -1.37      1.03   1008.56      1.00\n",
      "    z[1,155]      0.89      0.81      0.88     -0.41      2.08   1463.21      1.00\n",
      "    z[1,156]      0.22      0.94      0.26     -1.10      1.83   1187.79      1.00\n",
      "    z[1,157]      1.00      0.77      0.96     -0.29      2.24    710.09      1.00\n",
      "    z[1,158]      0.59      0.84      0.56     -0.76      1.88   1988.77      1.00\n",
      "    z[1,159]     -0.16      0.94     -0.18     -1.62      1.31    721.11      1.00\n",
      "    z[1,160]     -0.48      0.80     -0.47     -1.72      0.70   1218.43      1.00\n",
      "    z[1,161]      0.21      0.80      0.17     -0.97      1.67    813.36      1.00\n",
      "    z[1,162]     -0.04      0.92     -0.06     -1.42      1.33    999.76      1.00\n",
      "    z[1,163]      0.47      0.89      0.51     -1.03      1.84   1042.63      1.00\n",
      "    z[1,164]     -0.55      0.93     -0.54     -1.81      1.16   1388.45      1.00\n",
      "    z[1,165]     -0.10      0.88     -0.12     -1.30      1.56   1334.81      1.00\n",
      "    z[1,166]     -0.17      0.93     -0.17     -1.44      1.56   1032.04      1.00\n",
      "    z[1,167]      0.27      0.83      0.31     -1.10      1.53   1205.36      1.00\n",
      "    z[1,168]     -0.02      0.87     -0.01     -1.46      1.27   1334.26      1.00\n",
      "    z[1,169]     -0.51      0.97     -0.50     -2.11      0.97   1890.36      1.00\n",
      "    z[1,170]     -0.09      0.88     -0.07     -1.52      1.16    987.36      1.00\n",
      "    z[1,171]      0.08      0.68      0.08     -0.92      1.17    665.96      1.00\n",
      "    z[1,172]     -0.10      0.82     -0.07     -1.51      1.08   1420.17      1.00\n",
      "    z[1,173]     -0.33      0.81     -0.29     -1.71      0.84    813.83      1.00\n",
      "    z[1,174]      1.55      0.78      1.56      0.39      2.91    829.01      1.00\n",
      "    z[1,175]      0.54      0.72      0.54     -0.75      1.50   1314.25      1.00\n",
      "    z[1,176]      0.45      0.90      0.48     -0.95      1.90    809.52      1.00\n",
      "    z[1,177]     -0.26      0.82     -0.24     -1.52      1.05    761.27      1.00\n",
      "    z[1,178]     -0.10      0.65     -0.08     -1.04      0.97    765.03      1.00\n",
      "    z[1,179]     -0.13      1.03     -0.17     -1.97      1.38   1340.84      1.00\n",
      "    z[1,180]      0.13      0.96      0.12     -1.30      1.68   1419.33      1.00\n",
      "    z[1,181]     -0.52      0.90     -0.53     -1.99      0.97   1525.19      1.00\n",
      "    z[1,182]      0.69      0.72      0.71     -0.33      1.94    733.35      1.00\n",
      "    z[1,183]      0.27      0.77      0.29     -1.00      1.48    787.94      1.00\n",
      "    z[1,184]      0.11      0.98      0.08     -1.33      1.66   1070.13      1.00\n",
      "    z[1,185]      0.12      0.94      0.14     -1.51      1.48   1753.79      1.00\n",
      "    z[1,186]      0.23      0.85      0.30     -1.14      1.43    778.50      1.00\n",
      "    z[1,187]     -0.24      1.01     -0.21     -1.69      1.53   1192.18      1.00\n",
      "    z[1,188]     -0.34      0.97     -0.34     -2.09      1.03    966.64      1.00\n",
      "    z[1,189]     -0.65      0.88     -0.67     -2.05      0.66    928.85      1.01\n",
      "    z[1,190]     -0.08      0.68     -0.06     -1.14      0.99    931.69      1.00\n",
      "    z[1,191]     -0.29      0.90     -0.27     -1.78      1.08    970.38      1.00\n",
      "    z[1,192]     -0.14      0.78     -0.13     -1.43      0.97    949.81      1.00\n",
      "    z[1,193]     -0.21      0.90     -0.22     -1.70      1.19   1924.44      1.00\n",
      "    z[1,194]      1.41      0.80      1.44      0.26      2.76    646.03      1.00\n",
      "    z[1,195]      0.56      0.64      0.55     -0.41      1.54    758.56      1.00\n",
      "    z[1,196]      1.03      0.69      1.03     -0.07      2.13    667.68      1.00\n",
      "    z[1,197]      0.50      0.83      0.49     -0.73      1.84   1121.02      1.00\n",
      "    z[1,198]     -0.08      0.94     -0.08     -1.37      1.57    894.77      1.00\n",
      "    z[1,199]      0.11      0.88      0.10     -1.18      1.64    750.35      1.00\n",
      "    z[1,200]     -0.15      0.83     -0.15     -1.44      1.15    906.29      1.00\n",
      "    z[1,201]     -0.41      0.90     -0.42     -1.64      1.10   1222.40      1.00\n",
      "    z[1,202]     -0.25      0.98     -0.33     -1.95      1.07   1117.86      1.00\n",
      "    z[1,203]     -0.36      0.88     -0.38     -1.70      1.05    924.32      1.00\n",
      "    z[1,204]     -0.11      0.91     -0.13     -1.69      1.11   1643.04      1.00\n",
      "    z[1,205]     -0.54      0.88     -0.56     -1.93      0.87    712.38      1.00\n",
      "    z[1,206]      0.44      0.88      0.46     -0.97      1.76    953.96      1.01\n",
      "    z[1,207]      0.47      0.92      0.52     -0.77      2.26    905.01      1.00\n",
      "    z[1,208]     -0.34      0.96     -0.34     -1.90      1.31   2539.57      1.00\n",
      "    z[1,209]      0.99      0.68      0.98      0.02      2.10    724.99      1.00\n",
      "    z[1,210]     -0.85      0.90     -0.79     -2.16      0.65   1270.51      1.00\n",
      "    z[1,211]     -0.25      0.96     -0.19     -1.79      1.19   1093.82      1.00\n",
      "    z[1,212]      0.33      0.93      0.33     -1.18      1.75    897.85      1.00\n",
      "    z[1,213]     -0.43      0.98     -0.41     -2.26      0.97   1354.35      1.00\n",
      "    z[1,214]     -0.34      0.94     -0.36     -1.79      1.12   1391.44      1.00\n",
      "    z[1,215]     -0.01      0.91     -0.01     -1.37      1.58   1449.60      1.00\n",
      "    z[1,216]     -0.29      1.02     -0.26     -1.98      1.23    917.41      1.00\n",
      "    z[1,217]     -0.17      0.90     -0.18     -1.83      1.01   1231.46      1.00\n",
      "    z[1,218]     -0.39      0.96     -0.40     -1.83      1.01    755.58      1.00\n",
      "    z[1,219]      0.14      0.83      0.12     -1.12      1.43   1021.19      1.00\n",
      "    z[1,220]      0.02      0.91      0.02     -1.54      1.29   1180.54      1.00\n",
      "    z[1,221]     -0.22      0.95     -0.21     -1.70      1.17   1713.27      1.00\n",
      "    z[1,222]      1.42      0.61      1.42      0.45      2.32    990.51      1.00\n",
      "    z[1,223]      0.21      0.84      0.24     -0.92      1.75   1272.59      1.00\n",
      "    z[1,224]     -0.19      0.83     -0.23     -1.40      1.22   1125.45      1.00\n",
      "    z[1,225]     -0.30      1.13     -0.28     -2.14      1.35   1334.10      1.00\n",
      "    z[1,226]     -0.20      0.99     -0.26     -1.63      1.43   1167.07      1.00\n",
      "    z[1,227]     -0.33      0.95     -0.31     -1.80      1.25   1737.70      1.00\n",
      "    z[1,228]      0.17      0.74      0.16     -0.96      1.32   1347.22      1.00\n",
      "    z[1,229]     -0.84      0.88     -0.85     -2.34      0.48   2053.82      1.00\n",
      "    z[1,230]     -0.31      0.97     -0.28     -1.97      1.02   1322.33      1.00\n",
      "    z[1,231]     -0.31      0.90     -0.29     -1.82      1.04   1085.84      1.00\n",
      "    z[1,232]      0.47      0.89      0.46     -0.98      1.82    652.97      1.00\n",
      "    z[1,233]     -0.37      0.86     -0.38     -1.87      0.91    699.47      1.00\n",
      "    z[1,234]      0.17      0.87      0.21     -1.29      1.51   1307.48      1.00\n",
      "    z[1,235]      0.37      0.85      0.36     -1.03      1.61    844.73      1.00\n",
      "    z[1,236]      0.17      0.80      0.16     -1.02      1.53   1557.84      1.00\n",
      "    z[1,237]      0.29      0.87      0.29     -0.96      1.86   2309.23      1.00\n",
      "    z[1,238]      0.19      0.86      0.18     -1.19      1.58    860.28      1.00\n",
      "    z[1,239]      0.54      0.79      0.54     -0.63      1.84    905.79      1.00\n",
      "    z[1,240]      0.22      0.73      0.21     -1.09      1.29    921.44      1.00\n",
      "    z[1,241]     -0.11      0.90     -0.16     -1.48      1.21   1185.52      1.00\n",
      "    z[1,242]      0.35      0.81      0.37     -0.95      1.53   1280.23      1.00\n",
      "    z[1,243]     -0.08      0.99     -0.08     -1.67      1.47   1075.97      1.00\n",
      "    z[1,244]     -0.21      1.17     -0.16     -1.92      1.67   1710.79      1.00\n",
      "    z[1,245]      0.93      0.67      0.93     -0.03      2.06   1095.26      1.00\n",
      "    z[1,246]      0.50      0.76      0.51     -0.64      1.74    916.36      1.00\n",
      "    z[1,247]      0.09      0.96      0.12     -1.33      1.70    959.67      1.00\n",
      "    z[1,248]     -0.46      0.88     -0.46     -1.77      0.90   1020.26      1.00\n",
      "    z[1,249]      0.18      0.83      0.17     -1.04      1.50   1085.20      1.00\n",
      "    z[1,250]      0.32      0.79      0.36     -0.99      1.49   1071.23      1.00\n",
      "    z[1,251]     -0.04      0.77      0.00     -1.26      1.20    942.70      1.00\n",
      "    z[1,252]     -0.34      0.89     -0.33     -1.78      1.14    905.47      1.00\n",
      "    z[1,253]      0.23      0.92      0.21     -1.08      1.81   1551.57      1.00\n",
      "    z[1,254]      0.40      0.96      0.39     -1.24      1.80    678.46      1.00\n",
      "    z[1,255]     -0.24      0.79     -0.25     -1.47      0.98    896.10      1.00\n",
      "    z[1,256]      0.12      0.83      0.11     -1.07      1.46    870.01      1.00\n",
      "    z[1,257]      0.45      0.75      0.43     -0.90      1.54   1020.55      1.00\n",
      "    z[1,258]     -0.10      0.83     -0.11     -1.36      1.21    920.20      1.00\n",
      "    z[1,259]      0.93      0.75      0.90     -0.23      2.21    925.03      1.00\n",
      "    z[1,260]      0.76      0.84      0.79     -0.73      1.87    910.99      1.00\n",
      "    z[1,261]      0.02      0.89      0.03     -1.39      1.36    962.45      1.00\n",
      "    z[1,262]      0.20      0.88      0.22     -1.35      1.43    851.99      1.00\n",
      "    z[1,263]      0.00      0.91      0.02     -1.62      1.41   1588.40      1.00\n",
      "    z[1,264]     -0.23      0.89     -0.23     -1.45      1.36   1149.90      1.00\n",
      "    z[1,265]      0.78      0.77      0.81     -0.42      1.96    887.01      1.00\n",
      "    z[1,266]      0.67      0.68      0.68     -0.53      1.66   1004.08      1.00\n",
      "    z[1,267]     -0.16      0.75     -0.14     -1.42      0.97    975.83      1.00\n",
      "    z[1,268]      1.15      0.71      1.17      0.12      2.28    911.49      1.00\n",
      "    z[1,269]     -0.26      0.81     -0.23     -1.47      1.10   1083.05      1.00\n",
      "    z[1,270]      0.44      0.87      0.41     -0.84      1.87    892.22      1.00\n",
      "    z[1,271]     -0.31      1.00     -0.31     -1.83      1.37   1367.42      1.00\n",
      "    z[1,272]     -0.27      0.94     -0.32     -1.74      1.28    968.25      1.00\n",
      "    z[1,273]     -0.56      0.87     -0.56     -1.89      0.80    951.80      1.00\n",
      "    z[1,274]      0.65      0.67      0.67     -0.42      1.61   1054.36      1.00\n",
      "    z[1,275]     -0.11      0.97     -0.08     -1.77      1.34   1240.38      1.00\n",
      "    z[1,276]     -0.22      0.92     -0.20     -1.72      1.14   1235.74      1.00\n",
      "    z[1,277]      0.26      0.84      0.27     -1.05      1.54   1032.10      1.00\n",
      "    z[1,278]     -0.18      0.98     -0.14     -1.72      1.35   1905.65      1.00\n",
      "    z[1,279]      1.09      0.84      1.07     -0.21      2.40   1483.67      1.00\n",
      "    z[1,280]     -0.10      0.71     -0.08     -1.32      0.90    715.18      1.00\n",
      "    z[1,281]      0.34      0.71      0.32     -0.65      1.52    765.59      1.00\n",
      "    z[1,282]      0.01      0.88      0.01     -1.55      1.18   1166.81      1.00\n",
      "    z[1,283]     -0.20      0.88     -0.21     -1.71      1.05   1171.14      1.00\n",
      "    z[1,284]      0.38      0.93      0.36     -1.13      1.78   1103.59      1.00\n",
      "    z[1,285]      0.08      0.68      0.08     -1.00      1.11    958.46      1.00\n",
      "    z[1,286]      0.12      0.86      0.14     -1.42      1.26   1046.08      1.00\n",
      "    z[1,287]      0.56      0.78      0.55     -0.52      1.85   1162.72      1.00\n",
      "    z[1,288]      0.07      0.75      0.07     -1.10      1.28    944.09      1.00\n",
      "    z[1,289]     -0.08      1.00     -0.06     -1.55      1.42   1797.60      1.00\n",
      "    z[1,290]      0.11      0.71      0.14     -1.16      1.13    804.68      1.00\n",
      "    z[1,291]     -1.20      0.85     -1.21     -2.46      0.23   1015.27      1.00\n",
      "    z[1,292]     -0.11      0.98     -0.12     -1.61      1.44   2452.43      1.00\n",
      "    z[1,293]      0.22      0.91      0.24     -1.18      1.68    923.44      1.00\n",
      "    z[1,294]     -0.50      0.79     -0.52     -1.72      0.73    651.79      1.00\n",
      "    z[1,295]      0.14      1.00      0.17     -1.46      1.66   2007.70      1.00\n",
      "    z[1,296]     -0.21      0.99     -0.19     -1.80      1.37   1498.16      1.00\n",
      "    z[1,297]     -0.23      1.01     -0.24     -1.78      1.38   1611.28      1.00\n",
      "    z[1,298]     -0.16      1.03     -0.14     -1.81      1.38   1482.56      1.00\n",
      "    z[1,299]     -0.25      0.90     -0.24     -1.58      1.11   1445.89      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu')\n",
    "kl_dyads  = pd.read_csv('../data/kl_dyads')\n",
    "d2 = pd.read_csv('../data/kl_households'\"\", index_col=0)\n",
    "kl_data = dict(\n",
    "    N=kl_dyads.shape[0],\n",
    "    N_households=kl_dyads.hidB.max(),\n",
    "    did=kl_dyads.did.values - 1,\n",
    "    hidA=kl_dyads.hidA.values - 1,\n",
    "    hidB=kl_dyads.hidB.values - 1,\n",
    "    giftsAB=kl_dyads.giftsAB.values,\n",
    "    giftsBA=kl_dyads.giftsBA.values,\n",
    ")\n",
    "m.data_on_model = kl_data\n",
    "\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = dist.lkj(2, 4,  name = \"Rho_gr\")\n",
    "    sigma_gr = dist.exponential(1, shape = [2], name = \"sigma_gr\")\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = dist.multivariatenormal(0, cov, shape = [N_households],  name = 'gr')\n",
    "\n",
    "    # dyad effects\n",
    "    z = dist.normal(0, 1,shape = [2, N], name = 'z')\n",
    "    L_Rho_d = dist.lkjcholesky(2, 8, name = \"L_Rho_d\")\n",
    "    sigma_d = dist.exponential(1, name = \"sigma\")\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = dist.normal(0, 1, name = 'a')\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    lk(\"giftsAB\", Poisson(lambdaAB), obs=giftsAB)\n",
    "    lk(\"giftsBA\", Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "\n",
    "m.run(model) \n",
    "m.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "def model(N_households, N, did, hidA, hidB, giftsAB, giftsBA, link=False):\n",
    "    # gr matrix of varying effects\n",
    "    Rho_gr = dist.LKJ(2, 4, nanme = \"Rho_gr\")\n",
    "    sigma_gr = dist.Exponential(1, shape = [2], name = \"sigma_gr\")\n",
    "    cov = jnp.outer(sigma_gr, sigma_gr) * Rho_gr\n",
    "    gr = bi.random_centered(sigma_gr, Rho_gr, )\n",
    "    numpyro.sample(\"gr\", dist.MultivariateNormal(0, cov).expand([N_households]))\n",
    "\n",
    "    # dyad effects\n",
    "    z = numpyro.sample(\"z\", dist.Normal(0, 1).expand([2, N]))\n",
    "    L_Rho_d = numpyro.sample(\"L_Rho_d\", dist.LKJCholesky(2, 8))\n",
    "    sigma_d = numpyro.sample(\"sigma_d\", dist.Exponential(1))\n",
    "    d = numpyro.deterministic(\n",
    "        \"d\", ((jnp.repeat(sigma_d, 2)[..., None] * L_Rho_d) @ z).T\n",
    "    )\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    lambdaAB = jnp.exp(a + gr[hidA, 0] + gr[hidB, 1] + d[did, 0])\n",
    "    lambdaBA = jnp.exp(a + gr[hidB, 0] + gr[hidA, 1] + d[did, 1])\n",
    "    numpyro.sample(\"giftsAB\", dist.Poisson(lambdaAB), obs=giftsAB)\n",
    "    numpyro.sample(\"giftsBA\", dist.Poisson(lambdaBA), obs=giftsBA)\n",
    "\n",
    "    # compute correlation matrix for dyads\n",
    "    if link:\n",
    "        numpyro.deterministic(\"Rho_d\", L_Rho_d @ L_Rho_d.T)\n",
    "\n",
    "\n",
    "m14_7 = MCMC(NUTS(model), num_warmup=1000, num_samples=1000, num_chains=4)\n",
    "m14_7.run(random.PRNGKey(0), **kl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:01<00:00, 768.14it/s, 127 steps of size 3.22e-02. acc. prob=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI took: 1.9520 seconds\n",
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "      a[0]      1.33      0.90      1.11      0.15      2.60    394.53      1.02\n",
      "      b[0]      0.28      0.09      0.28      0.13      0.41    209.03      1.00\n",
      "  etasq[0]      0.20      0.20      0.14      0.01      0.42    280.91      1.00\n",
      "      g[0]      0.59      0.59      0.43      0.02      1.23    302.88      1.02\n",
      "  rhosq[0]      1.38      1.72      0.75      0.02      3.37    329.98      1.00\n",
      "      z[0]     -0.49      0.79     -0.46     -1.53      0.84    241.76      1.00\n",
      "      z[1]      0.37      0.76      0.39     -0.86      1.49    502.49      1.00\n",
      "      z[2]     -0.26      0.76     -0.21     -1.73      0.68    636.05      1.00\n",
      "      z[3]      0.93      0.65      0.95     -0.12      1.84    255.45      1.00\n",
      "      z[4]      0.30      0.61      0.28     -0.52      1.37    330.08      1.00\n",
      "      z[5]     -1.09      0.72     -1.02     -2.20     -0.05    271.82      1.00\n",
      "      z[6]      0.37      0.62      0.33     -0.64      1.30    371.45      1.00\n",
      "      z[7]     -0.37      0.70     -0.39     -1.51      0.65    501.95      1.00\n",
      "      z[8]      0.77      0.63      0.75     -0.31      1.69    333.48      1.00\n",
      "      z[9]     -0.46      0.77     -0.48     -1.78      0.70    299.46      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "from main import*\n",
    "Kline2 = pd.read_csv('../data/Kline2.csv', sep=\";\")\n",
    "islandsDistMatrix = pd.read_csv('../data/islandsDistMatrix.csv'\"\", index_col=0)\n",
    "d = Kline2\n",
    "d[\"society\"] = range(1, 11)  # index observations\n",
    "\n",
    "dat_list = dict(\n",
    "    T=d.total_tools.values,\n",
    "    P=d.population.values,\n",
    "    society=d.society.values - 1,\n",
    "    Dmat=islandsDistMatrix.values,\n",
    ")\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m14_8 = bi(platform='cpu')\n",
    "m14_8.data = dat_list\n",
    "\n",
    "@jit\n",
    "def cov_GPL2(x, sq_eta, sq_rho, sq_sigma):\n",
    "    N = x.shape[0]\n",
    "    K = sq_eta * jnp.exp(-sq_rho * jnp.square(x))\n",
    "    K = K.at[jnp.diag_indices(N)].add(sq_sigma)\n",
    "    return K\n",
    "\n",
    "\n",
    "def model(Dmat, P, society, T):\n",
    "    a = exponential('a', [1], 1)\n",
    "    b = exponential('b',[1],1)\n",
    "    g = exponential('g',[1],1)\n",
    "    etasq = exponential('etasq',[1],2)\n",
    "    rhosq = exponential('rhosq',[1],0.5)\n",
    "\n",
    "    # non-centered Gaussian Process prior\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, 0.01)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = normal('z', [10], 0, 1)\n",
    "    k = (L_SIGMA @ z[..., None])[..., 0]\n",
    "    lambda_ = a * P**b / g * jnp.exp(k[society])\n",
    "    sample(\"T\", Poisson(lambda_), obs=T)\n",
    "\n",
    "# Run sampler ------------------------------------------------\n",
    "start = tm.time()    \n",
    "m14_8.run(model) \n",
    "end = tm.time()    \n",
    "print(f\"BI took: {end - start:.4f} seconds\")\n",
    "m14_8.sampler.print_summary(0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Multinomial with centered random factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "    \n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4146024105,  967050713], dtype=uint32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init_key = jnp.array(init_key)\n",
    "init_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import os\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, set_matplotlib_formats\n",
    "from matplotlib.patches import Ellipse, transforms\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpy as onp\n",
    "import numpyro as numpyro\n",
    "\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.diagnostics import effective_sample_size, print_summary\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(30)\n",
    "\n",
    "init_key, sample_key = random.split(random.PRNGKey(0))\n",
    "init_key = jnp.array(init_key)\n",
    "init_key\n",
    "\n",
    "# Simulation ---------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "Y2 = jnp.array(Y2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:01<00:00, 1386.84it/s, 1023 steps of size 1.50e-07. acc. prob=0.79]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building model and sampling it ------------------\n",
    "def model(NY, NV, Y2):\n",
    "    means =  numpyro.sample('means', numpyro.distributions.Normal(0,1).expand([NY]))\n",
    "    offset =  numpyro.sample('offset', numpyro.distributions.Normal(0,1).expand([NV,1]))\n",
    "    sigma =  numpyro.sample('sigma', numpyro.distributions.Exponential(1).expand([NY])) \n",
    "    tmp = jnp.tile(means, (NV, 1)).reshape(NV,NY)  \n",
    "    mu_l = tmp + offset \n",
    "    numpyro.sample('Y2', numpyro.distributions.Normal(mu_l, jnp.tile(sigma, [NV, 1])), obs=Y2)\n",
    "\n",
    "dat = dict(\n",
    "    NY = NY,\n",
    "    NV = NV,\n",
    "    Y2 = Y2\n",
    ")\n",
    "m = MCMC(NUTS(model, init_strategy = numpyro.infer.init_to_median()), num_warmup=1000, num_samples=1000, num_chains=1)\n",
    "m.run(random.PRNGKey(0), extra_fields=[\"diverging\"], **dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 1000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>means[0]</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[1]</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[2]</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>means[3]</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[0, 0]</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[1, 0]</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[2, 0]</th>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[3, 0]</th>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.077</td>\n",
       "      <td>2.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[4, 0]</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[5, 0]</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[6, 0]</th>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset[7, 0]</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[0]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[1]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[2]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma[3]</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean   sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "means[0]      0.519  0.0   0.519    0.519        0.0      0.0    1000.0   \n",
       "means[1]      0.191  0.0   0.191    0.191        0.0      0.0    1000.0   \n",
       "means[2]      0.657  0.0   0.657    0.657        0.0      0.0    1000.0   \n",
       "means[3]     -0.613  0.0  -0.613   -0.613        0.0      0.0    1000.0   \n",
       "offset[0, 0]  0.530  0.0   0.530    0.530        0.0      0.0    1000.0   \n",
       "offset[1, 0]  0.812  0.0   0.812    0.812        0.0      0.0    1000.0   \n",
       "offset[2, 0] -0.366  0.0  -0.366   -0.366        0.0      0.0    1000.0   \n",
       "offset[3, 0]  2.077  0.0   2.077    2.077        0.0      0.0    1000.0   \n",
       "offset[4, 0]  0.988  0.0   0.988    0.988        0.0      0.0    1000.0   \n",
       "offset[5, 0]  0.342  0.0   0.342    0.342        0.0      0.0    1000.0   \n",
       "offset[6, 0]  1.198  0.0   1.198    1.198        0.0      0.0    1000.0   \n",
       "offset[7, 0]  0.697  0.0   0.697    0.697        0.0      0.0    1000.0   \n",
       "sigma[0]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[1]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[2]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "sigma[3]      0.000  0.0   0.000    0.000        0.0      0.0    1000.0   \n",
       "\n",
       "              ess_tail  r_hat  \n",
       "means[0]        1000.0    NaN  \n",
       "means[1]        1000.0    NaN  \n",
       "means[2]        1000.0    NaN  \n",
       "means[3]        1000.0    NaN  \n",
       "offset[0, 0]    1000.0    NaN  \n",
       "offset[1, 0]    1000.0    NaN  \n",
       "offset[2, 0]    1000.0    NaN  \n",
       "offset[3, 0]    1000.0    NaN  \n",
       "offset[4, 0]    1000.0    NaN  \n",
       "offset[5, 0]    1000.0    NaN  \n",
       "offset[6, 0]    1000.0    NaN  \n",
       "offset[7, 0]    1000.0    NaN  \n",
       "sigma[0]        1000.0    NaN  \n",
       "sigma[1]        1000.0    NaN  \n",
       "sigma[2]        1000.0    NaN  \n",
       "sigma[3]        1000.0    NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arviz as az\n",
    "data = az.from_numpyro(m)\n",
    "az.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28912305, 0.96183663, 1.42779941, 0.15728591])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random centered effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.7328625  0.13674371 0.13039377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.66280484 0.1774538  0.15974137]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    print(L_individual.shape)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = ((Sigma_individual[..., None] * L_individual) @ z_individual)\n",
    "    print(alpha.shape)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1, chain_method='vectorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bi' object has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39marray(a))) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumpypro estimation:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bi' object has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.006054 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 60.54 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[26] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[89] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: log1m: x is 1, but must be less than or equal to 1.000000 (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 12, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 432.2593 seconds\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#################################### Pustan Model  #############################\n",
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "tmp = dat\n",
    "tmp['y'] = np.array(tmp['y'])\n",
    "tmp['i_ID'] = np.array(tmp['i_ID']+1)\n",
    "tmp['ni'] = tmp['ni']\n",
    "tmp['K'] = tmp['K']\n",
    "tmp['N'] = int(N)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "    int<lower=0>  N;             // number of observations\n",
    "    int<lower=0>  K;             // number of occupations\n",
    "    int ni;                     // NUmber of Unique Individauls\n",
    "    array[N, K] int y;           // array of observed occupation indicators\n",
    "    array[N]int<lower=0>  i_ID;     // village indicator for each individual\n",
    "}\n",
    "parameters {\n",
    "    vector[K] a;                    // intercept for each occupation\n",
    "    matrix[ni, K]  z_individual;    // raw random effect for household \n",
    "    cholesky_factor_corr[ni] L_individual; // Cholesky factor for \n",
    "    vector<lower=0>[ni] Sigma_individual;\n",
    "\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[ni, K] b_individual;\n",
    "    b_individual = diag_pre_multiply(Sigma_individual, L_individual) * z_individual;\n",
    "}\n",
    "model{\n",
    "    array[N] vector[K] p;\n",
    "    matrix[N, K] random_effects;\n",
    "    to_vector(a) ~ normal(0, 1);\n",
    "    L_individual ~   lkj_corr_cholesky(2);\n",
    "    Sigma_individual ~ exponential(1);\n",
    "    to_vector(z_individual) ~ normal(0, 1);\n",
    "    // Likelihood for\n",
    "    for (k in 1:K) {\n",
    "        for (i in 1:N) {\n",
    "          random_effects[i, k] = b_individual[i_ID[i], k];\n",
    "          p[i,k] =  a[k] + random_effects[i, k];\n",
    "      }\n",
    "    }\n",
    "    for (i in 1:(N)) {\n",
    "        y[i,] ~ dirichlet_multinomial(exp(p[i,]));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = tmp)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500, init = [{'L_individual': np.zeros((tmp['ni'], tmp['ni']))}])\n",
    "end = tm.time()    \n",
    "#df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Estimation Multinomial:\n",
      "[0.79368174 0.11202765 0.0942907 ]\n",
      "Estimation DirichletMultinomial:\n",
      "Pytstan estimation\n",
      "[0.7914235  0.11247264 0.09610377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(np.array([3,1,1])))) \n",
    "print('Estimation Multinomial:')\n",
    "post = m.sampler.get_samples()\n",
    "print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "print('Estimation DirichletMultinomial:')\n",
    "#post = m2.sampler.get_samples()\n",
    "#print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "df = fit.to_frame()\n",
    "print('Pytstan estimation')\n",
    "print(jax.nn.softmax(jnp.array([df['a.1'].mean(),df['a.2'].mean(),df['a.3'].mean()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mutils import Mgaussian, cov_GPL2\n",
    "from jax.scipy.stats import norm\n",
    "gaus = Mgaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f067c1c5ea0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = sample.uniform(-4,4, sample_shape=(100,))\n",
    "raw  = jnp.sort(raw)\n",
    "sequence = jnp.array([i for i in range(1, 11) for _ in range(10)])\n",
    "unique = jnp.unique(jnp.array(sequence))\n",
    "result = []\n",
    "\n",
    "for i in range(0,len(unique)):  \n",
    "    result.append(jnp.mean(raw[jnp.where(sequence==(i + 1))], axis = 0))\n",
    "\n",
    "Dmat = gaus.distance_matrix(jnp.array(result))\n",
    "cdf_value = norm.cdf(raw , loc=0, scale=1)# to plot for after\n",
    "plt.plot(jnp.arange(0, 100), cdf_value)\n",
    "error = sample.normal(0, 0.1, sample_shape=(100,))\n",
    "y = cdf_value + error\n",
    "plt.plot(jnp.arange(0, 100), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process(Dmat, etasq, rhosq, sigmaq):\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, sigmaq)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = sample.normal(0, 1, sample_shape= (10,))\n",
    "    k = numpyro.deterministic(\"k\", (L_SIGMA @ z[..., None])[..., 0])\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform gaussain process through array of Nx3\n",
    "a = sample.normal(0,1, (8, 20))\n",
    "sigma = sample.exponential(1, sample_shape=(8*20,))\n",
    "etasq = sample.exponential(2, sample_shape=(8*20,))\n",
    "rhosq = sample.exponential(0.5, sample_shape=(8*20,))\n",
    "sigmaq = sample.exponential(2, sample_shape= (8*20,))\n",
    "tmp = jnp.stack([etasq, rhosq, sigmaq], axis = 1)\n",
    "t = vmap(lambda x: gaussian_process(Dmat, x[0], x[1], x[2]))(tmp) # need to return 8 * 20 * 10\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [03:53<00:00,  4.29it/s, 191 steps of size 2.40e-02. acc. prob=0.92]\n"
     ]
    }
   ],
   "source": [
    "def gaus_model(Dmat, y ,sequence):\n",
    "    a = dist.normal('a', 0,1)\n",
    "    sigma = dist.exponential('s', 1)\n",
    "    etasq = dist.exponential(\"etasq\",2)\n",
    "    rhosq = dist.exponential(\"rhosq\",0.5)\n",
    "    sigmaq = dist.exponential(\"sigmaq\",2)\n",
    "\n",
    "    SIGMA = cov_GPL2(Dmat, etasq, rhosq, sigmaq)\n",
    "    L_SIGMA = jnp.linalg.cholesky(SIGMA)\n",
    "    z = dist.normal('z', 0, 1, sample_shape= [10])\n",
    "    k = numpyro.deterministic(\"k\", (L_SIGMA @ z[..., None])[..., 0])\n",
    "    \n",
    "    mu = a + k[sequence]\n",
    "\n",
    "    lk('Y', Normal(mu, sigma), obs=y)\n",
    "\n",
    "dat = dict(\n",
    "    Dmat = Dmat,\n",
    "    y = y,\n",
    "    sequence = sequence - 1 \n",
    ")\n",
    "\n",
    "m = MCMC(NUTS(gaus_model), num_warmup=500, num_samples=500, num_chains=1)\n",
    "m.run(random.PRNGKey(0), **dat)\n",
    "res = az.from_numpyro(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f7ce542e0>]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.arange(0,10), jnp.mean(jnp.array(res['posterior']['a'])) + jnp.mean(jnp.array(res['posterior']['k'][0,:,:]), axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine latent, random and gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent + random = random + latent[village[i]] with village being village ID\n",
    "# gaussian simulation \n",
    "# 1. non linear function to generate gaussian proces for each parameters\n",
    "# model 2 = random + latent[village[i]] + gaussian_process\n",
    "# model 3  = model 2 + interaction effect\n",
    "#interaction effect = non linear function where input is hhmembers[i]*offsets[vilage[i]] with new coefficients params\n",
    "# Within model we need to change offset ouput as an integer so we do bxi*hhmembers[i]*offset[v_ID[i]]+ bxIsq*(hhmembers[i]*offset[v_ID[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    #individual \n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 50)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha_individual = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "\n",
    "    #household \n",
    "    Sigma_household = exponential('Sigma_household', [ni], 1 )\n",
    "    L_household = lkjcholesky('L_household', [], ni, 50)\n",
    "    z_household = normal('z_household', [ni,K], 0, 1)\n",
    "    alpha_household = random_centered2(Sigma_household, L_household, z_household)\n",
    "\n",
    "    #village \n",
    "    Sigma_village = exponential('Sigma_village', [ni], 1 )\n",
    "    L_village = lkjcholesky('L_village', [], ni, 50)\n",
    "    z_village = normal('z_village', [ni,K], 0, 1)\n",
    "    alpha_village = random_centered2(Sigma_village, L_village, z_village)\n",
    "\n",
    "    #LK\n",
    "    random_factors = alpha_individual[i_ID] + alpha_household[i_ID] + alpha_village[i_ID]\n",
    "    numpyro.sample(\"y\", dist.DirichletMultinomial(a + random_factors[i_ID], int(12083)), obs=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
