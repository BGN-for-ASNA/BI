{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSosa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n",
      "[-1.1842843]\n",
      "<function Mgaussian.gaussian_process at 0x000001CAA6D56B60>\n",
      "<PjitFunction of <function factors.random_centered at 0x000001CAA6D237E0>>\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "from main import *\n",
    "from functools import partial\n",
    "import time as tm\n",
    "# Bi modules\n",
    "bi = bi(platform='cpu')\n",
    "print(bi.dist.normal(0,1, sample = True, shape=(1,), seed = 1))\n",
    "bi.net.mat_to_edgl(jnp.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8],\n",
    "                              [9, 10, 11, 12],\n",
    "                              [13, 14, 15, 16]]))\n",
    "print(bi.gaussian_process)\n",
    "print(bi.random_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import numpyro as numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "###############################################################################\n",
    "############ SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION ###########\n",
    "def mysoftmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "K = 3\n",
    "N = 100\n",
    "N_obs = 2\n",
    "sigma_random = 0.6\n",
    "\n",
    "\n",
    "########################################################\n",
    "################### Fixed effect Sim ###################\n",
    "#a = np.random.normal(0, 1, K)\n",
    "a = np.array([3,1,1]) # Forcing a values\n",
    "\n",
    "\n",
    "# Factors--------------------------\n",
    "NY = 4\n",
    "NV = 8\n",
    "\n",
    "Y2 = np.full((NV, NY), np.nan) \n",
    "means = np.random.normal(0, 1, NY)\n",
    "offsets = np.random.normal(0, 1, NV)\n",
    "for i in range(NV):\n",
    "  for k in range(NY):\n",
    "    Y2[i,k] = means[k] + offsets[i]\n",
    "\n",
    "    \n",
    "b_individual = np.random.normal(0, 1, (N, K))\n",
    "mu = b_individual + a\n",
    "\n",
    "\n",
    "# Declare an empty Matrix to fill with data\n",
    "Y = np.empty((N * N_obs, K))\n",
    "\n",
    "# Declare an empty vector to fill with IDs\n",
    "id = []\n",
    "\n",
    "# Loop over each individual\n",
    "for i in range(N):\n",
    "    # Simulate N_obs draws from the multinomial\n",
    "    Y[i*N_obs:(i+1)*N_obs, :] = np.apply_along_axis(lambda x: np.random.multinomial(100, mysoftmax(x)), 0, mu[i])\n",
    "    # Assign ID vector\n",
    "    id += [i] * N_obs\n",
    "\n",
    "\n",
    "N = N*N_obs\n",
    "K = K\n",
    "ni = N\n",
    "y = jnp.array(Y, dtype=jnp.int32).reshape(N, K)\n",
    "i_ID = jnp.array(id)\n",
    "\n",
    "dat = dict(\n",
    "    K = K,\n",
    "    ni = ni,\n",
    "    y = y,\n",
    "    i_ID = i_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random centered effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.7328625  0.13674371 0.13039377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = random_centered2(Sigma_individual, L_individual, z_individual)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n",
      "[0.66280484 0.1774538  0.15974137]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(K, ni, y, i_ID):\n",
    "    a = normal('a', [K], 0,1)\n",
    "    Sigma_individual = exponential('Sigma_individual', [ni], 1 )\n",
    "    L_individual = lkjcholesky('L_individual', [], ni, 1) # Implies a uniform distribution over correlation matrices\n",
    "    print(L_individual.shape)\n",
    "    z_individual = normal('z_individual', [ni,K], 0, 1)\n",
    "    alpha = ((Sigma_individual[..., None] * L_individual) @ z_individual)\n",
    "    print(alpha.shape)\n",
    "    lk = jnp.exp(a + alpha[i_ID])\n",
    "    sample(\"y\", DirichletMultinomial(lk, int(100)), obs=y)\n",
    "\n",
    "m = bi()\n",
    "m.data = dat\n",
    "m.run(model, init_strategy = numpyro.infer.init_to_median(), \n",
    "      num_warmup=500, num_samples=500, num_chains=1, chain_method='vectorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Numpypro estimation:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bi' object has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39marray(a))) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumpypro estimation:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bi' object has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(a))) \n",
    "print('Numpypro estimation:')\n",
    "print(jax.nn.softmax(jnp.mean(jnp.array(m.trace['posterior']['a'][0]), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sampling:   0% (1/1000)\n",
      "Sampling:  10% (100/1000)\n",
      "Sampling:  20% (200/1000)\n",
      "Sampling:  30% (300/1000)\n",
      "Sampling:  40% (400/1000)\n",
      "Sampling:  50% (500/1000)\n",
      "Sampling:  50% (501/1000)\n",
      "Sampling:  60% (600/1000)\n",
      "Sampling:  70% (700/1000)\n",
      "Sampling:  80% (800/1000)\n",
      "Sampling:  90% (900/1000)\n",
      "Sampling: 100% (1000/1000)\n",
      "Sampling: 100% (1000/1000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.006054 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 60.54 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[6] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[26] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[89] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: log1m: x is 1, but must be less than or equal to 1.000000 (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 12, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: lkj_corr_cholesky_lpdf: Random variable[15] is 0, but must be positive! (in '/tmp/httpstan_bcudn7_c/model_cppt44mg.stan', line 24, column 4 to column 42)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pystan took: 432.2593 seconds\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#################################### Pustan Model  #############################\n",
    "import time as tm\n",
    "import stan\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "tmp = dat\n",
    "tmp['y'] = np.array(tmp['y'])\n",
    "tmp['i_ID'] = np.array(tmp['i_ID']+1)\n",
    "tmp['ni'] = tmp['ni']\n",
    "tmp['K'] = tmp['K']\n",
    "tmp['N'] = int(N)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "stan_code = \"\"\" \n",
    "data {\n",
    "    int<lower=0>  N;             // number of observations\n",
    "    int<lower=0>  K;             // number of occupations\n",
    "    int ni;                     // NUmber of Unique Individauls\n",
    "    array[N, K] int y;           // array of observed occupation indicators\n",
    "    array[N]int<lower=0>  i_ID;     // village indicator for each individual\n",
    "}\n",
    "parameters {\n",
    "    vector[K] a;                    // intercept for each occupation\n",
    "    matrix[ni, K]  z_individual;    // raw random effect for household \n",
    "    cholesky_factor_corr[ni] L_individual; // Cholesky factor for \n",
    "    vector<lower=0>[ni] Sigma_individual;\n",
    "\n",
    "}\n",
    "transformed parameters{\n",
    "    matrix[ni, K] b_individual;\n",
    "    b_individual = diag_pre_multiply(Sigma_individual, L_individual) * z_individual;\n",
    "}\n",
    "model{\n",
    "    array[N] vector[K] p;\n",
    "    matrix[N, K] random_effects;\n",
    "    to_vector(a) ~ normal(0, 1);\n",
    "    L_individual ~   lkj_corr_cholesky(2);\n",
    "    Sigma_individual ~ exponential(1);\n",
    "    to_vector(z_individual) ~ normal(0, 1);\n",
    "    // Likelihood for\n",
    "    for (k in 1:K) {\n",
    "        for (i in 1:N) {\n",
    "          random_effects[i, k] = b_individual[i_ID[i], k];\n",
    "          p[i,k] =  a[k] + random_effects[i, k];\n",
    "      }\n",
    "    }\n",
    "    for (i in 1:(N)) {\n",
    "        y[i,] ~ dirichlet_multinomial(exp(p[i,]));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "start = tm.time()\n",
    "stan_model = stan.build(stan_code, data = tmp)\n",
    "fit = stan_model.sample(num_chains=1, num_samples=500, num_warmup = 500, init = [{'L_individual': np.zeros((tmp['ni'], tmp['ni']))}])\n",
    "end = tm.time()    \n",
    "#df = fit.to_frame()\n",
    "print(f\"Pystan took: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated:\n",
      "[0.786986   0.10650697 0.10650697]\n",
      "Estimation Multinomial:\n",
      "[0.79368174 0.11202765 0.0942907 ]\n",
      "Estimation DirichletMultinomial:\n",
      "Pytstan estimation\n",
      "[0.7914235  0.11247264 0.09610377]\n"
     ]
    }
   ],
   "source": [
    "print('Simulated:')\n",
    "print(jax.nn.softmax(jnp.array(np.array([3,1,1])))) \n",
    "print('Estimation Multinomial:')\n",
    "post = m.sampler.get_samples()\n",
    "print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "print('Estimation DirichletMultinomial:')\n",
    "#post = m2.sampler.get_samples()\n",
    "#print(jax.nn.softmax(jnp.mean(post['a'], axis = 0)))\n",
    "df = fit.to_frame()\n",
    "print('Pytstan estimation')\n",
    "print(jax.nn.softmax(jnp.array([df['a.1'].mean(),df['a.2'].mean(),df['a.3'].mean()])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
