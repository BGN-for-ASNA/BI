{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 10:52:49.657250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751619169.778004   11341 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751619169.803405   11341 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751619169.960914   11341 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751619169.961165   11341 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751619169.961169   11341 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751619169.961174   11341 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from BI import bi\n",
    "\n",
    "import random as r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "m = bi(platform='cpu',backend='tfp')\n",
    "data_path = os.path.dirname(os.path.abspath(\"\")) + \"/BI/resources/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Continuous variable: Model (model 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>154.66</td>\n",
       "      <td>0.29</td>\n",
       "      <td>154.19</td>\n",
       "      <td>155.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>5.79</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.39</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>5.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a  154.66  0.29    154.19     155.10\n",
       "b    5.79  0.28      5.39       6.27\n",
       "s    5.13  0.19      4.86       5.45"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'Howell1.csv', sep=';') \n",
    "m.df = m.df[m.df.age > 18]\n",
    "m.scale(['weight'])\n",
    "\n",
    "def model(weight, height):\n",
    "    a = yield m.dist.normal(178, 20)\n",
    "    b = yield m.dist.log_normal(0, 1)  \n",
    "    s = yield m.dist.uniform(0, 50)   \n",
    "    y = yield m.dist.normal(a+b*weight, s, shape = (1,), obs = height)\n",
    "\n",
    "m.fit(model = model, obs = 'height', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical variable: Model (model 5.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a[0] -0.47  0.23     -0.91      -0.17\n",
       "a[1]  0.35  0.25     -0.01       0.72\n",
       "a[2]  0.65  0.27      0.26       1.09\n",
       "a[3] -0.56  0.30     -1.04      -0.09\n",
       "s     0.80  0.13      0.60       0.97"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'milk.csv', sep=';') \n",
    "m.index([\"clade\"])\n",
    "m.scale(['kcal_per_g'])\n",
    "\n",
    "def model(kcal_per_g,index_clade):\n",
    "    s = yield m.dist.exponential(1, 1)\n",
    "    a = yield m.dist.normal(0, 0.5, shape = (4,)) \n",
    "    l = a[index_clade]\n",
    "    y = yield m.dist.normal(l, s, shape = (1,), obs = kcal_per_g)\n",
    "    \n",
    "\n",
    "m.fit(model = model, obs = 'kcal_per_g', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous interactions terms (model 8.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs</th>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bw</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bws</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a      0.08  0.10     -0.08       0.23\n",
       "bs    -0.31  0.11     -0.47      -0.13\n",
       "bw     0.56  0.12      0.36       0.73\n",
       "bws   -0.32  0.11     -0.47      -0.15\n",
       "sigma  0.58  0.10      0.43       0.70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'tulips.csv', sep=';') \n",
    "m.scale(['blooms', 'water', 'shade'])\n",
    "\n",
    "def model(blooms, water,  shade, ):\n",
    "    sigma = yield m.dist.exponential(1)\n",
    "    bws = yield m.dist.normal(0 , 0.25 )\n",
    "    bs = yield m.dist.normal(0 , 0.25 )\n",
    "    bw = yield m.dist.normal(0 , 0.25 )\n",
    "    a = yield m.dist.normal(0.5 , 0.25 )\n",
    "    mu = a + bw*water + bs*shade + bws*water*shade\n",
    "    y = yield m.dist.normal(mu, sigma, shape=(1,), obs = blooms)\n",
    "\n",
    "m.fit(model = model, obs = 'blooms', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binomial (model 11.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean   sd  hdi_5.5%  hdi_94.5%\n",
       "a[0]  0.33  0.1      0.18       0.47"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi(platform='cpu',backend='tfp')\n",
    "# import data ------------------------------------------------\n",
    "m.data(data_path + 'chimpanzees.csv', sep=';') \n",
    "\n",
    "def model(pulled_left):\n",
    "    a = yield m.dist.normal(0 , 10, shape = (1,))\n",
    "    y = yield m.dist.binomial(1,logits = a, obs = pulled_left, shape = 1)\n",
    "\n",
    "\n",
    "m.fit(model = model, obs = 'pulled_left', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Binomial with indices (model 11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>4.01</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.90</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[2]</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[3]</th>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[4]</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[5]</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[6]</th>\n",
       "      <td>1.97</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[2]</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[3]</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a[0] -0.45  0.32     -0.95       0.08\n",
       "a[1]  4.01  0.72      2.90       5.12\n",
       "a[2] -0.75  0.36     -1.25      -0.17\n",
       "a[3] -0.74  0.34     -1.28      -0.21\n",
       "a[4] -0.45  0.34     -0.95       0.13\n",
       "a[5]  0.49  0.35     -0.14       0.95\n",
       "a[6]  1.97  0.46      1.27       2.74\n",
       "b[0] -0.04  0.29     -0.54       0.37\n",
       "b[1]  0.48  0.29      0.05       0.94\n",
       "b[2] -0.38  0.28     -0.81       0.06\n",
       "b[3]  0.38  0.29     -0.03       0.88"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'chimpanzees.csv', sep=';') \n",
    "m.df['treatment'] =  m.df.prosoc_left + 2 * m.df.condition\n",
    "m.df['actor'] = m.df['actor'] - 1\n",
    "\n",
    "def model(actor, treatment, pulled_left):\n",
    "    a = yield m.dist.normal(0, 1.5, shape = (7,))\n",
    "    b = yield m.dist.normal(0, 0.5, shape = (4,))\n",
    "    p = a[actor] + b[treatment]\n",
    "    y = yield m.dist.binomial(1, logits = p, shape = 1, obs = pulled_left)\n",
    "\n",
    "m.fit(model = model, obs = 'pulled_left', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson (model 11.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:342: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:299: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:300: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:301: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a[0]</th>\n",
       "      <td>3.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a[1]</th>\n",
       "      <td>3.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[0]</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b[1]</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a[0]  3.21  0.09      3.07       3.36\n",
       "a[1]  3.64  0.09      3.50       3.78\n",
       "b[0]  0.35  0.05      0.27       0.42\n",
       "b[1]  0.05  0.21     -0.25       0.41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "m = bi(platform='cpu',backend='tfp')\n",
    "# import data ------------------------------------------------\n",
    "m.data(data_path + 'Kline.csv', sep=';') \n",
    "m.scale(['population'])\n",
    "m.df[\"cid\"] = (m.df.contact == \"high\").astype(int)\n",
    "def model(cid, population, total_tools):\n",
    "    a = yield m.dist.normal(3,0.5, shape= (2,))\n",
    "    b = yield m.dist.normal(0,0.2, shape= (2,))\n",
    "    l = a[cid] + b[cid]*population\n",
    "    y = yield m.dist.poisson(log_rate = l, shape=1, obs = total_tools)\n",
    "\n",
    "m.fit(model = model, obs = 'total_tools', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Negative binomial (model 11.12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:342: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:299: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:300: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:301: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "import pandas as pd\n",
    "import random as random2\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "init_key, sample_key = jax.random.split(jax.random.PRNGKey(int(random2.randint(0, 10000000))))\n",
    "init_key = jnp.array(init_key)\n",
    "num_days = 3000\n",
    "y = tfd.Poisson(rate=1.5).sample(seed = init_key, sample_shape=(num_days,))\n",
    "num_weeks = 400\n",
    "y_new = tfd.Poisson(rate=0.5 * 7).sample(seed = init_key, sample_shape=(num_weeks,))\n",
    "y_all = np.concatenate([y, y_new])\n",
    "exposure = np.concatenate([np.repeat(1, num_days), np.repeat(7, num_weeks)])\n",
    "monastery = np.concatenate([np.repeat(0, num_days), np.repeat(1, num_weeks)])\n",
    "d = pd.DataFrame.from_dict(dict(y=y_all, days=exposure, monastery=monastery))\n",
    "d[\"log_days\"] = d.days.pipe(np.log)\n",
    "d.to_csv(data_path + 'Sim dat Gamma poisson.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:342: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return np.array(value, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:299: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:300: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  maxval = maxval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:301: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return jaxrand.uniform(key=seed, shape=shape, dtype=dtype, minval=minval,\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/numpy_array.py:450: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  lambda shape, dtype=np.float32, name=None, layout=None: np.ones(  # pylint: disable=g-long-lambda\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-1.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a  0.41  0.01      0.38       0.43\n",
       "b -1.11  0.03     -1.15      -1.07"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'Sim dat Gamma poisson.csv', sep=',') \n",
    "\n",
    "def model(log_days, monastery, y):\n",
    "    a = yield  m.dist.normal(0, 1)\n",
    "    b = yield  m.dist.normal(0, 1)\n",
    "    l = log_days + a +  b * monastery\n",
    "    y = yield m.dist.poisson(log_rate = l, shape=1, obs = y)\n",
    "\n",
    "m.fit(model = model, obs = 'y', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multinomial (model 11.13) (PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n",
      "(3,)\n",
      "(500,)\n",
      "(3,)\n",
      "(500,)\n",
      "(3,)\n",
      "(500,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sub got incompatible shapes for broadcasting: (500,), (2,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(career.shape)\n\u001b[32m     14\u001b[39m     y = \u001b[38;5;28;01myield\u001b[39;00m m.dist.categorical(probs =  p, obs = career,  shape= \u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcareer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m     17\u001b[39m m.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Main/main.py:168\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, model, obs, potential_fn, kinetic_fn, step_size, inverse_mass_matrix, adapt_step_size, adapt_mass_matrix, dense_mass, target_accept_prob, trajectory_length, max_tree_depth, init_strategy, find_heuristic_step_size, forward_mode_differentiation, regularize_mass_matrix, num_warmup, num_samples, num_chains, thinning, postprocess_fn, chain_method, progress_bar, jit_model_args, seed)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Samplers/mcmc_tfp.py:120\u001b[39m, in \u001b[36mmcmc.run\u001b[39m\u001b[34m(self, model, obs, n_chains, init, bijectors, target_log_prob_fn, num_results, num_burnin_steps, num_steps_between_results, parallel_iterations, seed, name)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtarget_log_prob\u001b[39m(*params):\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_log_prob_fn(params + (obs,))\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28mself\u001b[39m.sampler = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mNUTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mn_chains\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtarget_log_prob_fn\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_log_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m\u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Samplers/mcmc_tfp.py:100\u001b[39m, in \u001b[36mmcmc.NUTS\u001b[39m\u001b[34m(self, model, obs, n_chains, target_log_prob_fn, num_results, num_burnin_steps, num_steps_between_results, parallel_iterations, seed, name)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     99\u001b[39m     rng_keys = jax.random.split(jax.random.PRNGKey(\u001b[32m0\u001b[39m), n_chains)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     result =  \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_chain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.posterior, \u001b[38;5;28mself\u001b[39m.sample_stats = result[\u001b[32m0\u001b[39m], result[\u001b[32m1\u001b[39m]\n",
      "    \u001b[31m[... skipping hidden 28 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Samplers/mcmc_tfp.py:80\u001b[39m, in \u001b[36mmcmc.NUTS.<locals>.run_chain\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m     64\u001b[39m kernel = tensorflow_probability.substrates.jax.mcmc.TransformedTransitionKernel(\n\u001b[32m     65\u001b[39m         inner_kernel=inner_kernel,\n\u001b[32m     66\u001b[39m         bijector=\u001b[38;5;28mself\u001b[39m.bijectors\n\u001b[32m     67\u001b[39m )\n\u001b[32m     69\u001b[39m hmc  = tfp.mcmc.DualAveragingStepSizeAdaptation(\n\u001b[32m     70\u001b[39m     kernel,\n\u001b[32m     71\u001b[39m     target_accept_prob=\u001b[32m.8\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m     log_accept_prob_getter_fn=\u001b[38;5;28;01mlambda\u001b[39;00m pkr: pkr.inner_results.log_accept_ratio,\n\u001b[32m     78\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcmc\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps_between_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhmc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mtrace_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrace_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/mcmc/sample.py:330\u001b[39m, in \u001b[36msample_chain\u001b[39m\u001b[34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[39m\n\u001b[32m    326\u001b[39m current_state = tf.nest.map_structure(\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf.convert_to_tensor(x, name=\u001b[33m'\u001b[39m\u001b[33mcurrent_state\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    328\u001b[39m     current_state)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m previous_kernel_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m   previous_kernel_results = \u001b[43mkernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    333\u001b[39m   \u001b[38;5;66;03m# It simplifies the logic to use a dummy function here.\u001b[39;00m\n\u001b[32m    334\u001b[39m   trace_fn = \u001b[38;5;28;01mlambda\u001b[39;00m *args: ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/mcmc/dual_averaging_step_size_adaptation.py:538\u001b[39m, in \u001b[36mDualAveragingStepSizeAdaptation.bootstrap_results\u001b[39m\u001b[34m(self, init_state)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbootstrap_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, init_state):\n\u001b[32m    535\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m tf.name_scope(\n\u001b[32m    536\u001b[39m       mcmc_util.make_name(\u001b[38;5;28mself\u001b[39m.name, \u001b[33m'\u001b[39m\u001b[33mdual_averaging_step_size_adaptation\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    537\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33mbootstrap_results\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m     inner_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_kernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bootstrap_from_inner_results(init_state, inner_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/mcmc/transformed_kernel.py:492\u001b[39m, in \u001b[36mTransformedTransitionKernel.bootstrap_results\u001b[39m\u001b[34m(self, init_state, transformed_init_state)\u001b[39m\n\u001b[32m    487\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     transformed_init_state = tf.convert_to_tensor(\n\u001b[32m    489\u001b[39m         value=transformed_init_state, name=\u001b[33m'\u001b[39m\u001b[33mtransformed_init_state\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    490\u001b[39m kernel_results = TransformedTransitionKernelResults(\n\u001b[32m    491\u001b[39m     transformed_state=transformed_init_state,\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     inner_results=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_kernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbootstrap_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransformed_init_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m kernel_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/mcmc/nuts.py:498\u001b[39m, in \u001b[36mNoUTurnSampler.bootstrap_results\u001b[39m\u001b[34m(self, init_state)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# Confirm that the step size is compatible with the state parts.\u001b[39;00m\n\u001b[32m    472\u001b[39m _ = _prepare_step_size(\n\u001b[32m    473\u001b[39m     \u001b[38;5;28mself\u001b[39m.step_size, current_target_log_prob.dtype, \u001b[38;5;28mlen\u001b[39m(init_state))\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m NUTSKernelResults(\n\u001b[32m    476\u001b[39m     target_log_prob=current_target_log_prob,\n\u001b[32m    477\u001b[39m     grads_target_log_prob=current_grads_log_prob,\n\u001b[32m    478\u001b[39m     step_size=tf.nest.map_structure(\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tf.convert_to_tensor(  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[32m    480\u001b[39m             x,\n\u001b[32m    481\u001b[39m             dtype=current_target_log_prob.dtype,\n\u001b[32m    482\u001b[39m             name=\u001b[33m'\u001b[39m\u001b[33mstep_size\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    483\u001b[39m         \u001b[38;5;28mself\u001b[39m.step_size),\n\u001b[32m    484\u001b[39m     log_accept_ratio=tf.zeros_like(current_target_log_prob,\n\u001b[32m    485\u001b[39m                                    name=\u001b[33m'\u001b[39m\u001b[33mlog_accept_ratio\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    486\u001b[39m     leapfrogs_taken=tf.zeros_like(current_target_log_prob,\n\u001b[32m    487\u001b[39m                                   dtype=TREE_COUNT_DTYPE,\n\u001b[32m    488\u001b[39m                                   name=\u001b[33m'\u001b[39m\u001b[33mleapfrogs_taken\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    489\u001b[39m     is_accepted=tf.zeros_like(current_target_log_prob,\n\u001b[32m    490\u001b[39m                               dtype=tf.bool,\n\u001b[32m    491\u001b[39m                               name=\u001b[33m'\u001b[39m\u001b[33mis_accepted\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    492\u001b[39m     reach_max_depth=tf.zeros_like(current_target_log_prob,\n\u001b[32m    493\u001b[39m                                   dtype=tf.bool,\n\u001b[32m    494\u001b[39m                                   name=\u001b[33m'\u001b[39m\u001b[33mreach_max_depth\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    495\u001b[39m     has_divergence=tf.zeros_like(current_target_log_prob,\n\u001b[32m    496\u001b[39m                                  dtype=tf.bool,\n\u001b[32m    497\u001b[39m                                  name=\u001b[33m'\u001b[39m\u001b[33mhas_divergence\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m     energy=\u001b[43mcompute_hamiltonian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_target_log_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_axis_names\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperimental_shard_axis_names\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    501\u001b[39m     \u001b[38;5;66;03m# Allow room for one_step's seed.\u001b[39;00m\n\u001b[32m    502\u001b[39m     seed=samplers.zeros_seed(),\n\u001b[32m    503\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/mcmc/nuts.py:1102\u001b[39m, in \u001b[36mcompute_hamiltonian\u001b[39m\u001b[34m(target_log_prob, momentum_parts, shard_axis_names)\u001b[39m\n\u001b[32m   1096\u001b[39m momentum_sq_parts = (\n\u001b[32m   1097\u001b[39m     tf.cast(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[32m   1098\u001b[39m         compute_sum_sq(m, axes),\n\u001b[32m   1099\u001b[39m         dtype=target_log_prob.dtype)\n\u001b[32m   1100\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m m, axes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(momentum_parts, shard_axis_names))\n\u001b[32m   1101\u001b[39m \u001b[38;5;66;03m# TODO(jvdillon): Verify no broadcasting happening.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget_log_prob\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmomentum_sq_parts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:1083\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:583\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    581\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:182\u001b[39m, in \u001b[36mufunc.__call__\u001b[39m\u001b[34m(self, out, where, *args)\u001b[39m\n\u001b[32m    180\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    181\u001b[39m call = \u001b[38;5;28mself\u001b[39m.__static_props[\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_vectorized\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufuncs.py:1568\u001b[39m, in \u001b[36msubtract\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m   1541\u001b[39m \u001b[38;5;129m@binary_ufunc\u001b[39m(identity=\u001b[38;5;28;01mNone\u001b[39;00m, at=_subtract_at)\n\u001b[32m   1542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msubtract\u001b[39m(x: ArrayLike, y: ArrayLike, /) -> Array:\n\u001b[32m   1543\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Subtract two arrays element-wise.\u001b[39;00m\n\u001b[32m   1544\u001b[39m \n\u001b[32m   1545\u001b[39m \u001b[33;03m  JAX implementation of :obj:`numpy.subtract`. This is a universal function,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m \u001b[33;03m    Array([-10,  -9,  -8,  -7], dtype=int32)\u001b[39;00m\n\u001b[32m   1567\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1568\u001b[39m   out = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpromote_args\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msubtract\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1569\u001b[39m   jnp_error._set_error_if_nan(out)\n\u001b[32m   1570\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[31m[... skipping hidden 10 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:136\u001b[39m, in \u001b[36m_try_broadcast_shapes\u001b[39m\u001b[34m(name, *shapes)\u001b[39m\n\u001b[32m    134\u001b[39m       result_shape.append(non_1s[\u001b[32m0\u001b[39m])\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got incompatible shapes for broadcasting: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    137\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[31mTypeError\u001b[39m: sub got incompatible shapes for broadcasting: (500,), (2,)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jax.nn as nn\n",
    "m = bi('cpu',backend='tfp')\n",
    "m.data(data_path + 'Sim data multinomial.csv')\n",
    "def model(career, income ):\n",
    "    a = yield m.dist.normal(0, 1, shape= (2,))\n",
    "    b = yield m.dist.half_normal(0.5,  shape= (1,))\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = [0]\n",
    "    p = nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    y = yield m.dist.categorical(probs =  p, obs = career,  shape= 0)\n",
    "\n",
    "m.fit(model = model, obs = 'career', num_chains = 1) \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p.shape)\n\u001b[32m     11\u001b[39m     y = \u001b[38;5;28;01myield\u001b[39;00m Independent(Categorical(probs =  p))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m posterior, sample_stats = \u001b[43mNUTS\u001b[49m(model, obs = career)\n",
      "\u001b[31mNameError\u001b[39m: name 'NUTS' is not defined"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    a = yield normal(2, 0, 1)\n",
    "    b = yield half_normal(1,0.5)\n",
    "    s_1 = a[0] + b * income[0]\n",
    "    s_2 = a[1] + b * income[1]\n",
    "    s_3 = [0]\n",
    "    p = nn.softmax(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n",
    "    print(p.shape)\n",
    "    p = p[career] \n",
    "    print(p.shape)\n",
    "    y = yield Independent(Categorical(probs =  p))\n",
    "\n",
    "posterior, sample_stats = NUTS(model, obs = career)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_key, key = random.split(random.PRNGKey(int(51651)))\n",
    "init_key = jnp.array(init_key)\n",
    "tensor = JointDistributionCoroutine(model)\n",
    "infos = get_distributions(model)\n",
    "init_params = tensor.sample(seed = init_key)\n",
    "init_params =  list(init_params)[:-1]\n",
    "init_params\n",
    "init_params.append(jnp.array(d.career.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    a = yield normal(2, 0, 1)\n",
    "    b = yield HalfNormal(1, 0.5)\n",
    "    p = softmax_fn(a[career_income] + b[career_income])\n",
    "    print(p.shape)\n",
    "    y = yield tfd.Independent(Multinomial(1, probs = p))\n",
    "    \n",
    "posterior, sample_stats = NUTS(model, obs = jnp.array(d.career.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta binomial (model m12.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi</th>\n",
       "      <td>1.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean    sd  hdi_5.5%  hdi_94.5%\n",
       "alpha[0] -0.46  0.43     -1.20       0.15\n",
       "alpha[1] -0.33  0.44     -1.01       0.35\n",
       "phi       1.04  0.79      0.00       2.08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.nn as nn\n",
    "m = bi(platform='cpu',backend='tfp')\n",
    "m.data(data_path + 'UCBadmit.csv', sep=';') \n",
    "m.df[\"gid\"] = (m.df[\"applicant.gender\"] != \"male\").astype(int)\n",
    "m.df[\"applications\"] = m.df[\"applications\"].astype('float32').values\n",
    "m.df[\"admit\"] = m.df[\"admit\"].astype('float32').values\n",
    "def model(gid, applications, admit):\n",
    "    phi = yield m.dist.exponential(1)\n",
    "    alpha = yield m.dist.normal(0.,1.5, shape=(2,))\n",
    "    theta = phi + 2\n",
    "    pbar = nn.sigmoid(alpha[gid])\n",
    "    concentration1 = pbar*theta\n",
    "    concentration0 = (1 - pbar) * theta\n",
    "    y = yield m.dist.beta_binomial(applications, concentration1 = concentration1, concentration0 = concentration0, shape=1, obs = admit)\n",
    "\n",
    "\n",
    "m.fit(model = model, obs = 'admit') \n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zero inflated outcomes (PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'total_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m     ap = \u001b[38;5;28;01myield\u001b[39;00m m.dist.normal(-\u001b[32m1.5\u001b[39m , \u001b[32m1\u001b[39m)\n\u001b[32m     24\u001b[39m     y = \u001b[38;5;28;01myield\u001b[39;00m m.dist.zero_inflated_negative_binomial(total_count = \u001b[32m365\u001b[39m, inflated_loc_logits = al, logits = jnp.log(ap), shape=\u001b[32m1\u001b[39m, obs = y)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m     28\u001b[39m m.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Main/main.py:169\u001b[39m, in \u001b[36mbi.fit\u001b[39m\u001b[34m(self, model, obs, potential_fn, kinetic_fn, step_size, inverse_mass_matrix, adapt_step_size, adapt_mass_matrix, dense_mass, target_accept_prob, trajectory_length, max_tree_depth, init_strategy, find_heuristic_step_size, forward_mode_differentiation, regularize_mass_matrix, num_warmup, num_samples, num_chains, thinning, postprocess_fn, chain_method, progress_bar, jit_model_args, seed)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28mself\u001b[39m.sampler.data_on_model = \u001b[38;5;28mself\u001b[39m.data_on_model\n\u001b[32m    166\u001b[39m \u001b[38;5;28mself\u001b[39m.sampler.model = \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.diag = diag(sampler = \u001b[38;5;28mself\u001b[39m.sampler)\n\u001b[32m    171\u001b[39m sample_stats_name=[\u001b[33m'\u001b[39m\u001b[33mtarget_log_prob\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlog_accept_ratio\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mhas_divergence\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33menergy\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Samplers/mcmc_tfp.py:111\u001b[39m, in \u001b[36mmcmc.run\u001b[39m\u001b[34m(self, model, obs, n_chains, init, bijectors, target_log_prob_fn, num_results, num_burnin_steps, num_steps_between_results, parallel_iterations, seed, name)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, model,  obs, n_chains = \u001b[32m1\u001b[39m, init = \u001b[38;5;28;01mNone\u001b[39;00m, bijectors = \u001b[38;5;28;01mNone\u001b[39;00m, target_log_prob_fn = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    106\u001b[39m      num_results = \u001b[32m500\u001b[39m, num_burnin_steps=\u001b[32m500\u001b[39m, num_steps_between_results=\u001b[32m0\u001b[39m,\n\u001b[32m    107\u001b[39m      parallel_iterations = \u001b[32m10\u001b[39m, seed=\u001b[32m0\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    109\u001b[39m     obs = \u001b[38;5;28mself\u001b[39m.data_on_model[obs]\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbijectors\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbijectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m target_log_prob_fn == \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtarget_log_prob\u001b[39m(*params):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Samplers/mcmc_tfp.py:32\u001b[39m, in \u001b[36mmcmc.init_Model\u001b[39m\u001b[34m(self, model, init, bijectors, seed)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m.tensor = \u001b[38;5;28mself\u001b[39m.convert_to_tensor(model, \u001b[38;5;28mself\u001b[39m.vars) \n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     init_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m.init_params = \u001b[38;5;28mlist\u001b[39m(init_params)[:-\u001b[32m1\u001b[39m]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1205\u001b[39m, in \u001b[36mDistribution.sample\u001b[39m\u001b[34m(self, sample_shape, seed, name, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[32m   1191\u001b[39m \n\u001b[32m   1192\u001b[39m \u001b[33;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1202\u001b[39m \u001b[33;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[32m   1203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name_and_control_scope(name):\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:956\u001b[39m, in \u001b[36mJointDistribution._call_sample_n\u001b[39m\u001b[34m(self, sample_shape, seed, value, **kwargs)\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape, seed, value=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m      \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mallow_partially_specified\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m                                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/distribution_util.py:1350\u001b[39m, in \u001b[36mAppendDocstring.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1348\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fn\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:693\u001b[39m, in \u001b[36mJointDistribution._sample_n\u001b[39m\u001b[34m(self, sample_shape, seed, value)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;129m@distribution_util\u001b[39m.AppendDocstring(kwargs_dict={\n\u001b[32m    684\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33m`Tensor`s structured like `type(model)` used to parameterize \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    685\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mother dependent (\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdownstream\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m) distribution-making functions. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    691\u001b[39m   \u001b[38;5;66;03m# they're not already cached. This ensures we don't try to pass a stateless\u001b[39;00m\n\u001b[32m    692\u001b[39m   \u001b[38;5;66;03m# seed to a stateful sampler, or vice versa.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_static_distribution_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m   might_have_batch_dims = (\n\u001b[32m    696\u001b[39m       distribution_util.shape_may_be_nontrivial(sample_shape)\n\u001b[32m    697\u001b[39m       \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    698\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m might_have_batch_dims:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:361\u001b[39m, in \u001b[36mJointDistribution._get_static_distribution_attributes\u001b[39m\u001b[34m(self, seed)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    360\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_cached_static_attributes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     flat_list_of_static_attributes = \u001b[43mcallable_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_output_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached_static_attributes = StaticDistributionAttributes(\n\u001b[32m    366\u001b[39m         *\u001b[38;5;28mzip\u001b[39m(*flat_list_of_static_attributes))\n\u001b[32m    368\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cached_static_attributes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/callable_util.py:55\u001b[39m, in \u001b[36mget_output_spec\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE:\n\u001b[32m     54\u001b[39m   \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_as_tensor_spec\u001b[39m(t):\n\u001b[32m     58\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf.TensorSpec):\n",
      "    \u001b[31m[... skipping hidden 15 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:362\u001b[39m, in \u001b[36mJointDistribution._get_static_distribution_attributes.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_static_distribution_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    360\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_cached_static_attributes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    361\u001b[39m     flat_list_of_static_attributes = callable_util.get_output_spec(\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_and_trace_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrace_static_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamplers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached_static_attributes = StaticDistributionAttributes(\n\u001b[32m    366\u001b[39m         *\u001b[38;5;28mzip\u001b[39m(*flat_list_of_static_attributes))\n\u001b[32m    368\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cached_static_attributes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/joint_distribution.py:1047\u001b[39m, in \u001b[36mJointDistribution._execute_model\u001b[39m\u001b[34m(self, sample_shape, seed, value, stop_index, sample_and_trace_fn)\u001b[39m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stop_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m index == stop_index:\n\u001b[32m   1046\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m     d = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1049\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mmodel\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m     22\u001b[39m al = \u001b[38;5;28;01myield\u001b[39;00m m.dist.normal(\u001b[32m1\u001b[39m, \u001b[32m0.5\u001b[39m)\n\u001b[32m     23\u001b[39m ap = \u001b[38;5;28;01myield\u001b[39;00m m.dist.normal(-\u001b[32m1.5\u001b[39m , \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m y = \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_inflated_negative_binomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m365\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflated_loc_logits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/BI/Utils/tfp_dists.py:4213\u001b[39m, in \u001b[36mUnifiedDist.zero_inflated_negative_binomial\u001b[39m\u001b[34m(inflated_loc_logits, inflated_loc_probs, name, shape, sample, seed, obs, **kwargs)\u001b[39m\n\u001b[32m   4193\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m   4194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mzero_inflated_negative_binomial\u001b[39m(inflated_loc_logits=\u001b[38;5;28;01mNone\u001b[39;00m, inflated_loc_probs=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m'\u001b[39m\u001b[33mZeroInflatedNegativeBinomial\u001b[39m\u001b[33m'\u001b[39m, shape=(), sample=\u001b[38;5;28;01mFalse\u001b[39;00m, seed=\u001b[32m0\u001b[39m, obs=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   4195\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4196\u001b[39m \u001b[33;03m    Wrapper for the tfd.ZeroInflatedNegativeBinomial distribution.\u001b[39;00m\n\u001b[32m   4197\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4211\u001b[39m \u001b[33;03m            seed (int): The PRNG seed for sampling. Defaults to 0.\u001b[39;00m\n\u001b[32m   4212\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4213\u001b[39m     dist = \u001b[43mtfd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZeroInflatedNegativeBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43minflated_loc_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43minflated_loc_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflated_loc_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minflated_loc_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample:\n\u001b[32m   4215\u001b[39m         prng_key = jax.random.PRNGKey(seed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342\u001b[39m, in \u001b[36m_DistributionMeta.__new__.<locals>.wrapped_init\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# Note: if we ever want to have things set in `self` before `__init__` is\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# called, here is the place to do it.\u001b[39;00m\n\u001b[32m    341\u001b[39m self_._parameters = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;66;03m# Note: if we ever want to override things set in `self` by subclass\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# `__init__`, here is the place to do it.\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m self_._parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    346\u001b[39m   \u001b[38;5;66;03m# We prefer subclasses will set `parameters = dict(locals())` because\u001b[39;00m\n\u001b[32m    347\u001b[39m   \u001b[38;5;66;03m# this has nearly zero overhead. However, failing to do this, we will\u001b[39;00m\n\u001b[32m    348\u001b[39m   \u001b[38;5;66;03m# resolve the input arguments dynamically and only when needed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/inflated.py:290\u001b[39m, in \u001b[36minflated_factory.<locals>.my_init\u001b[39m\u001b[34m(self, inflated_loc_logits, inflated_loc_probs, name, **kwargs)\u001b[39m\n\u001b[32m    288\u001b[39m   dist = kwargs[\u001b[33m'\u001b[39m\u001b[33mdistribution\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m   dist = \u001b[43mdistribution_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmore_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m Inflated.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dist, inflated_loc_logits, inflated_loc_probs,\n\u001b[32m    292\u001b[39m                   inflated_loc, name=name)\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/decorator.py:234\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfun\u001b[39m(*args, **kw):\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         args, kw = \u001b[43mfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, *(extras + args), **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/decorator.py:204\u001b[39m, in \u001b[36mfix\u001b[39m\u001b[34m(args, kwargs, sig)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfix\u001b[39m(args, kwargs, sig):\n\u001b[32m    201\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m    Fix args and kwargs to be consistent with the signature\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     ba = \u001b[43msig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     ba.apply_defaults()  \u001b[38;5;66;03m# needed for test_dan_schult\u001b[39;00m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ba.args, ba.kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/inspect.py:3242\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3239\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3240\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3241\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/inspect.py:3157\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3155\u001b[39m                 msg = \u001b[33m'\u001b[39m\u001b[33mmissing a required\u001b[39m\u001b[38;5;132;01m{argtype}\u001b[39;00m\u001b[33m argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   3156\u001b[39m                 msg = msg.format(arg=param.name, argtype=argtype)\n\u001b[32m-> \u001b[39m\u001b[32m3157\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3159\u001b[39m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[32m   3160\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: missing a required argument: 'total_count'"
     ]
    }
   ],
   "source": [
    "\n",
    "r.seed(42)\n",
    "# Define parameters\n",
    "prob_drink = 0.2  # 20% of days\n",
    "rate_work = 1     # average 1 manuscript per day\n",
    "\n",
    "# sample one year of production\n",
    "N = 365\n",
    "\n",
    "np.random.seed(365)\n",
    "drink = np.random.binomial(1, prob_drink, N)\n",
    "y = (1 - drink) * np.random.poisson(rate_work, N)\n",
    "\n",
    "# setup platform------------------------------------------------\n",
    "m = bi(backend='tfp')\n",
    "# import data ------------------------------------------------\n",
    "\n",
    "m.data_on_model = dict(\n",
    "    y = jnp.array(y)\n",
    ")\n",
    "\n",
    "def model(y):\n",
    "    al = yield m.dist.normal(1, 0.5)\n",
    "    ap = yield m.dist.normal(-1.5 , 1)\n",
    "    y = yield m.dist.zero_inflated_negative_binomial(total_count = 365, inflated_loc_logits = al, logits = jnp.log(ap), shape=1, obs = y)\n",
    "\n",
    "m.fit(model = model, obs = 'y') \n",
    "m.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Varying interceps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_bar</th>\n",
       "      <td>1.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>2.13</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>3.05</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>3.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.39</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>2.10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>2.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>3.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.39</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>2.19</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>2.16</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>1.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>2.14</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>2.15</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>2.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>2.43</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>2.03</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>3.70</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[20]</th>\n",
       "      <td>2.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[21]</th>\n",
       "      <td>2.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[22]</th>\n",
       "      <td>2.37</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[23]</th>\n",
       "      <td>1.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[24]</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[25]</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[26]</th>\n",
       "      <td>-1.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[27]</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[28]</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[29]</th>\n",
       "      <td>1.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[30]</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[31]</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[32]</th>\n",
       "      <td>3.23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[33]</th>\n",
       "      <td>2.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.72</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[34]</th>\n",
       "      <td>2.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[35]</th>\n",
       "      <td>2.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[36]</th>\n",
       "      <td>2.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[37]</th>\n",
       "      <td>3.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.61</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[38]</th>\n",
       "      <td>2.74</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[39]</th>\n",
       "      <td>2.33</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.47</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[40]</th>\n",
       "      <td>-1.81</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[41]</th>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[42]</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[43]</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[44]</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[45]</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[46]</th>\n",
       "      <td>2.08</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[47]</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>1.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean    sd  hdi_5.5%  hdi_94.5%\n",
       "a_bar      1.35  0.25      0.99       1.80\n",
       "alpha[0]   2.13  0.83      0.73       3.25\n",
       "alpha[1]   3.05  1.07      1.34       4.71\n",
       "alpha[2]   0.98  0.65     -0.09       1.90\n",
       "alpha[3]   3.05  1.05      1.39       4.65\n",
       "alpha[4]   2.10  0.84      0.85       3.38\n",
       "alpha[5]   2.10  0.94      0.63       3.47\n",
       "alpha[6]   3.06  1.06      1.39       4.77\n",
       "alpha[7]   2.19  0.86      0.89       3.56\n",
       "alpha[8]  -0.19  0.57     -1.07       0.77\n",
       "alpha[9]   2.16  0.90      0.86       3.69\n",
       "alpha[10]  1.03  0.70      0.03       2.29\n",
       "alpha[11]  0.58  0.65     -0.35       1.70\n",
       "alpha[12]  0.98  0.60      0.03       1.87\n",
       "alpha[13]  0.22  0.62     -0.61       1.34\n",
       "alpha[14]  2.14  0.85      0.94       3.59\n",
       "alpha[15]  2.15  0.82      0.88       3.37\n",
       "alpha[16]  2.85  0.76      1.60       4.03\n",
       "alpha[17]  2.43  0.68      1.35       3.47\n",
       "alpha[18]  2.03  0.53      1.17       2.78\n",
       "alpha[19]  3.70  1.07      2.07       5.33\n",
       "alpha[20]  2.35  0.60      1.46       3.28\n",
       "alpha[21]  2.40  0.69      1.30       3.49\n",
       "alpha[22]  2.37  0.67      1.34       3.40\n",
       "alpha[23]  1.72  0.51      0.84       2.39\n",
       "alpha[24] -1.00  0.44     -1.68      -0.27\n",
       "alpha[25]  0.13  0.38     -0.43       0.72\n",
       "alpha[26] -1.43  0.49     -2.17      -0.64\n",
       "alpha[27] -0.50  0.39     -1.08       0.15\n",
       "alpha[28]  0.16  0.37     -0.43       0.72\n",
       "alpha[29]  1.43  0.47      0.55       2.03\n",
       "alpha[30] -0.62  0.41     -1.21       0.10\n",
       "alpha[31] -0.33  0.41     -1.00       0.30\n",
       "alpha[32]  3.23  0.76      1.95       4.21\n",
       "alpha[33]  2.68  0.66      1.72       3.68\n",
       "alpha[34]  2.71  0.65      1.60       3.60\n",
       "alpha[35]  2.06  0.53      1.24       2.84\n",
       "alpha[36]  2.08  0.50      1.27       2.78\n",
       "alpha[37]  3.83  0.91      2.61       5.23\n",
       "alpha[38]  2.74  0.67      1.67       3.75\n",
       "alpha[39]  2.33  0.57      1.47       3.23\n",
       "alpha[40] -1.81  0.51     -2.53      -0.91\n",
       "alpha[41] -0.57  0.34     -1.11      -0.03\n",
       "alpha[42] -0.45  0.33     -0.94       0.03\n",
       "alpha[43] -0.33  0.33     -0.84       0.18\n",
       "alpha[44]  0.57  0.34      0.03       1.12\n",
       "alpha[45] -0.56  0.33     -1.05      -0.00\n",
       "alpha[46]  2.08  0.53      1.29       2.88\n",
       "alpha[47] -0.02  0.31     -0.49       0.46\n",
       "sigma      1.61  0.21      1.23       1.88"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup platform------------------------------------------------\n",
    "m = bi(backend='tfp')\n",
    "# import data ------------------------------------------------\n",
    "m.data(data_path + 'reedfrogs.csv', sep=';') \n",
    "m.df[\"tank\"] = np.arange(m.df.shape[0])\n",
    "m.df[\"density\"] = m.df[\"density\"].astype('float32').values\n",
    "\n",
    "def model(tank, surv, density):\n",
    "    sigma = yield m.dist.exponential(1)\n",
    "    a_bar = yield m.dist.normal(0, 1.5)\n",
    "    alpha = yield m.dist.normal( a_bar, sigma, shape = 48)\n",
    "    p = alpha[tank]\n",
    "    y = yield m.dist.binomial(total_count = density, logits = p, shape=1, obs = surv)\n",
    "\n",
    "m.fit(model = model, obs = 'surv') \n",
    "m.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Varying effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "@jit\n",
    "def random_centered(sigma, cor_mat, offset_mat):\n",
    "    \"\"\"Generate the centered matrix of random factors \n",
    "\n",
    "    Args:\n",
    "        sigma (vector): Prior, vector of length N\n",
    "        cor_mat (2D array): correlation matrix, cholesky_factor_corr of dim N, N\n",
    "        offset_mat (2D array): matrix of offsets, matrix of dim N*k\n",
    "\n",
    "    Returns:\n",
    "        _type_: 2D array\n",
    "    \"\"\"\n",
    "    return jnp.dot(diag_pre_multiply(sigma, cor_mat), offset_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:292: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  minval = minval + np.zeros([1] * final_rank, dtype=dtype)\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tensorflow_probability/python/internal/backend/jax/random_generators.py:293: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'>  is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return jaxrand.randint(key=seed, shape=shape, minval=minval, maxval=maxval,\n",
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/arviz/data/base.py:272: UserWarning: More chains (500) than draws (1). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rho[0, 0]</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[0, 1]</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 0]</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rho[1, 1]</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3.55</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 0]</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[0, 1]</th>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 0]</th>\n",
       "      <td>1.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[1, 1]</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 0]</th>\n",
       "      <td>2.84</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[2, 1]</th>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 0]</th>\n",
       "      <td>4.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[3, 1]</th>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 0]</th>\n",
       "      <td>3.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[4, 1]</th>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 0]</th>\n",
       "      <td>3.82</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.52</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[5, 1]</th>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 0]</th>\n",
       "      <td>4.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[6, 1]</th>\n",
       "      <td>-1.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.93</td>\n",
       "      <td>-1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 0]</th>\n",
       "      <td>3.53</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[7, 1]</th>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 0]</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[8, 1]</th>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 0]</th>\n",
       "      <td>3.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[9, 1]</th>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 0]</th>\n",
       "      <td>4.68</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[10, 1]</th>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 0]</th>\n",
       "      <td>4.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[11, 1]</th>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 0]</th>\n",
       "      <td>3.73</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[12, 1]</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 0]</th>\n",
       "      <td>3.51</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[13, 1]</th>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 0]</th>\n",
       "      <td>4.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[14, 1]</th>\n",
       "      <td>-1.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 0]</th>\n",
       "      <td>5.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[15, 1]</th>\n",
       "      <td>-1.55</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 0]</th>\n",
       "      <td>1.69</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[16, 1]</th>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 0]</th>\n",
       "      <td>4.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[17, 1]</th>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 0]</th>\n",
       "      <td>3.82</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[18, 1]</th>\n",
       "      <td>-1.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 0]</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_cafe_b_cafe[19, 1]</th>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[0]</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_cafe[1]</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean    sd  hdi_5.5%  hdi_94.5%\n",
       "Rho[0, 0]             1.00  0.00      1.00       1.00\n",
       "Rho[0, 1]             0.00  0.00      0.00       0.00\n",
       "Rho[1, 0]            -0.37  0.09     -0.50      -0.22\n",
       "Rho[1, 1]             0.93  0.04      0.87       0.98\n",
       "a                     3.55  0.23      3.13       3.87\n",
       "a_cafe_b_cafe[0, 0]   3.00  0.21      2.64       3.29\n",
       "a_cafe_b_cafe[0, 1]  -0.64  0.24     -0.99      -0.24\n",
       "a_cafe_b_cafe[1, 0]   1.99  0.21      1.65       2.34\n",
       "a_cafe_b_cafe[1, 1]  -0.15  0.26     -0.53       0.25\n",
       "a_cafe_b_cafe[2, 0]   2.84  0.21      2.51       3.14\n",
       "a_cafe_b_cafe[2, 1]  -0.65  0.24     -1.04      -0.26\n",
       "a_cafe_b_cafe[3, 0]   4.46  0.21      4.16       4.84\n",
       "a_cafe_b_cafe[3, 1]  -1.37  0.23     -1.74      -0.98\n",
       "a_cafe_b_cafe[4, 0]   3.34  0.22      3.00       3.69\n",
       "a_cafe_b_cafe[4, 1]  -1.08  0.26     -1.43      -0.63\n",
       "a_cafe_b_cafe[5, 0]   3.82  0.21      3.52       4.17\n",
       "a_cafe_b_cafe[5, 1]  -0.91  0.25     -1.26      -0.50\n",
       "a_cafe_b_cafe[6, 0]   4.50  0.21      4.16       4.81\n",
       "a_cafe_b_cafe[6, 1]  -1.54  0.26     -1.93      -1.10\n",
       "a_cafe_b_cafe[7, 0]   3.53  0.21      3.18       3.85\n",
       "a_cafe_b_cafe[7, 1]  -1.05  0.23     -1.45      -0.72\n",
       "a_cafe_b_cafe[8, 0]   3.70  0.20      3.38       4.01\n",
       "a_cafe_b_cafe[8, 1]  -1.15  0.24     -1.56      -0.82\n",
       "a_cafe_b_cafe[9, 0]   3.04  0.21      2.68       3.34\n",
       "a_cafe_b_cafe[9, 1]  -1.01  0.26     -1.44      -0.63\n",
       "a_cafe_b_cafe[10, 0]  4.68  0.19      4.36       4.95\n",
       "a_cafe_b_cafe[10, 1] -1.16  0.25     -1.52      -0.74\n",
       "a_cafe_b_cafe[11, 0]  4.07  0.22      3.67       4.35\n",
       "a_cafe_b_cafe[11, 1] -0.93  0.27     -1.34      -0.53\n",
       "a_cafe_b_cafe[12, 0]  3.73  0.23      3.37       4.07\n",
       "a_cafe_b_cafe[12, 1] -0.56  0.32     -1.15      -0.12\n",
       "a_cafe_b_cafe[13, 0]  3.51  0.23      3.13       3.86\n",
       "a_cafe_b_cafe[13, 1] -1.05  0.25     -1.46      -0.67\n",
       "a_cafe_b_cafe[14, 0]  4.09  0.21      3.78       4.42\n",
       "a_cafe_b_cafe[14, 1] -1.38  0.24     -1.77      -1.01\n",
       "a_cafe_b_cafe[15, 0]  5.04  0.21      4.75       5.41\n",
       "a_cafe_b_cafe[15, 1] -1.55  0.26     -1.99      -1.19\n",
       "a_cafe_b_cafe[16, 0]  1.69  0.21      1.39       2.05\n",
       "a_cafe_b_cafe[16, 1] -0.27  0.25     -0.63       0.14\n",
       "a_cafe_b_cafe[17, 0]  4.38  0.20      4.07       4.69\n",
       "a_cafe_b_cafe[17, 1] -1.10  0.25     -1.53      -0.75\n",
       "a_cafe_b_cafe[18, 0]  3.82  0.21      3.49       4.17\n",
       "a_cafe_b_cafe[18, 1] -1.19  0.24     -1.56      -0.83\n",
       "a_cafe_b_cafe[19, 0]  1.26  0.20      0.98       1.62\n",
       "a_cafe_b_cafe[19, 1] -0.31  0.27     -0.76       0.07\n",
       "b                    -0.96  0.13     -1.15      -0.75\n",
       "sigma                 0.51  0.03      0.47       0.56\n",
       "sigma_cafe[0]         1.06  0.19      0.77       1.33\n",
       "sigma_cafe[1]         0.33  0.11      0.14       0.47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data ------------------------------------------------\n",
    "m = bi(backend='tfp')\n",
    "m.data(data_path + 'Sim data multivariatenormal.csv', sep = ',')\n",
    "m.data_on_model = dict(\n",
    "    cafe = jnp.array(m.df.cafe.values, dtype=jnp.int32),\n",
    "    wait = jnp.array(m.df.wait.values, dtype=jnp.float32),\n",
    "    N_cafes = len(m.df.cafe.unique()),\n",
    "    afternoon = jnp.array(m.df.afternoon.values, dtype=jnp.float32)\n",
    ")\n",
    "\n",
    "def model(cafe, wait, N_cafes, afternoon):    \n",
    "    sigma = yield m.dist.exponential(1)\n",
    "    a = yield m.dist.normal(5, 2)\n",
    "    b = yield m.dist.normal(-1, 0.5)\n",
    "    sigma_cafe = yield m.dist.exponential(1, shape = (2,))    \n",
    "    Rho = yield m.dist.lkj(2, 2)\n",
    "\n",
    "    a_cafe_b_cafe = yield m.dist.multivariate_normal_tri_l(shape =(N_cafes,), loc = jnp.stack([a, b]), scale_tril =  Rho * sigma_cafe)\n",
    "    mu = a_cafe_b_cafe[:, 0][cafe] + a_cafe_b_cafe[:, 1][cafe] * afternoon\n",
    "    y = yield m.dist.normal(mu, sigma, shape=1, obs = wait)\n",
    "\n",
    "m.fit(model = model, obs = 'wait') \n",
    "m.summary() # Contrary to numpyro it doesn't print the correlation matrix directly but the Cholesky factor. It is a lower-triangular matrix L such that when you multiply it by its own transpose (L @ L.T), you get the full, symmetrical correlation matrix R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Rho samples: (1, 500, 2, 2)\n",
      "Posterior Mean of the variable NAMED 'Rho':\n",
      " [[ 525.07513   66.57501]\n",
      " [-676.4057   815.9268 ]]\n"
     ]
    }
   ],
   "source": [
    "rho_samples =m.diag.trace.posterior[\"Rho\"]\n",
    "print(\"Shape of Rho samples:\", rho_samples.shape)\n",
    "mean_rho = rho_samples.mean(dim=[\"chain\", \"draw\"])\n",
    "print(\"Posterior Mean of the variable NAMED 'Rho':\\n\", mean_rho.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
