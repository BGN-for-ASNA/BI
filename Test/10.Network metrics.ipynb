{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf68e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from BI import bi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import networkx as nx\n",
    "m = bi(platform='cpu')\n",
    "data_path = os.path.dirname(os.path.abspath(\"\")) + \"/BI/resources/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac37f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32 18 20 12  6  8  8  8 10  4  6  2  4 10  4  4  4  4  4  6  4  4  4 10\n",
      "  6  6  4  8  6  8  8 12 24 34]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DegreeView({0: 16, 1: 9, 2: 10, 3: 6, 4: 3, 5: 4, 6: 4, 7: 4, 8: 5, 9: 2, 10: 3, 11: 1, 12: 2, 13: 5, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 3, 20: 2, 21: 2, 22: 2, 23: 5, 24: 3, 25: 3, 26: 2, 27: 4, 28: 3, 29: 4, 30: 4, 31: 6, 32: 12, 33: 17})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.karate_club_graph()\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# Get the adjacency matrix for JAX\n",
    "adj_matrix_np = nx.to_numpy_array(G)\n",
    "adj_matrix_jax = jnp.array(adj_matrix_np)\n",
    "\n",
    "print(m.net.degree(adj_matrix_jax))\n",
    "nx.degree(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d506314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running JAX implementation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/.venv/lib/python3.12/site-packages/jax/_src/ops/scatter.py:108: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scan body function carry input and carry output must have equal types, but they differ:\n\nThe input carry component loop_carry[1][1] has type float32[34] but the corresponding output carry component has type float64[34], so the dtypes do not match.\n\nRevise the function so that all output types match the corresponding input types.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Run the JAX implementation. The first run will be slow due to compilation.\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning JAX implementation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m bc_jax = \u001b[43mbetweenness_centrality_jax\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Run the NetworkX implementation for comparison\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning NetworkX implementation...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mbetweenness_centrality_jax\u001b[39m\u001b[34m(adj_matrix, normalized)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp.zeros(n_nodes)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# vmap the kernel over all possible source nodes for massive parallelism\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m all_dependencies = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_sssp_brandes_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Sum the results from each source node\u001b[39;00m\n\u001b[32m    100\u001b[39m betweenness = jnp.sum(all_dependencies, axis=\u001b[32m0\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 21 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36m_sssp_brandes_source\u001b[39m\u001b[34m(source_node, adj_matrix)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dist, sigma, S, num_next\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Run the BFS loop. It will stop producing new nodes after the graph diameter is reached.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m dist, sigma, S, _ = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfori_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbfs_body_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_bfs_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m num_levels = jnp.max(dist) + \u001b[32m1\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- Phase 2: Accumulation of dependencies ---\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 4 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/.venv/lib/python3.12/site-packages/jax/_src/lax/control_flow/loops.py:535\u001b[39m, in \u001b[36m_check_carry_type\u001b[39m\u001b[34m(name, body_fun, in_carry, out_carry_tree, out_avals)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pvary_msg:\n\u001b[32m    532\u001b[39m   pvary_msg += (\u001b[33m\"\u001b[39m\u001b[33mSee https://docs.jax.dev/en/latest/notebooks/shard_map.html#scan-vma \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    533\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfor more information.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    536\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m function carry input and carry output must have equal types, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbut they differ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdifferences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpvary_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRevise the function so that all output types match the corresponding \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput types.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: scan body function carry input and carry output must have equal types, but they differ:\n\nThe input carry component loop_carry[1][1] has type float32[34] but the corresponding output carry component has type float64[34], so the dtypes do not match.\n\nRevise the function so that all output types match the corresponding input types."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "@jit\n",
    "def _sssp_brandes_source(source_node, adj_matrix):\n",
    "    \"\"\"\n",
    "    Computes dependency accumulation for a single source node using Brandes' algorithm.\n",
    "    This version is fully JIT-compatible for unweighted graphs.\n",
    "    \"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    \n",
    "    # --- Phase 1: BFS using a JAX-native loop ---\n",
    "    # S stores the nodes at each distance level. Pre-allocated to max size.\n",
    "    S = jnp.full((n_nodes, n_nodes), -1, dtype=jnp.int32)\n",
    "    dist = jnp.full(n_nodes, -1, dtype=jnp.int32)\n",
    "    sigma = jnp.zeros(n_nodes, dtype=jnp.float32)\n",
    "    \n",
    "    dist = dist.at[source_node].set(0)\n",
    "    sigma = sigma.at[source_node].set(1.0)\n",
    "    S = S.at[0, 0].set(source_node)\n",
    "    \n",
    "    # Loop state: (dist, sigma, S, number_of_nodes_at_current_level)\n",
    "    initial_bfs_state = (dist, sigma, S, 1)\n",
    "\n",
    "    def bfs_body_fn(d, state):\n",
    "        dist, sigma, S, _ = state\n",
    "        nodes_at_d = S[d, :]\n",
    "        \n",
    "        # Get all neighbors of all nodes at the current level in a vectorized way\n",
    "        # This creates a boolean matrix: [num_nodes_at_d, n_nodes]\n",
    "        neighbor_matrix = adj_matrix[nodes_at_d, :]\n",
    "        \n",
    "        # Summing columns gives the number of shortest paths from the previous level\n",
    "        new_sigma = jnp.sum(neighbor_matrix * sigma[nodes_at_d, None], axis=0)\n",
    "\n",
    "        # A node w has been reached for the first time if dist is -1 and it's a neighbor\n",
    "        newly_reached = (dist == -1) & (jnp.sum(neighbor_matrix, axis=0) > 0)\n",
    "        \n",
    "        # Update distance and sigma for newly reached nodes\n",
    "        dist = jnp.where(newly_reached, d + 1, dist)\n",
    "        sigma = jnp.where(newly_reached, new_sigma, sigma)\n",
    "\n",
    "        # Update sigma for nodes that were already on a shortest path\n",
    "        already_reached = (dist == d + 1)\n",
    "        sigma = jnp.where(already_reached, sigma + new_sigma, sigma)\n",
    "        \n",
    "        # Populate the next level of S\n",
    "        next_nodes = jnp.where(dist == d + 1, jnp.arange(n_nodes), -1)\n",
    "        # Use roll and slice to handle storing a variable number of nodes\n",
    "        num_next = jnp.sum(dist == d + 1)\n",
    "        S = S.at[d + 1].set(jnp.roll(jnp.sort(next_nodes), n_nodes - num_next))\n",
    "        \n",
    "        return dist, sigma, S, num_next\n",
    "\n",
    "    # Run the BFS loop. It will stop producing new nodes after the graph diameter is reached.\n",
    "    dist, sigma, S, _ = jax.lax.fori_loop(0, n_nodes - 1, bfs_body_fn, initial_bfs_state)\n",
    "    num_levels = jnp.max(dist) + 1\n",
    "\n",
    "    # --- Phase 2: Accumulation of dependencies ---\n",
    "    dependency = jnp.zeros(n_nodes, dtype=jnp.float32)\n",
    "\n",
    "    def accum_body_fn(i, dependency):\n",
    "        d = num_levels - 1 - i\n",
    "        # Get successors of nodes at level d-1\n",
    "        nodes_at_prev_level = jnp.where(dist == d - 1, jnp.arange(n_nodes), -1)\n",
    "        successors_matrix = adj_matrix[nodes_at_prev_level, :]\n",
    "        \n",
    "        # Calculate the credit to flow back from nodes at level d\n",
    "        # credit = (sigma_predecessor / sigma_successor) * (1 + dependency_successor)\n",
    "        with jnp.errstate(divide='ignore', invalid='ignore'): # Handle division by zero\n",
    "            ratio = (1 + dependency) / sigma\n",
    "        \n",
    "        # Propagate credit backwards to predecessors\n",
    "        credit = jnp.sum(successors_matrix * ratio[None, :], axis=1)\n",
    "        \n",
    "        # Add this credit to the dependency of the predecessors\n",
    "        dependency = dependency.at[nodes_at_prev_level].add(sigma[nodes_at_prev_level] * credit)\n",
    "        return dependency\n",
    "\n",
    "    dependency = jax.lax.fori_loop(0, num_levels, accum_body_fn, dependency)\n",
    "                        \n",
    "    return dependency\n",
    "\n",
    "\n",
    "def betweenness_centrality_jax(adj_matrix, normalized=True):\n",
    "    \"\"\"\n",
    "    Compute betweenness centrality for an unweighted graph using a fully JIT-able approach.\n",
    "    \"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    if n_nodes <= 2:\n",
    "        return jnp.zeros(n_nodes)\n",
    "    \n",
    "    # vmap the kernel over all possible source nodes for massive parallelism\n",
    "    all_dependencies = jax.vmap(_sssp_brandes_source, in_axes=(0, None))(jnp.arange(n_nodes), adj_matrix)\n",
    "    \n",
    "    # Sum the results from each source node\n",
    "    betweenness = jnp.sum(all_dependencies, axis=0)\n",
    "        \n",
    "    if normalized:\n",
    "        # Brandes algorithm on undirected graphs counts each path twice, so we divide by 2.\n",
    "        # This aligns the result with networkx's definition.\n",
    "        scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "        betweenness = betweenness * scale\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "# --- Example Usage and Verification ---\n",
    "# Create a sample graph\n",
    "G = nx.karate_club_graph()\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# Get the binary adjacency matrix for JAX\n",
    "adj_matrix_np = (nx.to_numpy_array(G) > 0).astype(float)\n",
    "adj_matrix_jax = jnp.array(adj_matrix_np)\n",
    "\n",
    "# Run the JAX implementation. The first run will be slow due to compilation.\n",
    "print(\"Running JAX implementation...\")\n",
    "bc_jax = betweenness_centrality_jax(adj_matrix_jax, normalized=True)\n",
    "\n",
    "# Run the NetworkX implementation for comparison\n",
    "print(\"Running NetworkX implementation...\")\n",
    "bc_nx = nx.betweenness_centrality(G, normalized=True)\n",
    "bc_nx_array = jnp.array([bc_nx[i] for i in range(N)])\n",
    "\n",
    "# Compare the results\n",
    "print(\"\\nJAX results (first 5):\", np.round(np.array(bc_jax[:5]), 4))\n",
    "print(\"NX results (first 5): \", np.round(np.array(bc_nx_array[:5]), 4))\n",
    "print(\"\\nAre they close?\", np.allclose(bc_jax, bc_nx_array, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47aa528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running JAX implementation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/.venv/lib/python3.12/site-packages/jax/_src/ops/scatter.py:108: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'jax.numpy' has no attribute 'errstate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     99\u001b[39m adj_matrix_jax = jnp.array(adj_matrix_np)\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning JAX implementation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m bc_jax = \u001b[43mbetweenness_centrality_jax\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning NetworkX implementation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    105\u001b[39m bc_nx = nx.betweenness_centrality(G, normalized=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mbetweenness_centrality_jax\u001b[39m\u001b[34m(adj_matrix, normalized)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Ensure matrix has the correct dtype\u001b[39;00m\n\u001b[32m     82\u001b[39m adj_matrix = adj_matrix.astype(DTYPE)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m all_dependencies = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_sssp_brandes_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m betweenness = jnp.sum(all_dependencies, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalized:\n",
      "    \u001b[31m[... skipping hidden 21 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36m_sssp_brandes_source\u001b[39m\u001b[34m(source_node, adj_matrix)\u001b[39m\n\u001b[32m     66\u001b[39m     dependency = dependency.at[nodes_at_prev_level].add(sigma[nodes_at_prev_level] * credit)\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dependency\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m dependency = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfori_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum_body_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dependency\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36m_sssp_brandes_source.<locals>.accum_body_fn\u001b[39m\u001b[34m(i, dependency)\u001b[39m\n\u001b[32m     59\u001b[39m nodes_at_prev_level = jnp.where(dist == d - \u001b[32m1\u001b[39m, jnp.arange(n_nodes), -\u001b[32m1\u001b[39m)\n\u001b[32m     60\u001b[39m successors_matrix = adj_matrix[nodes_at_prev_level, :]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrstate\u001b[49m(divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, invalid=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     63\u001b[39m     ratio = (\u001b[32m1\u001b[39m + dependency) / sigma\n\u001b[32m     65\u001b[39m credit = jnp.sum(successors_matrix * ratio[\u001b[38;5;28;01mNone\u001b[39;00m, :], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'jax.numpy' has no attribute 'errstate'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# Use a consistent float type for all calculations\n",
    "DTYPE = jnp.float64\n",
    "\n",
    "@jit\n",
    "def _sssp_brandes_source(source_node, adj_matrix):\n",
    "    \"\"\"\n",
    "    Computes dependency accumulation for a single source node using Brandes' algorithm.\n",
    "    This version is fully JIT-compatible for unweighted graphs.\n",
    "    \"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    \n",
    "    # --- Phase 1: BFS using a JAX-native loop ---\n",
    "    S = jnp.full((n_nodes, n_nodes), -1, dtype=jnp.int32)\n",
    "    dist = jnp.full(n_nodes, -1, dtype=jnp.int32)\n",
    "    # --- FIX: Initialize sigma with the consistent dtype ---\n",
    "    sigma = jnp.zeros(n_nodes, dtype=DTYPE)\n",
    "    \n",
    "    dist = dist.at[source_node].set(0)\n",
    "    sigma = sigma.at[source_node].set(1.0)\n",
    "    S = S.at[0, 0].set(source_node)\n",
    "    \n",
    "    initial_bfs_state = (dist, sigma, S, 1)\n",
    "\n",
    "    def bfs_body_fn(d, state):\n",
    "        dist, sigma, S, _ = state\n",
    "        nodes_at_d = S[d, :]\n",
    "        \n",
    "        neighbor_matrix = adj_matrix[nodes_at_d, :]\n",
    "        new_sigma = jnp.sum(neighbor_matrix * sigma[nodes_at_d, None], axis=0)\n",
    "        newly_reached = (dist == -1) & (jnp.sum(neighbor_matrix, axis=0) > 0)\n",
    "        \n",
    "        dist = jnp.where(newly_reached, d + 1, dist)\n",
    "        sigma = jnp.where(newly_reached, new_sigma, sigma)\n",
    "\n",
    "        already_reached = (dist == d + 1)\n",
    "        sigma = jnp.where(already_reached, sigma + new_sigma, sigma)\n",
    "        \n",
    "        next_nodes = jnp.where(dist == d + 1, jnp.arange(n_nodes), -1)\n",
    "        num_next = jnp.sum(dist == d + 1)\n",
    "        S = S.at[d + 1].set(jnp.roll(jnp.sort(next_nodes), n_nodes - num_next))\n",
    "        \n",
    "        return dist, sigma, S, num_next\n",
    "\n",
    "    dist, sigma, S, _ = jax.lax.fori_loop(0, n_nodes - 1, bfs_body_fn, initial_bfs_state)\n",
    "    num_levels = jnp.max(dist) + 1\n",
    "\n",
    "    # --- Phase 2: Accumulation of dependencies ---\n",
    "    # --- FIX: Initialize dependency with the consistent dtype ---\n",
    "    dependency = jnp.zeros(n_nodes, dtype=DTYPE)\n",
    "\n",
    "    def accum_body_fn(i, dependency):\n",
    "        d = num_levels - 1 - i\n",
    "        nodes_at_prev_level = jnp.where(dist == d - 1, jnp.arange(n_nodes), -1)\n",
    "        successors_matrix = adj_matrix[nodes_at_prev_level, :]\n",
    "        \n",
    "        with jnp.errstate(divide='ignore', invalid='ignore'):\n",
    "            ratio = (1 + dependency) / sigma\n",
    "        \n",
    "        credit = jnp.sum(successors_matrix * ratio[None, :], axis=1)\n",
    "        dependency = dependency.at[nodes_at_prev_level].add(sigma[nodes_at_prev_level] * credit)\n",
    "        return dependency\n",
    "\n",
    "    dependency = jax.lax.fori_loop(0, num_levels - 1, accum_body_fn, dependency)\n",
    "                        \n",
    "    return dependency\n",
    "\n",
    "def betweenness_centrality_jax(adj_matrix, normalized=True):\n",
    "    \"\"\"\n",
    "    Compute betweenness centrality for an unweighted graph using a fully JIT-able approach.\n",
    "    \"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    if n_nodes <= 2:\n",
    "        return jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Ensure matrix has the correct dtype\n",
    "    adj_matrix = adj_matrix.astype(DTYPE)\n",
    "\n",
    "    all_dependencies = jax.vmap(_sssp_brandes_source, in_axes=(0, None))(jnp.arange(n_nodes), adj_matrix)\n",
    "    betweenness = jnp.sum(all_dependencies, axis=0)\n",
    "        \n",
    "    if normalized:\n",
    "        scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "        betweenness = betweenness * scale\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "# --- Example Usage and Verification ---\n",
    "G = nx.karate_club_graph()\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# --- FIX: Ensure the initial matrix uses the consistent dtype ---\n",
    "adj_matrix_np = (nx.to_numpy_array(G) > 0).astype(np.float64)\n",
    "adj_matrix_jax = jnp.array(adj_matrix_np)\n",
    "\n",
    "print(\"Running JAX implementation...\")\n",
    "bc_jax = betweenness_centrality_jax(adj_matrix_jax, normalized=True)\n",
    "\n",
    "print(\"Running NetworkX implementation...\")\n",
    "bc_nx = nx.betweenness_centrality(G, normalized=True)\n",
    "bc_nx_array = jnp.array([bc_nx[i] for i in range(N)])\n",
    "\n",
    "print(\"\\nJAX results (first 5):\", np.round(np.array(bc_jax[:5]), 4))\n",
    "print(\"NX results (first 5): \", np.round(np.array(bc_nx_array[:5]), 4))\n",
    "print(\"\\nAre they close?\", np.allclose(bc_jax, bc_nx_array, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e171be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Optional, Tuple, Dict\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def betweenness_centrality_jax(\n",
    "    adjacency_matrix: jnp.ndarray,\n",
    "    k: Optional[int] = None,\n",
    "    normalized: bool = True,\n",
    "    weight_matrix: Optional[jnp.ndarray] = None,\n",
    "    endpoints: bool = False,\n",
    "    seed: int = 42\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the shortest-path betweenness centrality for nodes using JAX.\n",
    "    \n",
    "    Betweenness centrality of a node v is the sum of the fraction of all-pairs \n",
    "    shortest paths that pass through v.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency_matrix : jnp.ndarray\n",
    "        Square adjacency matrix of shape (n, n) where n is the number of nodes.\n",
    "        adjacency_matrix[i, j] = 1 if there's an edge from i to j, 0 otherwise.\n",
    "    \n",
    "    k : int, optional (default=None)\n",
    "        If k is not None, use k node samples to estimate betweenness.\n",
    "        Higher values give better approximation.\n",
    "    \n",
    "    normalized : bool, optional (default=True)\n",
    "        If True, normalize betweenness values by the appropriate factor.\n",
    "    \n",
    "    weight_matrix : jnp.ndarray, optional (default=None)\n",
    "        Weight matrix of same shape as adjacency_matrix.\n",
    "        If None, all edges have weight 1.\n",
    "    \n",
    "    endpoints : bool, optional (default=False)\n",
    "        If True, include endpoints in shortest path counts.\n",
    "    \n",
    "    seed : int, optional (default=42)\n",
    "        Random seed for sampling nodes when k is specified.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    betweenness : jnp.ndarray\n",
    "        Array of betweenness centrality values for each node.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize betweenness centrality values\n",
    "    betweenness = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Determine which nodes to use as sources\n",
    "    if k is None or k >= n_nodes:\n",
    "        source_nodes = jnp.arange(n_nodes)\n",
    "    else:\n",
    "        key = random.PRNGKey(seed)\n",
    "        source_nodes = random.choice(key, n_nodes, (k,), replace=False)\n",
    "    \n",
    "    # Process each source node\n",
    "    for s in source_nodes:\n",
    "        if weight_matrix is None:\n",
    "            # Unweighted shortest paths (BFS-style)\n",
    "            S, P, sigma = _single_source_shortest_path_unweighted_jax(\n",
    "                adjacency_matrix, s\n",
    "            )\n",
    "        else:\n",
    "            # Weighted shortest paths (Dijkstra-style)\n",
    "            S, P, sigma = _single_source_shortest_path_weighted_jax(\n",
    "                adjacency_matrix, weight_matrix, s\n",
    "            )\n",
    "        \n",
    "        # Accumulate betweenness centrality\n",
    "        if endpoints:\n",
    "            betweenness = _accumulate_endpoints_jax(betweenness, S, P, sigma, s)\n",
    "        else:\n",
    "            betweenness = _accumulate_basic_jax(betweenness, S, P, sigma, s)\n",
    "    \n",
    "    # Rescale the results\n",
    "    betweenness = _rescale_jax(\n",
    "        betweenness, n_nodes, normalized, k, endpoints, len(source_nodes)\n",
    "    )\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _single_source_shortest_path_unweighted_jax(\n",
    "    adjacency_matrix: jnp.ndarray, \n",
    "    source: int\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Single-source shortest paths for unweighted graphs using BFS approach.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    S : jnp.ndarray\n",
    "        Nodes in order of non-increasing distance from source\n",
    "    P : jnp.ndarray\n",
    "        Predecessor matrix: P[v, u] = 1 if u is a predecessor of v\n",
    "    sigma : jnp.ndarray\n",
    "        Number of shortest paths from source to each node\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize distances and predecessors\n",
    "    dist = jnp.full(n_nodes, -1)\n",
    "    dist = dist.at[source].set(0)\n",
    "    sigma = jnp.zeros(n_nodes)\n",
    "    sigma = sigma.at[source].set(1.0)\n",
    "    \n",
    "    # Store predecessors as lists (using a different approach)\n",
    "    P = []\n",
    "    for _ in range(n_nodes):\n",
    "        P.append([])\n",
    "    \n",
    "    # BFS queue simulation\n",
    "    current_layer = [source]\n",
    "    current_dist = 0\n",
    "    S = []  # Stack for nodes in order of discovery\n",
    "    \n",
    "    while current_layer:\n",
    "        S.extend(current_layer)\n",
    "        next_layer = []\n",
    "        \n",
    "        for v in current_layer:\n",
    "            # Check all neighbors of v\n",
    "            for w in range(n_nodes):\n",
    "                if adjacency_matrix[v, w] > 0:  # There's an edge v -> w\n",
    "                    # First time we see w\n",
    "                    if dist[w] < 0:\n",
    "                        dist = dist.at[w].set(current_dist + 1)\n",
    "                        next_layer.append(w)\n",
    "                        sigma = sigma.at[w].set(0.0)\n",
    "                    \n",
    "                    # If w is at the next level from v\n",
    "                    if dist[w] == current_dist + 1:\n",
    "                        sigma = sigma.at[w].add(sigma[v])\n",
    "                        P[w].append(v)\n",
    "        \n",
    "        current_layer = next_layer\n",
    "        current_dist += 1\n",
    "    \n",
    "    # Convert P to matrix format for compatibility\n",
    "    P_matrix = jnp.zeros((n_nodes, n_nodes))\n",
    "    for w in range(n_nodes):\n",
    "        for v in P[w]:\n",
    "            P_matrix = P_matrix.at[w, v].set(1.0)\n",
    "    \n",
    "    # S should be in reverse order for the algorithm\n",
    "    S = jnp.array(S[::-1])\n",
    "    \n",
    "    return S, P_matrix, sigma\n",
    "\n",
    "\n",
    "def _single_source_shortest_path_weighted_jax(\n",
    "    adjacency_matrix: jnp.ndarray,\n",
    "    weight_matrix: jnp.ndarray,\n",
    "    source: int\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Single-source shortest paths for weighted graphs using Dijkstra's algorithm.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize distances and predecessors\n",
    "    dist = jnp.full(n_nodes, jnp.inf)\n",
    "    dist = dist.at[source].set(0.0)\n",
    "    sigma = jnp.zeros(n_nodes)\n",
    "    sigma = sigma.at[source].set(1.0)\n",
    "    \n",
    "    # Store predecessors as lists\n",
    "    P = []\n",
    "    for _ in range(n_nodes):\n",
    "        P.append([])\n",
    "    \n",
    "    # Dijkstra's algorithm\n",
    "    visited = jnp.zeros(n_nodes, dtype=bool)\n",
    "    S = []  # Stack for nodes in order of completion\n",
    "    \n",
    "    for _ in range(n_nodes):\n",
    "        # Find unvisited node with minimum distance\n",
    "        unvisited_dist = jnp.where(visited, jnp.inf, dist)\n",
    "        if jnp.all(jnp.isinf(unvisited_dist)):\n",
    "            break\n",
    "            \n",
    "        u = int(jnp.argmin(unvisited_dist))\n",
    "        \n",
    "        if jnp.isinf(dist[u]):\n",
    "            break\n",
    "            \n",
    "        visited = visited.at[u].set(True)\n",
    "        S.append(u)\n",
    "        \n",
    "        # Update distances to neighbors\n",
    "        for v in range(n_nodes):\n",
    "            if adjacency_matrix[u, v] > 0 and not visited[v]:\n",
    "                edge_weight = weight_matrix[u, v]\n",
    "                new_dist = dist[u] + edge_weight\n",
    "                \n",
    "                # If we found a shorter path\n",
    "                if dist[v] > new_dist:\n",
    "                    dist = dist.at[v].set(new_dist)\n",
    "                    sigma = sigma.at[v].set(sigma[u])\n",
    "                    P[v] = [u]  # Reset predecessors\n",
    "                \n",
    "                # If we found an equally short path\n",
    "                elif jnp.abs(dist[v] - new_dist) < 1e-10:\n",
    "                    sigma = sigma.at[v].add(sigma[u])\n",
    "                    P[v].append(u)\n",
    "    \n",
    "    # Convert P to matrix format\n",
    "    P_matrix = jnp.zeros((n_nodes, n_nodes))\n",
    "    for w in range(n_nodes):\n",
    "        for v in P[w]:\n",
    "            P_matrix = P_matrix.at[w, v].set(1.0)\n",
    "    \n",
    "    # S should be in reverse order\n",
    "    S = jnp.array(S[::-1])\n",
    "    \n",
    "    return S, P_matrix, sigma\n",
    "\n",
    "\n",
    "def _accumulate_basic_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    S: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    sigma: jnp.ndarray,\n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Accumulate betweenness centrality (basic version without endpoints).\n",
    "    \"\"\"\n",
    "    n_nodes = len(betweenness)\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Process nodes in reverse topological order (S is already reversed)\n",
    "    for i in range(len(S)):\n",
    "        w = int(S[i])\n",
    "        if w == source:\n",
    "            continue\n",
    "            \n",
    "        # Sum over predecessors\n",
    "        predecessors = P[w] > 0\n",
    "        for v in range(n_nodes):\n",
    "            if predecessors[v] and sigma[w] > 0:\n",
    "                coeff = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n",
    "                delta = delta.at[v].add(coeff)\n",
    "        \n",
    "        betweenness = betweenness.at[w].add(delta[w])\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _accumulate_endpoints_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    S: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    sigma: jnp.ndarray,\n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Accumulate betweenness centrality (with endpoints).\n",
    "    \"\"\"\n",
    "    n_nodes = len(betweenness)\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Add contribution for source node\n",
    "    betweenness = betweenness.at[source].add(len(S) - 1)\n",
    "    \n",
    "    # Process nodes in reverse topological order\n",
    "    for i in reversed(range(len(S))):\n",
    "        w = S[i]\n",
    "        if w == source:\n",
    "            continue\n",
    "            \n",
    "        # Add contribution for this endpoint\n",
    "        betweenness = betweenness.at[w].add(delta[w] + 1)\n",
    "        \n",
    "        # Sum over predecessors\n",
    "        predecessors = P[w] > 0\n",
    "        for v in range(n_nodes):\n",
    "            if predecessors[v]:\n",
    "                coeff = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n",
    "                delta = delta.at[v].add(coeff)\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _rescale_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    n_nodes: int,\n",
    "    normalized: bool,\n",
    "    k: Optional[int],\n",
    "    endpoints: bool,\n",
    "    n_sampled: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Rescale betweenness centrality values.\n",
    "    \"\"\"\n",
    "    if not normalized:\n",
    "        return betweenness\n",
    "    \n",
    "    if n_nodes <= 2:\n",
    "        return betweenness\n",
    "    \n",
    "    # Normalization factor\n",
    "    if endpoints:\n",
    "        # Include endpoints in normalization\n",
    "        scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "    else:\n",
    "        # Standard normalization\n",
    "        scale = 2.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "    \n",
    "    # Adjust for sampling\n",
    "    if k is not None and n_sampled < n_nodes:\n",
    "        scale *= n_nodes / n_sampled\n",
    "    \n",
    "    return betweenness * scale\n",
    "\n",
    "\n",
    "# Example usage and testing functions\n",
    "def create_test_graph() -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"Create a simple test graph for demonstration.\"\"\"\n",
    "    # Create a simple path graph: 0-1-2-3-4\n",
    "    n = 5\n",
    "    adj = jnp.zeros((n, n))\n",
    "    for i in range(n-1):\n",
    "        adj = adj.at[i, i+1].set(1.0)\n",
    "        adj = adj.at[i+1, i].set(1.0)  # Make undirected\n",
    "    \n",
    "    # Create weight matrix (all weights = 1)\n",
    "    weights = jnp.where(adj > 0, 1.0, 0.0)\n",
    "    \n",
    "    return adj, weights\n",
    "\n",
    "\n",
    "def test_betweenness_centrality():\n",
    "    \"\"\"Test the betweenness centrality implementation.\"\"\"\n",
    "    adj, weights = create_test_graph()\n",
    "    \n",
    "    # Test unweighted\n",
    "    bc_unweighted = betweenness_centrality_jax(adj, normalized=True)\n",
    "    print(\"Unweighted betweenness centrality:\")\n",
    "    for i, val in enumerate(bc_unweighted):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test weighted\n",
    "    bc_weighted = betweenness_centrality_jax(adj, weight_matrix=weights, normalized=True)\n",
    "    print(\"\\nWeighted betweenness centrality:\")\n",
    "    for i, val in enumerate(bc_weighted):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test with sampling\n",
    "    bc_sampled = betweenness_centrality_jax(adj, k=3, normalized=True, seed=42)\n",
    "    print(\"\\nSampled betweenness centrality (k=3):\")\n",
    "    for i, val in enumerate(bc_sampled):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test with endpoints\n",
    "    bc_endpoints = betweenness_centrality_jax(adj, endpoints=True, normalized=True)\n",
    "    print(\"\\nBetweenness centrality with endpoints:\")\n",
    "    for i, val in enumerate(bc_endpoints):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Compare with expected NetworkX results for path graph 0-1-2-3-4\n",
    "    expected = [0.0, 0.5, 0.6666666666666666, 0.5, 0.0]\n",
    "    print(\"\\nExpected NetworkX results:\")\n",
    "    for i, val in enumerate(expected):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    print(\"\\nDifference from expected for unweigthed:\")\n",
    "    for i, (got, exp) in enumerate(zip(bc_unweighted/2, expected)):\n",
    "        print(f\"Node {i}: {abs(got - exp):.6f}\")\n",
    "\n",
    "    print(\"\\nDifference from expected for weigthed:\")\n",
    "    for i, (got, exp) in enumerate(zip(bc_weighted/2, expected)):\n",
    "        print(f\"Node {i}: {abs(got - exp):.6f}\")\n",
    "\n",
    "# Additional debugging function\n",
    "def debug_single_source(adj, source=0):\n",
    "    \"\"\"Debug single source shortest paths.\"\"\"\n",
    "    print(f\"\\nDebugging single source from node {source}:\")\n",
    "    S, P, sigma = _single_source_shortest_path_unweighted_jax(adj, source)\n",
    "    \n",
    "    print(f\"S (traversal order): {S}\")\n",
    "    print(f\"Sigma (path counts): {sigma}\")\n",
    "    print(f\"Predecessors matrix P:\")\n",
    "    for i in range(len(P)):\n",
    "        preds = [j for j in range(len(P)) if P[i, j] > 0]\n",
    "        print(f\"  Node {i}: predecessors = {preds}\")\n",
    "    \n",
    "    return S, P, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb0d4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted betweenness centrality:\n",
      "Node 0: 0.000000\n",
      "Node 1: 1.000000\n",
      "Node 2: 1.333333\n",
      "Node 3: 1.000000\n",
      "Node 4: 0.000000\n",
      "\n",
      "Weighted betweenness centrality:\n",
      "Node 0: 0.000000\n",
      "Node 1: 1.000000\n",
      "Node 2: 1.333333\n",
      "Node 3: 1.000000\n",
      "Node 4: 0.000000\n",
      "\n",
      "Sampled betweenness centrality (k=3):\n",
      "Node 0: 0.000000\n",
      "Node 1: 0.833333\n",
      "Node 2: 1.111111\n",
      "Node 3: 1.111111\n",
      "Node 4: 0.000000\n",
      "\n",
      "Betweenness centrality with endpoints:\n",
      "Node 0: 0.666667\n",
      "Node 1: 0.666667\n",
      "Node 2: 0.666667\n",
      "Node 3: 0.666667\n",
      "Node 4: 0.666667\n",
      "\n",
      "Expected NetworkX results:\n",
      "Node 0: 0.000000\n",
      "Node 1: 0.500000\n",
      "Node 2: 0.666667\n",
      "Node 3: 0.500000\n",
      "Node 4: 0.000000\n",
      "\n",
      "Difference from expected:\n",
      "Node 0: 0.000000\n",
      "Node 1: 0.500000\n",
      "Node 2: 0.666667\n",
      "Node 3: 0.500000\n",
      "Node 4: 0.000000\n"
     ]
    }
   ],
   "source": [
    "test_betweenness_centrality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f254b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.5        0.66666667 0.5        0.        ]\n",
      "[0.         0.5        0.66666667 0.5        0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.5, 2: 0.6666666666666666, 3: 0.5, 4: 0.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj, weights = create_test_graph()\n",
    "print(betweenness_centrality_jax(adj, normalized=True)/2)\n",
    "# convert adj to networkx graph and compute betweenness centrality\n",
    "G = nx.from_numpy_array(np.array(adj))\n",
    "\n",
    "print(betweenness_centrality_jax(adj, weight_matrix=weights, normalized=True)/2)\n",
    "\n",
    "nx.betweenness_centrality(G, normalized=True, weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f396a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Optional, Tuple, Dict\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def betweenness_centrality_jax(\n",
    "    adjacency_matrix: jnp.ndarray,\n",
    "    k: Optional[int] = None,\n",
    "    normalized: bool = True,\n",
    "    weight_matrix: Optional[jnp.ndarray] = None,\n",
    "    endpoints: bool = False,\n",
    "    seed: int = 42,\n",
    "    directed: bool = False\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the shortest-path betweenness centrality for nodes using JAX.\n",
    "    \n",
    "    Betweenness centrality of a node v is the sum of the fraction of all-pairs \n",
    "    shortest paths that pass through v.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency_matrix : jnp.ndarray\n",
    "        Square adjacency matrix of shape (n, n) where n is the number of nodes.\n",
    "        adjacency_matrix[i, j] = 1 if there's an edge from i to j, 0 otherwise.\n",
    "    \n",
    "    k : int, optional (default=None)\n",
    "        If k is not None, use k node samples to estimate betweenness.\n",
    "        Higher values give better approximation.\n",
    "    \n",
    "    normalized : bool, optional (default=True)\n",
    "        If True, normalize betweenness values by the appropriate factor.\n",
    "    \n",
    "    weight_matrix : jnp.ndarray, optional (default=None)\n",
    "        Weight matrix of same shape as adjacency_matrix.\n",
    "        If None, all edges have weight 1.\n",
    "    \n",
    "    endpoints : bool, optional (default=False)\n",
    "        If True, include endpoints in shortest path counts.\n",
    "    \n",
    "    seed : int, optional (default=42)\n",
    "        Random seed for sampling nodes when k is specified.\n",
    "    \n",
    "    directed : bool, optional (default=False)\n",
    "        If True, treat the graph as directed. If False, treat as undirected.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    betweenness : jnp.ndarray\n",
    "        Array of betweenness centrality values for each node.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize betweenness centrality values\n",
    "    betweenness = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Determine which nodes to use as sources\n",
    "    if k is None or k >= n_nodes:\n",
    "        source_nodes = jnp.arange(n_nodes)\n",
    "    else:\n",
    "        key = random.PRNGKey(seed)\n",
    "        source_nodes = random.choice(key, n_nodes, (k,), replace=False)\n",
    "    \n",
    "    # Process each source node\n",
    "    for s in source_nodes:\n",
    "        if weight_matrix is None:\n",
    "            # Unweighted shortest paths (BFS-style)\n",
    "            S, P, sigma = _single_source_shortest_path_unweighted_jax(\n",
    "                adjacency_matrix, s\n",
    "            )\n",
    "        else:\n",
    "            # Weighted shortest paths (Dijkstra-style)\n",
    "            S, P, sigma = _single_source_shortest_path_weighted_jax(\n",
    "                adjacency_matrix, weight_matrix, s\n",
    "            )\n",
    "        \n",
    "        # Accumulate betweenness centrality\n",
    "        if endpoints:\n",
    "            betweenness = _accumulate_endpoints_jax(betweenness, S, P, sigma, s)\n",
    "        else:\n",
    "            betweenness = _accumulate_basic_jax(betweenness, S, P, sigma, s)\n",
    "    \n",
    "    # Rescale the results\n",
    "    betweenness = _rescale_jax(\n",
    "        betweenness, n_nodes, normalized, k, endpoints, len(source_nodes), directed\n",
    "    )\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _single_source_shortest_path_unweighted_jax(\n",
    "    adjacency_matrix: jnp.ndarray, \n",
    "    source: int\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Single-source shortest paths for unweighted graphs using BFS approach.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    S : jnp.ndarray\n",
    "        Nodes in order of non-increasing distance from source\n",
    "    P : jnp.ndarray\n",
    "        Predecessor matrix: P[v, u] = 1 if u is a predecessor of v\n",
    "    sigma : jnp.ndarray\n",
    "        Number of shortest paths from source to each node\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize distances and predecessors\n",
    "    dist = jnp.full(n_nodes, -1)\n",
    "    dist = dist.at[source].set(0)\n",
    "    sigma = jnp.zeros(n_nodes)\n",
    "    sigma = sigma.at[source].set(1.0)\n",
    "    \n",
    "    # Store predecessors as lists (using a different approach)\n",
    "    P = []\n",
    "    for _ in range(n_nodes):\n",
    "        P.append([])\n",
    "    \n",
    "    # BFS queue simulation\n",
    "    current_layer = [source]\n",
    "    current_dist = 0\n",
    "    S = []  # Stack for nodes in order of discovery\n",
    "    \n",
    "    while current_layer:\n",
    "        S.extend(current_layer)\n",
    "        next_layer = []\n",
    "        \n",
    "        for v in current_layer:\n",
    "            # Check all neighbors of v\n",
    "            for w in range(n_nodes):\n",
    "                if adjacency_matrix[v, w] > 0:  # There's an edge v -> w\n",
    "                    # First time we see w\n",
    "                    if dist[w] < 0:\n",
    "                        dist = dist.at[w].set(current_dist + 1)\n",
    "                        next_layer.append(w)\n",
    "                        sigma = sigma.at[w].set(0.0)\n",
    "                    \n",
    "                    # If w is at the next level from v\n",
    "                    if dist[w] == current_dist + 1:\n",
    "                        sigma = sigma.at[w].add(sigma[v])\n",
    "                        P[w].append(v)\n",
    "        \n",
    "        current_layer = next_layer\n",
    "        current_dist += 1\n",
    "    \n",
    "    # Convert P to matrix format for compatibility\n",
    "    P_matrix = jnp.zeros((n_nodes, n_nodes))\n",
    "    for w in range(n_nodes):\n",
    "        for v in P[w]:\n",
    "            P_matrix = P_matrix.at[w, v].set(1.0)\n",
    "    \n",
    "    # S should be in reverse order for the algorithm\n",
    "    S = jnp.array(S[::-1])\n",
    "    \n",
    "    return S, P_matrix, sigma\n",
    "\n",
    "\n",
    "def _single_source_shortest_path_weighted_jax(\n",
    "    adjacency_matrix: jnp.ndarray,\n",
    "    weight_matrix: jnp.ndarray,\n",
    "    source: int\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Single-source shortest paths for weighted graphs using Dijkstra's algorithm.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize distances and predecessors\n",
    "    dist = jnp.full(n_nodes, jnp.inf)\n",
    "    dist = dist.at[source].set(0.0)\n",
    "    sigma = jnp.zeros(n_nodes)\n",
    "    sigma = sigma.at[source].set(1.0)\n",
    "    \n",
    "    # Store predecessors as lists\n",
    "    P = []\n",
    "    for _ in range(n_nodes):\n",
    "        P.append([])\n",
    "    \n",
    "    # Dijkstra's algorithm\n",
    "    visited = jnp.zeros(n_nodes, dtype=bool)\n",
    "    S = []  # Stack for nodes in order of completion\n",
    "    \n",
    "    for _ in range(n_nodes):\n",
    "        # Find unvisited node with minimum distance\n",
    "        unvisited_dist = jnp.where(visited, jnp.inf, dist)\n",
    "        if jnp.all(jnp.isinf(unvisited_dist)):\n",
    "            break\n",
    "            \n",
    "        u = int(jnp.argmin(unvisited_dist))\n",
    "        \n",
    "        if jnp.isinf(dist[u]):\n",
    "            break\n",
    "            \n",
    "        visited = visited.at[u].set(True)\n",
    "        S.append(u)\n",
    "        \n",
    "        # Update distances to neighbors\n",
    "        for v in range(n_nodes):\n",
    "            if adjacency_matrix[u, v] > 0 and not visited[v]:\n",
    "                edge_weight = weight_matrix[u, v]\n",
    "                new_dist = dist[u] + edge_weight\n",
    "                \n",
    "                # If we found a shorter path\n",
    "                if dist[v] > new_dist:\n",
    "                    dist = dist.at[v].set(new_dist)\n",
    "                    sigma = sigma.at[v].set(sigma[u])\n",
    "                    P[v] = [u]  # Reset predecessors\n",
    "                \n",
    "                # If we found an equally short path\n",
    "                elif jnp.abs(dist[v] - new_dist) < 1e-10:\n",
    "                    sigma = sigma.at[v].add(sigma[u])\n",
    "                    P[v].append(u)\n",
    "    \n",
    "    # Convert P to matrix format\n",
    "    P_matrix = jnp.zeros((n_nodes, n_nodes))\n",
    "    for w in range(n_nodes):\n",
    "        for v in P[w]:\n",
    "            P_matrix = P_matrix.at[w, v].set(1.0)\n",
    "    \n",
    "    # S should be in reverse order\n",
    "    S = jnp.array(S[::-1])\n",
    "    \n",
    "    return S, P_matrix, sigma\n",
    "\n",
    "\n",
    "def _accumulate_basic_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    S: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    sigma: jnp.ndarray,\n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Accumulate betweenness centrality (basic version without endpoints).\n",
    "    \"\"\"\n",
    "    n_nodes = len(betweenness)\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Process nodes in reverse topological order (S is already reversed)\n",
    "    for i in range(len(S)):\n",
    "        w = int(S[i])\n",
    "        if w == source:\n",
    "            continue\n",
    "            \n",
    "        # Sum over predecessors\n",
    "        predecessors = P[w] > 0\n",
    "        for v in range(n_nodes):\n",
    "            if predecessors[v] and sigma[w] > 0:\n",
    "                coeff = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n",
    "                delta = delta.at[v].add(coeff)\n",
    "        \n",
    "        betweenness = betweenness.at[w].add(delta[w])\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _accumulate_endpoints_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    S: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    sigma: jnp.ndarray,\n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Accumulate betweenness centrality (with endpoints).\n",
    "    \"\"\"\n",
    "    n_nodes = len(betweenness)\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    \n",
    "    # Add contribution for source node\n",
    "    betweenness = betweenness.at[source].add(len(S) - 1)\n",
    "    \n",
    "    # Process nodes in reverse topological order\n",
    "    for i in reversed(range(len(S))):\n",
    "        w = S[i]\n",
    "        if w == source:\n",
    "            continue\n",
    "            \n",
    "        # Add contribution for this endpoint\n",
    "        betweenness = betweenness.at[w].add(delta[w] + 1)\n",
    "        \n",
    "        # Sum over predecessors\n",
    "        predecessors = P[w] > 0\n",
    "        for v in range(n_nodes):\n",
    "            if predecessors[v]:\n",
    "                coeff = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n",
    "                delta = delta.at[v].add(coeff)\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _rescale_jax(\n",
    "    betweenness: jnp.ndarray,\n",
    "    n_nodes: int,\n",
    "    normalized: bool,\n",
    "    k: Optional[int],\n",
    "    endpoints: bool,\n",
    "    n_sampled: int,\n",
    "    directed: bool = False\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Rescale betweenness centrality values.\n",
    "    \"\"\"\n",
    "    if not normalized:\n",
    "        return betweenness\n",
    "    \n",
    "    if n_nodes <= 2:\n",
    "        return betweenness\n",
    "    \n",
    "    # Normalization factor based on NetworkX implementation\n",
    "    if endpoints:\n",
    "        # Include endpoints in normalization\n",
    "        scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "    else:\n",
    "        # Standard normalization\n",
    "        if directed:\n",
    "            # For directed graphs: 1/((n-1)(n-2))\n",
    "            scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "        else:\n",
    "            # For undirected graphs: 2/((n-1)(n-2))\n",
    "            scale = 2.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "    \n",
    "    # Adjust for sampling\n",
    "    if k is not None and n_sampled < n_nodes:\n",
    "        scale *= n_nodes / n_sampled\n",
    "    \n",
    "    return betweenness * scale\n",
    "\n",
    "\n",
    "# Example usage and testing functions\n",
    "def create_test_graph() -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"Create a simple test graph for demonstration.\"\"\"\n",
    "    # Create a simple path graph: 0-1-2-3-4\n",
    "    n = 5\n",
    "    adj = jnp.zeros((n, n))\n",
    "    for i in range(n-1):\n",
    "        adj = adj.at[i, i+1].set(1.0)\n",
    "        adj = adj.at[i+1, i].set(1.0)  # Make undirected\n",
    "    \n",
    "    # Create weight matrix (all weights = 1)\n",
    "    weights = jnp.where(adj > 0, 1.0, 0.0)\n",
    "    \n",
    "    return adj, weights\n",
    "\n",
    "\n",
    "def test_betweenness_centrality():\n",
    "    \"\"\"Test the betweenness centrality implementation.\"\"\"\n",
    "    adj, weights = create_test_graph()\n",
    "    \n",
    "    # Test unweighted (undirected graph)\n",
    "    bc_unweighted = betweenness_centrality_jax(adj, normalized=True, directed=False)\n",
    "    print(\"Unweighted betweenness centrality:\")\n",
    "    for i, val in enumerate(bc_unweighted):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test weighted (undirected graph)\n",
    "    bc_weighted = betweenness_centrality_jax(adj, weight_matrix=weights, normalized=True, directed=False)\n",
    "    print(\"\\nWeighted betweenness centrality:\")\n",
    "    for i, val in enumerate(bc_weighted):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test with sampling\n",
    "    bc_sampled = betweenness_centrality_jax(adj, k=3, normalized=True, seed=42, directed=False)\n",
    "    print(\"\\nSampled betweenness centrality (k=3):\")\n",
    "    for i, val in enumerate(bc_sampled):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Test with endpoints\n",
    "    bc_endpoints = betweenness_centrality_jax(adj, endpoints=True, normalized=True, directed=False)\n",
    "    print(\"\\nBetweenness centrality with endpoints:\")\n",
    "    for i, val in enumerate(bc_endpoints):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    # Compare with expected NetworkX results for path graph 0-1-2-3-4\n",
    "    expected = [0.0, 0.5, 0.6666666666666666, 0.5, 0.0]\n",
    "    print(\"\\nExpected NetworkX results:\")\n",
    "    for i, val in enumerate(expected):\n",
    "        print(f\"Node {i}: {val:.6f}\")\n",
    "    \n",
    "    print(\"\\nDifference from expected:\")\n",
    "    for i, (got, exp) in enumerate(zip(bc_unweighted, expected)):\n",
    "        print(f\"Node {i}: {abs(got - exp):.6f}\")\n",
    "\n",
    "\n",
    "# Additional debugging function\n",
    "def debug_single_source(adj, source=0):\n",
    "    \"\"\"Debug single source shortest paths.\"\"\"\n",
    "    print(f\"\\nDebugging single source from node {source}:\")\n",
    "    S, P, sigma = _single_source_shortest_path_unweighted_jax(adj, source)\n",
    "    \n",
    "    print(f\"S (traversal order): {S}\")\n",
    "    print(f\"Sigma (path counts): {sigma}\")\n",
    "    print(f\"Predecessors matrix P:\")\n",
    "    for i in range(len(P)):\n",
    "        preds = [j for j in range(len(P)) if P[i, j] > 0]\n",
    "        print(f\"  Node {i}: predecessors = {preds}\")\n",
    "    \n",
    "    return S, P, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b911e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample graph\n",
    "G = nx.karate_club_graph()\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# Get the adjacency matrix for JAX\n",
    "adj_matrix_np = nx.to_numpy_array(G)\n",
    "adj_matrix_jax = jnp.array(adj_matrix_np)\n",
    "\n",
    "bc_unweighted = betweenness_centrality_jax(adj_matrix_jax, normalized=True, directed=False)\n",
    "bc_weighted = betweenness_centrality_jax(adj_matrix_jax, weight_matrix=adj_matrix_jax, normalized=True, directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66e2adb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.43763528, 0.05393669, 0.14365681, 0.01190927, 0.00063131,\n",
       "       0.02998737, 0.02998737, 0.        , 0.05592683, 0.00084776,\n",
       "       0.00063131, 0.        , 0.        , 0.0458634 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03247505,\n",
       "       0.        , 0.        , 0.        , 0.01761364, 0.0022096 ,\n",
       "       0.00384049, 0.        , 0.02233345, 0.00179473, 0.00292208,\n",
       "       0.01441198, 0.13827561, 0.14524711, 0.30407498], dtype=float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_unweighted/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bd0c647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.43763528138528146,\n",
       " 1: 0.053936688311688304,\n",
       " 2: 0.14365680615680618,\n",
       " 3: 0.011909271284271283,\n",
       " 4: 0.0006313131313131313,\n",
       " 5: 0.02998737373737374,\n",
       " 6: 0.029987373737373736,\n",
       " 7: 0.0,\n",
       " 8: 0.05592682780182781,\n",
       " 9: 0.0008477633477633478,\n",
       " 10: 0.0006313131313131313,\n",
       " 11: 0.0,\n",
       " 12: 0.0,\n",
       " 13: 0.04586339586339586,\n",
       " 14: 0.0,\n",
       " 15: 0.0,\n",
       " 16: 0.0,\n",
       " 17: 0.0,\n",
       " 18: 0.0,\n",
       " 19: 0.03247504810004811,\n",
       " 20: 0.0,\n",
       " 21: 0.0,\n",
       " 22: 0.0,\n",
       " 23: 0.017613636363636363,\n",
       " 24: 0.0022095959595959595,\n",
       " 25: 0.0038404882154882154,\n",
       " 26: 0.0,\n",
       " 27: 0.02233345358345358,\n",
       " 28: 0.0017947330447330447,\n",
       " 29: 0.0029220779220779218,\n",
       " 30: 0.014411976911976909,\n",
       " 31: 0.13827561327561325,\n",
       " 32: 0.145247113997114,\n",
       " 33: 0.30407497594997596}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.betweenness_centrality(G, normalized=True, weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9edc3c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.47376894, 0.06401515, 0.06941288, 0.00252525, 0.00094697,\n",
       "       0.02935606, 0.02935606, 0.        , 0.02481061, 0.01379419,\n",
       "       0.00094697, 0.        , 0.        , 0.00227273, 0.        ,\n",
       "       0.        , 0.        , 0.03049242, 0.00568182, 0.24065657,\n",
       "       0.        , 0.        , 0.        , 0.00189394, 0.06407828,\n",
       "       0.00094697, 0.        , 0.01231061, 0.01912879, 0.        ,\n",
       "       0.00568182, 0.12563131, 0.07222222, 0.3967803 ], dtype=float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_weighted/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5c9c5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4737689393939393,\n",
       " 1: 0.06401515151515152,\n",
       " 2: 0.0694128787878788,\n",
       " 3: 0.0025252525252525255,\n",
       " 4: 0.000946969696969697,\n",
       " 5: 0.029356060606060608,\n",
       " 6: 0.029356060606060608,\n",
       " 7: 0.0,\n",
       " 8: 0.02481060606060606,\n",
       " 9: 0.01379419191919192,\n",
       " 10: 0.000946969696969697,\n",
       " 11: 0.0,\n",
       " 12: 0.0,\n",
       " 13: 0.0022727272727272726,\n",
       " 14: 0.0,\n",
       " 15: 0.0,\n",
       " 16: 0.0,\n",
       " 17: 0.030492424242424244,\n",
       " 18: 0.005681818181818182,\n",
       " 19: 0.24065656565656565,\n",
       " 20: 0.0,\n",
       " 21: 0.0,\n",
       " 22: 0.0,\n",
       " 23: 0.001893939393939394,\n",
       " 24: 0.06407828282828282,\n",
       " 25: 0.000946969696969697,\n",
       " 26: 0.0,\n",
       " 27: 0.01231060606060606,\n",
       " 28: 0.019128787878787877,\n",
       " 29: 0.0,\n",
       " 30: 0.005681818181818182,\n",
       " 31: 0.12563131313131315,\n",
       " 32: 0.07222222222222223,\n",
       " 33: 0.3967803030303029}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.betweenness_centrality(G, normalized=True, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af87226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimized JAX betweenness centrality implementation...\n",
      "\n",
      "1. Path graph (5 nodes):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "while_loop body function carry input and carry output must have equal types, but they differ:\n\n  * the input carry component state[2] has type float32[5] but the corresponding output carry component has type float64[5], so the dtypes do not match;\n  * the input carry component state[3] has type float32[5,5] but the corresponding output carry component has type float64[5,5], so the dtypes do not match.\n\nRevise the function so that all output types match the corresponding input types.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 317\u001b[39m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOptimized implementation test completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[43mtest_optimized_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mtest_optimized_implementation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    298\u001b[39m path_adj = create_path_graph(\u001b[32m5\u001b[39m)\n\u001b[32m    300\u001b[39m bc_func = jit(functools.partial(betweenness_centrality_jax_optimized, normalized=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m bc_path = \u001b[43mbc_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBetweenness centrality: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbc_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    305\u001b[39m expected_path = jnp.array([\u001b[32m0.0\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m2.0\u001b[39m/\u001b[32m3.0\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.0\u001b[39m])\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mbetweenness_centrality_jax_optimized\u001b[39m\u001b[34m(adjacency_matrix, k, normalized, weight_matrix, endpoints, seed, directed)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Vectorize over all source nodes\u001b[39;00m\n\u001b[32m     42\u001b[39m vectorized_compute = vmap(compute_single_source)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m all_contributions = \u001b[43mvectorized_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Sum contributions from all sources\u001b[39;00m\n\u001b[32m     46\u001b[39m summed_betweenness = jnp.sum(all_contributions, axis=\u001b[32m0\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36m_single_source_bfs_optimized\u001b[39m\u001b[34m(adjacency_matrix, source)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (newly_discovered, new_distances, new_sigma, new_P, current_dist + \u001b[32m1\u001b[39m)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Run BFS\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m _, final_distances, final_sigma, final_P, _ = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbfs_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbfs_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# The stack S is the set of nodes sorted by INCREASING distance.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# The accumulation loop will iterate backwards over this stack.\u001b[39;00m\n\u001b[32m    109\u001b[39m S = jnp.argsort(final_distances)\n",
      "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/.venv/lib/python3.12/site-packages/jax/_src/lax/control_flow/loops.py:535\u001b[39m, in \u001b[36m_check_carry_type\u001b[39m\u001b[34m(name, body_fun, in_carry, out_carry_tree, out_avals)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pvary_msg:\n\u001b[32m    532\u001b[39m   pvary_msg += (\u001b[33m\"\u001b[39m\u001b[33mSee https://docs.jax.dev/en/latest/notebooks/shard_map.html#scan-vma \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    533\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfor more information.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    536\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m function carry input and carry output must have equal types, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbut they differ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdifferences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpvary_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRevise the function so that all output types match the corresponding \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput types.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: while_loop body function carry input and carry output must have equal types, but they differ:\n\n  * the input carry component state[2] has type float32[5] but the corresponding output carry component has type float64[5], so the dtypes do not match;\n  * the input carry component state[3] has type float32[5,5] but the corresponding output carry component has type float64[5,5], so the dtypes do not match.\n\nRevise the function so that all output types match the corresponding input types."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, lax, jit\n",
    "from typing import Optional, Tuple\n",
    "import functools\n",
    "\n",
    "def betweenness_centrality_jax_optimized(\n",
    "    adjacency_matrix: jnp.ndarray,\n",
    "    k: Optional[int] = None,\n",
    "    normalized: bool = True,\n",
    "    weight_matrix: Optional[jnp.ndarray] = None,\n",
    "    endpoints: bool = False,\n",
    "    seed: int = 42,\n",
    "    directed: bool = False\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Optimized JAX implementation of betweenness centrality using vmap and lax operations.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Determine source nodes\n",
    "    if k is None or k >= n_nodes:\n",
    "        source_nodes = jnp.arange(n_nodes)\n",
    "    else:\n",
    "        key = random.PRNGKey(seed)\n",
    "        source_nodes = random.choice(key, n_nodes, (k,), replace=False)\n",
    "    \n",
    "    # Choose algorithm based on whether weights are provided\n",
    "    if weight_matrix is None:\n",
    "        compute_single_source = functools.partial(\n",
    "            _single_source_bfs_optimized, \n",
    "            adjacency_matrix\n",
    "        )\n",
    "    else:\n",
    "        compute_single_source = functools.partial(\n",
    "            _single_source_dijkstra_optimized,\n",
    "            adjacency_matrix,\n",
    "            weight_matrix\n",
    "        )\n",
    "    \n",
    "    # Vectorize over all source nodes\n",
    "    vectorized_compute = vmap(compute_single_source)\n",
    "    all_contributions = vectorized_compute(source_nodes)\n",
    "    \n",
    "    # Sum contributions from all sources\n",
    "    summed_betweenness = jnp.sum(all_contributions, axis=0)\n",
    "    \n",
    "    # Brandes' algorithm counts each path twice in an undirected graph.\n",
    "    # The convention is to divide by 2.\n",
    "    if not directed:\n",
    "        summed_betweenness /= 2.0\n",
    "    \n",
    "    # Apply normalization\n",
    "    betweenness = _rescale_optimized(\n",
    "        summed_betweenness, n_nodes, normalized, k, endpoints, \n",
    "        len(source_nodes), directed\n",
    "    )\n",
    "    \n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _single_source_bfs_optimized(adjacency_matrix: jnp.ndarray, source: int) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Optimized single-source BFS using JAX control flow primitives.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_distances = jnp.full(n_nodes, -1, dtype=jnp.int32).at[source].set(0)\n",
    "    initial_sigma = jnp.zeros(n_nodes, dtype=jnp.float32).at[source].set(1.0)\n",
    "    initial_P = jnp.zeros((n_nodes, n_nodes), dtype=jnp.float32)\n",
    "    initial_layer = jnp.zeros(n_nodes, dtype=bool).at[source].set(True)\n",
    "    initial_dist = 0\n",
    "\n",
    "    initial_state = (initial_layer, initial_distances, initial_sigma, initial_P, initial_dist)\n",
    "    \n",
    "    def bfs_condition(state):\n",
    "        current_layer, _, _, _, _ = state\n",
    "        return jnp.any(current_layer)\n",
    "\n",
    "    def bfs_body(state):\n",
    "        current_layer, distances, sigma, P, current_dist = state\n",
    "        \n",
    "        # Find neighbors of the current layer\n",
    "        neighbors = jnp.dot(current_layer.astype(jnp.float32), adjacency_matrix) > 0\n",
    "        \n",
    "        # Newly discovered nodes are unvisited neighbors\n",
    "        newly_discovered = neighbors & (distances == -1)\n",
    "        new_distances = jnp.where(newly_discovered, current_dist + 1, distances)\n",
    "        \n",
    "        # For all nodes at the next level, update their sigma by summing from predecessors\n",
    "        path_to_next_level = (new_distances == current_dist + 1)\n",
    "        sigma_from_preds = jnp.dot(adjacency_matrix.T, jnp.where(current_layer, sigma, 0.0))\n",
    "        new_sigma = jnp.where(path_to_next_level, sigma + sigma_from_preds, sigma)\n",
    "        \n",
    "        # Update predecessor matrix for paths to the next level\n",
    "        pred_updates = jnp.outer(path_to_next_level, current_layer) * adjacency_matrix\n",
    "        new_P = P + pred_updates.T\n",
    "\n",
    "        return (newly_discovered, new_distances, new_sigma, new_P, current_dist + 1)\n",
    "\n",
    "    # Run BFS\n",
    "    _, final_distances, final_sigma, final_P, _ = lax.while_loop(\n",
    "        bfs_condition, bfs_body, initial_state\n",
    "    )\n",
    "    \n",
    "    # The stack S is the set of nodes sorted by INCREASING distance.\n",
    "    # The accumulation loop will iterate backwards over this stack.\n",
    "    S = jnp.argsort(final_distances)\n",
    "    \n",
    "    # Compute betweenness contribution\n",
    "    betweenness_contrib = _accumulate_dependencies_optimized(\n",
    "        S, final_P, final_sigma, source\n",
    "    )\n",
    "    \n",
    "    return betweenness_contrib\n",
    "\n",
    "\n",
    "def _single_source_dijkstra_optimized(\n",
    "    adjacency_matrix: jnp.ndarray, \n",
    "    weight_matrix: jnp.ndarray, \n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Dijkstra's algorithm using lax.fori_loop.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    distances = jnp.full(n_nodes, jnp.inf).at[source].set(0.0)\n",
    "    sigma = jnp.zeros(n_nodes).at[source].set(1.0)\n",
    "    P = jnp.zeros((n_nodes, n_nodes))\n",
    "    S = jnp.full(n_nodes, -1, dtype=jnp.int32)\n",
    "    visited = jnp.zeros(n_nodes, dtype=bool)\n",
    "\n",
    "    def dijkstra_body(i, state):\n",
    "        distances, sigma, visited, P, S = state\n",
    "        \n",
    "        unvisited_dist = jnp.where(visited, jnp.inf, distances)\n",
    "        u = jnp.argmin(unvisited_dist)\n",
    "        \n",
    "        S = S.at[i].set(u)\n",
    "        visited = visited.at[u].set(True)\n",
    "        \n",
    "        edge_weights = jnp.where(adjacency_matrix[u] > 0, weight_matrix[u], jnp.inf)\n",
    "        new_dist_via_u = distances[u] + edge_weights\n",
    "        \n",
    "        is_shorter = new_dist_via_u < distances\n",
    "        is_equal = jnp.isclose(new_dist_via_u, distances)\n",
    "\n",
    "        new_distances = jnp.where(is_shorter, new_dist_via_u, distances)\n",
    "        \n",
    "        reset_sigma = jnp.where(is_shorter, sigma[u], sigma)\n",
    "        new_sigma = jnp.where(is_equal, reset_sigma + sigma[u], reset_sigma)\n",
    "        \n",
    "        reset_P_col = jnp.zeros(n_nodes)\n",
    "        updated_P_col = jnp.where(is_shorter, reset_P_col.at[u].set(1), P[u])\n",
    "        updated_P_col = jnp.where(is_equal, updated_P_col.at[u].set(1), updated_P_col)\n",
    "        new_P = P.at[u].set(updated_P_col)\n",
    "\n",
    "        return new_distances, new_sigma, visited, new_P, S\n",
    "\n",
    "    initial_state = (distances, sigma, visited, P, S)\n",
    "    final_distances, final_sigma, _, final_P, final_S = lax.fori_loop(0, n_nodes, dijkstra_body, initial_state)\n",
    "    \n",
    "    # Reorder S by distance for accumulation\n",
    "    sorted_S = final_S[jnp.argsort(final_distances[final_S])]\n",
    "\n",
    "    betweenness_contrib = _accumulate_dependencies_optimized(\n",
    "        sorted_S, final_P.T, final_sigma, source\n",
    "    )\n",
    "    \n",
    "    return betweenness_contrib\n",
    "\n",
    "def _accumulate_dependencies_optimized(\n",
    "    S: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    sigma: jnp.ndarray,\n",
    "    source: int\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Optimized dependency accumulation.\n",
    "    S: stack of nodes in order of INCREASING distance from source.\n",
    "    P: predecessor matrix where P[w, v] = 1 if v is a predecessor of w.\n",
    "    \"\"\"\n",
    "    n_nodes = S.shape[0]\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    \n",
    "    def accumulate_step(i, delta):\n",
    "        # Iterate backwards through S\n",
    "        w = S[n_nodes - 1 - i]\n",
    "        \n",
    "        predecessors_mask = P[w, :] > 0\n",
    "        sigma_w = sigma[w]\n",
    "        \n",
    "        coeff = jnp.where(sigma_w > 0, (sigma / sigma_w) * (1.0 + delta[w]), 0.0)\n",
    "        \n",
    "        delta_update = jnp.sum(jnp.where(predecessors_mask, coeff, 0.0), axis=-1)\n",
    "        new_delta = delta + delta_update * predecessors_mask\n",
    "\n",
    "        return new_delta\n",
    "    \n",
    "    # Corrected logic for accumulation\n",
    "    def body_fn(i, state):\n",
    "        delta, betweenness = state\n",
    "        w = S[n_nodes - 1 - i]\n",
    "\n",
    "        coeff = (1 + delta[w]) / jnp.maximum(sigma[w], 1e-9)\n",
    "        \n",
    "        # Propagate dependency to predecessors\n",
    "        delta_update = jnp.dot(P[w, :], sigma) * coeff\n",
    "        delta = delta.at[jnp.arange(n_nodes)].add(jnp.where(P[w, :] > 0, delta_update, 0))\n",
    "\n",
    "        betweenness = betweenness.at[w].add(delta[w])\n",
    "        \n",
    "        return delta, betweenness\n",
    "\n",
    "    # The dependency accumulation needs to be done carefully\n",
    "    # Using the Brandes algorithm formulation directly\n",
    "    delta = jnp.zeros(n_nodes)\n",
    "    def accumulation_loop(i, state):\n",
    "        delta, betweenness = state\n",
    "        w = S[n_nodes - 1 - i]\n",
    "\n",
    "        # Get predecessors of w\n",
    "        predecessors = P[w, :]\n",
    "        \n",
    "        # Calculate coefficients for predecessors\n",
    "        coeffs = (sigma / jnp.maximum(sigma[w], 1e-9)) * (1 + delta[w])\n",
    "        \n",
    "        # Update delta for all predecessors of w\n",
    "        delta_update = jnp.dot(predecessors, coeffs)\n",
    "        \n",
    "        # The update needs to be applied to the correct indices, which is tricky.\n",
    "        # Let's use a simpler, more direct loop that is still JIT-able.\n",
    "        \n",
    "        w_delta = delta[w]\n",
    "        \n",
    "        def inner_loop(j, current_delta):\n",
    "            v = S[j] # v is a potential predecessor\n",
    "            is_pred = P[w, v] > 0\n",
    "            \n",
    "            update = (sigma[v] / jnp.maximum(sigma[w], 1e-9)) * (1 + w_delta)\n",
    "            \n",
    "            return jnp.where(is_pred, current_delta.at[v].add(update), current_delta)\n",
    "\n",
    "        # This inner loop is inefficient. The vectorized version is better.\n",
    "        # Let's correct the vectorized update.\n",
    "        v_indices = jnp.arange(n_nodes)\n",
    "        is_pred = P[w,:] > 0\n",
    "        update_values = (sigma[v_indices] / jnp.maximum(sigma[w], 1e-9)) * (1 + delta[w])\n",
    "        delta_updates = jnp.where(is_pred, update_values, 0)\n",
    "        \n",
    "        new_delta = delta + delta_updates\n",
    "        new_betweenness = jnp.where(w != source, betweenness.at[w].add(delta[w]), betweenness)\n",
    "        \n",
    "        return new_delta, new_betweenness\n",
    "\n",
    "    initial_state = (jnp.zeros(n_nodes), jnp.zeros(n_nodes))\n",
    "    _, final_betweenness = lax.fori_loop(0, n_nodes, accumulation_loop, initial_state)\n",
    "\n",
    "    return final_betweenness\n",
    "\n",
    "\n",
    "def _rescale_optimized(\n",
    "    betweenness: jnp.ndarray,\n",
    "    n_nodes: int,\n",
    "    normalized: bool,\n",
    "    k: Optional[int],\n",
    "    endpoints: bool,\n",
    "    n_sampled: int,\n",
    "    directed: bool = False\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"Rescales the betweenness values.\"\"\"\n",
    "    if not normalized or n_nodes <= 2:\n",
    "        return betweenness\n",
    "    \n",
    "    # Normalization factor for undirected graphs is (n-1)(n-2)/2\n",
    "    # For directed, it's (n-1)(n-2)\n",
    "    # Since we already divided by 2 for undirected, the scale is the same here.\n",
    "    scale = 1.0 / ((n_nodes - 1) * (n_nodes - 2))\n",
    "    \n",
    "    if k is not None and n_sampled < n_nodes:\n",
    "        scale *= n_nodes / n_sampled\n",
    "    \n",
    "    return betweenness * scale\n",
    "\n",
    "def create_path_graph(n: int) -> jnp.ndarray:\n",
    "    adj = jnp.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        adj = adj.at[i, i + 1].set(1.0)\n",
    "        adj = adj.at[i + 1, i].set(1.0)\n",
    "    return adj\n",
    "\n",
    "def test_optimized_implementation():\n",
    "    print(\"Testing optimized JAX betweenness centrality implementation...\")\n",
    "    \n",
    "    print(\"\\n1. Path graph (5 nodes):\")\n",
    "    path_adj = create_path_graph(5)\n",
    "    \n",
    "    bc_func = jit(functools.partial(betweenness_centrality_jax_optimized, normalized=True))\n",
    "    bc_path = bc_func(adjacency_matrix=path_adj)\n",
    "    \n",
    "    print(f\"Betweenness centrality: {bc_path}\")\n",
    "    \n",
    "    expected_path = jnp.array([0.0, 0.5, 2.0/3.0, 0.5, 0.0])\n",
    "    print(f\"Expected values:        {expected_path}\")\n",
    "    print(f\"Max difference:         {jnp.max(jnp.abs(bc_path - expected_path))}\")\n",
    "    \n",
    "    print(\"\\n2. Path graph with sampling (k=3):\")\n",
    "    bc_sampled_func = jit(functools.partial(betweenness_centrality_jax_optimized, k=3, normalized=True, seed=42))\n",
    "    bc_sampled = bc_sampled_func(adjacency_matrix=path_adj)\n",
    "    print(f\"Sampled betweenness:    {bc_sampled}\")\n",
    "    \n",
    "    print(\"\\nOptimized implementation test completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_optimized_implementation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
