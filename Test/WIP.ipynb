{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db3763f",
   "metadata": {},
   "source": [
    "# Simple classification with CNN\n",
    "from : https://gricad-gitlab.univ-grenoble-alpes.fr/talks/fidle/-/blob/master/MNIST.Keras3/02-CNN-MNIST.ipynb?ref_type=heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289aee70",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7642e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa/work/BI/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.local_device_count 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 15:24:49.116325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751721889.307876   43559 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751721889.362298   43559 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751721889.772036   43559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751721889.772083   43559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751721889.772086   43559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751721889.772088   43559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "from typing import List, Optional, Dict, Any\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "newPath = os.path.dirname(os.path.abspath(\"\"))\n",
    "if newPath not in sys.path:\n",
    "    sys.path.append(newPath)\n",
    "from BI import bi,jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "m = bi(platform='cpu',cores=5)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1681a2",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f3bf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  (60000, 28, 28, 1)\n",
      "y_train :  (60000,)\n",
      "x_test  :  (10000, 28, 28, 1)\n",
      "y_test  :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test  = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "print(\"x_train : \",x_train.shape)\n",
    "print(\"y_train : \",y_train.shape)\n",
    "print(\"x_test  : \",x_test.shape)\n",
    "print(\"y_test  : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e76cefcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAADppJREFUeJzt3H2s1/P/x/HnR6kURZTMyI6IXCyTwjK5Wky2Dm1GzRprhrb+EWFUttAolpKz8ZXWhiHXhlnlYrVyRjbXF9MfWirSlYss5/P74/v9PsevvpzXR+eiut22/ujs/Tjv92mru/dJr0q1Wq0GAETEPm39AAC0H6IAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKLAHmnVqlVRqVTivvvu22Wfc8mSJVGpVGLJkiW77HNCeyMKtBvz5s2LSqUSjY2Nbf0oLWLKlClRqVR2+NGlS5e2fjRIHdv6AWBvM3fu3Nh///3z5x06dGjDp4E/EwVoZaNGjYpDDjmkrR8Ddsq3j9it/Pbbb3HHHXfEqaeeGj169Ihu3brFWWedFYsXL/6fm/vvvz/69u0b++23X5x99tnx0Ucf7XDNZ599FqNGjYqePXtGly5dYtCgQfHiiy/+7fP8/PPP8dlnn8X333/f7K+hWq3G5s2bwwHFtEeiwG5l8+bN8cgjj8SwYcNi+vTpMWXKlFi/fn0MHz48Vq5cucP18+fPj1mzZsUNN9wQt9xyS3z00Udx7rnnxtq1a/Oajz/+OE4//fT49NNPY9KkSTFjxozo1q1bjBw5Mp577rm/fJ4VK1bE8ccfH7Nnz27211BXVxc9evSIAw44IMaMGfOnZ4G25ttH7FYOOuigWLVqVXTq1Ck/Nm7cuDjuuOPiwQcfjEcfffRP13/11Vfx5ZdfxuGHHx4RERdeeGEMGTIkpk+fHjNnzoyIiAkTJsSRRx4Z7733XnTu3DkiIq6//voYOnRo3HzzzVFfX7/Lnn38+PFxxhlnROfOneOdd96JOXPmxIoVK6KxsTG6d+++S+4D/4QosFvp0KFD/sVsU1NTbNy4MZqammLQoEHx/vvv73D9yJEjMwgREYMHD44hQ4bEq6++GjNnzowNGzbEokWL4s4774wtW7bEli1b8trhw4fH5MmTY/Xq1X/6HH80bNiwZn8baMKECX/6+WWXXRaDBw+O0aNHx0MPPRSTJk1q1ueBluTbR+x2Hn/88Tj55JOjS5cucfDBB0evXr3ilVdeiU2bNu1w7THHHLPDx4499thYtWpVRPz7TaJarcbtt98evXr1+tOPyZMnR0TEunXrWuxrufLKK6NPnz7x5ptvttg9oIQ3BXYrCxYsiLFjx8bIkSNj4sSJ0bt37+jQoUPcfffd8fXXXxd/vqampoiIuPHGG2P48OE7vaZfv37/6Jn/zhFHHBEbNmxo0XtAc4kCu5Vnnnkm6urqYuHChVGpVPLj//2v+v/vyy+/3OFjX3zxRRx11FER8e+/9I2I2HfffeP888/f9Q/8N6rVaqxatSpOOeWUVr837IxvH7Fb+e/fJ/zx+/jLly+PZcuW7fT6559/PlavXp0/X7FiRSxfvjwuuuiiiIjo3bt3DBs2LBoaGmLNmjU77NevX/+Xz1Pyv6Tu7HPNnTs31q9fHxdeeOHf7qE1eFOg3fnXv/4Vr7322g4fnzBhQowYMSIWLlwY9fX1cfHFF8c333wTDz/8cAwYMCC2bt26w6Zfv34xdOjQuO6662Lbtm3xwAMPxMEHHxw33XRTXjNnzpwYOnRonHTSSTFu3Lioq6uLtWvXxrJly+Lbb7+NDz/88H8+64oVK+Kcc86JyZMnx5QpU/7y6+rbt29cfvnlcdJJJ0WXLl3i3XffjSeffDIGDhwY1157bfN/gaAFiQLtzty5c3f68bFjx8bYsWPju+++i4aGhnj99ddjwIABsWDBgnj66ad3elDdVVddFfvss0888MADsW7duhg8eHDMnj07DjvssLxmwIAB0djYGFOnTo158+bFDz/8EL17945TTjkl7rjjjl32dY0ePTqWLl0azz77bPz666/Rt2/fuOmmm+K2226Lrl277rL7wD9RqfpnlQD8h79TACCJAgBJFABIogBAEgUAkigAkJr97xT+eKQAALuf5vwLBG8KACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKSObf0A8Hc6dOhQvOnRo0cLPMmuMX78+Jp2Xbt2Ld7079+/eHPDDTcUb+67777izRVXXFG8iYj49ddfizf33HNP8Wbq1KnFmz2BNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH4u1hjjzyyOJNp06dijdnnnlm8Wbo0KHFm4iIAw88sHhz2WWX1XSvPc23335bvJk1a1bxpr6+vnizZcuW4k1ExIcffli8eeutt2q6197ImwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKlWq1Wm3VhpdLSz8IfDBw4sKbdokWLijc9evSo6V60rqampuLN1VdfXbzZunVr8aYWa9asqWn3448/Fm8+//zzmu61p2nOH/feFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOSU1HaqZ8+eNe2WL19evKmrq6vpXnuaWn7tNm7cWLw555xzijcREb/99lvxxgm4/JFTUgEoIgoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKljWz8AO7dhw4aadhMnTizejBgxonjzwQcfFG9mzZpVvKnVypUrizcXXHBB8eann34q3pxwwgnFm4iICRMm1LSDEt4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQKtVqtdqsCyuVln4W2kj37t2LN1u2bCneNDQ0FG8iIq655prizZgxY4o3TzzxRPEGdifN+ePemwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFLHtn4A2t7mzZtb5T6bNm1qlftERIwbN65489RTTxVvmpqaijfQnnlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUqVarVabdWGl0tLPwh6uW7duNe1eeuml4s3ZZ59dvLnooouKN2+88UbxBtpKc/6496YAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkQDzavaOPPrp48/777xdvNm7cWLxZvHhx8aaxsbF4ExExZ86c4k0zf3uzl3AgHgBFRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIDkQjz1SfX198eaxxx4r3hxwwAHFm1rdeuutxZv58+cXb9asWVO8YffgQDwAiogCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByIB78x4knnli8mTlzZvHmvPPOK97UqqGhoXgzbdq04s3q1auLN7Q+B+IBUEQUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSA/HgHzjwwAOLN5dccklN93rssceKN7X8vl20aFHx5oILLije0PociAdAEVEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBySirsJrZt21a86dixY/Fm+/btxZvhw4cXb5YsWVK84Z9xSioARUQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCVn5YFe6iTTz65eDNq1KjizWmnnVa8iajtcLtafPLJJ8Wbt99+uwWehLbgTQGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAMmBeLR7/fv3L96MHz++eHPppZcWb/r06VO8aU2///578WbNmjXFm6ampuIN7ZM3BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJAfiUZNaDoK74oorarpXLYfbHXXUUTXdqz1rbGws3kybNq148+KLLxZv2HN4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHIg3h7m0EMPLd4MGDCgeDN79uzizXHHHVe8ae+WL19evLn33ntrutcLL7xQvGlqaqrpXuy9vCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJKamtoGfPnsWbhoaGmu41cODA4k1dXV1N92rPli5dWryZMWNG8eb1118v3vzyyy/FG2gt3hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD26gPxhgwZUryZOHFi8Wbw4MHFm8MPP7x40979/PPPNe1mzZpVvLnrrruKNz/99FPxBvY03hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD26gPx6uvrW2XTmj755JPizcsvv1y82b59e/FmxowZxZuIiI0bN9a0A8p5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQKpUq9Vqsy6sVFr6WQBoQc35496bAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKSOzb2wWq225HMA0A54UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg/R+J6Mjw+/r7+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the first image from the training set\n",
    "image = x_train[0]\n",
    "\n",
    "# Reshape from (28, 28, 1) to (28, 28) for visualization\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {y_train[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49399f80",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00d6b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization : Min=0, max=255\n",
      "After normalization  : Min=0.0, max=1.0\n"
     ]
    }
   ],
   "source": [
    "print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n",
    "\n",
    "xmax=x_train.max()\n",
    "x_train = x_train / xmax\n",
    "x_test  = x_test  / xmax\n",
    "\n",
    "print('After normalization  : Min={}, max={}'.format(x_train.min(),x_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a47a80",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b8bbe",
   "metadata": {},
   "source": [
    "### Custom functions for BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3793857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "def cnn2D(\n",
    "    image: jnp.ndarray,\n",
    "    kernel: jnp.ndarray, # Changed from optional to required for use in a model\n",
    "    padding: str = 'VALID',\n",
    "    strides: tuple[int, int] = (1, 1)\n",
    ") -> jnp.ndarray: # Simplified return to just the feature map\n",
    "    \"\"\"\n",
    "    Applies a 2D convolution kernel to a 2D image ( Feature Extraction). This function is a low-level wrapper for JAX's convolution operator. It handles the necessary reshaping for a single image and kernel.\n",
    "    - *What it does*: It slides a small matrix of weights, called a kernel or filter, over the image. At each position, it computes a dot product between the kernel and the patch of the image it's covering. This produces a single value in the output feature map.\n",
    "    - *Why it's essential*: Each kernel learns to recognize a specific, simple feature. For example, in the first layer, one kernel might learn to detect vertical edges, another might detect horizontal edges, and a third might detect a specific color or texture. The output feature map is essentially a map showing where in the image that specific feature was found.\n",
    "    - *Analogy*: Think of the kernel as a small magnifying glass or a flashlight beam that you slide over a large document. This    flashlight is designed to light up only when it sees a specific pattern (e.g., the letter 'e'). The resulting feature map is a     new document where the only bright spots are the locations of the letter 'e'.\n",
    "\n",
    "    Args:\n",
    "        image: A 2D JAX array representing the input image (H, W).\n",
    "        kernel: A 2D JAX array representing the convolution kernel (kH, kW).\n",
    "                In a real model, this kernel is a learnable parameter.\n",
    "        padding: 'VALID' (no padding) or 'SAME' (pads to keep output size same as input).\n",
    "        strides: The stride of the convolution. Not used in the Keras example but good to have.\n",
    "\n",
    "    Returns:\n",
    "        The 2D feature map resulting from the convolution.\n",
    "    \"\"\"\n",
    "    if image.ndim != 2:\n",
    "        raise ValueError(\"Input `image` must be a 2D array.\")\n",
    "    if kernel.ndim != 2:\n",
    "        raise ValueError(\"Input `kernel` must be a 2D array.\")\n",
    "\n",
    "    # --- Pre-processing for JAX's convolution operator ---\n",
    "    # `lax.conv_general_dilated` is highly optimized but requires specific 4D input shapes.\n",
    "    # The format is (N, H, W, C): Batch, Height, Width, Channels.\n",
    "    # Since we are processing one image and one channel, we add empty axes.\n",
    "    image_reshaped = image[jnp.newaxis, ..., jnp.newaxis]  # (H, W) -> (1, H, W, 1)\n",
    "\n",
    "    # The kernel format is (H, W, I, O): Height, Width, Input Channels, Output Channels.\n",
    "    # We are mapping 1 input channel to 1 output channel.\n",
    "    kernel_reshaped = kernel[..., jnp.newaxis, jnp.newaxis] # (kH, kW) -> (kH, kW, 1, 1)\n",
    "\n",
    "    # --- The Convolution Operation ---\n",
    "    # This is the core computation where the kernel is slid across the image.\n",
    "    output = lax.conv_general_dilated(\n",
    "        lhs=image_reshaped,                          # The input image\n",
    "        rhs=kernel_reshaped,                         # The filter (weights)\n",
    "        window_strides=strides,                      # How many pixels to slide the kernel\n",
    "        padding=padding.upper(),                     # How to handle borders\n",
    "        dimension_numbers=('NHWC', 'HWIO', 'NHWC')   # Specifies the meaning of each dimension\n",
    "    )\n",
    "\n",
    "    # --- Post-processing ---\n",
    "    # The output is 4D, so we squeeze it back to a 2D feature map for clarity.\n",
    "    output_feature_map = jnp.squeeze(output, axis=(0, 3))\n",
    "\n",
    "    return output_feature_map\n",
    "\n",
    "\n",
    "def cnn_max_pool(\n",
    "    feature_map: jnp.ndarray,\n",
    "    window_shape: Tuple[int, int] = (2, 2),\n",
    "    strides: Tuple[int, int] = (2, 2)\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Performs max pooling to downsample a feature map (Downsampling and Invariance).\n",
    "    What it does: It slides a window over the feature map and, for each region, takes the maximum value. This drastically reduces the size of the feature map (e.g., a 2x2 window with a stride of 2 will halve the height and width).\n",
    "    - *Why it's essential*:\n",
    "    - *Computational Efficiency*: Smaller feature maps mean fewer parameters and computations in subsequent layers.\n",
    "    - *Translational Invariance*: By taking the max value, the network becomes less sensitive to the exact location of the feature. If  the vertical edge moves one pixel to the right, the max value in the pooling window will likely be the same. This makes the  model more robust.\n",
    "    - *Analogy*: Imagine a detailed map of a city. Max pooling is like dividing the map into a grid and, for each square, only keeping  a record of the tallest building in that square. You lose fine-grained detail, but you get a smaller, more abstract summary of   the city's skyline that is easier to process.\n",
    "\n",
    "    Args:\n",
    "        feature_map: Input array. Can be a single 2D map (H, W) or a\n",
    "                     3D map with channels (H, W, C).\n",
    "        window_shape: The (height, width) of the pooling window.\n",
    "        strides: How many pixels to move the window at each step.\n",
    "\n",
    "    Returns:\n",
    "        The downsampled JAX array.\n",
    "    \"\"\"\n",
    "    # --- Pre-processing for JAX's reduce_window operator ---\n",
    "    # Just like convolution, this operator expects 4D input (N, H, W, C).\n",
    "    if feature_map.ndim == 2:  # (H, W)\n",
    "        image_reshaped = feature_map[jnp.newaxis, ..., jnp.newaxis] # -> (1, H, W, 1)\n",
    "    elif feature_map.ndim == 3: # (H, W, C)\n",
    "        image_reshaped = feature_map[jnp.newaxis, ...] # -> (1, H, W, C)\n",
    "    else:\n",
    "        raise ValueError(f\"Input must be 2D or 3D, but got {feature_map.ndim} dims.\")\n",
    "\n",
    "    # The pooling window should not reduce across the batch or channel dimensions.\n",
    "    # It operates independently on each feature map.\n",
    "    full_window_shape = (1, window_shape[0], window_shape[1], 1)\n",
    "    full_strides = (1, strides[0], strides[1], 1)\n",
    "\n",
    "    # --- The Pooling Operation ---\n",
    "    # `lax.reduce_window` slides a window over the input and applies a\n",
    "    # reduction function (`lax.max`) to the elements within that window.\n",
    "    output = lax.reduce_window(\n",
    "        operand=image_reshaped,\n",
    "        init_value=-jnp.inf,      # The identity for max operation\n",
    "        computation=lax.max,      # The reduction function\n",
    "        window_dimensions=full_window_shape,\n",
    "        window_strides=full_strides,\n",
    "        padding='VALID'\n",
    "    )\n",
    "\n",
    "    # --- Post-processing ---\n",
    "    # Squeeze the batch dimension back out to match input style.\n",
    "    return jnp.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "from jax import random\n",
    "from functools import partial\n",
    "\n",
    "@partial(jax.jit, static_argnames=['training', 'rate'])\n",
    "def dropout(\n",
    "    inputs: jnp.ndarray,\n",
    "    rate: float,\n",
    "    key: jnp.ndarray,\n",
    "    training: bool = True\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Applies dropout to prevent overfitting.Dropout is a technique to make the network more robust and less reliant on any single neuron  (Preventing Overfitting).During training, it randomly sets a fraction of input units to 0.During inference (testing), it does nothing.\n",
    "\n",
    "    - *What it does*: During training, it randomly \"turns off\" (sets to zero) a fraction of the neurons in a layer for each training example.\n",
    "    - *Why it's essential*: This forces the network to learn redundant representations. It can't rely on a few specific neurons to make     a decision, because they might be dropped out at any moment. Other neurons must learn to pick up the slack. This prevents the   model from \"memorizing\" the training data (overfitting) and helps it generalize better to new, unseen data.\n",
    "    - *Analogy*: It's like training a basketball team where, in every practice scrimmage, you randomly send one or two players to the   bench. The team learns to win without being dependent on any single star player. They develop a more resilient and flexible   team-based strategy.\n",
    "\n",
    "    Args:\n",
    "        inputs: The input array to apply dropout to.\n",
    "        rate: The fraction of input units to drop (e.g., 0.2 means 20%).\n",
    "        key: A JAX PRNGKey for generating the random dropout mask.\n",
    "        training: If True, applies dropout. If False, returns inputs untouched.\n",
    "\n",
    "    Returns:\n",
    "        The array with dropout applied.\n",
    "    \"\"\"\n",
    "    # --- Bypass during inference ---\n",
    "    # Dropout should only be active during training.\n",
    "    if not training or rate == 0:\n",
    "        return inputs\n",
    "\n",
    "    # --- Create a random mask ---\n",
    "    # The probability of keeping a unit (not dropping it).\n",
    "    keep_prob = 1.0 - rate\n",
    "    # Generate a random mask of 1s and 0s with the same shape as the input.\n",
    "    mask = random.bernoulli(key, p=keep_prob, shape=inputs.shape)\n",
    "\n",
    "    # --- Apply mask and scale ---\n",
    "    # Apply the mask. Where mask is 0, the output is 0.\n",
    "    # Crucially, we scale up the remaining values by `1 / keep_prob`.\n",
    "    # This ensures that the expected sum of the outputs remains the same,\n",
    "    # so we don't need to make any changes during inference. This is called\n",
    "    # \"inverted dropout\".\n",
    "    return jnp.where(mask, inputs / keep_prob, 0)\n",
    "\n",
    "def flatten(feature_maps: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Reshapes a batch of 3D feature maps into a 2D matrix.The Flatten operation is the bridge between the convolutional part of the network and the dense (fully-connected) part.\n",
    "\n",
    "    This prepares the output of the convolutional layers to be fed into\n",
    "    a dense (fully-connected) layer.\n",
    "\n",
    "    Role in a CNN: Transitioning from Feature Maps to a Feature Vector\n",
    "    - *What it does*: It takes the multi-dimensional output of the final pooling layer (e.g., (height, width, channels)) and collapses  it into a single, long 1D vector.\n",
    "    - *Why it's essential*: Convolutional and pooling layers are great at processing spatial data and creating feature maps. However,   to make a final classification, we need to use standard Dense layers. Dense layers expect a 1D vector of features as input, not   a 3D tensor. The flatten layer performs this crucial reshaping.\n",
    "    - *Analogy*: You've just analyzed a painting by noting the presence of \"a smiling mouth here,\" \"a blue background there,\" and \"a    sharp nose here.\" The flatten layer is like taking all these separate notes and writing them down in a single long list before     handing it to a person who will make the final judgment (\"This is the Mona Lisa\").\n",
    "\n",
    "    Args:\n",
    "        feature_maps: A 3D tensor of shape (H, W, C).\n",
    "\n",
    "    Returns:\n",
    "        A 2D tensor of shape (1, H * W * C).\n",
    "    \"\"\"\n",
    "    # The -1 tells reshape to automatically calculate the size of this dimension.\n",
    "    # For example, an input of (5, 5, 16) becomes (1, 5 * 5 * 16) = (1, 400).\n",
    "    return jnp.ravel(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(image, shape=(3,3)):\n",
    "    # ce qui sera appris sera les kernel et les biais, les kernels doivent donc etre defini anvec des distributions\n",
    "    cov1=cnn2D(image, shape=shape)\n",
    "    cov1=jax.nn.relu(cov1)\n",
    "    pool1=cnn_max_pool(cov1)\n",
    "    step1=dropout(pool1, rate=0.5)\n",
    "\n",
    "    cov2=cnn2D(image, shape=shape)\n",
    "    cov2=jax.nn.relu(cov2)\n",
    "    pool2=cnn_max_pool(cov2)\n",
    "    step2=dropout(pool2, rate=0.5)\n",
    "    \n",
    "    f=CNNWithFlatten(step2)\n",
    "    dens=m.bnn.layer(f,dist.normal(0,1),activation = \"relu\")\n",
    "    step3=dropout(dens, rate=0.5)\n",
    "\n",
    "    dens=m.bnn.layer(step3,dist.normal(0,1),activation = \"relu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f433d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from jax.nn import relu, log_softmax\n",
    "\n",
    "# Helper for a simple dense layer\n",
    "def dense_layer(inputs, out_dim):\n",
    "    in_dim = inputs.shape[-1]\n",
    "    # Define learnable weights and biases for the dense layer\n",
    "    W = numpyro.param('W', dist.Normal(0, 0.01).sample(numpyro.prng_key(), (in_dim, out_dim)))\n",
    "    b = numpyro.param('b', dist.Normal(0, 0.01).sample(numpyro.prng_key(), (out_dim,)))\n",
    "    return jnp.dot(inputs, W) + b\n",
    "\n",
    "def cnn_model(images, labels=None, training=True):\n",
    "    \"\"\"\n",
    "    A NumPyro model recreating the Keras Sequential model.\n",
    "    \"\"\"\n",
    "    # Input images are expected to be (N, 28, 28, 1) where N is batch size\n",
    "    # We will process one image at a time for simplicity in this model structure.\n",
    "    # A batched version would use jax.vmap.\n",
    "    \n",
    "    # Let's define a function for a single image\n",
    "    def predict(img):\n",
    "        # Remove channel dim for our helper functions\n",
    "        img = jnp.squeeze(img, axis=-1) # (28, 28, 1) -> (28, 28)\n",
    "\n",
    "        # --- Layer 1: Conv2D(8, (3,3)) + ReLU ---\n",
    "        # Define 8 kernels of size (3,3) as learnable parameters\n",
    "        kernels_1 = numpyro.param('k1', dist.Normal(0, 0.01).sample(numpyro.prng_key(), (8, 3, 3)))\n",
    "        # Apply each kernel to the image and stack the results\n",
    "        # This creates 8 feature maps, giving us a (H, W, 8) tensor\n",
    "        x = jnp.stack([relu(cnn2D(img, k)) for k in kernels_1], axis=-1)\n",
    "\n",
    "        # --- Layer 2: MaxPooling2D((2,2)) ---\n",
    "        x = cnn_max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        # --- Layer 3: Dropout(0.2) ---\n",
    "        x = dropout(x, rate=0.2, key=numpyro.prng_key(), training=training)\n",
    "\n",
    "        # --- Layer 4: Conv2D(16, (3,3)) + ReLU ---\n",
    "        # The input to this layer has 8 channels. The output will have 16.\n",
    "        # So we need a kernel of shape (16, 8, 3, 3) -> (out_channels, in_channels, H, W)\n",
    "        kernels_2 = numpyro.param('k2', dist.Normal(0, 0.01).sample(numpyro.prng_key(), (16, 8, 3, 3)))\n",
    "        \n",
    "        # This convolution is more complex: each output map depends on all input maps\n",
    "        # We need a more advanced convolution function for this, but for demonstration,\n",
    "        # we'll approximate it by convolving and summing. A real implementation uses `lax.conv` directly.\n",
    "        output_maps = []\n",
    "        for k_out in kernels_2: # For each of the 16 output kernels\n",
    "            # Convolve the 8 input channels with the 8 parts of the kernel and sum them up\n",
    "            channel_convs = jnp.stack([cnn2D(x[..., i], k_out[i]) for i in range(8)])\n",
    "            output_map = jnp.sum(channel_convs, axis=0)\n",
    "            output_maps.append(relu(output_map))\n",
    "        x = jnp.stack(output_maps, axis=-1)\n",
    "\n",
    "        # --- Layer 5: MaxPooling2D((2,2)) ---\n",
    "        x = cnn_max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        # --- Layer 6: Dropout(0.2) ---\n",
    "        x = dropout(x, rate=0.2, key=numpyro.prng_key(), training=training)\n",
    "\n",
    "        # --- Layer 7: Flatten ---\n",
    "        x = flatten(x)\n",
    "\n",
    "        # --- Layer 8: Dense(100) + ReLU ---\n",
    "        with numpyro.plate('d1', 1): # A plate for the dense layer parameters\n",
    "            x = relu(dense_layer(x, 100))\n",
    "\n",
    "        # --- Layer 9: Dropout(0.5) ---\n",
    "        x = dropout(x, rate=0.5, key=numpyro.prng_key(), training=training)\n",
    "\n",
    "        # --- Layer 10: Dense(10) ---\n",
    "        with numpyro.plate('d2', 1): # Another plate for the final layer\n",
    "            logits = dense_layer(x, 10)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    # Use jax.vmap to apply the per-image predict function over the entire batch\n",
    "    # This is a powerful JAX feature that automatically vectorizes the function.\n",
    "    batch_predict = jax.vmap(predict)\n",
    "    all_logits = batch_predict(images)\n",
    "\n",
    "    # --- Final Layer: Softmax (implicit in Categorical) and Sampling ---\n",
    "    with numpyro.plate(\"data\", images.shape[0]):\n",
    "        # The `obs=labels` part connects the model's prediction to the actual data.\n",
    "        # This is what allows numpyro to calculate the likelihood for training/inference.\n",
    "        numpyro.sample(\"obs\", dist.Categorical(logits=all_logits), obs=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9f18c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from jax.nn import relu, log_softmax\n",
    "\n",
    "# (Re-include your helper functions cnn2D, cnn_max_pool, flatten, dropout here)\n",
    "# ...\n",
    "\n",
    "def cnn_model_mcmc(images, labels=None, total_data_size=None, training=True):\n",
    "    \"\"\"\n",
    "    A NumPyro CNN model adapted for MCMC with subsampling.\n",
    "    \"\"\"\n",
    "    # --- Define Priors for the Learnable Weights ---\n",
    "    # The kernel for the first conv layer: 8 filters of size 3x3\n",
    "    k1 = numpyro.sample('k1', dist.Normal(jnp.zeros((8, 3, 3)), jnp.ones((8, 3, 3))))\n",
    "\n",
    "    # The kernel for the second conv layer. Input has 8 channels, output 16.\n",
    "    # Shape is (out_channels, in_channels, height, width)\n",
    "    k2 = numpyro.sample('k2', dist.Normal(jnp.zeros((16, 8, 3, 3)), jnp.ones((16, 8, 3, 3))))\n",
    "\n",
    "    # Weights and biases for the two dense layers\n",
    "    # Dense 1: 400 -> 100\n",
    "    w1 = numpyro.sample('w1', dist.Normal(jnp.zeros((400, 100)), jnp.ones((400, 100))))\n",
    "    b1 = numpyro.sample('b1', dist.Normal(jnp.zeros(100), jnp.ones(100)))\n",
    "    # Dense 2: 100 -> 10\n",
    "    w2 = numpyro.sample('w2', dist.Normal(jnp.zeros((100, 10)), jnp.ones((100, 10))))\n",
    "    b2 = numpyro.sample('b2', dist.Normal(jnp.zeros(10), jnp.ones(10)))\n",
    "\n",
    "    # --- Define the forward pass for a single image ---\n",
    "    def predict(img):\n",
    "        # Layer 1: Conv2D(8, (3,3)) + ReLU\n",
    "        # Note: This simplified convolution is for demonstration.\n",
    "        # A full implementation would use lax.conv_general_dilated for multi-channel input.\n",
    "        img = jnp.squeeze(img, axis=-1)\n",
    "        x = jnp.stack([relu(cnn2D(img, k)) for k in k1], axis=-1) # Becomes (26, 26, 8)\n",
    "        \n",
    "        # Layer 2: MaxPool + Dropout\n",
    "        x = cnn_max_pool(x) # Becomes (13, 13, 8)\n",
    "        x = dropout(x, 0.2, key=numpyro.prng_key(), training=training)\n",
    "\n",
    "        # A simplified second conv layer for this example\n",
    "        # We just convolve the first channel of the input with each of the 16 filters\n",
    "        x_ch0 = x[..., 0] # Use first channel as representative input\n",
    "        x = jnp.stack([relu(cnn2D(x_ch0, k[0])) for k in k2], axis=-1) # Becomes (11, 11, 16)\n",
    "\n",
    "        # Layer 5-7: MaxPool -> Dropout -> Flatten\n",
    "        x = cnn_max_pool(x) # Becomes (5, 5, 16) -> 400 elements\n",
    "        x = dropout(x, 0.2, key=numpyro.prng_key(), training=training)\n",
    "        x = flatten(x) # Becomes (400,)\n",
    "\n",
    "        # Layer 8: Dense(100) + ReLU\n",
    "        x = relu(jnp.dot(x, w1) + b1)\n",
    "        x = dropout(x, 0.5, key=numpyro.prng_key(), training=training)\n",
    "        \n",
    "        # Layer 10: Dense(10) (Output logits)\n",
    "        logits = jnp.dot(x, w2) + b2\n",
    "        return logits\n",
    "\n",
    "    # --- The MCMC Subsampling Plate ---\n",
    "    # This is the key part!\n",
    "    # We declare the plate over the *entire* dataset size.\n",
    "    # When we run MCMC, we'll only pass a `batch_size` number of `images`.\n",
    "    # NumPyro scales the log probability from the batch to estimate it for the full data.\n",
    "    with numpyro.plate(\"data\", size=total_data_size, subsample_size=images.shape[0]):\n",
    "        # The `vmap` automatically vectorizes the `predict` function over the batch of images.\n",
    "        batch_logits = jax.vmap(predict)(images)\n",
    "        # The `obs` statement links the model's output to the observed data.\n",
    "        numpyro.sample(\"obs\", dist.Categorical(logits=batch_logits), obs=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fc83000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43559/3037664488.py:65: UserWarning: subsample_size does not match len(subsample), 60000 vs 1000. Did you accidentally use different subsample_size in the model and guide?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: shapes=[(1000,), (60000,)]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:219\u001b[39m, in \u001b[36m_broadcast_shapes_uncached\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_try_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrank_promoted_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbroadcast_shapes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    221\u001b[39m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:136\u001b[39m, in \u001b[36m_try_broadcast_shapes\u001b[39m\u001b[34m(name, *shapes)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got incompatible shapes for broadcasting: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    137\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[31mTypeError\u001b[39m: broadcast_shapes got incompatible shapes for broadcasting: (1000,), (60000,).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:197\u001b[39m, in \u001b[36mbroadcast_shapes\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/util.py:299\u001b[39m, in \u001b[36mcache.<locals>.wrap.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrace_context_in_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_ignore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m              \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/util.py:293\u001b[39m, in \u001b[36mcache.<locals>.wrap.<locals>.cached\u001b[39m\u001b[34m(_, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(max_size)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached\u001b[39m(_, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:203\u001b[39m, in \u001b[36m_broadcast_shapes_cached\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_broadcast_shapes_cached\u001b[39m(*shapes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...]) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...]:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:222\u001b[39m, in \u001b[36m_broadcast_shapes_uncached\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    221\u001b[39m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Incompatible shapes for broadcasting: shapes=[(1000,), (60000,)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:219\u001b[39m, in \u001b[36m_broadcast_shapes_uncached\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_try_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrank_promoted_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbroadcast_shapes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    221\u001b[39m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:136\u001b[39m, in \u001b[36m_try_broadcast_shapes\u001b[39m\u001b[34m(name, *shapes)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got incompatible shapes for broadcasting: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    137\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[31mTypeError\u001b[39m: broadcast_shapes got incompatible shapes for broadcasting: (1000,), (60000,).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m rng_key = random.PRNGKey(\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Here, we pass the BATCH of data, but we also tell the model the size of the FULL dataset.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mmcmc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_data_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_data_for_mcmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 4. Print the summary\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# This shows statistics for the posterior distribution of each parameter (k1, w1, etc.)\u001b[39;00m\n\u001b[32m     35\u001b[39m mcmc.print_summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/mcmc.py:702\u001b[39m, in \u001b[36mMCMC.run\u001b[39m\u001b[34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m map_args = (rng_key, init_state, init_params)\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_chains == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m     states_flat, last_state = \u001b[43mpartial_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    703\u001b[39m     states = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[jnp.newaxis, ...], states_flat)\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/mcmc.py:465\u001b[39m, in \u001b[36mMCMC._single_chain_mcmc\u001b[39m\u001b[34m(self, init, args, kwargs, collect_fields, remove_sites)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Check if _sample_fn is None, then we need to initialize the sampler.\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sampler, \u001b[33m\"\u001b[39m\u001b[33m_sample_fn\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     new_init_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m     init_state = new_init_state \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m init_state\n\u001b[32m    473\u001b[39m sample_fn, postprocess_fn = \u001b[38;5;28mself\u001b[39m._get_cached_fns()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/hmc.py:751\u001b[39m, in \u001b[36mHMC.init\u001b[39m\u001b[34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;66;03m# vectorized\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    748\u001b[39m     rng_key, rng_key_init_model = jnp.swapaxes(\n\u001b[32m    749\u001b[39m         vmap(random.split)(rng_key), \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m\n\u001b[32m    750\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m init_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrng_key_init_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._potential_fn \u001b[38;5;129;01mand\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    755\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    756\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mValid value of `init_params` must be provided with `potential_fn`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    757\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/hmc.py:695\u001b[39m, in \u001b[36mHMC._init_state\u001b[39m\u001b[34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_init_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    690\u001b[39m         (\n\u001b[32m    691\u001b[39m             new_init_params,\n\u001b[32m    692\u001b[39m             potential_fn,\n\u001b[32m    693\u001b[39m             postprocess_fn,\n\u001b[32m    694\u001b[39m             model_trace,\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m         ) = \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m            \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforward_mode_differentiation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_mode_differentiation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    704\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    705\u001b[39m             init_params = new_init_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/util.py:688\u001b[39m, in \u001b[36minitialize_model\u001b[39m\u001b[34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[39m\n\u001b[32m    678\u001b[39m model_kwargs = {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[32m    679\u001b[39m substituted_model = substitute(\n\u001b[32m    680\u001b[39m     seed(model, rng_key \u001b[38;5;28;01mif\u001b[39;00m is_prng_key(rng_key) \u001b[38;5;28;01melse\u001b[39;00m rng_key[\u001b[32m0\u001b[39m]),\n\u001b[32m    681\u001b[39m     substitute_fn=init_strategy,\n\u001b[32m    682\u001b[39m )\n\u001b[32m    683\u001b[39m (\n\u001b[32m    684\u001b[39m     inv_transforms,\n\u001b[32m    685\u001b[39m     replay_model,\n\u001b[32m    686\u001b[39m     has_enumerate_support,\n\u001b[32m    687\u001b[39m     model_trace,\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m ) = \u001b[43m_get_model_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstituted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m model_trace.items():\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    692\u001b[39m         site[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    693\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(site[\u001b[33m\"\u001b[39m\u001b[33mfn\u001b[39m\u001b[33m\"\u001b[39m], dist.Delta)\n\u001b[32m    694\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m site[\u001b[33m\"\u001b[39m\u001b[33mis_observed\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    695\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/infer/util.py:482\u001b[39m, in \u001b[36m_get_model_transforms\u001b[39m\u001b[34m(model, model_args, model_kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_model_transforms\u001b[39m(model, model_args=(), model_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    481\u001b[39m     model_kwargs = {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     model_trace = \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m     inv_transforms = {}\n\u001b[32m    484\u001b[39m     \u001b[38;5;66;03m# model code may need to be replayed in the presence of deterministic sites\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/handlers.py:191\u001b[39m, in \u001b[36mtrace.get_trace\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> OrderedDict[\u001b[38;5;28mstr\u001b[39m, Message]:\n\u001b[32m    184\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    189\u001b[39m \u001b[33;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trace\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:121\u001b[39m, in \u001b[36mMessenger.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:121\u001b[39m, in \u001b[36mMessenger.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/handlers.py:846\u001b[39m, in \u001b[36mseed.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    842\u001b[39m     cloned_seeded_fn = seed(\n\u001b[32m    843\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, rng_seed=\u001b[38;5;28mself\u001b[39m.rng_key, hide_types=\u001b[38;5;28mself\u001b[39m.hide_types\n\u001b[32m    844\u001b[39m     )\n\u001b[32m    845\u001b[39m     cloned_seeded_fn.stateful = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloned_seeded_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/handlers.py:847\u001b[39m, in \u001b[36mseed.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     cloned_seeded_fn.stateful = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cloned_seeded_fn.\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:121\u001b[39m, in \u001b[36mMessenger.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mcnn_model_mcmc\u001b[39m\u001b[34m(images, labels, total_data_size, training)\u001b[39m\n\u001b[32m     67\u001b[39m batch_logits = jax.vmap(predict)(images)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# The `obs` statement links the model's output to the observed data.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mnumpyro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_logits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:250\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(name, fn, obs, rng_key, sample_shape, infer, obs_mask)\u001b[39m\n\u001b[32m    235\u001b[39m initial_msg = {\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minfer\u001b[39m\u001b[33m\"\u001b[39m: {} \u001b[38;5;28;01mif\u001b[39;00m infer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m infer,\n\u001b[32m    247\u001b[39m }\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# ...and use apply_stack to send it to the Messengers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m msg = \u001b[43mapply_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m msg[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:55\u001b[39m, in \u001b[36mapply_stack\u001b[39m\u001b[34m(msg)\u001b[39m\n\u001b[32m     53\u001b[39m pointer = \u001b[32m0\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pointer, handler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(_PYRO_STACK)):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# When a Messenger sets the \"stop\" field of a message,\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# it prevents any Messengers above it on the stack from being applied.\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m msg.get(\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/numpyro/primitives.py:592\u001b[39m, in \u001b[36mplate.process_message\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    590\u001b[39m overlap_idx = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(expected_shape) - \u001b[38;5;28mlen\u001b[39m(dist_batch_shape), \u001b[32m0\u001b[39m)\n\u001b[32m    591\u001b[39m trailing_shape = expected_shape[overlap_idx:]\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m broadcast_shape = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrailing_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdist_batch_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    595\u001b[39m batch_shape = expected_shape[:overlap_idx] + broadcast_shape\n\u001b[32m    596\u001b[39m msg[\u001b[33m\"\u001b[39m\u001b[33mfn\u001b[39m\u001b[33m\"\u001b[39m] = msg[\u001b[33m\"\u001b[39m\u001b[33mfn\u001b[39m\u001b[33m\"\u001b[39m].expand(batch_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:199\u001b[39m, in \u001b[36mbroadcast_shapes\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    197\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _broadcast_shapes_cached(*shapes)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/BI/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:222\u001b[39m, in \u001b[36m_broadcast_shapes_uncached\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    219\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _try_broadcast_shapes(*rank_promoted_shapes, name=\u001b[33m'\u001b[39m\u001b[33mbroadcast_shapes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    221\u001b[39m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Incompatible shapes for broadcasting: shapes=[(1000,), (60000,)]"
     ]
    }
   ],
   "source": [
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "# 1. Set up the MCMC kernel\n",
    "# The NUTS kernel is a good general-purpose choice.\n",
    "kernel = NUTS(cnn_model_mcmc)\n",
    "\n",
    "# 2. Set up the MCMC runner\n",
    "num_warmup = 500\n",
    "num_samples = 1000\n",
    "\n",
    "# This makes the example runnable in a reasonable time.\n",
    "# For a real run, you might use the full 60k, but it will be very slow.\n",
    "num_data_for_mcmc = 1000\n",
    "batch_size = 100\n",
    "\n",
    "x_subset = x_train[:num_data_for_mcmc]\n",
    "y_subset = y_train[:num_data_for_mcmc]\n",
    "\n",
    "mcmc = MCMC(\n",
    "    kernel,\n",
    "    num_warmup=num_warmup,\n",
    "    num_samples=num_samples,\n",
    "    num_chains=1, # Use 1 chain for speed. For robust results, use 2 or more.\n",
    "    progress_bar=True,\n",
    "    jit_model_args=True # JIT-compiles the model for speed\n",
    ")\n",
    "\n",
    "# 3. Run the MCMC\n",
    "rng_key = random.PRNGKey(0)\n",
    "# Here, we pass the BATCH of data, but we also tell the model the size of the FULL dataset.\n",
    "mcmc.run(rng_key, images=x_train, labels=y_train, total_data_size=num_data_for_mcmc, training=True)\n",
    "\n",
    "# 4. Print the summary\n",
    "# This shows statistics for the posterior distribution of each parameter (k1, w1, etc.)\n",
    "mcmc.print_summary()\n",
    "\n",
    "# You can get the posterior samples for later analysis and prediction\n",
    "posterior_samples = mcmc.get_samples()\n",
    "print(\"\\nShape of posterior samples for k1:\", posterior_samples['k1'].shape)\n",
    "# Expected output: (1000, 8, 3, 3) -> (num_samples, shape_of_k1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
