# Linear Multiple Regression for continuous vairables
## General Principles
To study relationships between multiple continuous variables (e.g., effect of height and age on weight), we can use a Multiple Regression approach. Essentially, we extend the [Linear Regression for continuous variable](1.&#32;Linear&#32;Regression&#32;for&#32;continuous&#32;variable.md) by adding a regression coefficient $\beta$ for each continuous variables. 

![Plot](https://miro.medium.com/v2/resize:fit:786/format:webp/0*dJqdzk1aMo2OQR7O)

## Considerations
- We have the same considerations as for [Regression for continuous variable](1.&#32;Linear&#32;Regression&#32;for&#32;continuous&#32;variable.md).

- We need regression coefficient $beta$ for each [independent variables ğŸ›ˆ](2.&#32;Multiple&#32;continuous&#32;Variables.md "An independent variable is the factor that we change or control to see if it affects an outcome (the dependent variable).").

- Model interpretation of the regression coefficients $\beta$  is considered for a fixed value of the other dependent variables' regression coefficients â€”i.e., for a given age, a variation of 1 unit in height reflects the value of the regression coefficient $\beta\$ for height.

## Example
Below is an example code snippet demonstrating Bayesian multiple regression using Bayesian Inference (BI) package:


```python
from BI import bi.hard
# Import data
d = pd.read_csv('/home/sosa/BI/data/Howell1.csv', sep=';')

# Manipulate and scale data
d = d[d.age > 18]
#self.df["weight.per.g"].pipe(lambda x: (x - x.mean()) / x.std())
d.weight = d.weight - d.weight.mean()
d.age = d.age - d.age.mean()
weight = jnp.array(d.weight.values)

# Define your model
def model():
    sigma = yield uniform(1, 0, 50)
    alpha = yield normal(1, 178, 20)
    beta = yield normal(1, 0, 1)    
    beta2 = yield normal(1, 0, 1) 
    y = yield Independent(Normal(a + beta * weight + beta2 * age, s))
    
posterior, sample_stats = NUTStrans(model, 
                                    obs = jnp.array(d.height.values),  # define the dependent variable 
                                    n_chains = 4)  # define number of chains
```

## Mathematical Details
### *Formula*
We model the relationship between the independent variables (X1, X2, ..., Xn) and the dependent variable (Y) using the following equation:

$$
ğ‘Œ = \alpha +\beta_1 * ğ‘‹_1 + beta_2 * ğ‘‹_2 + ... + \beta_n * ğ‘‹_ğ‘› + \sigma
$$

Where:

- $Y$ is the dependent variable.
- $\alpha$ is the intercept term.
- $X_1$, $X_2$, ..., $X_n$ are the independent variables.
- $\beta_1$, $\beta_2$, ..., $\beta_n$ are the regression coefficients.
- $sigma$ is the error term.

### *Bayesian model*
We can express the Bayesian multiple regression model using probability distributions as follows:


$$
ğ‘(ğ‘Œâˆ£ğ‘‹, \alpha,\beta) = Normal(\alpha + \sum_i^n  \beta_i * X_i, ÏƒÂ²)
$$

$$
p(\alpha) = Normal(0,1)
$$

$$
p(\beta_i) = Normal(0,1)
$$

$$
p(Ïƒ) = Exponential(1)
$$

Where:

- $p(Y | ğ‘‹, \alpha,\beta)$ is the likelihood function.
- $p(\beta_i)$ and $p(\alpha)$ are the prior distributions for the regression coefficients - and intercept.
- $p(\sigma)$ is the prior distribution for the standard deviation, ensuring - it is positive.

## Reference(s)