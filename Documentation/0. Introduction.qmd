# Introduction

This document is a guide to Bayesian analysis and the implementation of Bayesian inference (BI). It is intended for users ranging from those with little or no experience to advanced practitioners. In this introduction, we outline the main steps of Bayesian analysis. Subsequent chapters present increasingly complex models in a stepâ€byâ€step manner. Each following chapters will all have the same structure in order to allow users to easily find the information they are looking for. The structure is the following:

1. *Introduction to the model with non mathematical explanations.*
   
2. *Specific conciderations for the model.*
   
3. *Code to run the model.*
   
4. *Mathematical formulas of the model.*
   
5. *Notes related to the model.*

We recommend reading the introduction first since some key concepts here will not be revisited in later chapters.

## Bayesian analysis
Bayesian analysis is a statistical approach that uses probability theory to update beliefs about the parameters of a model as new data becomes available. Bayesian methods have several key advantages as they allow [<span style="color:#0D6EFD">direct Uncertainty Quantification ğŸ›ˆ</span>]{#Uncertainty}, [<span style="color:#0D6EFD">incorporation of prior knowledge ğŸ›ˆ</span>]{#Uncertainty} and[<span style="color:#0D6EFD">flexibility for complex models ğŸ›ˆ</span>]{#Uncertainty}.


## Model set-up, Bayesian Linear Regression example
To illustrate the basics of setting up a Bayesian model, letâ€™s consider a simple linear regression example. In this example, we build a simple model where we predict a [<span style="color:#0D6EFD">dependent variable ğŸ›ˆ</span>]{#DP} ($y$) from a single [<span style="color:#0D6EFD">independent variable ğŸ›ˆ</span>]{#IP} ($x$). We will present some equations and basic modeling will be discuss in further details in [Chapter 1: Multiple Continuous Variables](1.&#32;Linear&#32;Regression&#32;for&#32;continuous&#32;variable.qmd). Where we will not focus on the equations and their details but rather used them to describe the different components of a Bayesian model, how parameters optimization algorithm works in Bayesian analysis, and provide basic technical vocabulary related to Bayesian methods.


### The Likelihood
The [<span style="color:#0D6EFD">*likelihood* ğŸ›ˆ</span>]{#lk} can be consider as your main equation that combines the different terms of the model. Depending on the type of problem you are trying to solve (classification, regression, etc.) and the type of data you are working with (continuous, discrete, binomial, etc.), the likelihood will be different. Additionally, a model can have multiple likelihoods (e.g., network models).
$$
y \sim \text{Normal}(\mu, \sigma)
$$

Where as both in the *dependent variable* ($y$) and the *independent variable* ($x$) are continuous variables, we can use a linear model to describe the relationship between these two variables. As we are using Bayesian methods, we are describing this relationship using a [<span style="color:#0D6EFD">*probability distribution* ğŸ›ˆ</span>]{#pdist} .


### Modeling Likelihood
Once the *likelihood* is defined, we can know define the mathematical equation that describe our parameters and their relationship with the *dependent variable* ($y$). We can express this relationship in the form of a linear function:
$$
\mu = \alpha + \beta x
$$

Where $\alpha$ is the [<span style="color:#0D6EFD">*intercept* ğŸ›ˆ</span>]{#pdist} and $\beta$ is the [<span style="color:#0D6EFD">*slope* ğŸ›ˆ</span>]{#slope} of the line. These parameters are the *unknowns* that we want to estimate to evaluate the strength and direction of the relationship between the *independent variable* ($x$) and the *dependent variable* ($y$).

### Link functions Link 
Depending on the type of problem you are trying to solve, the likelihood will be different (continuous, discrete, binomial, etc.) and you will need to choose the appropriate distribution to describe the relationship between the parameters and the data. By using a different distribution, you will need to use a different [<span style="color:#0D6EFD">*link function* ğŸ›ˆ</span>]{#slope}. 

For the moment, we just need to know that those different distributions required *link function* (for each specific family we will discuss the corresponding link function). however, below is a table summarizing some of the most common link functions, the mathematical form of each, their typical applications, and how to interpret them.

| **Link Function**         | **Mathematical Form**                                      | **Typical Use / Model**                      | **Interpretation & Range**                                  |
|---------------------------|------------------------------------------------------------|----------------------------------------------|-------------------------------------------------------------|
| **Identity**              | $g(\mu) = \mu$                                           | Linear regression (Normal)                   | Directly models $\mu$; $\mu$ can be any real number.    |
| **Logit**                 | $g(\mu) = \log\left(\frac{\mu}{1-\mu}\right)$             | Logistic regression (Binomial)               | Models probabilities (0, 1); coefficients reflect log-odds. |
| **Probit**                | $g(\mu) = \Phi^{-1}(\mu)$                                  | Probit regression (Binomial)                 | Similar to logit; uses the inverse standard normal CDF.     |
| **Log**                   | $g(\mu) = \log(\mu)$                                       | Poisson, Gamma regression (Count data)       | Ensures $\mu > 0$; coefficients represent multiplicative effects. |
| **Inverse**               | $g(\mu) = \frac{1}{\mu}$                                   | Gamma regression                             | Models positive $\mu$; relates changes inversely to $\mu$.|



### The Prior Distributions
For each parameters of our equation, we need to define a  [<span style="color:#0D6EFD">*prior distribution* ğŸ›ˆ</span>]{#prior} that encodes our initial beliefs about the parameter. In the case of the linear regression model, we need to specify *prior distributions* for ($\alpha$), slope ($\beta$), and standard deviation ($\sigma$):

$$
\alpha \sim \text{Normal}(0, 1)
$$

$$
\beta \sim \text{Normal}(0, 1)
$$


$$
\sigma \sim \text{Uniform}(0, 1)
$$



#### Which prior distribution range to use?

The choice of prior ranges can significantly affect Bayesian analysis results. There are several approaches to selecting them:

- **Expert Knowledge**: The prior distributions can be based on expert knowledge or historical data. This approach is useful when there is a lot of information available about the parameters.

- **Noninformative Priors**: When there is little or no information about the parameters, noninformative priors can be used. These priors are designed to have minimal influence on the posterior distribution, allowing the data to dominate the inference process.

- **Scaled data**: If the data is [<span style="color:#0D6EFD">*scaled* ğŸ›ˆ</span>]{#scaled}, the prior distributions can be chosen to reflect this. For example, if the data are scaled, the prior distributions for the intercept and slope can be centered around 0 and 1, respectively. By scaling the independent variable, we obtain a unit of change based on variance; that is, the effect represents a oneâ€“standardâ€“deviation change in $x$ on $y$. Scaling the data improves both numerical stability and interpretability. When all data are scaled to the same range, it leads to more stable numerical behavior during estimation. Additionally, it facilitates setting priors that are both meaningful and relatively uninformative. By aligning the scale of the data with the scale assumed in the priors, we ensure that the posterior distributions exhibit reasonable spread and that our uncertainty quantification is consistent with the dataâ€™s scale. For the remainder of this document, we will assume that the data are scaled.


### The Posterior Distribution

Once data are observed, Bayesâ€™ Theorem is used to update our beliefs about the parameters. Bayes' theorem, which states that the posterior probability of a parameter is proportional to the product of the prior probability and the likelihood of the data given the parameter. This approach allows for the incorporation of prior knowledge and the use of Bayesian updating to improve the accuracy of the model.We express what we know (or donâ€™t know) using probability distributions, and we update these beliefs as evidence accumulates.


$$
P(\theta \mid \text{data}) = \frac{P(\text{data} \mid \theta) \cdot P(\theta)}{P(\text{data})}
$$

Where:

- $\theta$ represents the unknown parameters we are interested in.
  
- $P(\theta)$ is the **prior distribution**, representing our beliefs about $\theta$ before seeing the data.
  
- $P(\text{data} \mid \theta)$ is the **likelihood**, representing the model of how the data are generated given $\theta$.
  
- $P(\theta \mid \text{data})$ is the **posterior distribution**, representing our updated beliefs after observing the data.



This distribution reflects our updated beliefs about the parameters after observing the data. It tells us not only the most likely values of $\alpha$, $\beta$, and $\sigma$ but also quantifies the uncertainty in these estimates.

We can use _Bayesian updating_ using the _Bayesian theorem_ to 'reshape' the prior distributions by considering every possible combination of values for Âµ and Ïƒ and scoring each combination by its relative plausibility in light of the data. These relative plausibilities are the posterior probabilities of each combination of values Âµ and Ïƒ: the _posterior distributions_. Various techniques can be used to approximate the mathematical definition of Bayes' theorem: *grid approximation*, *quadratic approximation*, and Markov chain Monte Carlo (_MCMC_). In BI, we use MCMC.Description of this algorithms are out of the scope of this document. For more information, please refer to the [Bayesian Inference]().


### Model 'diagnostic'
Once a Bayesian model has been fit, it is crucial to evaluate how well it captures the observed data and to assess whether the Markov chain Monte Carlo (MCMC) sampling has converged. Bayesian model diagnostics help us answer questions like: â€œAre our uncertainty estimates reliable?â€, â€œDoes the model generate data similar to what we observed?â€, and â€œHave the chains mixed well?â€ Mulitple diagnostics approaches can be used to assess the model's performance. Below are some key diagnostic tools and techniques available in BI.


| **Diagnostic Tool**          | **Purpose**                                              | **Key Indicator**               | **Interpretation**                                        |
|------------------------------|----------------------------------------------------------|---------------------------------|-----------------------------------------------------------|
| [<span style="color:#0D6EFD">*posterior predictive checks* (PPCs) ğŸ›ˆ</span>]{#PPCs}  | Assess if model can reproduce observed data              | Graphs, p-values, summary stats | Good fit if simulated data resemble observed data         |
| Credible Interval (CI)       | Quantify uncertainty in parameter estimates              | 95% CI or other percentage      | 95% probability the parameter lies within the interval     |
| [<span style="color:#0D6EFD">*highest posterior density intervals* (HPDI) ğŸ›ˆ</span>]{#HPDI}                         | Identify the narrowest interval containing a given probability mass | 95% HPDI                     | Smallest interval capturing 95% of the posterior density  |
| [<span style="color:#0D6EFD">*effective sample size* (ESS) ğŸ›ˆ</span>]{#ESS}  | Measure independent information in the chain             | ESS value (ideally high)        | Low ESS indicates high autocorrelation (poor mixing)       |
| [<span style="color:#0D6EFD">*potential scale reduction factor* (Rhat) ğŸ›ˆ</span>]{#Rhat}          | Check convergence across multiple chains                 | Rhat â‰ˆ 1 (typically <1.1)       | Values near 1 indicate convergence; >>1 suggests non-convergence |
| [<span style="color:#0D6EFD">*Trace plots* ğŸ›ˆ</span>]{#TP}         | Visualize the sampling path to check convergence and mixing | Plot showing parameter values over iterations | Stationary, 'hairy caterpillar' pattern suggests convergence |
| [<span style="color:#0D6EFD">*autocorrelation plots* ğŸ›ˆ</span>]{#AutoCor} | Assess dependency between samples over lags              | Autocorrelation values across lags | Rapid decay to zero suggests good mixing; slow decay indicates poor mixing |
| [<span style="color:#0D6EFD">*density plots* ğŸ›ˆ</span>]{#DesPlot} | Visualize the posterior distribution of a parameter      | Smoothness and shape of the curve | Unimodal and smooth suggests convergence; multimodal or irregular may suggest poor mixing |
