{
  "hash": "ad204547baff0770b8727f388e13873d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Survival Analysis\"\ndescription: \"Analyzing time-to-event data, focusing on the duration until an event of interest occurs.\"\ncategories: [Survival Analysis, Time-to-Event]\nimage: \"Figures/12.png\"\norder: 15\n---\n\n\n\n\n\n\n## General Principles\n\nSurvival analysis studies the time until an event of interest (e.g., death, recovery, information acquisition) occurs. When analyzing binary survival outcomes (e.g., alive or dead), we can use models such as Cox proportional hazards to evaluate the effect of predictors on survival probabilities.\n\nKey concepts include:\n\n1.  **Hazard Function**: The instantaneous risk of the event occurring at a given time.\n2.  **Survival Function**: The probability of surviving beyond a given time.\n3.  **Covariates**: Variables (e.g., age, treatment) that may affect survival probabilities.\n4.  **Baseline Hazard**: The hazard when all covariates are zero, which forms the reference for comparing different conditions.\n\n## Considerations\n\n::: callout-note\n- Bayesian models provide a framework to account for [<span style=\"color:#0D6EFD\">uncertainty ðŸ›ˆ</span>]{#uncertainty} in parameter estimates through posterior distributions. You will need to define [<span style=\"color:#0D6EFD\">prior distributions ðŸ›ˆ</span>]{#prior} for all model parameters, such as baseline hazard, covariate effects, and variance terms.\n\n- In survival analysis:\n\n  - The **baseline hazard** can follow distributions like Exponential, Weibull, or Gompertz, depending on the data.\n\n  - Censoring (when the event is not observed for some subjects) must be accounted for in the likelihood function. Proper handling is essential for unbiased results.\n\n- Bayesian survival models allow flexible handling of time-dependent covariates, random effects, and incorporate uncertainty more naturally than Frequentist methods.\n:::\n\n## Example\n\nHereâ€™s an example of a Bayesian survival analysis using the **Bayesian Inference (BI)** package. The data come from a clinical trial of mastectomy for breast cancer. The goal is to estimate the effect of the `metastasized` covariate, coded as 0 (no metastasis) and 1 (metastasis), on the survival outcome `event` for each patient. Time is continuous and censoring is indicated by the event variable.\n\n::: {.panel-tabset group=\"language\"}\n\n### Python\n\n::: {#56fe1af6 .cell execution_count=1}\n``` {.python .cell-code}\nfrom BI import bi\nimport numpy as np\nimport jax.numpy as jnp\n# Setup device------------------------------------------------\nm = bi(platform='cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\nfrom importlib.resources import files\ndata_path = files('BI.resources.data') / 'mastectomy.csv'\nm.data(data_path, sep=',') \n\nm.df.metastasized = (m.df.metastasized == \"yes\").astype(np.int64)\nm.df.event = jnp.array(m.df.event.values, dtype=jnp.int32)\n\n## Create survival object\nm.models.survival.surv_object(time='time', event='event', cov='metastasized', interval_length=3)\n\n# Plot censoring ------------------------------------------------\nm.models.survival.plot_censoring(cov='metastasized')\n\n# Model ------------------------------------------------\ndef model(intervals, death, metastasized, exposure):\n    # Parameter prior distributions-------------------------\n    ## Base hazard distribution\n    lambda0 = m.dist.gamma(0.01, 0.01, shape= intervals.shape, name = 'lambda0')\n    ## Covariate effect distribution\n    beta = m.dist.normal(0, 1000, shape = (1,),  name='beta')\n    ### Likelihood\n    #### Compute hazard rate based on covariate effect\n    lambda_ = m.models.survival.hazard_rate(cov = metastasized, beta = beta, lambda0 = lambda0)\n    #### Compute exposure rates\n    mu = exposure * lambda_\n\n    # Likelihood calculation\n    y = m.dist.poisson(mu + jnp.finfo(mu.dtype).tiny, obs = death)\n\n# Run mcmc ------------------------------------------------\nm.fit(model, num_samples=500) \n\n# Summary ------------------------------------------------\nprint(m.summary())\n\n# Plot hazards and survival function ------------------------------------------------\nm.models.survival.plot_surv()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWARNING:2025-09-25 08:48:43,267:jax._src.xla_bridge:794: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\njax.local_device_count 32\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/1000 [00:00<?, ?it/s]\rwarmup:   0%|          | 1/1000 [00:00<08:28,  1.96it/s, 1 steps of size 2.34e+00. acc. prob=0.00]\rwarmup:   2%|â–         | 20/1000 [00:00<00:22, 42.73it/s, 1023 steps of size 2.66e-01. acc. prob=0.74]\rwarmup:   3%|â–Ž         | 31/1000 [00:00<00:18, 51.62it/s, 1023 steps of size 1.65e-01. acc. prob=0.75]\rwarmup:   4%|â–         | 41/1000 [00:00<00:17, 55.20it/s, 1023 steps of size 1.34e-01. acc. prob=0.76]\rwarmup:   5%|â–         | 49/1000 [00:01<00:16, 56.51it/s, 511 steps of size 2.34e-01. acc. prob=0.77] \rwarmup:   6%|â–Œ         | 57/1000 [00:01<00:15, 61.05it/s, 1023 steps of size 1.38e-01. acc. prob=0.77]\rwarmup:   6%|â–‹         | 65/1000 [00:01<00:14, 64.21it/s, 1023 steps of size 3.22e-01. acc. prob=0.78]\rwarmup:   7%|â–‹         | 73/1000 [00:01<00:14, 61.97it/s, 619 steps of size 1.54e-01. acc. prob=0.77] \rwarmup:   8%|â–Š         | 80/1000 [00:01<00:14, 61.77it/s, 1023 steps of size 2.87e-01. acc. prob=0.78]\rwarmup:   9%|â–Š         | 87/1000 [00:01<00:14, 62.76it/s, 1023 steps of size 1.90e-01. acc. prob=0.78]\rwarmup:   9%|â–‰         | 94/1000 [00:01<00:14, 64.19it/s, 150 steps of size 2.51e-01. acc. prob=0.78] \rwarmup:  10%|â–ˆ         | 105/1000 [00:01<00:11, 76.50it/s, 511 steps of size 7.33e-03. acc. prob=0.76]\rwarmup:  11%|â–ˆâ–        | 113/1000 [00:01<00:12, 72.69it/s, 511 steps of size 1.37e-02. acc. prob=0.77]\rwarmup:  12%|â–ˆâ–        | 123/1000 [00:02<00:11, 77.16it/s, 1023 steps of size 8.42e-03. acc. prob=0.77]\rwarmup:  13%|â–ˆâ–Ž        | 132/1000 [00:02<00:11, 76.69it/s, 1023 steps of size 9.63e-03. acc. prob=0.77]\rwarmup:  14%|â–ˆâ–        | 143/1000 [00:02<00:10, 85.15it/s, 511 steps of size 4.42e-03. acc. prob=0.77] \rwarmup:  15%|â–ˆâ–Œ        | 152/1000 [00:02<00:10, 78.01it/s, 1 steps of size 1.15e-02. acc. prob=0.77]  \rwarmup:  16%|â–ˆâ–Œ        | 161/1000 [00:02<00:11, 71.02it/s, 511 steps of size 3.70e-03. acc. prob=0.77]\rwarmup:  17%|â–ˆâ–‹        | 169/1000 [00:02<00:12, 67.21it/s, 1023 steps of size 1.03e-02. acc. prob=0.77]\rwarmup:  18%|â–ˆâ–Š        | 178/1000 [00:02<00:11, 69.66it/s, 1023 steps of size 8.95e-03. acc. prob=0.77]\rwarmup:  19%|â–ˆâ–Š        | 186/1000 [00:02<00:11, 68.12it/s, 511 steps of size 1.15e-02. acc. prob=0.77] \rwarmup:  19%|â–ˆâ–‰        | 194/1000 [00:03<00:11, 70.98it/s, 511 steps of size 5.34e-03. acc. prob=0.77]\rwarmup:  20%|â–ˆâ–ˆ        | 202/1000 [00:03<00:11, 69.45it/s, 1023 steps of size 5.75e-03. acc. prob=0.77]\rwarmup:  21%|â–ˆâ–ˆ        | 210/1000 [00:03<00:11, 66.16it/s, 1023 steps of size 7.70e-03. acc. prob=0.77]\rwarmup:  22%|â–ˆâ–ˆâ–       | 218/1000 [00:03<00:11, 67.35it/s, 1023 steps of size 4.88e-03. acc. prob=0.77]\rwarmup:  23%|â–ˆâ–ˆâ–Ž       | 228/1000 [00:03<00:10, 75.41it/s, 1023 steps of size 8.55e-03. acc. prob=0.78]\rwarmup:  24%|â–ˆâ–ˆâ–       | 238/1000 [00:03<00:09, 81.37it/s, 144 steps of size 5.19e-03. acc. prob=0.78] \rwarmup:  25%|â–ˆâ–ˆâ–       | 248/1000 [00:03<00:08, 85.62it/s, 511 steps of size 3.11e-03. acc. prob=0.78]\rwarmup:  26%|â–ˆâ–ˆâ–Œ       | 258/1000 [00:03<00:08, 87.81it/s, 511 steps of size 6.43e-03. acc. prob=0.77]\rwarmup:  27%|â–ˆâ–ˆâ–‹       | 267/1000 [00:03<00:09, 80.70it/s, 511 steps of size 1.04e-02. acc. prob=0.78]\rwarmup:  28%|â–ˆâ–ˆâ–Š       | 276/1000 [00:04<00:09, 77.06it/s, 255 steps of size 3.76e-03. acc. prob=0.78]\rwarmup:  28%|â–ˆâ–ˆâ–Š       | 284/1000 [00:04<00:09, 73.34it/s, 1023 steps of size 6.26e-03. acc. prob=0.78]\rwarmup:  29%|â–ˆâ–ˆâ–‰       | 292/1000 [00:04<00:09, 74.69it/s, 511 steps of size 1.00e-02. acc. prob=0.78] \rwarmup:  30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [00:04<00:09, 71.29it/s, 1023 steps of size 6.19e-03. acc. prob=0.78]\rwarmup:  31%|â–ˆâ–ˆâ–ˆ       | 308/1000 [00:04<00:10, 68.29it/s, 1023 steps of size 3.10e-03. acc. prob=0.78]\rwarmup:  32%|â–ˆâ–ˆâ–ˆâ–      | 317/1000 [00:04<00:09, 73.16it/s, 380 steps of size 8.10e-03. acc. prob=0.78] \rwarmup:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 325/1000 [00:04<00:09, 74.70it/s, 1023 steps of size 3.88e-03. acc. prob=0.78]\rwarmup:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 334/1000 [00:04<00:08, 78.77it/s, 511 steps of size 5.63e-03. acc. prob=0.78] \rwarmup:  34%|â–ˆâ–ˆâ–ˆâ–      | 342/1000 [00:05<00:08, 76.21it/s, 511 steps of size 4.10e-03. acc. prob=0.78]\rwarmup:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 351/1000 [00:05<00:08, 77.97it/s, 1023 steps of size 5.46e-03. acc. prob=0.78]\rwarmup:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360/1000 [00:05<00:08, 79.96it/s, 511 steps of size 7.81e-03. acc. prob=0.78] \rwarmup:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 369/1000 [00:05<00:08, 75.50it/s, 698 steps of size 4.54e-03. acc. prob=0.78]\rwarmup:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 377/1000 [00:05<00:08, 69.77it/s, 157 steps of size 5.97e-03. acc. prob=0.78]\rwarmup:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 386/1000 [00:05<00:08, 72.21it/s, 1023 steps of size 6.02e-03. acc. prob=0.78]\rwarmup:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 395/1000 [00:05<00:07, 76.19it/s, 1023 steps of size 4.95e-03. acc. prob=0.78]\rwarmup:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 403/1000 [00:05<00:07, 75.23it/s, 373 steps of size 4.64e-03. acc. prob=0.78] \rwarmup:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 411/1000 [00:05<00:07, 75.49it/s, 511 steps of size 9.35e-03. acc. prob=0.78]\rwarmup:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 423/1000 [00:06<00:06, 87.70it/s, 322 steps of size 6.29e-03. acc. prob=0.78]\rwarmup:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 433/1000 [00:06<00:06, 89.30it/s, 511 steps of size 9.96e-03. acc. prob=0.78]\rwarmup:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 443/1000 [00:06<00:06, 86.64it/s, 511 steps of size 4.88e-03. acc. prob=0.78]\rwarmup:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 452/1000 [00:06<00:06, 80.83it/s, 2 steps of size 1.04e-02. acc. prob=0.78]  \rwarmup:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 461/1000 [00:06<00:06, 80.02it/s, 1023 steps of size 6.29e-03. acc. prob=0.78]\rwarmup:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 470/1000 [00:06<00:06, 78.34it/s, 1023 steps of size 8.06e-03. acc. prob=0.78]\rwarmup:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481/1000 [00:06<00:06, 84.96it/s, 1023 steps of size 6.14e-03. acc. prob=0.78]\rwarmup:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 490/1000 [00:06<00:06, 84.88it/s, 433 steps of size 5.52e-03. acc. prob=0.78] \rsample:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501/1000 [00:06<00:05, 89.19it/s, 511 steps of size 6.52e-03. acc. prob=0.97]\rsample:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 511/1000 [00:07<00:05, 91.61it/s, 511 steps of size 6.52e-03. acc. prob=0.96]\rsample:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 521/1000 [00:07<00:05, 91.47it/s, 511 steps of size 6.52e-03. acc. prob=0.97]\rsample:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 531/1000 [00:07<00:05, 91.13it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 541/1000 [00:07<00:04, 92.02it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 551/1000 [00:07<00:04, 94.12it/s, 511 steps of size 6.52e-03. acc. prob=0.96]\rsample:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 561/1000 [00:07<00:04, 91.73it/s, 511 steps of size 6.52e-03. acc. prob=0.96]\rsample:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 571/1000 [00:07<00:04, 88.56it/s, 1023 steps of size 6.52e-03. acc. prob=0.96]\rsample:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 582/1000 [00:07<00:04, 92.62it/s, 511 steps of size 6.52e-03. acc. prob=0.96] \rsample:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 594/1000 [00:07<00:04, 98.49it/s, 353 steps of size 6.52e-03. acc. prob=0.95]\rsample:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604/1000 [00:08<00:04, 97.52it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614/1000 [00:08<00:03, 98.02it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624/1000 [00:08<00:03, 96.84it/s, 1023 steps of size 6.52e-03. acc. prob=0.95]\rsample:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634/1000 [00:08<00:03, 96.84it/s, 511 steps of size 6.52e-03. acc. prob=0.95] \rsample:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645/1000 [00:08<00:03, 99.94it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 656/1000 [00:08<00:03, 100.59it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 667/1000 [00:08<00:03, 102.68it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678/1000 [00:08<00:03, 104.69it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 689/1000 [00:08<00:02, 105.59it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [00:08<00:02, 105.48it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711/1000 [00:09<00:02, 101.17it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 722/1000 [00:09<00:02, 95.89it/s, 511 steps of size 6.52e-03. acc. prob=0.95] \rsample:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732/1000 [00:09<00:02, 96.69it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 743/1000 [00:09<00:02, 97.77it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 754/1000 [00:09<00:02, 97.69it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765/1000 [00:09<00:02, 99.89it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 776/1000 [00:09<00:02, 98.15it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 786/1000 [00:09<00:02, 95.43it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796/1000 [00:09<00:02, 96.00it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806/1000 [00:10<00:02, 93.31it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 817/1000 [00:10<00:01, 97.16it/s, 511 steps of size 6.52e-03. acc. prob=0.94]\rsample:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 828/1000 [00:10<00:01, 99.92it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839/1000 [00:10<00:01, 102.19it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 850/1000 [00:10<00:01, 102.83it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 861/1000 [00:10<00:01, 102.61it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872/1000 [00:10<00:01, 103.06it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883/1000 [00:10<00:01, 104.96it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 894/1000 [00:10<00:01, 103.98it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 905/1000 [00:11<00:00, 99.10it/s, 1023 steps of size 6.52e-03. acc. prob=0.95]\rsample:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 915/1000 [00:11<00:00, 94.66it/s, 1023 steps of size 6.52e-03. acc. prob=0.95]\rsample:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 925/1000 [00:11<00:00, 92.35it/s, 415 steps of size 6.52e-03. acc. prob=0.95] \rsample:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936/1000 [00:11<00:00, 95.56it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1000 [00:11<00:00, 98.51it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957/1000 [00:11<00:00, 93.20it/s, 767 steps of size 6.52e-03. acc. prob=0.95]\rsample:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 968/1000 [00:11<00:00, 95.69it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 978/1000 [00:11<00:00, 95.03it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988/1000 [00:11<00:00, 94.78it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998/1000 [00:12<00:00, 89.76it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\rsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:12<00:00, 82.66it/s, 511 steps of size 6.52e-03. acc. prob=0.95]\narviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                 mean    sd  hdi_5.5%  hdi_94.5%  mcse_mean  mcse_sd  \\\nbeta[0]          0.77  0.48       0.0       1.49       0.04     0.03   \nlambda0[0]       0.00  0.00       0.0       0.00       0.00     0.00   \nlambda0[1]       0.00  0.00       0.0       0.01       0.00     0.00   \nlambda0[2]       0.00  0.01       0.0       0.01       0.00     0.00   \nlambda0[3]       0.00  0.01       0.0       0.01       0.00     0.00   \n...               ...   ...       ...        ...        ...      ...   \nlambda_[43, 71]  0.00  0.01       0.0       0.00       0.00     0.00   \nlambda_[43, 72]  0.00  0.02       0.0       0.00       0.00     0.00   \nlambda_[43, 73]  0.00  0.02       0.0       0.00       0.00     0.00   \nlambda_[43, 74]  0.00  0.01       0.0       0.00       0.00     0.01   \nlambda_[43, 75]  0.00  0.03       0.0       0.00       0.00     0.01   \n\n                 ess_bulk  ess_tail  r_hat  \nbeta[0]            171.68    206.44    NaN  \nlambda0[0]         143.46    113.83    NaN  \nlambda0[1]         306.90    219.76    NaN  \nlambda0[2]         337.30    325.35    NaN  \nlambda0[3]         219.38    227.65    NaN  \n...                   ...       ...    ...  \nlambda_[43, 71]    167.71    235.17    NaN  \nlambda_[43, 72]    157.28    192.96    NaN  \nlambda_[43, 73]     82.53     84.53    NaN  \nlambda_[43, 74]    156.31    204.17    NaN  \nlambda_[43, 75]     71.75     81.01    NaN  \n\n[3421 rows x 9 columns]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/sosa/work/test/lib/python3.10/site-packages/arviz/plots/hdiplot.py:166: FutureWarning:\n\nhdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n\n/home/sosa/work/test/lib/python3.10/site-packages/arviz/plots/hdiplot.py:166: FutureWarning:\n\nhdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n\n/home/sosa/work/test/lib/python3.10/site-packages/arviz/plots/hdiplot.py:166: FutureWarning:\n\nhdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n\n/home/sosa/work/test/lib/python3.10/site-packages/arviz/plots/hdiplot.py:166: FutureWarning:\n\nhdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](12. Survival analysis_files/figure-html/cell-2-output-6.png){width=633 height=503}\n:::\n\n::: {.cell-output .cell-output-display}\n![](12. Survival analysis_files/figure-html/cell-2-output-7.png){width=1272 height=561}\n:::\n:::\n\n\n:::\n\n## Mathematical Details\n\nThe model is defined as follows:\n\n$$\ndN_i(t) \\sim \\text{Poisson}(\\lambda_i(t)Y_i(t)dt)\n$$\n\n$$\n\\lambda_i(t) = \\lambda_{0}(t)\\exp(X_i\\beta)\n$$\n\nThe hierarchical priors for the regression coefficients are:\n\n$$\n\\beta \\sim \\text{Normal}(\\mu_\\beta, \\sigma^2_\\beta)\n$$\n\n$$\n\\mu_\\beta \\sim \\text{Normal}(0, 100)\n$$\n\n$$\n\\sigma^2_\\beta \\sim \\text{InverseGamma}(0.1, 0.1)\n$$\n\n-   Where:\n    -   $N_i(t)$ is the counting process for subject $i$, which counts the number of observed events up to time $t$. For survival analysis, this is typically 0 or 1.\n  \n    -   $dN_i(t)$ is the increment of the process over a small interval $dt$, indicating if an event occurred for subject $i$ at time $t$.\n\n    *   **$Y_i(t)$ is the at-risk indicator**, taking a value of 1 if subject *i* is under observation and has not yet experienced an event just prior to time *t*, and 0 otherwise. This indicator is the mechanism that handles censoring:\n        *   If a subject is **censored** at time $t'$, their at-risk indicator $Y_i(t)$ remains 1 up to $t'$, signifying they were at risk during this period.\n        *   At the moment of censoring $t'$, no event is recorded (the counting process $N_i(t)$ does not increment).\n        *   For all subsequent times $t > t'$, the indicator $Y_i(t)$ switches to 0, effectively removing the individual from the risk set for any future calculations.\n\n    -   $\\lambda_i(t)$ is the hazard rate for subject $i$ at time $t$.\n\n    -   $\\lambda_{0}(t)$ is the baseline hazard rate function at time $t$. A key assumption is that this baseline hazard is the same for all subjects.\n\n    -   $X_i$ is the covariates for subject $i$.\n\n    -   $\\beta$ is the regression coefficients. \n\n-   **Priors:**\n    -   We assign prior distributions to the unknown parameters. The regression coefficients $\\beta$ are given a Normal prior.\n\n    -   The hyperparameters of the $\\beta$ prior, $\\mu_\\beta$ and $\\sigma^2_\\beta$, are themselves given vague priors to be learned from the data.\n\n    -   The baseline hazard $\\lambda_0(t)$ is also treated as an unknown parameter and is often modeled non-parametrically, for instance, using a gamma process or as a piecewise constant function, where priors are placed on the hazard level in each time interval.\n\n\nThe key assumption of this model is that the hazard ratios are constant over time. Censoring is typically handled in the likelihood function used for estimation, not by multiplying the hazard function by a factor. The data for each subject $i$ is represented by a tuple $(t_i, \\delta_i, X_i)$, where $t_i$ is the observed time (either event or censoring time), $\\delta_i$ is an event indicator (1 if the event was observed, 0 if censored), and $X_i$ is the vector of covariates.\n\n## Reference(s)\nhttps://en.wikipedia.org/wiki/Proportional_hazards_model\nhttps://www.mathworks.com/help/stats/cox-proportional-hazard-regression.html\nhttps://www.pymc.io/projects/examples/en/latest/survival_analysis/survival_analysis.html\nhttps://vflores-io.github.io/posts/20240924_numpyro_logreg_surv_analysis/np01_logreg_surv_analysis/\n\n",
    "supporting": [
      "12. Survival analysis_files"
    ],
    "filters": [],
    "includes": {}
  }
}