{
  "hash": "659688246875341a54c035297389da0d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Multinomial Model\"\ndescription: \"Modeling the counts of outcomes across multiple categorical trials.\"\ncategories: [Regression, GLM, Classification]\nimage: \"Figures/9.png\"\norder: 12\n---\n\n## General Principles\nTo model the relationship between a vector outcome variable in which each element of the vector is a frequency from a set of more than two categories and one or more independent variables, we can use a _Multinomial_ model.\n\n## Considerations\n::: callout-note\n- We have the same considerations as for the [Categorical model](9.&#32;Categorical&#32;model.qmd).\n\n:::\n\n## Example\nBelow is an example code snippet demonstrating a Bayesian multinomial model using the Bayesian Inference (BI) package. This example is based on @mcelreath2018statistical.\n\n::: {.panel-tabset group=\"language\"}\n## Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom BI import bi, jnp\nimport jax\n# Setup device ------------------------------------------------\nm = bi('cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\nfrom importlib.resources import files\ndata_path = files('BI.resources.data') / 'Sim data multinomial.csv'\nm.data(data_path, sep=',') \n\n# Define model ------------------------------------------------\ndef model(income, career):\n    # Parameter prior distributions\n    alpha = m.dist.normal(0, 1, shape=(2,), name='a')\n    beta = m.dist.half_normal(0.5, shape=(1,), name='b')\n    s_1 = alpha[0] + beta * income[0]\n    s_2 = alpha[1] + beta * income[1]\n    s_3 = [0]\n    p = jnp.exp(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n    # Likelihood\n    m.dist.multinomial(probs = p[career], obs=career)\n    \n# Run sampler ------------------------------------------------ \nm.fit(model)  \n\n# Summary ------------------------------------------------\nm.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\njax.local_device_count 16\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/1000 [00:00<?, ?it/s]\rwarmup:   0%|          | 1/1000 [00:01<32:58,  1.98s/it, 1 steps of size 2.34e+00. acc. prob=0.00]\rwarmup:   3%|â–Ž         | 33/1000 [00:02<00:44, 21.97it/s, 127 steps of size 2.26e-02. acc. prob=0.73]\rwarmup:   6%|â–Œ         | 57/1000 [00:02<00:23, 40.93it/s, 375 steps of size 7.53e-03. acc. prob=0.74]\rwarmup:   9%|â–Š         | 86/1000 [00:02<00:13, 68.14it/s, 127 steps of size 2.95e-02. acc. prob=0.76]\rwarmup:  11%|â–ˆâ–        | 113/1000 [00:02<00:09, 95.52it/s, 7 steps of size 5.54e-01. acc. prob=0.77] \rwarmup:  18%|â–ˆâ–Š        | 184/1000 [00:02<00:04, 195.41it/s, 3 steps of size 1.85e+00. acc. prob=0.78]\rwarmup:  28%|â–ˆâ–ˆâ–Š       | 277/1000 [00:02<00:02, 333.36it/s, 7 steps of size 6.88e-01. acc. prob=0.78]\rwarmup:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 374/1000 [00:02<00:01, 467.66it/s, 3 steps of size 8.32e-01. acc. prob=0.79]\rwarmup:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 470/1000 [00:02<00:00, 581.37it/s, 15 steps of size 5.55e-01. acc. prob=0.79]\rsample:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 566/1000 [00:02<00:00, 674.19it/s, 3 steps of size 7.96e-01. acc. prob=0.90] \rsample:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 662/1000 [00:02<00:00, 748.48it/s, 7 steps of size 7.96e-01. acc. prob=0.91]\rsample:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 759/1000 [00:03<00:00, 806.21it/s, 3 steps of size 7.96e-01. acc. prob=0.90]\rsample:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 851/1000 [00:03<00:00, 837.14it/s, 3 steps of size 7.96e-01. acc. prob=0.90]\rsample:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942/1000 [00:03<00:00, 809.27it/s, 3 steps of size 7.96e-01. acc. prob=0.90]\rsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:03<00:00, 295.44it/s, 7 steps of size 7.96e-01. acc. prob=0.90]\narviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5.5%</th>\n      <th>hdi_94.5%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a[0]</th>\n      <td>0.00</td>\n      <td>0.97</td>\n      <td>-1.60</td>\n      <td>1.51</td>\n      <td>0.05</td>\n      <td>0.04</td>\n      <td>428.89</td>\n      <td>395.09</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a[1]</th>\n      <td>82.06</td>\n      <td>1.02</td>\n      <td>80.40</td>\n      <td>83.58</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>472.75</td>\n      <td>340.24</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[0]</th>\n      <td>40.96</td>\n      <td>0.50</td>\n      <td>40.12</td>\n      <td>41.65</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>616.30</td>\n      <td>368.44</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## R\n\n```R\nlibrary(BI)\nm=importbi(platform='cpu')\n```\n:::\n\n## Mathematical Details\nWe can model a vector of frequencies using a Dirichlet distribution. For an outcome variable $Y_i$ with $K$ categories, the *Dirichlet* likelihood function is:\n\n$$\nY_i \\sim \\text{Multinomial}(\\theta_i) \\\\\n\\theta_i = \\text{Softmax}(\\phi_i) \\\\\n\\phi_{[i,1]} = \\alpha_1 + \\beta_1 X_i \\\\\n\\phi_{[i,2]} = \\alpha_2 + \\beta_2 X_i \\\\\n... \\\\\n\\phi_{[i,k]} = 0 \\\\\n\\alpha_{k} \\sim \\text{Normal}(0,1) \\\\\n\\beta_{k} \\sim \\text{Normal}(0.1)\n$$\n\nWhere:\n\n- $Y_i$ is the outcome (i.e. the vector of frequencies for each  $k$ categories) for observation *i*.\n  \n- $\\theta_i$ is a vector unique to each observation, *i*, which gives the probability of observing *i* in category *k*. \n  \n- $\\phi_i$ give the linear model for each of the $k$ categories. Note that we use the softmax function to ensure that that the probabilities $\\theta_i$ form a [<span style=\"color:#0D6EFD\">simplex ðŸ›ˆ</span>]{#simplex}.\n  \n- Each element of $\\phi_i$ is obtained by applying a linear regression model with its own respective intercept $\\alpha_k$ and slope coefficient $\\beta_k$. To ensure the model is identifiable, one category, *K*, is arbitrarily chosen as a reference or baseline category. The linear predictor for this reference category is set to zero. The coefficients for the other categories then represent the change in the log-odds of being in that category versus the reference category.\n\n\n## Reference(s)\n\n",
    "supporting": [
      "10. Multinomial model_files/figure-pdf"
    ],
    "filters": []
  }
}