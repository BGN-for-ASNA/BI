{
  "hash": "ffdfabc940870feaf70f260e3e304084",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Multinomial Model\"\ndescription: \"Modeling the counts of outcomes across multiple categorical trials.\"\ncategories: [Regression, GLM, Classification]\nimage: \"Figures/9.png\"\norder: 12\n---\n\n## General Principles\nTo model the relationship between a vector outcome variable in which each element of the vector is a frequency from a set of more than two categories and one or more independent variables, we can use a _Multinomial_ model.\n\n## Considerations\n::: callout-note\n- We have the same considerations as for the [Categorical model](9.&#32;Categorical&#32;model.qmd).\n\n:::\n\n## Example\nBelow is an example code snippet demonstrating a Bayesian multinomial model using the Bayesian Inference (BI) package. This example is based on @mcelreath2018statistical.\n\n::: {.panel-tabset group=\"language\"}\n## Python\n\n::: {#bf23592f .cell execution_count=1}\n``` {.python .cell-code}\nfrom BI import bi, jnp\nimport jax\n# Setup device ------------------------------------------------\nm = bi('cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\nfrom importlib.resources import files\ndata_path = files('BI.resources.data') / 'Sim data multinomial.csv'\nm.data(data_path, sep=',') \n\n# Define model ------------------------------------------------\ndef model(income, career):\n    # Parameter prior distributions\n    alpha = m.dist.normal(0, 1, shape=(2,), name='a')\n    beta = m.dist.half_normal(0.5, shape=(1,), name='b')\n    s_1 = alpha[0] + beta * income[0]\n    s_2 = alpha[1] + beta * income[1]\n    s_3 = [0]\n    p = jnp.exp(jnp.stack([s_1[0], s_2[0], s_3[0]]))\n    # Likelihood\n    m.dist.multinomial(probs = p[career], obs=career)\n    \n# Run sampler ------------------------------------------------ \nm.fit(model)  \n\n# Summary ------------------------------------------------\nm.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\njax.local_device_count 16\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/1000 [00:00<?, ?it/s]\rwarmup:   0%|          | 1/1000 [00:01<27:35,  1.66s/it, 1 steps of size 2.34e+00. acc. prob=0.00]\rwarmup:   5%|â–Œ         | 54/1000 [00:01<00:22, 42.55it/s, 127 steps of size 1.60e-02. acc. prob=0.75]\rwarmup:   8%|â–Š         | 85/1000 [00:01<00:13, 69.31it/s, 255 steps of size 1.99e-02. acc. prob=0.76]\rwarmup:  13%|â–ˆâ–Ž        | 134/1000 [00:01<00:07, 121.90it/s, 7 steps of size 9.80e-01. acc. prob=0.78]\rwarmup:  24%|â–ˆâ–ˆâ–       | 243/1000 [00:02<00:02, 269.21it/s, 1 steps of size 2.15e+00. acc. prob=0.79]\rwarmup:  34%|â–ˆâ–ˆâ–ˆâ–      | 344/1000 [00:02<00:01, 401.01it/s, 7 steps of size 6.26e-01. acc. prob=0.78]\rwarmup:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460/1000 [00:02<00:00, 555.10it/s, 3 steps of size 8.59e-01. acc. prob=0.79]\rsample:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 569/1000 [00:02<00:00, 675.35it/s, 3 steps of size 7.96e-01. acc. prob=0.91]\rsample:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 672/1000 [00:02<00:00, 761.41it/s, 7 steps of size 7.96e-01. acc. prob=0.91]\rsample:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778/1000 [00:02<00:00, 836.97it/s, 7 steps of size 7.96e-01. acc. prob=0.90]\rsample:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878/1000 [00:02<00:00, 874.90it/s, 3 steps of size 7.96e-01. acc. prob=0.90]\rsample:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 978/1000 [00:02<00:00, 908.98it/s, 7 steps of size 7.96e-01. acc. prob=0.90]\rsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 358.14it/s, 7 steps of size 7.96e-01. acc. prob=0.90]\narviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5.5%</th>\n      <th>hdi_94.5%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a[0]</th>\n      <td>0.00</td>\n      <td>0.97</td>\n      <td>-1.60</td>\n      <td>1.51</td>\n      <td>0.05</td>\n      <td>0.04</td>\n      <td>428.89</td>\n      <td>395.09</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a[1]</th>\n      <td>82.06</td>\n      <td>1.02</td>\n      <td>80.40</td>\n      <td>83.58</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>472.75</td>\n      <td>340.24</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[0]</th>\n      <td>40.96</td>\n      <td>0.50</td>\n      <td>40.12</td>\n      <td>41.65</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>616.30</td>\n      <td>368.44</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## R\n\n```R\nlibrary(BayesianInference)\njax = reticulate::import('jax')\n# Setup platform------------------------------------------------\nm=importBI(platform='cpu')\n\n# import data ------------------------------------------------\nm$data(paste(system.file(package = \"BayesianInference\"),\"/data/Sim data multinomial.csv\", sep = ''), sep=',')\nkeys <- c(\"income\", \"career\")\nincome = unique(m$df$income)\nincome = income[order(income)]\nvalues <- list(jnp$array(as.integer(income)),jnp$array( as.integer(m$df$career)))\nm$data_on_model = py_dict(keys, values, convert = TRUE)\n\n# Define model ------------------------------------------------\nmodel <- function(income, career){\n  # Parameter prior distributions\n  alpha = bi.dist.normal(0, 1, name='alpha', shape = c(2))\n  beta = bi.dist.normal(0.5, name='beta')\n  \n  s_1 = alpha[0] + beta * income[0]\n  s_2 = alpha[1] + beta * income[1]\n  s_3 = 0 # reference category\n  \n  p = jax$nn$softmax(jnp$stack(list(s_1, s_2, s_3)))\n  \n  # Likelihood\n  m$dist$multinomial(probs=p[career], obs=career)\n}\n\n\n# Run sampler ------------------------------------------------ \nm$fit(model)  \n\n# Summary ------------------------------------------------\nm$summary()\n```\n:::\n\n## Mathematical Details\nWe can model a vector of frequencies using a Dirichlet distribution. For an outcome variable $Y_i$ with $K$ categories, the *Dirichlet* likelihood function is:\n\n$$\nY_i \\sim \\text{Multinomial}(\\theta_i) \\\\\n\\theta_i = \\text{Softmax}(\\phi_i) \\\\\n\\phi_{[i,1]} = \\alpha_1 + \\beta_1 X_i \\\\\n\\phi_{[i,2]} = \\alpha_2 + \\beta_2 X_i \\\\\n... \\\\\n\\phi_{[i,k]} = 0 \\\\\n\\alpha_{k} \\sim \\text{Normal}(0,1) \\\\\n\\beta_{k} \\sim \\text{Normal}(0.1)\n$$\n\nWhere:\n\n- $Y_i$ is the outcome (i.e. the vector of frequencies for each  $k$ categories) for observation *i*.\n  \n- $\\theta_i$ is a vector unique to each observation, *i*, which gives the probability of observing *i* in category *k*. \n  \n- $\\phi_i$ give the linear model for each of the $k$ categories. Note that we use the softmax function to ensure that that the probabilities $\\theta_i$ form a [<span style=\"color:#0D6EFD\">simplex ðŸ›ˆ</span>]{#simplex}.\n  \n- Each element of $\\phi_i$ is obtained by applying a linear regression model with its own respective intercept $\\alpha_k$ and slope coefficient $\\beta_k$. To ensure the model is identifiable, one category, *K*, is arbitrarily chosen as a reference or baseline category. The linear predictor for this reference category is set to zero. The coefficients for the other categories then represent the change in the log-odds of being in that category versus the reference category.\n\n\n## Reference(s)\n\n",
    "supporting": [
      "10. Multinomial model_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}