{
  "hash": "053523456d68a8b60a86c86cda75839f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Measurement Error Models\"\ndescription: \"Statistical models that explicitly account for errors in the measurement of predictor variables.\"\ncategories: [Regression, Biases]\nimage: \"Figures/16.png\"\norder: 19\n---\n\n\n\n\n\n\n## General Principles\nMeasurement error refers to the variability in the measurement of a variable, and measurement error can be generated by several factors, such as sampling bias, censoring bias, and group size heterogeneity. It is an important consideration in many fields, including statistics, economics, and engineering, where accurate measurements are crucial for making informed decisions. To account for measurement error, we can use a _measurement error model_. This model assumes that the measurement of a variable is subject to an error, which can be modeled using a probability distribution. The model can be used to estimate the parameters of the measurement error distribution, such as the mean and variance, and to make predictions about the measurements based on the estimated parameters. Measurement error models are _composed models_ (i.e., models with sub-models) that evaluate different generative processes, starting with the measurement error process, which is then used to generate the observed data.\n\n\n## Example\nBelow is an example code snippet demonstrating a Bayesian measurement error model using the Bayesian Inference (BI) package. The data consist of three continuous variables (marriage rate, divorce rate, age), and the goal is to estimate the effect of age and marriage rate on the divorce rate while considering that the divorce rate has a measurement error. This example is based on @mcelreath2018statistical.\n\n::: {.panel-tabset group=\"language\"}\n## Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom BI import bi, jnp\n\n# Setup device------------------------------------------------\nm = bi(platform='cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\ndata_path = m.load.WaffleDivorce(only_path=True)\nm.data(data_path, sep=';') \nm.scale(['MedianAgeMarriage', 'Marriage']) # Scale\ndat = dict(\n    D_obs = m.z_score(m.df['Divorce'].values),   \n    D_sd = jnp.array(m.df['Divorce SE'].values / m.df['Divorce'].std()), \n    A = jnp.array(m.df['MedianAgeMarriage'].values), \n    M = jnp.array(m.df['Marriage'].values),\n    N = m.df.shape[0]   \n)\nm.data_on_model = dat # Send to model (convert to jax array)\n\n# Define model ------------------------------------------------\ndef model(D_obs, D_sd, A, N, M):  \n    a = m.dist.normal(0, 0.2, name = 'a') \n    beta = m.dist.normal(0, 0.5, name = 'beta')\n    eta = m.dist.normal(0, 0.5, name = 'eta')  \n    s = m.dist.exponential(1, name = 's') \n    mu = a + beta * A + eta * M\n    D_true = m.dist.normal(mu, s, name = 'D_true') \n    m.dist.normal(D_true , D_sd, obs = D_obs) \n\n# Run MCMC ------------------------------------------------\nm.fit(model)  # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm.summary() # Get posterior distributions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\njax.local_device_count 32\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/1000 [00:00<?, ?it/s]\rwarmup:   0%|          | 1/1000 [00:00<12:23,  1.34it/s, 1 steps of size 2.34e+00. acc. prob=0.00]\rwarmup:   8%|▊         | 80/1000 [00:00<00:07, 128.29it/s, 31 steps of size 9.59e-02. acc. prob=0.77]\rwarmup:  17%|█▋        | 172/1000 [00:00<00:03, 276.00it/s, 15 steps of size 6.15e-01. acc. prob=0.78]\rwarmup:  28%|██▊       | 282/1000 [00:01<00:01, 449.16it/s, 15 steps of size 3.56e-01. acc. prob=0.78]\rwarmup:  40%|███▉      | 397/1000 [00:01<00:00, 610.89it/s, 15 steps of size 5.31e-01. acc. prob=0.79]\rsample:  51%|█████▏    | 513/1000 [00:01<00:00, 746.19it/s, 15 steps of size 2.98e-01. acc. prob=0.91]\rsample:  63%|██████▎   | 628/1000 [00:01<00:00, 851.48it/s, 15 steps of size 2.98e-01. acc. prob=0.92]\rsample:  74%|███████▎  | 735/1000 [00:01<00:00, 895.07it/s, 15 steps of size 2.98e-01. acc. prob=0.92]\rsample:  84%|████████▍ | 843/1000 [00:01<00:00, 945.64it/s, 15 steps of size 2.98e-01. acc. prob=0.92]\rsample:  95%|█████████▍| 949/1000 [00:01<00:00, 961.67it/s, 15 steps of size 2.98e-01. acc. prob=0.92]\rsample: 100%|██████████| 1000/1000 [00:01<00:00, 580.94it/s, 15 steps of size 2.98e-01. acc. prob=0.92]\narviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5.5%</th>\n      <th>hdi_94.5%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>D_true[0]</th>\n      <td>1.20</td>\n      <td>0.35</td>\n      <td>0.73</td>\n      <td>1.83</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>594.50</td>\n      <td>311.15</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[1]</th>\n      <td>0.72</td>\n      <td>0.56</td>\n      <td>-0.18</td>\n      <td>1.54</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>825.18</td>\n      <td>357.15</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[2]</th>\n      <td>0.46</td>\n      <td>0.32</td>\n      <td>-0.00</td>\n      <td>0.99</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>804.31</td>\n      <td>242.18</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[3]</th>\n      <td>1.44</td>\n      <td>0.47</td>\n      <td>0.65</td>\n      <td>2.05</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>761.95</td>\n      <td>307.56</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[4]</th>\n      <td>-0.91</td>\n      <td>0.13</td>\n      <td>-1.13</td>\n      <td>-0.70</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>988.33</td>\n      <td>321.69</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[5]</th>\n      <td>0.66</td>\n      <td>0.41</td>\n      <td>0.04</td>\n      <td>1.36</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1246.87</td>\n      <td>323.91</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[6]</th>\n      <td>-1.39</td>\n      <td>0.38</td>\n      <td>-1.89</td>\n      <td>-0.76</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1009.18</td>\n      <td>298.94</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[7]</th>\n      <td>-0.35</td>\n      <td>0.52</td>\n      <td>-1.17</td>\n      <td>0.49</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>1089.02</td>\n      <td>423.66</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[8]</th>\n      <td>-1.91</td>\n      <td>0.62</td>\n      <td>-2.89</td>\n      <td>-0.98</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>679.08</td>\n      <td>393.51</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[9]</th>\n      <td>-0.63</td>\n      <td>0.17</td>\n      <td>-0.87</td>\n      <td>-0.36</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>1349.49</td>\n      <td>348.55</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[10]</th>\n      <td>0.78</td>\n      <td>0.27</td>\n      <td>0.38</td>\n      <td>1.22</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1051.89</td>\n      <td>257.32</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[11]</th>\n      <td>-0.55</td>\n      <td>0.50</td>\n      <td>-1.40</td>\n      <td>0.22</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>847.21</td>\n      <td>393.66</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[12]</th>\n      <td>0.14</td>\n      <td>0.55</td>\n      <td>-0.69</td>\n      <td>0.99</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>695.14</td>\n      <td>205.29</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[13]</th>\n      <td>-0.89</td>\n      <td>0.24</td>\n      <td>-1.25</td>\n      <td>-0.51</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1197.99</td>\n      <td>353.12</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[14]</th>\n      <td>0.57</td>\n      <td>0.28</td>\n      <td>0.11</td>\n      <td>1.00</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1263.50</td>\n      <td>425.36</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[15]</th>\n      <td>0.29</td>\n      <td>0.34</td>\n      <td>-0.20</td>\n      <td>0.84</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>902.36</td>\n      <td>369.49</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[16]</th>\n      <td>0.50</td>\n      <td>0.42</td>\n      <td>-0.09</td>\n      <td>1.20</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>918.81</td>\n      <td>387.37</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[17]</th>\n      <td>1.29</td>\n      <td>0.37</td>\n      <td>0.78</td>\n      <td>1.93</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1072.81</td>\n      <td>329.82</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[18]</th>\n      <td>0.46</td>\n      <td>0.39</td>\n      <td>-0.13</td>\n      <td>1.09</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>858.17</td>\n      <td>321.87</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[19]</th>\n      <td>0.44</td>\n      <td>0.56</td>\n      <td>-0.49</td>\n      <td>1.26</td>\n      <td>0.03</td>\n      <td>0.02</td>\n      <td>483.84</td>\n      <td>347.58</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[20]</th>\n      <td>-0.57</td>\n      <td>0.29</td>\n      <td>-1.06</td>\n      <td>-0.13</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>840.30</td>\n      <td>406.25</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[21]</th>\n      <td>-1.11</td>\n      <td>0.26</td>\n      <td>-1.56</td>\n      <td>-0.75</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1349.49</td>\n      <td>173.98</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[22]</th>\n      <td>-0.27</td>\n      <td>0.25</td>\n      <td>-0.63</td>\n      <td>0.13</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1306.06</td>\n      <td>365.28</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[23]</th>\n      <td>-1.02</td>\n      <td>0.29</td>\n      <td>-1.48</td>\n      <td>-0.57</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1007.31</td>\n      <td>270.10</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[24]</th>\n      <td>0.46</td>\n      <td>0.40</td>\n      <td>-0.28</td>\n      <td>0.98</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1027.80</td>\n      <td>353.03</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[25]</th>\n      <td>-0.03</td>\n      <td>0.28</td>\n      <td>-0.52</td>\n      <td>0.37</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1017.75</td>\n      <td>393.51</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[26]</th>\n      <td>-0.04</td>\n      <td>0.53</td>\n      <td>-0.88</td>\n      <td>0.76</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>1122.42</td>\n      <td>305.21</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[27]</th>\n      <td>-0.16</td>\n      <td>0.39</td>\n      <td>-0.71</td>\n      <td>0.48</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1349.49</td>\n      <td>351.46</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[28]</th>\n      <td>-0.25</td>\n      <td>0.52</td>\n      <td>-1.03</td>\n      <td>0.61</td>\n      <td>0.02</td>\n      <td>0.05</td>\n      <td>966.76</td>\n      <td>160.75</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[29]</th>\n      <td>-1.83</td>\n      <td>0.26</td>\n      <td>-2.20</td>\n      <td>-1.40</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1106.20</td>\n      <td>352.03</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[30]</th>\n      <td>0.19</td>\n      <td>0.48</td>\n      <td>-0.60</td>\n      <td>0.93</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>1349.49</td>\n      <td>302.06</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[31]</th>\n      <td>-1.67</td>\n      <td>0.16</td>\n      <td>-1.96</td>\n      <td>-1.43</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>1115.72</td>\n      <td>284.32</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[32]</th>\n      <td>0.12</td>\n      <td>0.23</td>\n      <td>-0.25</td>\n      <td>0.48</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1187.57</td>\n      <td>311.15</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[33]</th>\n      <td>-0.08</td>\n      <td>0.49</td>\n      <td>-0.79</td>\n      <td>0.76</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>833.38</td>\n      <td>302.17</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[34]</th>\n      <td>-0.11</td>\n      <td>0.25</td>\n      <td>-0.48</td>\n      <td>0.30</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1349.49</td>\n      <td>219.22</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[35]</th>\n      <td>1.31</td>\n      <td>0.44</td>\n      <td>0.62</td>\n      <td>2.04</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1131.53</td>\n      <td>353.12</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[36]</th>\n      <td>0.24</td>\n      <td>0.34</td>\n      <td>-0.32</td>\n      <td>0.74</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>790.58</td>\n      <td>383.87</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[37]</th>\n      <td>-1.04</td>\n      <td>0.21</td>\n      <td>-1.38</td>\n      <td>-0.73</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1349.49</td>\n      <td>365.09</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[38]</th>\n      <td>-0.91</td>\n      <td>0.55</td>\n      <td>-1.92</td>\n      <td>-0.16</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>767.57</td>\n      <td>425.43</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[39]</th>\n      <td>-0.71</td>\n      <td>0.29</td>\n      <td>-1.12</td>\n      <td>-0.24</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>945.80</td>\n      <td>438.47</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[40]</th>\n      <td>0.26</td>\n      <td>0.53</td>\n      <td>-0.64</td>\n      <td>1.09</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>1201.76</td>\n      <td>255.08</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[41]</th>\n      <td>0.76</td>\n      <td>0.33</td>\n      <td>0.14</td>\n      <td>1.17</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>763.53</td>\n      <td>224.82</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[42]</th>\n      <td>0.20</td>\n      <td>0.17</td>\n      <td>-0.11</td>\n      <td>0.46</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>1349.49</td>\n      <td>461.64</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[43]</th>\n      <td>0.80</td>\n      <td>0.48</td>\n      <td>0.07</td>\n      <td>1.56</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>931.02</td>\n      <td>304.36</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[44]</th>\n      <td>-0.40</td>\n      <td>0.52</td>\n      <td>-1.27</td>\n      <td>0.35</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>1349.49</td>\n      <td>368.12</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[45]</th>\n      <td>-0.39</td>\n      <td>0.24</td>\n      <td>-0.74</td>\n      <td>-0.02</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>933.88</td>\n      <td>332.15</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[46]</th>\n      <td>0.13</td>\n      <td>0.31</td>\n      <td>-0.30</td>\n      <td>0.67</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1349.49</td>\n      <td>294.58</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[47]</th>\n      <td>0.60</td>\n      <td>0.47</td>\n      <td>-0.15</td>\n      <td>1.36</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>1337.89</td>\n      <td>292.95</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[48]</th>\n      <td>-0.64</td>\n      <td>0.29</td>\n      <td>-1.07</td>\n      <td>-0.13</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>1349.49</td>\n      <td>337.37</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D_true[49]</th>\n      <td>0.88</td>\n      <td>0.62</td>\n      <td>-0.11</td>\n      <td>1.85</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>817.15</td>\n      <td>370.41</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>-0.05</td>\n      <td>0.10</td>\n      <td>-0.21</td>\n      <td>0.11</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>700.95</td>\n      <td>468.17</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <td>-0.62</td>\n      <td>0.16</td>\n      <td>-0.88</td>\n      <td>-0.37</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>407.98</td>\n      <td>254.65</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>eta</th>\n      <td>0.05</td>\n      <td>0.17</td>\n      <td>-0.18</td>\n      <td>0.36</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>370.43</td>\n      <td>429.80</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>s</th>\n      <td>0.60</td>\n      <td>0.11</td>\n      <td>0.44</td>\n      <td>0.78</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>325.49</td>\n      <td>352.19</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## R\n``` R\nlibrary(BayesianInference)\njnp = reticulate::import('jax.numpy')\n\n# Setup platform------------------------------------------------\nm=importBI(platform='cpu')\n\n# Import data ------------------------------------------------\nm$data(paste(system.file(package = \"BayesianInference\"),\"/data/WaffleDivorce.csv\", sep = ''), sep=';')\n\nm$scale(list('MedianAgeMarriage', 'Marriage'))\n\nm$data_on_model$D_obs = m$z_score(jnp$array(m$df['Divorce']))\nm$data_on_model$D_sd = jnp$array(m$df['Divorce SE']) / sd(unlist(m$df['Divorce']))\nm$data_on_model$A = jnp$array(m$df['MedianAgeMarriage'])\nm$data_on_model$M = jnp$array(m$df['Marriage'])\nm$data_on_model$N = as.integer(nrow(m$df))\n\n# Define model ------------------------------------------------\nmodel <- function(D_obs, D_sd, A, N, M){\n  a = bi.dist.normal(0, 0.2, name = 'a') \n  beta = bi.dist.normal(0, 0.5, name = 'beta')\n  eta = bi.dist.normal(0, 0.5, name = 'eta') \n  s = bi.dist.exponential(1, name = 's') \n  mu = a + beta * A + eta * M\n  D_true = bi.dist.normal(mu, s, name = 'D_true') \n  bi.dist.normal(D_true , D_sd, obs = D_obs) \n}\n\n# Run MCMC ------------------------------------------------\nm$fit(model) # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm$summary() # Get posterior distribution\n\n```\n## Julia\n```julia\nusing BayesianInference\n\n# Setup device------------------------------------------------\nm = importBI(platform=\"cpu\")\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\ndata_path = m.load.WaffleDivorce(only_path=true)\nm.data(data_path, sep=\";\") \nm.scale([\"MedianAgeMarriage\", \"Marriage\"]) # Scale\ndat = pydict(\n    D_obs = m.z_score(m.df[\"Divorce\"].values),   \n    D_sd = jnp.array(m.df[\"Divorce SE\"].values / m.df[\"Divorce\"].std()), \n    A = jnp.array(m.df[\"MedianAgeMarriage\"].values), \n    M = jnp.array(m.df[\"Marriage\"].values),\n    N = m.df.shape[0]   \n)\nm.data_on_model = dat # Send to model (convert to jax array)\n\n# Define model ------------------------------------------------\n@BI function model(D_obs, D_sd, A, N, M)\n    a = m.dist.normal(0, 0.2, name = \"a\") \n    beta = m.dist.normal(0, 0.5, name = \"beta\")\n    eta = m.dist.normal(0, 0.5, name = \"eta\")  \n    s = m.dist.exponential(1, name = \"s\") \n    mu = a + beta * A + eta * M\n    D_true = m.dist.normal(mu, s, name = \"D_true\") \n    m.dist.normal(D_true , D_sd, obs = D_obs) \n\n\nend\n\n# Run mcmc ------------------------------------------------\nm.fit(model)  # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm.summary() # Get posterior distributions\n```\n\n:::\n\n## Mathematical Details\n### *Bayesian formulation*\n\n$$\nD_i^* \\sim \\text{Normal}(D_i, \\varsigma_i)\n$$\n\n$$\nD_i \\sim \\text{Normal}(\\mu_i, \\sigma)\n$$\n\n$$\n\\mu_i = \\alpha + \\beta A_i + \\eta M_i \n$$\n\n$$\n\\sigma \\sim \\text{Normal}(1)\n$$\n\nwhere:\n\n- $D_i^*$ is the observed divorce rate.\n\n- $D_i$ is the true divorce rate.\n\n- $\\mu_i$ is the mean of the true divorce rate.\n\n- $\\sigma$ is the standard deviation of the true divorce rate.\n\n- $\\alpha$ is the intercept term.\n\n- $\\beta$ is the regression coefficient for age.\n\n- $\\eta$ is the regression coefficient for marriage rate.    \n\n\n## Notes\n::: callout-note\nThis is an approach that can be extended to any kind of model previously described. For example, one could generate a Bernoulli measurement error model by generating a process for the probabilities of success and failure. We can even go further by potentially having an error rate that is present only in one of the two outcomes.\n\n\n:::\n\n## Reference(s)\n::: {#refs}\n:::\n\n",
    "supporting": [
      "16. Measuring error_files/figure-pdf"
    ],
    "filters": []
  }
}