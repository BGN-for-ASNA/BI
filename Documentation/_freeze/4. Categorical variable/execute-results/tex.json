{
  "hash": "cd2200be879e5b404a45064e235552c1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Regression with a Categorical Independent Variable\"\ndescription: \"Incorporating categorical predictors (i.e., factor variables) into a regression model using dummy variables.\"\ncategories: [Regression, GLM]\nimage: \"Figures/4.png\"\norder: 5\n---\n\n## General Principles\nTo study the relationship between a categorical independent variable and a continuous dependent variable, we use a _Categorical model_ which applies _stratification_.\n\n_Stratification_ involves modeling how the *k* different categories of the independent variable affect the target continuous variable by performing a regression for each *k* category and assigning a regression coefficient for each category. To implement stratification, categorical variables are often encoded using [<span style=\"color:#0D6EFD\">one-hot encoding ðŸ›ˆ</span>]{#ohe} or by converting categories to [<span style=\"color:#0D6EFD\">indices ðŸ›ˆ</span>]{#indices}.\n\n\n## Considerations\n::: callout-note\n- We have the same considerations as for [Regression for a Continuous Variable](1.&#32;Linear&#32;Regression&#32;for&#32;continuous&#32;variable.qmd).\n \n- As we generate regression coefficients for each *k* category, we need to specify a prior with a shape equal to the number of categories *k* in the code (see comments in the code).\n  \n- To compare differences between categories, we need to compute the distribution of the differences between categories, known as the contrast distribution. **Never compare confidence intervals or p-values directly**.\n\n\n:::\n\n## Example\nBelow is an example of code that demonstrates Bayesian regression with an independent categorical variable using the Bayesian Inference (BI) package. The data consist of one continuous dependent variable (*kcal_per_g*), representing the caloric value of milk per gram, a categorical independent variable (*index_clade*), representing species clade membership, and a continuous independent variable (*mass*), representing the mass of individuals in the clade. The goal is to estimate the differences in milk calories between clades. This example is based on @mcelreath2018statistical.\n\n::: {.panel-tabset group=\"language\"}\n### Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom BI import bi\n\n# Setup device------------------------------------------------\nm = bi(platform='cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\nfrom importlib.resources import files\ndata_path = files('BI.resources.data') / 'milk.csv'\nm.data(data_path, sep=';') \nm.index([\"clade\"]) # Convert clade names into index\nm.scale(['kcal_per_g']) # Scale\n\n# Define model ------------------------------------------------\ndef model(kcal_per_g, index_clade, mass):\n    a = m.dist.normal(0, 0.5, shape=(4,), name = 'a') # shape based on the number of clades\n    b = m.dist.normal(0, 0.5, shape=(4,), name = 'b')\n    s = m.dist.exponential( 1, name = 's')    \n    mu = a[index_clade]+b[index_clade]*mass\n    m.dist.normal(mu, s, obs=kcal_per_g)\n\n\n# Run mcmc ------------------------------------------------\nm.fit(model) # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\njax.local_device_count 16\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/1000 [00:00<?, ?it/s]\rwarmup:   0%|          | 1/1000 [00:01<21:28,  1.29s/it, 1 steps of size 2.34e+00. acc. prob=0.00]\rwarmup:   4%|â–         | 45/1000 [00:01<00:21, 44.40it/s, 511 steps of size 5.30e-03. acc. prob=0.73]\rwarmup:   8%|â–Š         | 77/1000 [00:01<00:11, 78.39it/s, 107 steps of size 6.12e-03. acc. prob=0.75]\rwarmup:  11%|â–ˆâ–        | 114/1000 [00:01<00:07, 122.23it/s, 7 steps of size 2.40e-01. acc. prob=0.77]\rwarmup:  22%|â–ˆâ–ˆâ–       | 215/1000 [00:01<00:02, 279.18it/s, 31 steps of size 2.15e-01. acc. prob=0.78]\rwarmup:  32%|â–ˆâ–ˆâ–ˆâ–      | 318/1000 [00:01<00:01, 430.03it/s, 7 steps of size 4.73e-01. acc. prob=0.78] \rwarmup:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427/1000 [00:01<00:00, 576.45it/s, 7 steps of size 6.45e-01. acc. prob=0.79]\rsample:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 531/1000 [00:01<00:00, 688.32it/s, 15 steps of size 3.48e-01. acc. prob=0.90]\rsample:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 639/1000 [00:02<00:00, 787.38it/s, 15 steps of size 3.48e-01. acc. prob=0.93]\rsample:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 740/1000 [00:02<00:00, 845.11it/s, 7 steps of size 3.48e-01. acc. prob=0.93] \rsample:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837/1000 [00:02<00:00, 870.53it/s, 15 steps of size 3.48e-01. acc. prob=0.93]\rsample:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939/1000 [00:02<00:00, 911.97it/s, 7 steps of size 3.48e-01. acc. prob=0.93] \rsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 405.41it/s, 15 steps of size 3.48e-01. acc. prob=0.93]\narviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5.5%</th>\n      <th>hdi_94.5%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a[0]</th>\n      <td>-0.32</td>\n      <td>0.35</td>\n      <td>-0.79</td>\n      <td>0.34</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>430.93</td>\n      <td>365.09</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a[1]</th>\n      <td>0.59</td>\n      <td>0.30</td>\n      <td>0.10</td>\n      <td>1.06</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>412.79</td>\n      <td>283.95</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a[2]</th>\n      <td>0.31</td>\n      <td>0.37</td>\n      <td>-0.28</td>\n      <td>0.87</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>404.55</td>\n      <td>368.44</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>a[3]</th>\n      <td>-0.17</td>\n      <td>0.49</td>\n      <td>-0.92</td>\n      <td>0.64</td>\n      <td>0.03</td>\n      <td>0.02</td>\n      <td>376.94</td>\n      <td>232.82</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[0]</th>\n      <td>-0.00</td>\n      <td>0.01</td>\n      <td>-0.02</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>456.57</td>\n      <td>350.35</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[1]</th>\n      <td>-0.17</td>\n      <td>0.12</td>\n      <td>-0.36</td>\n      <td>0.04</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>356.03</td>\n      <td>342.61</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[2]</th>\n      <td>0.08</td>\n      <td>0.07</td>\n      <td>-0.02</td>\n      <td>0.19</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>371.61</td>\n      <td>388.81</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b[3]</th>\n      <td>-0.27</td>\n      <td>0.27</td>\n      <td>-0.72</td>\n      <td>0.13</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>352.82</td>\n      <td>217.58</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>s</th>\n      <td>0.80</td>\n      <td>0.12</td>\n      <td>0.59</td>\n      <td>0.97</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>386.61</td>\n      <td>438.95</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### R\n```R\nlibrary(BI)\nm=importbi(platform='cpu')\n\n# Load csv file\nm$data(paste(system.file(package = \"BI\"),\"/data/milk.csv\", sep = ''), sep=';')\nm$scale(list('kcal.per.g')) # Manipulate\nm$index(list('clade')) # Scale\nm$data_to_model(list('kcal_per_g', 'index_clade')) # Send to model (convert to jax array)\n\n# Define model ------------------------------------------------\nmodel <- function(kcal_per_g, index_clade){\n  # Parameter prior distributions\n  beta = bi.dist.normal( 0, 0.5, name = 'beta', shape = c(4))  # shape based on the number of clades\n  sigma =bi.dist.exponential(1, name = 's')\n  # Likelihood\n  m$normal(beta[index_clade], sigma, obs=kcal_per_g)\n}\n\n# Run mcmc ------------------------------------------------\nm$fit(model) # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm$summary() # Get posterior distributions\n```\n:::\n\n::: callout-caution\nFor R users, when working with indices you have to ensure 1) that indices are intergers (i.e. ```as.integer(index_clade)```) and, 2) that indices start at 0 (i.e. ```as.integer(index_clade)-1```).\n:::\n\n## Mathematical Details\n### *Frequentist formulation*\nWe model the relationship between the categorical input feature (X) and the target variable (Y) using the following equation:\n\n$$\nY_i = \\alpha + \\beta_k X_i + \\sigma\n$$\n\nWhere:\n\n- $Y_i$ is the dependent variable for observation *i*. \n  \n- $\\alpha$ is the intercept term.\n  \n- $\\beta_k$ are the regression coefficients for each _k_ category.\n  \n- $X_i$ is the encoded categorical input variable for observation *i*. \n  \n- $\\sigma$ is the error term.\n\nWe can interpret $\\beta_i$ as the effect of each category on $Y$ relative to the baseline (usually one of the categories or the intercept). \n\n### *Bayesian formulation*\nIn the Bayesian formulation, we define each parameter with [<span style=\"color:#0D6EFD\">priors ðŸ›ˆ</span>]{#prior}. We can express the Bayesian regression model accounting for prior distributions as follows:\n\n$$\nY \\sim \\text{Normal}(\\alpha +  \\beta_K X, \\sigma)\n$$\n\n$$\n\\alpha \\sim \\text{Normal}(0,1)\n$$\n\n$$\n\\beta_K \\sim \\text{Normal}(0,1)\n$$\n\n$$\n\\sigma \\sim \\text{Exponential}(1)\n$$\n\nWhere:\n\n- $Y_i$ is the dependent variable for observation *i*.\n  \n- $\\alpha$ is the intercept term, which in this case has a unit-normal prior.\n  \n- $\\beta_K$ are slope coefficients for the _K_ distinct independent variables categories, which also have unit-normal priors.\n  \n- $X_i$ is the encoded categorical input variable for observation *i*. \n  \n- $\\sigma$ is a standard deviation parameter, which here has a Exponential prior that constrains it to be positive.\n\n## Notes\n::: callout-note\n\n- We can apply multiple variables similarly to [Chapter 2: Multiple Continuous Variables](2.&#32;Multiple&#32;continuous&#32;Variables.qmd).\n\n- We can apply interaction terms similarly to [Chapter 3: Interaction between Continuous Variables](3.&#32;Interaction&#32;between&#32;continuous&#32;variables.qmd).\n:::\n\n## Reference(s)\n::: {#refs}\n:::\n\n",
    "supporting": [
      "4. Categorical variable_files/figure-pdf"
    ],
    "filters": []
  }
}