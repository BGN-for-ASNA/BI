{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Univariate Linear Regression\"\n",
        "description: \"An introduction to linear regression models.\"\n",
        "categories: [Regression]\n",
        "image: \"Figures/regression_random_sampling.gif\"\n",
        "order: 2\n",
        "reading-time: true\n",
        "---\n",
        "\n",
        "\n",
        "## General Principles\n",
        "\n",
        "To study relationships between a continuous independent variable and a continuous dependent variable (e.g., height and weight), we can use linear regression. Essentially, we draw a line that passes through the point cloud of the two variables being tested. For this, we need to have:\n",
        "\n",
        "1) An intercept $\\alpha$, which represents the origin of the line,i.e., the expected value of the dependent variable (height) when the independent variable (weight) is equal to zero.\n",
        "\n",
        "2) A coefficient $\\beta$, which informs us about the slope of the line. In other words, it tells us how much Y (height) increases for each increment of the independent variable (weight).\n",
        "\n",
        "3) A standard deviation term $\\sigma$, which informs us about the spread of points around the line, i.e., the variance around the prediction.\n",
        "\n",
        "\n",
        "## Considerations\n",
        "\n",
        "::: callout-note\n",
        "-   Bayesian models allow us to update our understanding of parameters conditional on an observed data set. This allows us to consider [<span style=\"color:#0D6EFD\">model parameter uncertainty ðŸ›ˆ</span>]{#uncertainty}, which quantifies our confidence or uncertainty in the parameters in the form of a [<span style=\"color:#0D6EFD\">posterior distribution ðŸ›ˆ</span>]{#posterior}. Therefore, we need to declare [<span style=\"color:#0D6EFD\">prior distributions ðŸ›ˆ</span>]{#prior} for each model parameter, in this case for: $\\alpha$, $\\beta$, and $\\sigma$.\n",
        "\n",
        "- Prior distributions are built following these considerations:\n",
        "\n",
        "  - As the data are [<span style=\"color:#0D6EFD\">normalizedðŸ›ˆ</span>]{#scaled} (see introduction), we can use a Normal distribution for $\\alpha$ and $\\beta$, with a mean of 0 and a standard deviation of 1. This tends to be a weakly regularizing prior, and weaker priors like a $Normal(0,10)$ are also possible.\n",
        "\n",
        "  - Since $\\sigma$ must be strictly positive, we must use a distribution with support on the positive reals, such as the *Exponential* or *Folded-Normal* distribution.\n",
        "\n",
        "- Gaussian regression deals directly with continuous outcomes, estimating a linear relationship between predictors and the outcome variable without depending on a non linear [<span style=\"color:#0D6EFD\">link function ðŸ›ˆ</span>]{#linkF} (see introduction). This simplifies interpretation, as coefficients represent direct changes in the outcome variable.\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "## Example\n",
        "\n",
        "Below is an example code snippet demonstrating *Bayesian linear regression* using the Bayesian Inference (**BI**) package. Data consist of two continuous variables (height and weight), and the goal is to estimate the effect of weight on height. This example is based on @mcelreath2018statistical.\n",
        "\n",
        "::: {.panel-tabset group=\"language\"}\n",
        "## Python"
      ],
      "id": "c4743687"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from BI import bi\n",
        "\n",
        "# Setup device------------------------------------------------\n",
        "m = bi(platform='cpu')\n",
        "\n",
        "# Import Data & Data Manipulation ------------------------------------------------\n",
        "# Import\n",
        "from importlib.resources import files\n",
        "data_path = m.load.howell1(only_path = True)\n",
        "m.data(data_path, sep=';') \n",
        "m.df = m.df[m.df.age > 18] # Subset data to adults\n",
        "m.scale(['weight']) # Normalize\n",
        "\n",
        "# Define model ------------------------------------------------\n",
        "def model(weight, height):    \n",
        "    a = m.dist.normal(178, 20, name = 'a') \n",
        "    b = m.dist.log_normal(0, 1, name = 'b') \n",
        "    s = m.dist.uniform(0, 50, name = 's') \n",
        "    m.dist.normal(a + b * weight , s, obs = height) \n",
        "\n",
        "# Run mcmc ------------------------------------------------\n",
        "m.fit(model)  # Optimize model parameters through MCMC sampling\n",
        "\n",
        "# Summary ------------------------------------------------\n",
        "m.summary() # Get posterior distributions"
      ],
      "id": "df2e3e1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\n",
        "\n",
        "``` r\n",
        "library(BayesianInference)\n",
        "m <- importBI(platform = \"cpu\")\n",
        "\n",
        "# Load csv file\n",
        "m$data(m$load$howell1(only_path = T), sep = \";\")\n",
        "\n",
        "# Filter data frame\n",
        "m$df <- m$df[m$df$age > 18, ] # Subset data to adults\n",
        "\n",
        "# Scale\n",
        "m$scale(list(\"weight\")) # Normalize\n",
        "\n",
        "# Convert data to JAX arrays\n",
        "m$data_to_model(list(\"weight\", \"height\"))\n",
        "\n",
        "# Define model ------------------------------------------------\n",
        "model <- function(height, weight) {\n",
        "    # Parameter prior distributions\n",
        "    s <- bi.dist.uniform(0, 50, name = \"s\")\n",
        "    a <- bi.dist.normal(178, 20, name = \"a\")\n",
        "    b <- bi.dist.normal(0, 1, name = \"b\")\n",
        "\n",
        "    # Likelihood\n",
        "    bi.dist.normal(a + b * weight, s, obs = height)\n",
        "}\n",
        "\n",
        "# Run MCMC ------------------------------------------------\n",
        "m$fit(model) # Optimize model parameters through MCMC sampling\n",
        "\n",
        "# Summary ------------------------------------------------\n",
        "m$summary()\n",
        "``` \n",
        "\n",
        "## Julia\n",
        "```julia\n",
        "using BayesianInference\n",
        "\n",
        "# Setup device------------------------------------------------\n",
        "m = importBI(platform=\"cpu\")\n",
        "\n",
        "# Import Data & Data Manipulation ------------------------------------------------\n",
        "# Import\n",
        "data_path = m.load.howell1(only_path = true)\n",
        "m.data(data_path, sep=';') \n",
        "m.df = m.df[m.df.age > 18] # Subset data to adults\n",
        "m.scale([\"weight\"]) # Normalize\n",
        "\n",
        "# Define model ------------------------------------------------\n",
        "@BI function model(weight, height)\n",
        "    # Priors\n",
        "    a = m.dist.normal(178, 20, name = 'a') \n",
        "    b = m.dist.log_normal(0, 1, name = 'b') \n",
        "    s = m.dist.uniform(0, 50, name = 's') \n",
        "    m.dist.normal(a + b * weight , s, obs = height) \n",
        "end\n",
        "\n",
        "# Run mcmc ------------------------------------------------\n",
        "m.fit(model)  # Optimize model parameters through MCMC sampling\n",
        "\n",
        "# Summary ------------------------------------------------\n",
        "m.summary() # Get posterior distributions\n",
        "```\n",
        ":::\n",
        "\n",
        "## Mathematical Details\n",
        "\n",
        "### *Frequentist Formulation*\n",
        "\n",
        "The following equation describe the frequentist formulation of linear regression:\n",
        "\n",
        "$$\n",
        "Y_i = \\alpha + \\beta  X_i + \\epsilon_i\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "-   $Y_i$ is the dependent variable for observation *i*.\n",
        "\n",
        "-   $\\alpha$ is the intercept term.\n",
        "\n",
        "-   $\\beta$ is the regression coefficient.\n",
        "\n",
        "-   $X_i$ is the input variable for observation *i*.\n",
        "\n",
        "-   $\\epsilon_i$ is the error term for observation *i*, and the vector of the error terms, $\\epsilon$, are assumed to be independent and identically distributed.\n",
        "\n",
        "### *Bayesian Formulation*\n",
        "\n",
        "In the Bayesian formulation, we define each parameter with [<span style=\"color:#0D6EFD\">priors ðŸ›ˆ</span>]{#prior}. We can express a Bayesian version of this regression model using the following model:\n",
        "\n",
        "$$\n",
        "Y_i \\sim \\text{Normal}(\\alpha + \\beta   X_i, \\sigma)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\alpha \\sim \\text{Normal}(0, 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\beta \\sim \\text{Normal}(0, 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sigma \\sim \\text{Uniform}(0, 50)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "-   $Y_i$ is the dependent variable for observation *i*.\n",
        "\n",
        "-   $\\alpha$ and $\\beta$ are the intercept and regression coefficient, respectively.\n",
        "\n",
        "-   $X_i$ is the independent variable for observation *i*.\n",
        "\n",
        "-   $\\sigma$ is the standard deviation of the Normal distribution, which describes the variance in the relationship between the dependent variable $Y$ and the independent variable $X$.\n",
        "\n",
        "\n",
        "## Notes\n",
        "::: callout-note\n",
        "We observe a difference between the *Frequentist* and the *Bayesian* formulation regarding the error term. Indeed, in the *Frequentist* formulation, the error term $\\epsilon$ represents residual fluctuations around the predicted values. This assumption leads to point estimates for $\\alpha$ and $\\beta$. In contrast, the *Bayesian* formulation treats $\\sigma$ as a parameter with its own prior distribution. This allows us to incorporate our uncertainty about the error term into the model.\n",
        ":::\n",
        "\n",
        "## Reference(s)\n",
        "\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "a1a198c0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/sosa/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}