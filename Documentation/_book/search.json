[
  {
    "objectID": "14. Varying slopes.html",
    "href": "14. Varying slopes.html",
    "title": "16Â  Varying slopes",
    "section": "",
    "text": "16.1 General Principles\nTo model the relationship between predictor variables and a dependent variable while allowing for varying effects across groups or clusters, we use a varying slopes model.\nThis approach is useful when we expect the relationship between predictors and the dependent variable to differ across groups (e.g., different slopes for different subjects, locations, or time periods). This allows every unit in the data to have its own unique response to any treatment, exposure, or event, while also improving estimates via pooling.",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#considerations",
    "href": "14. Varying slopes.html#considerations",
    "title": "16Â  Varying slopes",
    "section": "16.2 Considerations",
    "text": "16.2 Considerations\n\n\n\n\n\n\nCaution\n\n\n\n\nWe have the same considerations as for 12. Varying intercepts.\nThe idea is pretty similar to categorical models, where a slope is specified for each category. However, here, we also estimate relationships between different groups. This leads to a different mathematical approach, as to model these relationships between groups, we model a matrix of covariance ðŸ›ˆ.\nThe covariance matrix requires a correlation matrix distribution which is modeled using a \\(LKJcorr\\) distribution that holds a parameter \\(Î·\\). \\(Î·\\) is usually set to 2 to define a weakly informative prior that is skeptical of extreme correlations near âˆ’1 or 1. When we use \\(LKJcorr(1)\\), the prior is flat over all valid correlation matrices. When the value is greater than 1, then extreme correlations are less likely.\nThe Half-Cauchy distribution is used when modeling the covariance matrix to specify strictly positive values for the diagonal of the covariance matrix, ensuring positive variances.",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#example",
    "href": "14. Varying slopes.html#example",
    "title": "16Â  Varying slopes",
    "section": "16.3 Example",
    "text": "16.3 Example\nBelow is an example code snippet demonstrating Bayesian regression with varying effects:\n\n16.3.1 Simulated data\n\nPythonR\n\n\nfrom BI import bi\n# Setup device------------------------------------------------\nm = bi(platform='cpu')\n\n# Import Data & Data Manipulation ------------------------------------------------\n# Import\nfrom importlib.resources import files\ndata_path = files('bi.resources.data') / 'Sim data multivariatenormal.csv'\nm.data(data_path, sep=',') \n\n# Define model ------------------------------------------------\ndef model(cafe, wait, N_cafes, afternoon):\n    a = m.dist.normal(5, 2,  name = 'a')\n    b = m.dist.normal(-1, 0.5, name = 'b')\n    sigma_cafe = m.dist.exponential(1, shape=(2,),  name = 'sigma_cafe')\n    sigma = m.dist.exponential( 1,  name = 'sigma')\n    Rho = m.dist.lkj(2, 2, name = 'Rho')\n    cov = jnp.outer(sigma_cafe, sigma_cafe) * Rho\n    a_cafe_b_cafe = m.dist.multivariatenormal(jnp.stack([a, b]), cov, shape = [N_cafes], name = 'a_b_cafe')    \n\n    a_cafe, b_cafe = a_cafe_b_cafe[:, 0], a_cafe_b_cafe[:, 1]\n    mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n    m.dist.normal(mu, sigma, obs=wait)\n\n# Run sampler ------------------------------------------------\nm.run(model) \n\n\nlibrary(BI)\n\n# setup platform------------------------------------------------\nm=importBI(platform='cpu')\n\n# Import data ------------------------------------------------\nm$data(paste(system.file(package = \"BI\"),\"/data/Sim data multivariatenormal.csv\", sep = ''), sep=',')\nm$data_to_model(list('cafe', 'wait', 'afternoon'))\n\n# Define model ------------------------------------------------\nmodel &lt;- function(cafe, afternoon, wait, N_cafes = as.integer(20) ){\n  a = bi.dist.normal(5, 2, name = 'a')\n  b = bi.dist.normal(-1, 0.5, name = 'b')\n  sigma_cafe = bi.dist.exponential(1, shape= c(2), name = 'sigma_cafe')\n  sigma = bi.dist.exponential( 1, name = 'sigma')\n  Rho = bi.dist.lkj(as.integer(2), as.integer(2), name = 'Rho')\n  cov = jnp$outer(sigma_cafe, sigma_cafe) * Rho\n  \n  a_cafe_b_cafe = bi.dist.multivariatenormal(\n    jnp$squeeze(jnp$stack(list(a, b))), \n    cov, shape = c(N_cafes), name = 'a_cafe')  \n  \n  a_cafe = a_cafe_b_cafe[, 0]\n  b_cafe = a_cafe_b_cafe[, 1]\n  \n  mu = a_cafe[cafe] + b_cafe[cafe] * afternoon\n  \n  m$normal(mu, sigma, obs=wait)\n}\n\n# Run MCMC ------------------------------------------------\nm$run(model) # Optimize model parameters through MCMC sampling\n\n# Summary ------------------------------------------------\nm$summary() # Get posterior distribution",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#mathematical-details",
    "href": "14. Varying slopes.html#mathematical-details",
    "title": "16Â  Varying slopes",
    "section": "16.4 Mathematical Details",
    "text": "16.4 Mathematical Details",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#mathematical-details-1",
    "href": "14. Varying slopes.html#mathematical-details-1",
    "title": "16Â  Varying slopes",
    "section": "16.5 Mathematical Details",
    "text": "16.5 Mathematical Details\n\n16.5.1 Formula\nWe model the relationship between the independent variable \\(X\\) and the outcome variable \\(Y\\) with varying intercepts (\\(\\alpha\\)) and varying slopes (\\(\\beta\\)) for each group (\\(k\\)) using the following equation:\n\\[\nY_{ik} = \\alpha_k + \\beta_k X_{ik} + \\sigma\n\\]\nWhere:\n\n\\(Y_{ik}\\) is the outcome variable for observation \\(i\\) in group \\(k\\).\n\\(X_{ik}\\) is the independent variable for observation \\(i\\) in group \\(k\\).\n\\(\\alpha_k\\) is the varying intercept for group \\(k\\).\n\\(\\beta_k\\) is the varying regression coefficient for group \\(k\\).\n\\(\\sigma\\) is the error term, assumed to be strictly positive.\n\n\n\n16.5.2 Bayesian Model\nWe can express the Bayesian regression model accounting for prior distributions as follows:\n\\[\nY_{ik} \\sim \\text{Normal}(\\mu_{ik} , \\sigma)\n\\] _{ik} = _k + k X{ik} + \\[\n\\alpha_k \\sim Normal(0,1)\n\\] _k Normal(0,1) \\[\n\\sigma \\sim Exponential(0,1)\n\\]\nThe varying intercepts (\\(\\alpha_k\\)) and slopes (\\(\\beta_k\\)) are modeled using a Multivariate Normal distribution:\n\\[\n\\begin{pmatrix}\n\\alpha_k \\\\\n\\beta_k\n\\end{pmatrix} \\sim \\text{MultivariateNormal}\\left(\n\\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix},\n\\begin{pmatrix}\n\\sigma_\\alpha^2 & \\sigma_\\pi \\sigma_{\\alpha\\rho} \\\\\n\\sigma_\\alpha \\sigma_{\\pi\\rho} & \\sigma_\\pi\n\\end{pmatrix}\n\\right)\n\\]\nWhere:\n\n\\(\\left(\\begin{array}{cc} 0 \\\\ 0 \\end{array}\\right)\\) is the prior for the average intercept.\n\\(\\left(\\begin{array}{cc} \\sigma_\\alpha^2 & \\sigma_\\alpha \\sigma_{\\pi \\rho} \\\\ \\sigma_\\alpha \\sigma_{\\pi \\rho} & \\sigma_\\pi^2 \\end{array}\\right)\\) is the covariance matrix which specifies the variance and covariance of \\(\\alpha_k\\) and \\(\\beta_k\\),\nwhere:\n\n\\(\\sigma_\\alpha^2\\) is the variance of \\(\\alpha_k\\).\n\\(\\sigma_\\pi^2\\) is the variance of \\(\\beta_k\\).\n\\(\\sigma_\\alpha \\sigma_{\\pi \\rho}\\) is the covariance between \\(\\alpha_k\\) and \\(\\beta_k\\). For computational reasons, it is often better to implement a centered version of the varying intercept ðŸ›ˆ that is equivalent to the Multivariate Normal distribution approach:\n\n\n\\[\n\\left(\\begin{array}{cc} \\alpha_k \\\\ \\beta_k\\end{array}\\right)\n\\sim\n\\left(\\begin{array}{cc}\n\\sigma_\\alpha\\\\\n\\sigma_\\pi\n\\end{array}\\right) \\circ\nL *\n\\left(\\begin{array}{cc}\n\\widehat{\\alpha}_k \\\\\n\\widehat{\\pi}_k\n\\end{array}\\right)\n\\]\n\nWhere:\n\n\\(\\sigma_\\alpha \\sim \\text{Exponential}(1)\\) is the prior standard deviation among intercepts.\n\\(\\sigma_\\beta \\sim \\text{Exponential}(1)\\) is the prior standard deviation among slopes.\n\\(L \\sim \\text{LKJcorr}(\\eta)\\) is the prior for the correlation matrix using the Cholesky Factor ðŸ›ˆ\n\n\nThe full centered version of the model is thus:\n\\[\nY_{i} \\sim \\text{Normal}(\\mu_k , \\sigma) \\\\\n\\]\n\\[\n\\mu_k =   \\alpha_k + \\beta_i X_i \\\\\n\\]\n\\[\n\\left(\\begin{array}{cc} \\alpha_k \\\\ \\beta_k\\end{array}\\right)\n\\sim\n\\left(\\begin{array}{cc}\n\\sigma_\\alpha\\\\\n\\sigma_\\pi\n\\end{array}\\right) \\circ\nL *\n\\left(\\begin{array}{cc}\n\\widehat{\\alpha}_k \\\\\n\\widehat{\\pi}_k\n\\end{array}\\right)\n\\]\n\\[\n\\alpha \\sim Normal(0,1)\n\\] \\[\n\\beta \\sim Normal(0,1)\n\\] \\[\n\\sigma_\\alpha \\sim Exponential(1)\n\\]\n\\[\n\\sigma_\\pi \\sim Exponential(1)\n\\]\n\\[\nL \\sim LKJcorr(2)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#multivariate-model-with-one-random-slope-for-each-variable",
    "href": "14. Varying slopes.html#multivariate-model-with-one-random-slope-for-each-variable",
    "title": "16Â  Varying slopes",
    "section": "16.6 Multivariate Model with One Random Slope for Each Variable",
    "text": "16.6 Multivariate Model with One Random Slope for Each Variable\nWe can apply a multivariate model similarly to Chapter 2. In this case, we apply the same principle, but with a covariance matrix of a dimension equal to the number of varying slopes we define. For example, if we want to generate random slopes for \\(i\\) actors in a model with two independent variables \\(X_1\\) and \\(X_2\\), we can define the formula as follows:\n\\[\np(Y_{i} |\\mu_i , \\sigma) \\sim \\text{Normal}(\\mu_i , \\sigma)\n\\]\n\\[\n\\mu_i =   \\alpha_i + \\beta_{1i} X_{1i}  + \\beta_{1i} X_{2i}\n\\]\n\\[\n\\begin{pmatrix}\n\\alpha_{i}\\\\\n\\beta_{1i}\\\\\n\\beta_{2i}\n\\end{pmatrix}\n\\sim \\begin{pmatrix}\n\\sigma_{\\alpha}\\\\\n\\sigma_{\\pi}\\\\\n\\sigma_{\\gamma}\n\\end{pmatrix} \\circ L \\cdot \\begin{pmatrix}\n\\widehat{\\alpha}_{k} \\\\\n\\widehat{\\pi}_{k} \\\\\n\\widehat{\\gamma}_{k}\n\\end{pmatrix}\n\\]\n\\[\n\\sigma_{\\alpha} \\sim Exponential(1)\n\\] _{} Exponential(1) \\[\n\\sigma_{\\gamma} \\sim Exponential(1)\n\\]\n\\[\nL \\sim LKJcorr(2)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#multivariate-random-slopes-on-a-single-variable",
    "href": "14. Varying slopes.html#multivariate-random-slopes-on-a-single-variable",
    "title": "16Â  Varying slopes",
    "section": "16.7 Multivariate Random Slopes on a Single Variable",
    "text": "16.7 Multivariate Random Slopes on a Single Variable\nFor more than two varying effects, we apply the same principle but with a covariance matrix for each varying effect that are summed to generate the varying intercept and slope. For example, if we want to generate random slopes for \\(i\\) actors and \\(k\\) groups, we can define the formula as follows:\n\\[\np(Y_{i} |\\mu_i , \\sigma) \\sim \\text{Normal}(\\mu_i , \\sigma) \\\\\n\\]\n\\[\n\\mu_i =   \\alpha_i + \\beta_{i} X_i\n\\] \\[\n\\alpha_i = \\alpha + \\alpha_{actor[i]} + \\alpha_{group[i]}\n\\] \\[\n\\beta_{i} = \\beta + \\beta_{actor[i]} + \\beta_{group[i]}\n\\]\n\\[\n\\alpha \\sim Normal(0,1)\n\\]\n\\[\n\\beta \\sim Normal(0,1)\n\\]\n\\[\n\\begin{pmatrix}\n\\alpha_{\\text{actor}} \\\\\n\\beta_{\\text{actor}}\n\\end{pmatrix}\n\\sim\n\\begin{pmatrix}\n\\sigma_{\\alpha a} \\\\\n\\sigma_{\\pi a}\n\\end{pmatrix} \\circ L_a \\cdot \\begin{pmatrix}\n\\widehat{\\alpha}_{ka} \\\\\n\\widehat{\\pi}_{ka}\n\\end{pmatrix}\n\\]\n\\[\n\\sigma_{\\alpha a} \\sim Exponential(1)\n\\] \\[\n\\sigma_{\\pi a} \\sim Exponential(1)\n\\] \\[\nL_{a} \\sim LKJcorr(2)\n\\]\n\\[\n\\begin{pmatrix}\n\\alpha_{\\text{group}} \\\\\n\\beta_{\\text{group}}\n\\end{pmatrix}\n\\sim  \n\\begin{pmatrix}\n\\sigma_{\\alpha g} \\\\\n\\sigma_{\\pi g}\n\\end{pmatrix} \\circ L_g \\cdot\n\\begin{pmatrix}\n\\widehat{\\alpha}_{kg} \\\\\n\\widehat{\\pi}_{kg}\n\\end{pmatrix}\n\\]\n\\[\n\\sigma_{\\alpha g} \\sim Exponential(1)\n\\] \\[\n\\sigma_{\\pi g} \\sim Exponential(1)\n\\] \\[\nL_{g} \\sim LKJcorr(2)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#notes",
    "href": "14. Varying slopes.html#notes",
    "title": "16Â  Varying slopes",
    "section": "16.8 Notes",
    "text": "16.8 Notes\n\n\n\n\n\n\nNote\n\n\n\n\nWe can apply interaction terms similarly to Chapter 3.\nWe can apply categorical variables similarly to Chapter 4.\nWe can apply varying slopes with any distribution presented in previous chapters. Below is the formula and the code snippet for a Binomial multivariate model with interaction between two independent variables \\(X_1\\) and \\(X_2\\) and multiple varying effects for each actor and each group\n\n\\[\np(Y_{i} |n , p_i) \\sim \\text{Binomial}(n = 1, p_i) \\\\\n\\]\n\\[\nlogit{p_i}=   \\alpha_i + (\\beta_{1i}  + \\beta_{2i} X_{2i})  X_{1i}\n\\] \\[\n\\alpha_i = \\alpha + \\alpha_{actor[i]} + \\alpha_{group[i]}\n\\] \\[\n\\beta_{1i} = \\beta + \\beta_{1 actor[i]} + \\beta_{ group[i]}\n\\] \\[\n\\beta_{2i} = \\beta + \\beta_{2 actor[i]} + \\beta_{2 group[i]}\n\\]\n\\[\n\\alpha \\sim Normal(0,1)\n\\] \\[\n\\beta \\sim Normal(0,1)\n\\]\n\\[\n\\begin{pmatrix}\n\\alpha_{\\text{actor}} \\\\\n\\beta_{1 \\, \\text{actor}} \\\\\n\\beta_{2 \\, \\text{actor}}\n\\end{pmatrix}\n\\sim  \n\\begin{pmatrix}\n\\sigma_{\\alpha a} \\\\\n\\sigma_{\\pi a} \\\\\n\\sigma_{\\gamma a}\n\\end{pmatrix} \\circ L_a \\cdot\n\\begin{pmatrix}\n\\widehat{\\alpha}_{ka} \\\\\n\\widehat{\\pi}_{ka} \\\\\n\\widehat{\\gamma}_{ka}\n\\end{pmatrix}\n\\]\n\\[\n\\sigma_{\\alpha a} \\sim Exponential(1)\n\\]\n\\[\n\\sigma_{\\pi a} \\sim Exponential(1)\n\\] \\[\n\\sigma_{\\gamma a} \\sim Exponential(1)\n\\] \\[\nL_{a} \\sim LKJcorr(2)\n\\]\n\\[\n\\begin{pmatrix}\n\\alpha_{\\text{group}} \\\\\n\\beta_{1 \\, \\text{group}} \\\\\n\\beta_{2 \\, \\text{group}}\n\\end{pmatrix}\n\\sim  \n\\begin{pmatrix}\n\\sigma_{\\alpha g} \\\\\n\\sigma_{\\pi g} \\\\\n\\sigma_{\\gamma g}\n\\end{pmatrix} \\circ L_g \\cdot\n\\begin{pmatrix}\n\\widehat{\\alpha}_{kg} \\\\\n\\widehat{\\pi}_{kg} \\\\\n\\widehat{\\gamma}_{kg}\n\\end{pmatrix}\n\\]\n\\[\n\\sigma_{\\alpha g} \\sim Exponential(1)\n\\] \\[\n\\sigma_{\\pi g} \\sim Exponential(1)\n\\] \\[\n\\sigma_{\\gamma g} \\sim Exponential(1)\n\\] \\[\nL_{g} \\sim LKJcorr(2)\n\\]\nfrom main import*\n# Setup device------------------------------------------------\nm = bi(platform='cpu')\n# Import data\nm.read_csv(\"../data/chimpanzees.csv\", sep=\";\")\nm.df[\"block_id\"] = m.df.block\nm.df[\"treatment\"] = 1 + m.df.prosoc_left + 2 * m.df.condition\nm.data_to_model(['pulled_left', 'treatment', 'actor', 'block_id'])\n\n\ndef model(tid, actor, block_id, L=None, link=False):\n    # fixed priors\n    g = dist.normal(0, 1, name = 'g', shape = (4,))\n    sigma_actor = dist.exponential(1, name = 'sigma_actor', shape = (4,))\n    L_Rho_actor = dist.lkjcholesky(4, 2, name = \"L_Rho_actor\")\n    sigma_block = dist.exponential(1, name = \"sigma_block\", shape = (4,))\n    L_Rho_block = dist.lkjcholesky(4, 2, name = \"L_Rho_block\")\n\n    # adaptive priors - non-centered\n    z_actor = dist.normal(0, 1, name = \"z_actor\", shape = (4,7))\n    z_block = dist.normal(0, 1, name = \"z_block\", shape = (4,3))\n    alpha = deterministic(\n        \"alpha\", ((sigma_actor[..., None] * L_Rho_actor) @ z_actor).T\n    )\n    beta = deterministic(\n        \"beta\", ((sigma_block[..., None] * L_Rho_block) @ z_block).T\n    )\n\n    logit_p = g[tid] + alpha[actor, tid] + beta[block_id, tid]\n    dist(\"L\", dist.Binomial(logits=logit_p), obs=L)\n\n    # compute ordinary correlation matrixes from Cholesky factors\n    if link:\n        deterministic(\"Rho_actor\", L_Rho_actor @ L_Rho_actor.T)\n        deterministic(\"Rho_block\", L_Rho_block @ L_Rho_block.T)\n        deterministic(\"p\", expit(logit_p))\n\n# Run mcmc ------------------------------------------------\nm.run(model) \n\n# Summary ------------------------------------------------\nm.sampler.print_summary(0.89)",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  },
  {
    "objectID": "14. Varying slopes.html#references",
    "href": "14. Varying slopes.html#references",
    "title": "16Â  Varying slopes",
    "section": "16.9 Reference(s)",
    "text": "16.9 Reference(s)\nMcElreath (2018)\n\n\n\n\nMcElreath, Richard. 2018. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Varying slopes</span>"
    ]
  }
]