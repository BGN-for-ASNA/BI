# Interaction terms
## General Principles
To study relationships between two independent continuous variables and their interaction effect on a dependent variable (e.g., temperature and humidity affecting energy consumption), we can use Regression Analysis with Interaction Terms. In this approach, we extend the simple linear regression model to include an interaction term (a multiplication) between the two continuous variables.

Parallel lines indicate that there is no interaction effect, while different slopes suggest that one might be present. Below is the plot for temperature x humidity. The crossed lines on the graph suggest that there is an interaction effect. The graph shows that energy consumption levels are higher for humidity when the temperature is high. Conversely, energy consumption levels are higher for temperature when humidity is low. 

![](https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2017/10/interactions_plot_categorical.png?w=576&ssl=1)

## Considerations
::: callout-caution 
- We have the same assumptions as for [Regression for continuous variable](1.&#32;Linear&#32;Regression&#32;for&#32;continuous&#32;variable.qmd).

- We wish to model the relationship between independent variable *Y* and dependent variable $X_1$ to vary as a function of dependent variable $X_2$. To do this, we explicitly model the hypothesis that the slope between *Y* and $X_1$ dependsâ€”is conditionalâ€”upon $X_2$.

- For continuous interactions with scaled data, the intercept becomes the [<span style="color:#0D6EFD">grand mean ðŸ›ˆ</span>]{#grandMean} of the outcome variable. 

- The interpretation of estimates is more complex. The estimate of non-interaction terms reflects the expected change in *Y* when $X_1$ increases by one unit, holding $X_2$ constant at its average value. The estimate of interaction terms represents how the effect of $X_1$ on *Y* changes depending on the value of $X_2$, and vice versa, showing how the relationship between the two variables influences the outcome *Y*.

- [<span style="color:#0D6EFD">Triptych ðŸ›ˆ</span>]{#triptych} plots are very handy for understanding the impact of interactions, especially when more than two interactions are present.
  
:::

## Example
Below is example code demonstrating Bayesian regression with an interaction term between two continuous variables using the Bayesian Inference (BI) package. Data consist of three continuous variables (temperature, humidity, energy consumption), and the goal is to estimate the effect of the interaction between temperature and humidity on energy consumption.

::: {.panel-tabset group="language"}
### Python
```python
from main import*

# Setup device------------------------------------------------
m = bi(platform='cpu')

# Import Data & Data Manipulation ------------------------------------------------
m.data('../data/tulips.csv', sep=';') # Import
m.scale(['blooms', 'water', 'shade']) # Scale
m.data_to_model(['blooms', 'water', 'shade']) # Send to model (convert to jax array)

# Define model ------------------------------------------------
def model(blooms,shade, water):
    sigma = dist.exponential(1, name = 'sigma', shape = (1,))
    bws = dist.normal(0, 0.25, name = 'bws', shape = (1,))
    bs = dist.normal(0, 0.25, name = 'bs', shape = (1,))
    bw = dist.normal(0, 0.25, name = 'bw', shape = (1,))
    a = dist.normal(0.5, 0.25, name = 'a', shape = (1,))
    mu = a + bw*water + bs*shade + bws*water*shade
    m.lk("y", dist.normal(mu, sigma), obs=blooms)
    
# Run mcmc ------------------------------------------------
m.run(model) # Optimize model parameters through MCMC sampling

# Summary ------------------------------------------------
m.sampler.print_summary(0.89) # Get posterior distributions

```

### R
```R
library(BI)
m=importBI(platform='cpu')

# Load csv file
m$data(paste(system.file(package = "BI"),"/data/tulips.csv", sep = ''), sep=';')
m$scale(list('blooms', 'water', 'shade')) # Scale
m$data_to_model(list('blooms', 'water', 'shade')) # Send to model (convert to jax array)

# Define model ------------------------------------------------
model <- function(blooms, water,shade){
  # Parameters priors distributions
  alpha = bi.dist.normal( 0.5, 0.25, name = 'a',shape= c(1))
  beta1 = bi.dist.normal( 0,  0.25, name = 'b1',shape= c(1))
  beta2 = bi.dist.normal(  0,  0.25, name = 'b2',shape= c(1))   
  beta_interaction_ = bi.dist.normal(  0, 0.25, name = 'bint',shape= c(1)) 
  sigma = bi.dist.normal(0, 50, name = 's',shape = c(1))
  # Likelihood
  m$lk("y", bi.dist.normal(alpha + beta1*water + beta2*shade + beta_interaction_*water*shade, sigma), obs=blooms)
}

# Run mcmc ------------------------------------------------
m$run(model) # Optimize model parameters through MCMC sampling

# Summary ------------------------------------------------
m$summary() # Get posterior distributions

```
:::

## Mathematical Details
## *Frequentist formulation*
We model the relationship between the input features ($X_1$ and $X_2$) and the target variable ($Y$) using the following equation:
$$
ð‘Œ_i = \alpha + \beta_1 ð‘‹_{1i} + \beta_2 ð‘‹_{2i} + \beta_{interaction} ð‘‹_{1i} ð‘‹_{2i} + \sigma
$$

Where:

- $Y_i$ is the dependent variable for observation *i*.
  
- $\alpha$ is the intercept term.
  
- $X_{1i}$ and $X_{2i}$ are the two values of the independent continuous variables for observation *i*.
  
- $\beta_1$ and $\beta_2$ are the regression coefficients for $X_{1}$ and $X_{2}$, respectively.
  
- $\beta_{interaction}$ is the regression coefficient for the interaction term $(X_{1}  X_{2})$.
  
- $\sigma$ is the error term, assumed to be normally distributed.

In this context, the interaction term $X_{1i} * X_{2i}$ captures the joint effect of $X_{1i}$ and $X_{2i}$ on the target variable $Y_i$.

### *Bayesian formulation*
In the Bayesian formulation, we define each parameter with [<span style="color:#0D6EFD">priors ðŸ›ˆ</span>]{#prior}. We can express the Bayesian regression model accounting for prior distribution as follows:

$$
Y \sim Normal(\alpha +  \beta_1  X_{1i}â€‹ + \beta_2  X_{2i}â€‹â€‹ + \beta_{interaction}  X_1{1i} X_{2i}â€‹ ,  \sigma)
$$

$$
\alpha \sim Normal(0,1)
$$

$$
\beta_1 \sim Normal(0,1)
$$

$$
\beta_2 \sim Normal(0,1)
$$

$$
\beta_{interaction} \sim Normal(0,1)
$$

$$
Ïƒ \sim Exponential(1)
$$

Where:

- $Y_i$ is the dependent variable for observation *i*.
  
- $\alpha$ is the prior distribution for the intercept.
  
- $\beta_1$,  $\beta_2$, and $\beta_{interaction}$ are the prior distributions for the regression coefficients.
  
- $X_{1i}$ and $X_{2i}$ are the two values of the independent continuous variables for observation *i*.
  
- $\sigma$ is the prior distribution for the standard deviation, ensuring it is positive.

## Reference(s)
@mcelreath2018statistical
