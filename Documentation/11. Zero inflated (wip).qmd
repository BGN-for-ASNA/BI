## Zero inflated 
## General Principles
Zero-Inflated Regression models are used when the outcome variable is a count variable with an excess of zero counts. These models combine a count model (e.g., Poisson or Negative Binomial) with a separate model for predicting the probability of excess zeros.


## Considerations
In Bayesian Zero-Inflated regression, we consider uncertainty in the model parameters and provide a full posterior distribution over them. We need to declare prior distributions for _W_{1\pi}, W_{2\pi}, ..., W_{n\pi}_, _W_{1\lambda}, W_{2\lambda}, ..., W_{n\lambda}_, _b_\pi_, and _b_\lambda_.


## Example

Below is an example code snippet demonstrating Bayesian Zero-Inflated Poisson regression using TensorFlow Probability:

```python
from jax.scipy.special import expit
r.seed(42)
from main import*

# Simulated data------------------------------------------------
prob_drink = 0.2  # 20% of days
rate_work = 1     # average 1 manuscript per day

# sample one year of production
N = 365

np.random.seed(365)
drink = np.random.binomial(1, prob_drink, N)
y = (1 - drink) * np.random.poisson(rate_work, N)

# Setup device------------------------------------------------
m = bi(platform='cpu')
m.data_on_model = dict(
    y = jnp.array(y)
)

# Define model ------------------------------------------------
def model(y):
    al = dist.normal( 1, 0.5, name = 'al')
    ap = dist.normal( -1.5, 1,name = 'ap')
    p = expit(ap)
    lambda_ = jnp.exp(al)
    lk("y", ZeroInflatedPoisson(p, lambda_), obs=y)

# Run mcmc ------------------------------------------------
m.run(model) 

# Summary ------------------------------------------------
m.sampler.print_summary(0.89)

```

## Mathematical Details
## *Formula*
We model the relationship between the predictor variables _X_ and the count outcome variable _Y_ using two components:
1. A logistic regression model to predict the probability of an excess zero.
2. A count model (e.g., Poisson or Negative Binomial) to predict the count outcome.

The overall model can be represented as follows:

$$
\begin{aligned}
& \text{logit}(\pi) = \alpha_\pi + \beta_\pi X \\
& \text{log}(\lambda) = \alpha_\lambda + \beta_\lambda X\\
& Y \sim \begin{cases} 
0 & \text{with probability } \pi \\
\text{CountModel}(\lambda) & \text{with probability } (1 - \pi) 
\end{cases}
\end{aligned}
$$

Where:
- $\pi$ is the probability of an excess zero.
- $\lambda$ is the mean rate parameter of the count model.
- $\alpha_\pi$ and $\beta_\pi$  are respectivelly, the intercept and the regression coefficient for the logistic model.
- $\alpha_\lambda$ and $\beta_\lambda$ are respectivelly, the regression coefficient for the  the count model.
- $X$ is the independent variables.

### *Bayesian model*
We can express the Bayesian regression model accounting for prior distribution as follows:

$$
ùëù(ùëå‚à£\lambda) \sim  ZIPoisson(\pi,\lambda)
$$

$$
logit(\pi) = \alpha_\pi + \beta_\pi X
$$

$$
log(\lambda) = \alpha_\lambda + \beta_\lambda X
$$

$$
p(\alpha_\pi) \sim Normal(0,1)
$$

$$
p(\beta_\pi) \sim Normal(0,1)
$$

$$
p(\alpha_\lambda) \sim Normal(0,1)
$$

$$
p(\beta_\lambda) \sim Normal(0,1)
$$

Where:
- $\pi$ is the probability of an excess zero.
- $\lambda$ is the mean rate parameter of the count model.
- $\alpha_\pi$ and $\beta_\pi$  are respectivelly, the intercept and the regression coefficient for the logistic model.
- $\alpha_\lambda$ and $\beta_\lambda$ are respectivelly, the regression coefficient for the  the count model.
- $X$ is the independent variables.

## Reference(s)
@mcelreath2018statistical

